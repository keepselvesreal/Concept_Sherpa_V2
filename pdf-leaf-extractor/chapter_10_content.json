{
  "chapter": "10",
  "title": "Database operations",
  "page_info": {
    "page": 262,
    "title": "Database operations",
    "pattern_matched": "Chapter 10",
    "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
  },
  "leaf_nodes": [
    {
      "text": "- 10.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 82,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.1 Fetching data from the database",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.1 Fetching data from the database (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 83,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.2 Storing data in the database",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.2 Storing data in the database (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 84,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.3 Simple data manipulation",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.3 Simple data manipulation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 85,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.4 Advanced data manipulation",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.4 Advanced data manipulation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 86,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 87,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    }
  ]
}