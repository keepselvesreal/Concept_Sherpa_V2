{
  "pdf_file": "/home/nadle/projects/Knowledge_Sherpa/v2/2022_Data-Oriented Programming_Manning.pdf",
  "total_pages": 426,
  "chapters_found": {
    "1": {
      "page": 32,
      "title": "Complexity of object-oriented programming",
      "pattern_matched": "Chapter 1",
      "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
    },
    "2": {
      "page": 56,
      "title": "Separation between code and data",
      "pattern_matched": "Chapter 2",
      "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
    },
    "3": {
      "page": 76,
      "title": "Basic data manipulation",
      "pattern_matched": "Chapter 3",
      "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
    },
    "4": {
      "page": 102,
      "title": "State management",
      "pattern_matched": "Chapter 4",
      "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
    },
    "5": {
      "page": 126,
      "title": "Basic concurrency control",
      "pattern_matched": "Chapter 5",
      "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
    },
    "6": {
      "page": 152,
      "title": "Unit tests",
      "pattern_matched": "Chapter 6",
      "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
    },
    "7": {
      "page": 176,
      "title": "Basic data validation",
      "pattern_matched": "Chapter 7",
      "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
    },
    "8": {
      "page": 202,
      "title": "Advanced concurrency control",
      "pattern_matched": "Chapter 8",
      "text_preview": "174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do yo"
    },
    "10": {
      "page": 262,
      "title": "Database operations",
      "pattern_matched": "Chapter 10",
      "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
    },
    "12": {
      "page": 303,
      "title": "Advanced data validation",
      "pattern_matched": "Chapter 12",
      "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
    }
  },
  "total_leaf_nodes": 181,
  "leaf_nodes": [
    {
      "text": "- Part1 Introduction content",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "Part1 Introduction (사용자 추가)",
      "raw_line": "- Part1 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 1,
      "accurate_page_range": "30-31",
      "extracted_content": "\n=== Page 30 ===\n2 PART 1 Flexibility\nThe requirements for the Klafim prototype\n Two kinds of library users are members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n The book belongs to a physical library.\nTheo Well, that’s pretty clear.\nNancy How much time would it take for your company to deliver the prototype?\nTheo I think we should be able to deliver within a month. Let’s say Wednesday the\n30th.\nNancy That’s too long. We need it in two weeks!\nTheo That’s tough! Can you cut a feature or two?\nNancy Unfortunately, we cannot cut any feature, but if you like, you can make the\nsearch very basic.\n(Theo really doesn’t want to lose this contract, so he’s willing to work hard and sleep later.)\nTheo I think it should be doable by Wednesday the 16th.\nNancy Perfect!\n\n=== Page 31 ===\nComplexity of object-\noriented programming\nA capricious entrepreneur\nThis chapter covers\n The tendency of OOP to increase system\ncomplexity\n What makes OOP systems hard to understand\n The cost of mixing code and data together into\nobjects\nIn this chapter, we’ll explore why object-oriented programming (OOP) systems tend to\nbe complex. This complexity is not related to the syntax or the semantics of a specific\nOOP language. It is something that is inherent to OOP’s fundamental insight—\nprograms should be composed from objects, which consist of some state, together\nwith methods for accessing and manipulating that state.\nOver the years, OOP ecosystems have alleviated this complexity by adding new\nfeatures to the language (e.g., anonymous classes and anonymous functions) and\nby developing frameworks that hide some of this complexity, providing a simpler\ninterface for developers (e.g., Spring and Jackson in Java). Internally, the frame-\nworks rely on the advanced features of the language such as reflection and custom\nannotations.\n3"
    },
    {
      "text": "- 1.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 2,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.1.0 Introduction (사용자 추가)",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.1.0 Introduction (사용자 추가) (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 3,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.1.1 The design phase",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.1.1 The design phase (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 4,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.1.2 UML 101",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.1.2 UML 101 (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 5,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.1.3 Explaining each piece of the class diagram",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.1.3 Explaining each piece of the class diagram (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 6,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.1.4 The implementation phase",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.1.4 The implementation phase (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 7,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.2.0 Introduction (사용자 추가)",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.2.0 Introduction (사용자 추가) (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 8,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.2.1 Many relations between classes",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.2.1 Many relations between classes (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 9,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.2.2 Unpredictable code behavior",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.2.2 Unpredictable code behavior (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 10,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.2.3 Not trivial data serialization",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.2.3 Not trivial data serialization (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 11,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 1.2.4 Complex class hierarchies",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- 1.2.4 Complex class hierarchies (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 12,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "1 Complexity of object-oriented programming",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 13,
      "chapter_info": {
        "page": 32,
        "title": "Complexity of object-oriented programming",
        "pattern_matched": "Chapter 1",
        "text_preview": "4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased "
      },
      "chapter_sections": {
        "start_page": 32,
        "end_page": 55,
        "content": "\n--- Page 32 ---\n4 CHAPTER 1 Complexity of object-orientedprogramming\nThis chapter is not meant to be read as a critical analysis of OOP. Its purpose is to\nraise your awareness of the tendency towards OOP’s increased complexity as a pro-\ngramming paradigm. Hopefully, it will motivate you to discover a different program-\nming paradigm, where system complexity tends to be reduced. This paradigm is\nknown as data-oriented programming (DOP).\n1.1 OOP design: Classic or classical?\n NOTE Theo, Nancy, and their new project were introduced in the opener for part 1.\nTake a moment to read the opener if you missed it.\nTheo gets back to the office with Nancy’s napkin in his pocket and a lot of anxiety in his\nheart because he knows he has committed to a tough deadline. But he had no choice! Last\nweek, Monica, his boss, told him quite clearly that he had to close the deal with Nancy no\nmatter what.\nAlbatross, where Theo works, is a software consulting company with customers all over\nthe world. It originally had lots of customers among startups. Over the last year, however,\nmany projects were badly managed, and the Startup department lost the trust of its cus-\ntomers. That’s why management moved Theo from the Enterprise department to the\nStartup department as a Senior Tech lead. His job is to close deals and to deliver on time.\n1.1.1 The design phase\nBefore rushing to his laptop to code the system, Theo grabs a sheet of paper, much big-\nger than a napkin, and starts to draw a UML class diagram of the system that will imple-\nment the Klafim prototype. Theo is an object-oriented programmer. For him, there is no\nquestion—every business entity is represented by an object, and every object is made\nfrom a class.\nThe requirements for the Klafim prototype\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There can be several copies of a book.\n A book belongs to a physical library.\nTheo spends some time thinking about the organization of the system. He identifies the\nmain classes for the Klafim Global Library Management System.\n--- Page 33 ---\n1.1 OOP design: Classic or classical? 5\nThe main classes of the library management system\n Library—The central part of the system design.\n Book—A book.\n BookItem—A book can have multiple copies, and each copy is considered as\na book item.\n BookLending—When a book is lent, a book lending object is created.\n Member—A member of the library.\n Librarian—A librarian.\n User—A base class for Librarian and Member.\n Catalog—Contains a list of books.\n Author—A book author.\nThat was the easy part. Now comes the difficult part: the relations between the classes.\nAfter two hours or so, Theo comes up with a first draft of a design for the Global Library\nManagement System. It looks like the diagram in figure 1.1.\n NOTE The design presented here doesn’t pretend to be the smartest OOP design:\nexperienced OOP developers would probably use a couple of design patterns to sug-\ngest a much better design. This design is meant to be naive and by no means covers all\nthe features of the system. It serves two purposes:\n For Theo, the developer, it is rich enough to start coding.\n For me, the author of the book, it is rich enough to illustrate the complexity of a\ntypical OOP system.\nTheo feels proud of himself and of the design diagram he just produced. He definitely\ndeserves a cup of coffee!\nNear the coffee machine, Theo meets Dave, a junior software developer who joined\nAlbatross a couple of weeks ago. Theo and Dave appreciate each other, as Dave’s curiosity\nleads him to ask challenging questions. Meetings near the coffee machine often turn into\ninteresting discussions about programming.\nTheo Hey Dave! How’s it going?\nDave Today? Not great. I’m trying to fix a bug in my code! I can’t understand why\nthe state of my objects always changes. I’ll figure it out though, I’m sure. How’s\nyour day going?\nTheo I just finished the design of a system for a new customer.\nDave Cool! Would it be OK for me to see it? I’m trying to improve my design skills.\nTheo Sure! I have the diagram on my desk. We can take a look now if you like.\n--- Page 34 ---\n6 CHAPTER 1 Complexity of object-orientedprogramming\nC Library\nname : String\naddress : String\nC Catalog\nsearch(searchCriteria, queryStr) : List<Book>\naddBookItem(librarian: Librarian, bookItem: BookItem) : BookItem\n*\n* C Librarian\nC Book\nblockMember(member: Member) : Bool\nid : String unblockMember(member: Member) : Bool\ntitle : String addBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\n*\n*\nC Member\n*\nC Author isBlocked() : Bool\nid : String block() : Bool\nfullName: String unblock() : Bool\nreturnBook(bookLending: BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\n*\nC User\nC BookItem\nid : String\nid : String\nemail : String\nlibId: String\npassword : String\ncheckout(member: Member) : BookLending\nlogin() : Bool\nC BookLending\nid : String\nlendingDate : date *\ndueDate : date\nisLate() : Bool\nreturnBook() : Bool\nFigure 1.1 A class diagram for Klafim’s Global Library Management System\n1.1.2 UML 101\nLatte in hand, Dave follows Theo to his desk. Theo proudly shows Dave his piece of art: the\nUML diagram for the Library Management System (figure 1.1). Dave seems really excited.\nDave Wow! Such a detailed class diagram.\nTheo Yeah. I’m pretty happy with it.\n--- Page 35 ---\n1.1 OOP design: Classic or classical? 7\nDave The thing is that I can never remember the meaning of the different arrows.\nTheo There are four types of arrows in my class diagram: composition, association,\ninheritance, and usage.\nDave What’s the difference between composition and association?\n NOTE Don’t worry if you’re not familiar with OOP jargon. We’re going to leave it\naside in the next chapter.\nTheo It’s all about whether the objects can live without each other. With composi-\ntion, when one object dies, the other one dies too. While in an association rela-\ntion, each object has an independent life.\nTIP In a composition relation, when one object dies, the other one also dies. While\nin an association relation, each object has an independent life cycle.\nIn the class diagram, there are two kinds of composition symbolized by an arrow with\na plain diamond at one edge and an optional star at the other edge. Figure 1.2 shows\nthe relation between:\n A Library that owns a Catalog—A one-to-one composition. If a Library object\ndies, then its Catalog object dies with it.\n A Library that owns many Members—A one-to-many composition. If a Library\nobject dies, then all its Member objects die with it.\nC Library\nname : String * C Member\naddress : String\nFigure 1.2 The two kinds of\nC Catalog composition: one-to-one and\none-to-many. In both cases,\nList<Book> search(searchCriteria, queryStr) when an object dies, the\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\ncomposed object dies with it.\nTIP A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\nDave Do you have association relations in your diagram?\nTheo Take a look at the arrow between Book and Author. It has an empty diamond\nand a star at both edges, so it’s a many-to-many association relation.\nA book can be written by multiple authors, and an author can write multiple books.\nMoreover, Book and Author objects can live independently. The relation between\nbooks and authors is a many-to-many association (figure 1.3).\n--- Page 36 ---\n8 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\ntitle : String\n*\n*\nC Author\nid : String Figure 1.3 Many-to-many association relation:\nfullName: String\neach object lives independently.\nTIP A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\nDave I also see a bunch of dashed arrows in your diagram.\nTheo Dashed arrows are for usage relations: when a class uses a method of another\nclass. Consider, for example, the Librarian::blockMember method. It calls\nMember::block.\nTIP Dashed arrows indicate usage relations (figure 1.4), for instance, when a class\nuses a method of another class.\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember(member: Member)\nC Member\nBool isBlocked()\nBool block()\nBool unblock()\nBool returnBook(bookLending: BookLending) Figure 1.4 Usage relation: a class\nBookLending checkout(bookItem: BookItem) uses a method of another class.\nDave I see. And I guess a plain arrow with an empty triangle, like the one between\nMember and User, represents inheritance.\nTheo Absolutely!\nTIP Plain arrows with empty triangles represent class inheritance (figure 1.5), where\nthe arrow points towards the superclass.\n--- Page 37 ---\n1.1 OOP design: Classic or classical? 9\nCC Member\nisBlocked() : Bool\nblock() : Bool\nunblock() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String Figure 1.5 Inheritance relation: a class\nlogin() : Bool derives from another class.\n1.1.3 Explaining each piece of the class diagram\nDave Thanks for the UML refresher! Now I think I can remember what the different\narrows mean.\nTheo My pleasure. Want to see how it all fits together?\nDave What class should we look at first?\nTheo I think we should start with Library.\nTHE LIBRARY CLASS\nThe Library is the root class of the library system. Figure 1.6 shows the system structure.\nCC Library\nname : String\naddress : String\n*\nC Member\nC Catalog\nBool isBlocked()\nList<Book> search(searchCriteria, queryStr) Bool block()\nBookItem addBookItem(librarian: Librarian, Bool unblock()\nbookItem: BookItem) Bool returnBook(bookLending: BookLending)\nBookLending checkout(bookItem: BookItem)\n*\nCC Librarian\nBool blockMember(member: Member)\nBool unblockMember(member: Member)\nBookItem addBookItem(bookItem: BookItem)\nList<BookLending> getBookLendingsOfMember\n(member: Member)\nFigure 1.6 The Library class\n--- Page 38 ---\n10 CHAPTER 1 Complexity of object-orientedprogramming\nIn terms of code (behavior), a Library object does nothing on its own. It delegates\neverything to the objects it owns. In terms of data, a Library object owns\n Multiple Member objects\n Multiple Librarian objects\n A single Catalog object\n NOTE In this book, we use the terms code and behavior interchangeably.\nLIBRARIAN, MEMBER, AND USER CLASSES\nLibrarian and Member both derive from User. Figure 1.7 shows this relation.\nC Member C Librarian\nisBlocked() : Bool blockMember(member: Member) : Bool\nblock() : Bool unblockMember(member: Member) : Bool\nunblock() : Bool addBookItem(bookItem: BookItem) : BookItem\nreturnBook(bookLending : BookLending) : Bool : Member) :\ncheckout(bookItem: BookItem) : BookLending\nCC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.7 Librarian and Member derive from User.\nThe User class represents a user of the library:\n In terms of data members, it sticks to the bare minimum: it has an id, email,\nand password (with no security and encryption for now).\n In terms of code, it can log in via login.\nThe Member class represents a member of the library:\n It inherits from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Check out a book via checkout.\n– Return a book via returnBook.\n– Block itself via block.\n– Unblock itself via unblock.\n– Answer if it is blocked via isBlocked.\n It owns multiple BookLending objects.\n It uses BookItem in order to implement checkout.\n--- Page 39 ---\n1.1 OOP design: Classic or classical? 11\nThe Librarian class represents a librarian:\n It derives from User.\n In terms of data members, it has nothing more than User.\n In terms of code, it can\n– Block and unblock a Member.\n– List the member’s book lendings via getBookLendings.\n– Add book items to the library via addBookItem.\n It uses Member to implement blockMember, unblockMember, and getBook-\nLendings.\n It uses BookItem to implement checkout.\n It uses BookLending to implement getBookLendings.\nTHE CATALOG CLASS\nThe Catalog class is responsible for the management of the books. Figure 1.8 shows\nthe relation among the Catalog, Librarian, and Book classes. In terms of code, a\nCatalog object can\n Search books via search.\n Add book items to the library via addBookItem.\nC Catalog\nList<Book> search(searchCriteria, queryStr)\nBookItem addBookItem(librarian: Librarian, bookItem: BookItem)\nC Librarian *\nC Book\nBool blockMember(member: Member)\nBool unblockMember(member: Member) id : String\nBookItem addBookItem(bookItem: BookItem) title : String\nList<BookLending> getBookLendingsOfMember (member: Member)\nFigure 1.8 The Catalog class\nA Catalog object uses Librarian in order to implement addBookItem. In terms of\ndata, a Catalog owns multiple Book objects.\nTHE BOOK CLASS\nFigure 1.9 presents the Book class. In terms of data, a Book object\n Should have as its bare minimum an id and a title.\n Is associated with multiple Author objects (a book might have multiple authors).\n Owns multiple BookItem objects, one for each copy of the book.\n--- Page 40 ---\n12 CHAPTER 1 Complexity of object-orientedprogramming\nC Book\nid : String\n*\ntitle : String\n* *\nC BookItem C Author\nid : String id : String\nIibld: String fullName: String\nBookLending checkout(member: Member)\nC BookLending\nid : String\nlendingDate : date\ndueDate : date\nBool isLate()\nBool returnBook() Figure 1.9 The Book class\nTHE BOOKITEM CLASS\nThe BookItem class represents a book copy, and a book could have many copies. In\nterms of data, a BookItem object\n Should have as its bare minimum data for members: an id and a libId (for its\nphysical library ID).\n Owns multiple BookLending objects, one for each time the book is lent.\nIn terms of code, a BookItem object can be checked out via checkout.\n1.1.4 The implementation phase\nAfter this detailed investigation of Theo’s diagrams, Dave lets it sink in as he slowly sips his\ncoffee. He then expresses his admiration to Theo.\nDave Wow! That’s amazing!\nTheo Thank you.\nDave I didn’t realize people were really spending the time to write down their design\nin such detail before coding.\nTheo I always do that. It saves me lot of time during the coding phase.\nDave When will you start coding?\nTheo When I finish my latte.\nTheo grabs his coffee mug and notices that his hot latte has become an iced latte. He was\nso excited to show his class diagram to Dave that he forgot to drink it!\n--- Page 41 ---\n1.2 Sources of complexity 13\n1.2 Sources of complexity\nWhile Theo is getting himself another cup of coffee (a cappuccino this time), I\nwould like to challenge his design. It might look beautiful and clear on the paper,\nbut I claim that this design makes the system hard to understand. It’s not that Theo\npicked the wrong classes or that he misunderstood the relations among the classes.\nIt goes much deeper:\n It’s about the programming paradigm he chose to implement the system.\n It’s about the object-oriented paradigm.\n It’s about the tendency of OOP to increase the complexity of a system.\nTIP OOP has a tendency to create complex systems.\nThroughout this book, the type of complexity I refer to is that which makes systems\nhard to understand as defined in the paper, “Out of the Tar Pit,” by Ben Moseley\nand Peter Marks (2006), available at http://mng.bz/enzq. It has nothing to do with\nthe type of complexity that deals with the amount of resources consumed by a pro-\ngram. Similarly, when I refer to simplicity, I mean not complex (in other words, easy\nto understand).\nKeep in mind that complexity and simplicity (like hard and easy) are not absolute\nbut relative concepts. We can compare the complexity of two systems and determine\nwhether system A is more complex (or simpler) than system B.\n NOTE Complexity in the context of this book means hard to understand.\nAs mentioned in the introduction of this chapter, there are many ways in OOP to\nalleviate complexity. The purpose of this book is not be critical of OOP, but rather\nto present a programming paradigm called data-oriented programming (DOP) that\ntends to build systems that are less complex. In fact, the DOP paradigm is compati-\nble with OOP.\nIf one chooses to build an OOP system that adheres to DOP principles, the system\nwill be less complex. According to DOP, the main sources of complexity in Theo’s sys-\ntem (and of many traditional OOP systems) are that\n Code and data are mixed.\n Objects are mutable.\n Data is locked in objects as members.\n Code is locked into classes as methods.\nThis analysis is similar to what functional programming (FP) thinks about traditional\nOOP. However, as we will see throughout the book, the data approach that DOP takes\nin order to reduce system complexity differs from the FP approach. In appendix A, we\nillustrate how to apply DOP principles both in OOP and in FP styles.\nTIP DOP is compatible both with OOP and FP.\n--- Page 42 ---\n14 CHAPTER 1 Complexity of object-orientedprogramming\nIn the remaining sections of this chapter, we will illustrate each of the previous\naspects, summarized in table 1.1. We’ll look at this in the context of the Klafim project\nand explain in what sense these aspects are a source of complexity.\nTable 1.1 Aspects of OOP and their impact on system complexity\nAspect Impact on complexity\nCode and data are mixed. Classes tend to be involved in many relations.\nObjects are mutable. Extra thinking is needed when reading code.\nObjects are mutable. Explicit synchronization is required on multi-threaded environments.\nData is locked in objects. Data serialization is not trivial.\nCode is locked in classes. Class hierarchies are complex.\n1.2.1 Many relations between classes\nOne way to assess the complexity of a class diagram is to look only at the entities and\ntheir relations, ignoring members and methods, as in figure 1.10. When we design a\nsystem, we have to define the relations between different pieces of code and data.\nThat’s unavoidable.\nC Library\nC Catalog\n* *\nC Book C Librarian\n*\n*\nC Member\n*\nC Author\nC BookItem C User\nFigure 1.10 A class\ndiagram overview for\nC BookLending * Klafim’s Library\nManagement System\nTIP In OOP, code and data are mixed together in classes: data as members and code as\nmethods.\n--- Page 43 ---\n1.2 Sources of complexity 15\nFrom a system analysis perspective, the fact that code and data are mixed together\nmakes the system complex in the sense that entities tend to be involved in many rela-\ntions. In figure 1.11, we take a closer look at the Member class. Member is involved in five\nrelations: two data relations and three code relations.\n Data relations:\n– Library has many Members.\n– Member has many BookLendings.\n Code relations:\n– Member extends User.\n– Librarian uses Member.\n– Member uses BookItem.\nC Librarian\nC Library * C Member\n*\nC User C BookLending C BookItem Figure 1.11 The class Member is\ninvolved in five relations.\nImagine for a moment that we were able, somehow, to split the Member class into two\nseparate entities:\n MemberCode for the code\n MemberData for the data\nInstead of a Member class with five relations, we would have the diagram shown in fig-\nure 1.12 with:\n A MemberCode entity and three relations.\n A MemberData entity and two relations.\nC Library C Librarian\n*\nC MemberData C MemberCode\n*\nC BookLending C User C BookItem Figure 1.12 A class diagram where Member\nis split into code and data entities\n--- Page 44 ---\n16 CHAPTER 1 Complexity of object-orientedprogramming\nThe class diagram where Member is split into MemberCode and MemberData is made of\ntwo independent parts. Each part is easier to understand than the original diagram.\nLet’s split every class of our original class diagram into code and data entities.\nFigure 1.13 shows the resulting diagram. Now the system is made of two indepen-\ndent parts:\n A part that involves only data entities.\n A part that involves only code entities.\nC LibraryData * C LibrarianData C CatalogCode\n*\nC MemberData C CatalogData C LibrarianCode\n*\nC BookData C MemberCode C BookLendingCode C BookItemCode\n*\n* *\nC BookItemData C AuthorData C UserCode C BookItem\n*\nC BookLendingData\nFigure 1.13 A class diagram where every class is split into code and data entities\nTIP A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\nThe resulting system, made up of two independent subsystems, is easier to understand\nthan the original system. The fact that the two subsystems are independent means that\neach subsystem can be understood separately and in any order. The resulting system\nnot simpler by accident; it is a logical consequence of separating code from data.\nTIP A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n1.2.2 Unpredictable code behavior\nYou might be a bit tired after the system-level analysis that we presented in the previ-\nous section. Let’s get refreshed and look at some code.\nTake a look at the code in listing 1.1, where we get the blocked status of a member\nand display it twice. If I tell you that when I called displayBlockedStatusTwice, the\nprogram displayed true on the first console.log call, can you tell me what the pro-\ngram displayed on the second console.log call?\n--- Page 45 ---\n1.2 Sources of complexity 17\nListing1.1 Really simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nvar isBlocked = this.isBlocked;\nconsole.log(isBlocked);\nconsole.log(isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\n“Of course, it displayed true again,” you say. And you are right!\nNow, take a look at a slightly different pseudocode as shown in listing 1.2. Here we\ndisplay, twice, the blocked status of a member without assigning a variable. Same ques-\ntion as before: if I tell you that when I called displayBlockedStatusTwice, the pro-\ngram displayed true on the first console.log call, can you tell me what the program\ndisplayed on the second console.log call?\nListing1.2 Apparently simple code\nclass Member {\nisBlocked;\ndisplayBlockedStatusTwice() {\nconsole.log(this.isBlocked);\nconsole.log(this.isBlocked);\n}\n}\nmember.displayBlockedStatusTwice();\nThe correct answer is...in a single-threaded environment, it displays true, while in a\nmulti-threaded environment, it’s unpredictable. Indeed, in a multi-threaded environ-\nment between the two console.log calls, there could be a context switch that changes\nthe state of the object (e.g., a librarian unblocked the member). In fact, with a slight\nmodification, the same kind of code unpredictability could occur even in a single-\nthreaded environment like JavaScript, when data is modified via asynchronous code\n(see the section about Principle #3 in appendix A). The difference between the two\ncode snippets is that\n In the first listing (listing 1.1), we access a Boolean value twice , which is a prim-\nitive value.\n In the second listing (listing 1.2), we access a member of an object twice.\nTIP When data is mutable, code is unpredictable.\n--- Page 46 ---\n18 CHAPTER 1 Complexity of object-orientedprogramming\nThis unpredictable behavior of the second listing is one of the annoying conse-\nquences of OOP. Unlike primitive types, which are usually immutable, object mem-\nbers are mutable. One way to solve this problem in OOP is to protect sensitive code\nwith concurrency safety mechanisms like mutexes, but that introduces issues like a\nperformance hit and a risk of deadlocks.\nWe will see later in the book that DOP treats every piece of data in the same way:\nboth primitive types and collection types are immutable values. This value treatment for\nall citizens brings serenity to DOP developers’ minds, and more brain cells are avail-\nable to handle the interesting pieces of the applications they build.\nTIP Data immutability brings serenity to DOP developers’ minds.\n1.2.3 Not trivial data serialization\nTheo is really tired, and he falls asleep at his desk. He’s having dream. In his dream, Nancy\nasks him to make Klafim’s Library Management System accessible via a REST API using\nJSON as a transport layer. Theo has to implement a /search endpoint that receives a\nquery in JSON format and returns the results in JSON format. Listing 1.3 shows an input\nexample of the /search endpoint, and listing 1.4 shows an output example of the /search\nendpoint.\nListing1.3 A JSON input of the /search endpoint\n{\n\"searchCriteria\": \"author\",\n\"query\": \"albert\"\n}\nListing1.4 A JSON output of the /search endpoint\n[\n{\n\"title\": \"The world as I see it\",\n\"authors\": [\n{\n\"fullName\": \"Albert Einstein\"\n}\n]\n},\n{\n\"title\": \"The Stranger\",\n\"authors\": [\n{\n\"fullName\": \"Albert Camus\"\n}\n]\n}\n]\n--- Page 47 ---\n1.2 Sources of complexity 19\nTheo would probably implement the /search endpoint by creating three classes simi-\nlarly to what is shown in the following list and in figure 1.14. (Not surprisingly, every-\nthing in OOP has to be wrapped in a class. Right?)\n SearchController is responsible for handling the query.\n SearchQuery converts the JSON query string into data.\n SearchResult converts the search result data into a JSON string.\nC SearchController\nString handle(searchQuery: String)\nC SearchQuery\nC SearchResult\nC Catalog\nsearchCriteria: String\nSearchResult(books: List<Book>)\nList<Book> search(searchCriteria, queryStr) query: String\nString toJSON()\nSearchQuery(jsonString: String)\n* *\nC Book\nid : String\ntitle : String\nFigure 1.14 The class diagram for SearchController\nThe SearchController (see figure 1.14) would have a single handle method with the\nfollowing flow:\n Creates a SearchQuery object from the JSON query string.\n Retrieves searchCriteria and queryStr from the SearchQuery object.\n Calls the search method of the catalog:Catalog with searchCriteria and\nqueryStr and receives books:List<Book>.\n Creates a SearchResult object with books.\n Converts the SearchResult object to a JSON string.\nWhat about other endpoints, for instance, those allowing librarians to add book items\nthrough /add-book-item? Theo would have to repeat the exact same process and cre-\nate three classes:\n AddBookItemController to handle the query\n BookItemQuery to convert the JSON query string into data\n BookItemResult to convert the search result data into a JSON string\nThe code that deals with JSON deserialization that Theo wrote previously in Search-\nQuery would have to be rewritten in BookItemQuery. Same thing for the code that\ndeals with JSON serialization he wrote previously in SearchResult; it would have to be\nrewritten in BookItemResult.\n--- Page 48 ---\n20 CHAPTER 1 Complexity of object-orientedprogramming\nThe bad news is that Theo would have to repeat the same process for every end-\npoint of the system. Each time he encounters a new kind of JSON input or output,\nhe would have to create a new class and write code. Theo’s dream is turning into a\nnightmare!\nSuddenly, his phone rings, next to where he was resting his head on the desk. As Theo\nwakes up, he realizes that Nancy never asked for JSON. It was all a dream...a really bad\ndream!\nTIP In OOP, data serialization is difficult.\nIt’s quite frustrating that handling JSON serialization and deserialization in OOP\nrequires the addition of so many classes and writing so much code—again and again!\nThe frustration grows when you consider that serializing a search query, a book item\nquery, or any query is quite similar. It comes down to\n Going over data fields.\n Concatenating the name of the data fields and the value of the data fields, sepa-\nrated by a comma.\nWhy is such a simple thing so hard to achieve in OOP? In OOP, data has to follow a\nrigid shape defined in classes, which means that data is locked in members. There is\nno simple way to access data generically.\nTIP In OOP, data is locked in classes as members.\nWe will refine later what we mean by generic access to the data, and we will see how\nDOP provides a generic way to handle JSON serialization and deserialization. Until\nthen, you will have to continue suffering. But at least you are starting to become aware\nof this suffering, and you know that it is avoidable.\n NOTE Most OOP programming languages alleviate a bit of the difficulty involved\nin the conversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n1.2.4 Complex class hierarchies\nOne way to avoid writing the same code twice in OOP involves class inheritance. Indeed,\nwhen every requirement of the system is known up front, you design your class hier-\narchy is such a way that classes with common behavior derive from a base class.\nFigure 1.15 shows an example of this pattern that focuses on the part of our class\ndiagram that deals with members and librarians. Both Librarians and Members need\nthe ability to log in, and they inherit this ability from the User class.\nSo far, so good, but when new requirements are introduced after the system is imple-\nmented, it’s a completely different story. Fast forward to Monday, March 29th, at 11:00 AM,\nwhere two days are left before the deadline (Wednesday at midnight).\n--- Page 49 ---\n1.2 Sources of complexity 21\nC Librarian\nblockMember(member: Member) : Bool\nunblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String Figure 1.15 The part of the\npassword : String class diagram that deals with\nlogin() : Bool members and librarians\nNancy calls Theo with an urgent request. Theo is not sure if it’s a dream or reality. He\npinches himself and he can feel the jolt. It’s definitely reality!\nNancy How is the project doing?\nTheo Fine, Nancy. We’re on schedule to meet the deadline. We’re running our last\nround of regression tests now.\nNancy Fantastic! It means we have time for adding a tiny feature to the system, right?\nTheo Depends what you mean by “tiny.”\nNancy We need to add VIP members to the system.\nTheo What do you mean by VIP members?\nNancy VIP members are allowed to add book items to the library by themselves.\nTheo Hmm...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nI’ll ask you the same question Nancy asked Theo: why is adding VIP members to our\nsystem not a tiny task? After all, Theo has already written the code that allows librari-\nans to add book items to the library (it’s in Librarian::addBookItem). What prevents\nhim from reusing this code for VIP members? The reason is that, in OOP, the code is\nlocked into classes as methods.\nTIP In OOP, code is locked into classes.\nVIP members are members that are allowed to add book items to the library by them-\nselves. Theo decomposes the customer requirements into two pieces:\n--- Page 50 ---\n22 CHAPTER 1 Complexity of object-orientedprogramming\n VIP members are library members.\n VIP members are allowed to add book items to the library by themselves.\nTheo then decides that he needs a new class, VIPMember. For the first requirement\n(VIP members are library members), it seems reasonable to make VIPMember derive\nfrom Member. However, handling the second requirement (VIP members are allowed\nto add book items) is more complex. He cannot make a VIPMember derive from\nLibrarian because the relation between VIPMember and Librarian is not linear:\n On one hand, VIP members are like librarians in that they are allowed to add\nbook items.\n On the other hand, VIP members are not like librarians in that they are not\nallowed to block members or list the books lent to a member.\nThe problem is that the code that adds book items is locked in the Librarian class.\nThere is no way for the VIPMember class to use this code.\nFigure 1.16 shows one possible solution that makes the code of Librarian::add-\nBookItem available to both Librarian and VIPMember classes. Here are the changes to\nthe previous class diagram:\n A base class UserWithBookItemRight extends User.\n addBookItem moves from Librarian to UserWithBookItemRight.\n Both VIPMember and Librarian extend UserWithBookItemRight.\nC Librarian\nblockMember(member: Member) : Bool C VIPMember\nunblockMember(member: Member) : Bool\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC Member\nCC UserWithBookItemRight\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool addBookItem(bookItem: BookItem) : BookItem\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.16 A class diagram for a system with VIP members\nIt wasn’t easy, but Theo manages to handle the change on time, thanks to an all nighter\ncoding on his laptop. He was even able to add new tests to the system and run the regres-\nsion tests again. However, he was so excited that he didn’t pay attention to the diamond\n--- Page 51 ---\n1.2 Sources of complexity 23\nproblem VIPMember introduced in his class diagram due to multiple inheritance: VIPMember\nextends both Member and UserWithBookItemRight, which both extend User.\nWednesday, March 31, at 10:00 AM (14 hours before the deadline), Theo calls Nancy to\ntell her the good news.\nTheo We were able to add VIP members to the system on time, Nancy.\nNancy Fantastic! I told you it was a tiny feature.\nTheo Yeah, well...\nNancy Look, I was going to call you anyway. I just finished a meeting with my business\npartner, and we realized that we need another tiny feature before the launch.\nWill you be able to handle it before the deadline?\nTheo Again, it depends what you mean by “tiny.”\nNancy We need to add Super members to the system.\nTheo What do you mean by Super members?\nNancy Super members are allowed to list the books lent to other members.\nTheo Err...\nNancy What?\nTheo That’s not a tiny change!\nNancy Why?\nAs with VIP members, adding Super members to the system requires changes to Theo’s\nclass hierarchy. Figure 1.17 shows the solution Theo has in mind.\nC Librarian\nC VIPMember C SuperMember\ngetBookLendingsOfMember(member: Member) : List<BookLending>\nCC UserWithBlockMemberRight\nCC UserWithBookItemRight\nblockMember(member: Member) : Bool\naddBookItem(bookItem: BookItem) : BookItem\nunblockMember(member: Member) : Bool\nCC Member\nisBlocked() : Bool\nreturnBook(bookLending : BookLending) : Bool\ncheckout(bookItem: BookItem) : BookLending\nC User\nid : String\nemail : String\npassword : String\nlogin() : Bool\nFigure 1.17 A class diagram for a system with Super and VIP members\nThe addition of Super members has made the system really complex. Theo suddenly\nnotices that he has three diamonds in his class diagram—not gemstones but three “Deadly\n--- Page 52 ---\n24 CHAPTER 1 Complexity of object-orientedprogramming\nDiamonds of Death” as OOP developers sometimes name the ambiguity that arises when a\nclass D inherits from two classes B and C, where both inherit from class A!\nHe tries to avoid the diamonds by transforming the User class into an interface and\nusing the composition over inheritance design pattern. But with the stress of the deadline\nlooming, he isn’t able to use all of his brain cells. In fact, the system has become so com-\nplex, he’s unable to deliver the system by the deadline. Theo tells himself that he should\nhave used composition instead of class inheritance. But, it’s too late now.\nTIP In OOP, prefer composition over class inheritance.\nAt 10:00 PM, two hours before the deadline, Theo calls Nancy to explain the situation.\nTheo Look Nancy, we really did our best, but we won’t be able to add Super mem-\nbers to the system before the deadline.\nNancy No worries, my business partner and I decided to omit this feature for now.\nWe’ll add it later.\nWith mixed feelings of anger and relief, Theo stops pacing around his office. He realizes\nhe will be spending tonight in his own bed, rather than plowing away on his computer at\nthe office. That should make his wife happy.\nTheo I guess that means we’re ready for the launch tomorrow morning.\nNancy Yes. We’ll offer this new product for a month or so, and if we get good market\ntraction, we’ll move forward with a bigger project.\nTheo Cool. Let’s be in touch in a month then. Good luck on the launch!\nSummary\n Complexity in the context of this book means hard to understand.\n We use the terms code and behavior interchangeably.\n DOP stands for data-oriented programming.\n OOP stands for object-oriented programming.\n FP stands for functional programming.\n In a composition relation, when one object dies, the other one also dies.\n A composition relation is represented by a plain diamond at one edge and an\noptional star at the other edge.\n In an association relation, each object has an independent life cycle.\n A many-to-many association relation is represented by an empty diamond and a\nstar at both edges.\n Dashed arrows indicate a usage relation; for instance, when a class uses a method\nof another class.\n Plain arrows with empty triangles represent class inheritance, where the arrow\npoints towards the superclass.\n The design presented in this chapter doesn’t pretend to be the smartest OOP\ndesign. Experienced OOP developers would probably use a couple of design\npatterns and suggest a much better diagram.\n--- Page 53 ---\nSummary 25\n Traditional OOP systems tend to increase system complexity, in the sense that\nOOP systems are hard to understand.\n In traditional OOP, code and data are mixed together in classes: data as mem-\nbers and code as methods.\n In traditional OOP, data is mutable.\n The root cause of the increase in complexity is related to the mixing of code\nand data together into objects.\n When code and data are mixed, classes tend to be involved in many relations.\n When objects are mutable, extra thinking is required in order to understand\nhow the code behaves.\n When objects are mutable, explicit synchronization mechanisms are required\non multi-threaded environments.\n When data is locked in objects, data serialization is not trivial.\n When code is locked in classes, class hierarchies tend to be complex.\n A system where every class is split into two independent parts, code and data, is\nsimpler than a system where code and data are mixed.\n A system made of multiple simple independent parts is less complex than a sys-\ntem made of a single complex part.\n When data is mutable, code is unpredictable.\n A strategic use of design patterns can help mitigate complexity in traditional\nOOP to some degree.\n Data immutability brings serenity to DOP developers’ minds.\n Most OOP programming languages alleviate slightly the difficulty involved the\nconversion from and to JSON. It either involves reflection, which is definitely a\ncomplex thing, or code verbosity.\n In traditional OOP, data serialization is difficult.\n In traditional OOP, data is locked in classes as members.\n In traditional OOP, code is locked into classes.\n DOP reduces complexity by rethinking data.\n DOP is compatible both with OOP and FP.\n--- Page 54 ---\nSeparation between\ncode and data\nA whole new world\nThis chapter covers\n The benefits of separating code from data\n Designing a system where code and data are\nseparate\n Implementing a system that respects the\nseparation between code and data\nThe first insight of DOP is that we can decrease the complexity of our systems by\nseparating code from data. Indeed, when code is separated from data, our systems\nare made of two main pieces that can be thought about separately: data entities and\ncode modules. This chapter is a deep dive in the first principle of DOP (summa-\nrized in figure 2.1).\nPRINCIPLE #1 Separate code from data such that the code resides in functions,\nwhose behavior doesn’t depend on data that is somehow encapsulated in the func-\ntion’s context.\n26\n--- Page 55 ---\n2.1 The two parts of a DOP system 27\nStateless (static)\nFunctions\nData asfirst argument\nCode modules\nUsage\nRelations\nNo inheritance\nSeparate code from data\nOnly members\nData entities No code\nAssociation\nRelations\nComposition\nFigure 2.1 DOP principle #1 summarized: Separate code from data.\nIn this chapter, we’ll illustrate the separation between code and data in the context of\nKlafim’s Library Management System that we introduced in chapter 1. We’ll also unveil\nthe benefits that this separation brings to the system:\n The system is simple. It is easy to understand.\n The system is flexible and extensible. Quite often, it requires no design changes to\nadapt to changing requirements.\nThis chapter focuses on the design of the code in a system where code and data are\nseparate. In the next chapter, we’ll focus on the design of the data. As we progress in\nthe book, we’ll discover other benefits of separating code from data.\n2.1 The two parts of a DOP system\nWhile Theo is driving home after delivering the prototype, he asks himself whether the\nKlafim project was a success or not. Sure, he was able to satisfy the customer, but it was\nmore luck than brains. He wouldn’t have made it on time if Nancy had decided to keep\nthe Super members feature. Why was it so complicated to add tiny features to the system?\nWhy was the system he built so complex? He thought there should be a way to build more\nflexible systems!\nThe next morning, Theo asks on Hacker News and on Reddit for ways to reduce system\ncomplexity and build flexible systems. Some folks mention using different programming\nlanguages, while others talk about advanced design patterns. Finally, Theo’s attention gets\ncaptured by a comment from a user named Joe. He mentions data-oriented programming and\nclaims that its main goal is to reduce system complexity. Theo has never heard this term\nbefore. Out of curiosity, he decides to contact Joe by email. What a coincidence! Joe lives\nin San Francisco too. Theo invites him to a meeting in his office.\nJoe is a 40-year-old developer. He was a Java developer for nearly a decade before adopt-\ning Clojure around 7 years ago. When Theo tells Joe about the Library Management System",
        "sections_found": []
      },
      "accurate_page_range": "32-55"
    },
    {
      "text": "- 2.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- 2.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 14,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- 2.1 The two parts of a DOP system",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- 2.1 The two parts of a DOP system (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 15,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- 2.2 Data entities",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- 2.2 Data entities (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 16,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- 2.3 Code modules",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- 2.3 Code modules (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 17,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- 2.4 DOP systems are easy to understand",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- 2.4 DOP systems are easy to understand (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 18,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- 2.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- 2.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 19,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- 2.5 DOP systems are flexible",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- 2.5 DOP systems are flexible (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 20,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "2 Separation between code and data",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 21,
      "chapter_info": {
        "page": 56,
        "title": "Separation between code and data",
        "pattern_matched": "Chapter 2",
        "text_preview": "28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his te"
      },
      "chapter_sections": {
        "start_page": 56,
        "end_page": 75,
        "content": "\n--- Page 56 ---\n28 CHAPTER 2 Separation between code and data\nhe designed and built, and about his struggles to adapt to changing requirements, Joe is\nnot surprised.\nJoe tells Theo that the systems that he and his team have built in Clojure over the last 7\nyears are less complex and more flexible than the systems he used to build in Java. Accord-\ning to Joe, the systems they build now tend to be much simpler because they follow the\nprinciples of DOP.\nTheo I’ve never heard of data-oriented programming. Is it a new concept?\nJoe Yes and no. Most of the foundational ideas of data-oriented programming, or\nDOP as we like to call it, are well known to programmers as best practices. The\nnovelty of DOP, however, is that it combines best practices into a cohesive\nwhole.\nTheo That’s a bit abstract for me. Can you give me an example?\nJoe Sure! Take, for instance, the first insight of DOP. It’s about the relations between\ncode and data.\nTheo You mean the encapsulation of data in objects?\nJoe Actually, DOP is against data encapsulation.\nTheo Why is that? I thought data encapsulation was a positive programming paradigm.\nJoe Data encapsulation has both merits and drawbacks. Think about the way you\ndesigned the Library Management System. According to DOP, the main cause\nof complexity and inflexibility in systems is that code and data are mixed\ntogether in objects.\nTIP DOP is against data encapsulation.\nTheo It sounds similar to what I’ve heard about functional programming. So, if I\nwant to adopt DOP, do I need to get rid of object-oriented programming and\nlearn functional programming?\nJoe No, DOP principles are language-agnostic. They can be applied in both object-\noriented and functional programming languages.\nTheo That’s a relief! I was afraid that you were going to teach me about monads,\nalgebraic data types, and higher order functions.\nJoe No, none of that is required in DOP.\nTIP DOP principles are language-agnostic.\nTheo What does the separation between code and data look like in DOP then?\nJoe Data is represented by data entities that only hold members. Code is aggre-\ngated into modules where all functions are stateless.\nTheo What do you mean by stateless functions?\nJoe Instead of having the state encapsulated in the object, the data entity is passed\nas an argument.\nTheo I don’t get that.\nJoe Here, let’s make it visual.\n--- Page 57 ---\n2.2 Data entities 29\nJoe steps up to a whiteboard and quickly draws a diagram to illustrate his comment. Fig-\nure 2.2 shows Joe’s drawing.\nCode modules Stateless functions\nSeparate code from data\nData entities Only members\nFigure 2.2 The separation between code and data\nTheo It’s still not clear.\nJoe It will become clearer when I show you how it looks in the context of your\nLibrary Management System.\nTheo OK. Shall we start with code or with data?\nJoe Well, it’s data-oriented programming, so let’s start with data.\n2.2 Data entities\nIn DOP, we start the design process by discovering the data entities of our system.\nHere’s what Joe and Theo have to say about data entities.\nJoe What are the data entities of your system?\nTheo What do you mean by data entities?\nJoe I mean the parts of your system that hold information.\n NOTE Data entities are the parts of your system that hold information.\nTheo Well, it’s a Library Management System, so we have books and members.\nJoe Of course, but there are more. One way to discover the data entities of a system\nis to look for nouns and noun phrases in the requirements of the system.\nTheo looks at Nancy’s requirement napkin. He highlights the nouns and noun phrases\nthat seem to represent data entities.\nHighlighting terms in the requirements that correspond to data entities\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n--- Page 58 ---\n30 CHAPTER 2 Separation between code and data\nJoe Excellent. Can you see a natural way to group these entities?\nTheo Not sure, but it seems to me that users, members, and librarians form one\ngroup, whereas books, authors, and book copies form another group.\nJoe Sounds good to me. What would you call each group?\nTheo Probably user management for the first group and catalog for the second\ngroup.\nThe data entities of the system organized in a nested list\n The catalog data\n– Data about books\n– Data about authors\n– Data about book items\n– Data about book lendings\n The user management data\n– Data about users\n– Data about members\n– Data about librarians\nTheo I’m not sure about the relations between books and authors. Should it be asso-\nciation or composition?\nJoe Don’t worry too much about the details for the moment. We’ll refine our data\nentity design later. For now, let’s visualize the two groups in a mind map.\nTheo and Joe confer for a bit. Figure 2.3 shows the mind map they come up with.\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 2.3 The data entities of the\nsystem organized in a mind map\n--- Page 59 ---\n2.3 Code modules 31\nThe most precise way to visualize the data entities of a DOP system is to draw a data\nentity diagram with different arrows for association and composition. We will come\nback to data entity diagrams later.\nTIP Discover the data entities of your system and then sort them into high-level\ngroups, either as a nested list or as a mind map.\nWe will dive deeper into the design and representation of data entities in the next\nchapter. For now, let’s simplify things and say that the data of our library system is\nmade of two high-level groups: user management and catalog.\n2.3 Code modules\nThe second step of the design process in DOP is to define the code modules. Let’s lis-\nten in on Joe and Theo again.\nJoe Now that you have identified the data entities of your system and have\narranged them into high-level groups, it’s time to think about the code part of\nyour system.\nTheo What do you mean by the code part?\nJoe One way to think about that is to identity the functionality of your system.\nTheo looks again at Nancy’s requirements. This time he highlights the verb phrases that\nrepresent functionality.\nHighlighting terms in the requirements that correspond to functionality\n There are two kinds of users: library members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\nIn addition, it’s obvious to Theo that members can also return a book. Moreover, there\nshould be a way to detect whether a user is a librarian or not. He adds those to the require-\nments and then lists the functionality of the system.\nThe functionality of the library system\n Search for a book.\n Add a book item.\n Block a member.\n--- Page 60 ---\n32 CHAPTER 2 Separation between code and data\n(continued)\n Unblock a member.\n Log a user into the system.\n List the books currently lent to a member.\n Borrow a book.\n Return a book.\n Check whether a user is a librarian.\nJoe Excellent! Now, tell me what functionality needs to be exposed to the outside\nworld?\nTheo What do you mean by exposed to the outside world?\nJoe Imagine that the Library Management System exposes an API over HTTP.\nWhat functionality would be exposed by the HTTP endpoints?\nTheo Well, all system functionality would be exposed except checking to see if a user\nis a librarian.\nJoe OK. Now give each exposed function a short name and gather them together\nin a module box called Library.\nThat takes Theo less than a minute. Figure 2.4 shows the module that contains the\nexposed functions of the library devised by Theo.\nC Library\nsearchBook()\naddBookItem()\nblockMember()\nunblockMember()\ngetBookLendings() Figure 2.4 The Library module\ncheckoutBook() contains the exposed functions of the\nreturnBook() Library Management System.\nTIP The first step in designing the code part of a DOP system is to aggregate the\nexposed functions into a single module.\nJoe Beautiful! You just created your first code module.\nTheo To me it looks like a class. What’s the difference between a module and a class?\nJoe A module is an aggregation of functions. In OOP, a module is represented\nbya class, but in other programming languages, it might be a package or a\nnamespace.\nTheo I see.\nJoe The important thing about DOP code modules is that they contain only state-\nless functions.\nTheo You mean like static methods in Java?\nJoe Yes, and the classes of these static methods should not have any data members.\n--- Page 61 ---\n2.3 Code modules 33\nTheo So, how do the functions know what piece of information they operate on?\nJoe Easy. We pass that as the first argument to the function.\nTheo OK. Can you give me an example?\nJoe, biting his nails, takes a look at the list of functions of the Library module in figure 2.4.\nHe spots a likely candidate.\nJoe Let’s take, for example, getBookLendings. In classic OOP, what would its\narguments be?\nTheo A librarian ID and a member ID.\nJoe So, in traditional OOP, getBookLendings would be a method of a Library\nclass that receives two arguments: librarianId and memberId.\nTheo Yep.\nJoe Now comes the subtle part. In DOP, getBookLendings is part of the Library\nmodule, and it receives the LibraryData as an argument.\nTheo Could you show me what you mean?\nJoe Sure.\nJoe goes over to Theo’s keyboard and starts typing. He enters an example of what a class\nmethod looks like in OOP:\nclass Library {\ncatalog\nuserManagement\ngetBookLendings(userId, memberId) {\n// accesses library state via this.catalog and this.userManagement\n}\n}\nTheo Right! The method accesses the state of the object (in our case, the library\ndata) via this.\nJoe Would you say that the object’s state is an argument of the object’s methods?\nTheo I’d say that the object’s state is an implicit argument to the object’s methods.\nTIP In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\nJoe Well, in DOP, we pass data as an explicit argument. The signature of getBook-\nLendings would look like this.\nListing2.1 The signature of getBookLendings\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\n}\n}\n--- Page 62 ---\n34 CHAPTER 2 Separation between code and data\nJoe The state of the library is stored in libraryData, and libraryData is passed\nto the getBookLendings static method as an explicit argument.\nTheo Is that a general rule?\nJoe Absolutely! The same rule applies to the other functions of the Library mod-\nule and to other modules as well. All of the modules are stateless—they receive\nthe library data that they manipulate as an argument.\nTIP In DOP, functions of a code module are stateless. They receive the data that they\nmanipulate as an explicit argument, which is usually the first argument.\n NOTE A module is an aggregation of functions. In DOP, the module functions are\nstateless.\nTheo It reminds me of Python and the way the self argument appears in method\nsignatures. Here, let me show you an example.\nListing2.2 A Python object as an explicit argument in method signatures\nclass Library:\ncatalog = {}\nuserManagement = {}\ndef getBookLendings(self, userId, memberId):\n# accesses library state via self.catalog and self.userManagement\nJoe Indeed, but the difference I’m talking about is much deeper than a syntax\nchange. It’s about the fact that data lives outside the modules.\nTheo I got that. As you said, module functions are stateless.\nJoe Exactly! Would you like to try and apply this principle across the whole\nLibrary module?\nTheo Sure.\nTheo refines the design of the Library module by including the details about the func-\ntions’ arguments. He presents the diagram in figure 2.5 to Joe.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId) Figure 2.5 The Library module\nreturnBook(libraryData, userId, bookItemId)\nwith the functions’ arguments\nJoe Perfect. Now, we’re ready to tackle the high-level design of our system.\nTheo What’s a high-level design in DOP?\n--- Page 63 ---\n2.3 Code modules 35\nJoe A high-level design in DOP is the definition of modules and the interaction\nbetween them.\nTheo I see. Are there any guidelines to help me define the modules?\nJoe Definitely. The high-level modules of the system correspond to the high-level\ndata entities.\nTheo You mean the data entities that appear in the data mind map?\nJoe Exactly!\nTheo looks again at the data mind map (figure 2.6). He focuses on the high-level data enti-\nties library, catalog, and user management. This means that in the system, besides the\nLibrary module, we have two high-level modules:\n The Catalog module deals with catalog data.\n The UserManagement module deals with user management data.\nCatalog\nLibrary data Figure 2.6 A mind map of the high-\nlevel data entities of the Library\nUser management\nManagement System\nTheo then draws the high-level design of the Library Management System with the Catalog\nand UserManagement modules. Figure 2.7 shows the addition of these modules, where:\n Functions of Catalog receive catalogData as their first argument.\n Functions of UserManagement receive userManagementData as their first argument.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.7 The modules of the Library Management System with their functions’ arguments\n--- Page 64 ---\n36 CHAPTER 2 Separation between code and data\nIt’s not 100% clear for Theo at this point how the data entities get passed between mod-\nules. For the moment, he thinks of libraryData as a class with two members:\n catalog holds the catalog data.\n userManagement holds the user management data.\nTheo also sees that the functions of Library share a common pattern. (Later on in this\nchapter, we’ll see the code for some functions of the Library module.)\n They receive libraryData as an argument.\n They pass libraryData.catalog to the functions of Catalog.\n They pass libraryData.userManagement to the functions of UserManagement.\nTIP The high-level modules of a DOP system correspond to the high-level data enti-\nties.\n2.4 DOP systems are easy to understand\nTheo takes a look at the two diagrams that represent the high-level design of his system:\n The data entities in the data mind map in figure 2.8\n The code modules in the module diagram in figure 2.9\nA bit perplexed, Theo asks Joe:\nTheo I’m not sure that this system is better than a traditional OOP system where\nobjects encapsulate data.\nJoe The main benefit of a DOP system over a traditional OOP system is that it’s eas-\nier to understand.\nTheo What makes it easier to understand?\nJoe The fact that the system is split cleanly into code modules and data entities.\nTheo How does that help?\nJoe When you try to understand the data entities of the system, you don’t have to\nthink about the details of the code that manipulates the data entities.\nTheo So, when I look at the data mind map of my Library Management System, I can\nunderstand it on its own?\nJoe Exactly, and similarly, when you try to understand the code modules of the sys-\ntem, you don’t have to think about the details of the data entities manipulated\nby the code. There is a clear separation of concerns between the code and the\ndata.\nTheo looks again at the data mind map in figure 2.8. He has kind of an Aha! moment:\nData lives on its own!\n NOTE A DOP system is easier to understand because the system is split into two\nparts: data entities and code modules.\n--- Page 65 ---\n2.4 DOP systems are easy to understand 37\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nFigure 2.8 A data mind map of the\nLibrarians\nLibrary Management System\nNow, Theo looks at the module diagram in figure 2.9. He feels a bit confused and asks Joe\nfor clarification:\n On one hand, the module diagram looks similar to the class diagrams from classic\nOOP, boxes for classes and arrows for relations between classes.\n On the other hand, the code module diagram looks much simpler than the class\ndiagrams from classic OOP, but he cannot explain why.\nC Library\nsearchBook(libraryData, searchQuery)\naddBookItem(libraryData, bookItemInfo)\nblockMember(libraryData, memberId)\nunblockMember(libraryData, memberId)\nlogin(libraryData, loginInfo)\ngetBookLendings(libraryData, userId)\ncheckoutBook(libraryData, userId, bookItemId)\nreturnBook(libraryData, userId, bookItemId)\nC Catalog\nC UserManagement\nsearchBook(catalogData, searchQuery)\nblockMember(userManagementData, memberId)\naddBookItem(catalogData, bookItemInfo)\nunblockMember(userManagementData, memberId)\ncheckoutBook(catalogData, bookItemId)\nlogin(userManagementData, loginInfo)\nreturnBook(catalogData, bookItemId)\nisLibrarian(userManagementData, userId)\ngetBookLendings(catalogData, userId)\nFigure 2.9 The modules of the Library Management System with the function arguments\nTheo The module diagram seems much simpler than the class diagrams I am used to\nin OOP. I feel it, but I can’t put it into words.\nJoe The reason is that module diagrams have constraints.\n--- Page 66 ---\n38 CHAPTER 2 Separation between code and data\nTheo What kind of constraints?\nJoe Constraints on the functions we saw before. All the functions are static (or\nstateless), but there’s also constraints on the relations between the modules.\nTIP All the functions in a DOP module are stateless.\nTheo In what way are the relations between modules constrained?\nJoe There is a single kind of relation between DOP modules—the usage relation. A\nmodule uses code from another module. There’s no association, no composi-\ntion, and no inheritance between modules. That’s what makes a DOP module\ndiagram easy to understand.\nTheo I understand why there is no association and no composition between DOP\nmodules. After all, association and composition are data relations. But why no\ninheritance relation? Does that mean that DOP is against polymorphism?\nJoe That’s a great question! The quick answer is that in DOP, we achieve polymor-\nphism with a different mechanism than class inheritance. We will talk about it\nsome day.\n NOTE For a discussion of polymorphism in DOP, see chapter 13.\nTheo Now, you’ve piqued my curiosity. I thought inheritance was the only way to\nachieve polymorphism.\nTheo looks again at the module diagram in figure 2.9. Now he not only feels that this dia-\ngram is simpler than traditional OOP class diagrams, he understands why it’s simpler: all\nthe functions are static, and all the relations between modules are of type usage. Table 2.1\nsummarizes Theo’s perception.\nTIP The only kind of relation between DOP modules is the usage relation.\nTable 2.1 What makes each part of a DOP system easy to understand\nSystem part Constraint on entities Constraints on relations\nData entities Members only (no code) Association and composition\nCode modules Stateless functions (no members) Usage (no inheritance)\nTIP Each part of a DOP system is easy to understand because it provides constraints.\n2.5 DOP systems are flexible\nTheo I see how a sharp separation between code and data makes DOP systems easier\nto understand than classic OOP systems. But what about adapting to changes\nin requirements?\nJoe Another benefit of DOP systems is that it is easy to extend them and to adapt to\nchanging requirements.\n--- Page 67 ---\n2.5 DOP systems are flexible 39\nTheo I remember that, when Nancy asked me to add Super members and VIP mem-\nbers to the system, it was hard to adapt my OOP system. I had to introduce a\nfew base classes, and the class hierarchy became really complex.\nJoe I know exactly what you mean. I’ve experienced the same kind of struggle so\nmany times. Describe the changes in the requirements for Super members and\nVIP members, and I’m quite sure that you’ll see how easy it would be to extend\nyour DOP system.\nThe requirements for Super members and VIP members\n Super members are members that are allowed to list the book lendings to\nother members.\n VIP members are members that are allowed to add book items to the library.\nTheo opens his IDE and starts to code the getBookLendings function of the Library\nmodule (see listing 2.3), first without addressing the requirements for Super members.\nTheo remembers what Joe told him about module functions in DOP:\n Functions are stateless.\n Functions receive the data they manipulate as their first argument.\nIn terms of functionality, getBookLendings has two parts:\n Checks that the user is a librarian.\n Retrieves the book lendings from the catalog.\nBasically, the code of getBookLendings has two parts as well:\n Calls the isLibrarian function from the UserManagement module and passes it\nthe UserManagementData.\n Calls the getBookLendings function from the Catalog module and passes it the\nCatalogData.\nListing2.3 Getting the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\n}\ngeneric data collections.\n--- Page 68 ---\n40 CHAPTER 2 Separation between code and data\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nIt’s Theo’s first piece of DOP code and passing around all those data objects—library-\nData, libraryData.userManagement, and libraryData.catalog—feels a bit awkward.\nBut he did it! Joe looks at Theo’s code and seems satisfied.\nJoe Now, how would you adapt your code to Super members?\nTheo I would add a function isSuperMember to the UserManagement module and\ncall it from Library.getBookLendings.\nJoe Exactly! It’s as simple as that.\nTheo types the code on his laptop so that he can show it to Joe. Here’s how Theo adapts\nhis code for Super members.\nListing2.4 Allowing Super members to get the book lendings of a member\nclass Library {\nstatic getBookLendings(libraryData, userId, memberId) {\nif(Usermanagement.isLibrarian(libraryData.userManagement, userId) ||\nUsermanagement.isSuperMember(libraryData.userManagement, userId)) {\nreturn Catalog.getBookLendings(libraryData.catalog, memberId);\n} else {\nthrow \"Not allowed to get book lendings\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isSuperMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic getBookLendings(catalogData, memberId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto query data with generic\n}\ndata collections.\nNow, the awkward feeling caused by passing around all those data objects is dominated by\na feeling of relief. Adapting to this change in requirements takes only a few lines of code\nand requires no changes in the system design. Once again, Joe seems satisfied.\nTIP DOP systems are flexible. Quite often they adapt to changing requirements with-\nout changing the system design.\n--- Page 69 ---\n2.5 DOP systems are flexible 41\nTheo starts coding addBookItem. He looks at the signature of Library.addBookItem,\nand the meaning of the third argument bookItemInfo isn’t clear to him. He asks Joe for\nclarification.\nListing2.5 The signature of Library.addBookItem\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\n}\n}\nTheo What is bookItemInfo?\nJoe Let’s call it the book item information. Imagine we have a way to represent this\ninformation in a data entity named bookItemInfo.\nTheo You mean an object?\nJoe For now, it’s OK to think about bookItemInfo as an object. Later on, I will\nshow you how to we represent data in DOP.\nBesides this subtlety about how the book item information is represented by book-\nItemInfo, the code for Library.addBookItem in listing 2.6 is quite similar to the code\nTheo wrote for Library.getBookLendings in listing 2.4. Once again, Theo is amazed by\nthe fact that adding support for VIP members requires no design change.\nListing2.6 Allowing VIP members to add a book item to the library\nclass Library {\nstatic addBookItem(libraryData, userId, bookItemInfo) {\nif(UserManagement.isLibrarian(libraryData.userManagement, userId) ||\nUserManagement.isVIPMember(libraryData.userManagement, userId)) {\nreturn Catalog.addBookItem(libraryData.catalog, bookItemInfo);\n} else {\nthrow \"Not allowed to add a book item\";\nThere are other\n}\nways to manage\n}\nerrors.\n}\nclass UserManagement {\nstatic isLibrarian(userManagementData, userId) {\n// will be implemented later\nIn chapter 3, we will see how\n}\nto manage permissions with\nstatic isVIPMember(userManagementData, userId) {\ngeneric data collections.\n// will be implemented later\n}\n}\nclass Catalog {\nstatic addBookItem(catalogData, memberId) {\n// will be implemented later\nIn chapter 4, we will see how\n}\nto manage state of the system\n}\nwith immutable data.\n--- Page 70 ---\n42 CHAPTER 2 Separation between code and data\nTheo It takes a big mindset shift to learn how to separate code from data!\nJoe What was the most challenging thing to accept?\nTheo The fact that data is not encapsulated in objects.\nJoe It was the same for me when I switched from OOP to DOP.\nNow it’s time to eat! Theo takes Joe for lunch at Simple, a nice, small restaurant near the\noffice.\nSummary\n DOP principles are language-agnostic.\n DOP principle #1 is to separate code from data.\n The separation between code and data in DOP systems makes them simpler\n(easier to understand) than traditional OOP systems.\n Data entities are the parts of your system that hold information.\n DOP is against data encapsulation.\n The more flexible a system is, the easier it is to adapt to changing requirements.\n The separation between code and data in DOP systems makes them more flexi-\nble than traditional OOP systems.\n When code is separated from data, we have the freedom to design code and\ndata in isolation.\n We represent data as data entities.\n We discover the data entities of our system and sort them into high-level groups,\neither as a nested list or as a mind map.\n A DOP system is easier to understand than a traditional OOP system because\nthe system is split into two parts: data entities and code modules.\n In DOP, a code module is an aggregation of stateless functions.\n DOP systems are flexible. Quite often they adapt to changing requirements\nwithout changing the system design.\n In traditional OOP, the state of the object is an implicit argument to the meth-\nods of the object.\n Stateless functions receive data they manipulate as an explicit argument.\n The high-level modules of a DOP system correspond to high-level data entities.\n The only kind of relation between code modules is the usage relation.\n The only kinds of relation between data entities are the association and the compo-\nsition relation.\n For a discussion of polymorphism in DOP, see chapter 13.\n--- Page 71 ---\nBasic data manipulation\nMeditation and programming\nThis chapter covers\n Representing records with string maps to improve\nflexibility\n Manipulating data with generic functions\n Accessing each piece of information via its\ninformation path\n Gaining JSON serialization for free\nAfter learning why and how to separate code from data in the previous chapter,\nlet’s talk about data on its own. In contrast to traditional OOP, where system design\ntends to involve a rigid class hierarchy, DOP prescribes that we represent our data\nmodel as a flexible combination of maps and arrays (or lists), where we can access\neach piece of information via an information path. This chapter is a deep dive into\nthe second principle of DOP.\nPRINCIPLE #2 Represent data entities with generic data structures.\n43\n--- Page 72 ---\n44 CHAPTER 3 Basic data manipulation\nWe increase system flexibility when we represent records as string maps and not as\nobjects instantiated from classes. This liberates data from the rigidity of a class-based sys-\ntem. Data becomes a first-class citizen powered by generic functions to add, remove, or\nrename fields.\n NOTE We refer to maps that have strings as keys as string maps.\nThe dependency between the code that manipulates data and the data is a weak\ndependency. The code only needs to know the keys of specific fields in the record it\nwants to manipulate. The code doesn’t even need to know about all the keys in the\nrecord, only the ones relevant to it. In this chapter, we’ll deal only with data query.\nWe’ll discuss managing changes in system state in the next chapter.\n3.1 Designing a data model\nDuring lunch at Simple, Theo and Joe don’t talk about programming. Instead, they start\ngetting to know each other on a personal level. Theo discovers that Joe is married to Kay,\nwho has just opened her creative therapy practice after many years of studying various\nfields related to well-being. Neriah, their 14-year-old son, is passionate about drones, whereas\nAurelia, their 12-year-old daughter, plays the transverse flute.\nJoe tells Theo that he’s been practicing meditation for 10 years. Meditation, he says, has\ntaught him how to break away from being continually lost in a “storm thought” (especially\nnegative thoughts, which can be the source of great suffering) to achieve a more direct\nrelationship with reality. The more he learns to experience reality as it is, the calmer his\nmind. When he first started to practice meditation, it was sometimes difficult and even\nweird, but by persevering, he has increased his feeling of well-being with each passing year.\nWhen they’re back at the office, Joe tells Theo that his next step in their DOP journey\nwill be about data models. This includes data representation.\nJoe When we design the data part of our system, we’re free to do it in isolation.\nTheo What do you mean by isolation?\nJoe I mean that you don’t have to bother with code, only data.\nTheo Oh, right. I remember you telling me how that makes a DOP system simpler\nthan OOP. Separation of concerns is a design principle I’m used to in OOP.\nJoe Indeed.\nTheo And, when we think about data, the only relations we have to think about are\nassociation and composition.\nJoe Correct.\nTheo Will the data model design be significantly different than the data model I’m\nused to designing as an OOP developer?\nJoe Not so much.\nTheo OK. Let me see if I can draw a DOP-style data entity diagram.\nTheo takes a look at the data mind map that he drew earlier in the morning. He then\ndraws the diagram in figure 3.1.\nHe refines the details of the fields of each data entity and the kind of relations between\nentities. Figure 3.2 shows the result of this redefined data entity diagram.\n--- Page 73 ---\n3.1 Designing a data model 45\nBooks\nAuthors\nCatalog\nBook items\nLibrary data Book lendings\nUsers\nUser management Members\nLibrarians Figure 3.1 A data mind map of\nthe Library Management System\nCC Library\nname: String\naddress: String\nCC Catalog CC UserManagement\n* * *\nCC Book CC Librarian CC Member\nemail: String email: String\ntitle : String\npassword: String password: String\npublicationYear: Number\n*\nISBN: String\npublisher: String\n* *\nCC Author CC BookLending\nname: String lendingDate: String\nCC BookItem\n* libld: String\npurchaseDate: String\nFigure 3.2 A data model of the Library Management System\n--- Page 74 ---\n46 CHAPTER 3 Basic data manipulation\nJoe The next step is to be more explicit about the relations between entities.\nTheo What do you mean?\nJoe For example, in your entity diagram, Book and Author are connected by a\nmany-to-many association relation. How is this relation going to be repre-\nsented in your program?\nTheo In the Book entity, there will be a collection of author IDs, and in the Author\nentity, there will be a collection of book IDs.\nJoe Sounds good. And what will the book ID be?\nTheo The book ISBN.\n NOTE The International Standard Book Number (ISBN) is a numeric commercial\nbook identifier that is intended to be unique.\nJoe And where will you hold the index that enables you to retrieve a Book from its\nISBN?\nTheo In the Catalog because the catalog holds a bookByISBN index.\nJoe What about author ID?\nTheo Author ID is the author name in lowercase and with dashes instead of white\nspaces (assuming that we don’t have two authors with the same name).\nJoe And I guess that you also hold the author index in the Catalog?\nTheo Exactly!\nJoe Excellent. You’ve been 100% explicit about the relation between Book and\nAuthor. I’ll ask you to do the same with the other relations of the system.\nIt’s quite easy for Theo to do, as he has done that so many times as an OOP developer. Fig-\nure 3.3 provides the detailed entity diagram of Theo’s system.\n NOTE By positional collection, we mean a collection where the elements are in order\n(like a list or an array). By index, we mean a collection where the elements are accessi-\nble via a key (like a hash map or a dictionary).\nThe Catalog entity contains two indexes:\n booksByIsbn—The keys are book ISBNs, and the values are Book entities. Its type is\nnoted as {Book}.\n authorsById—The keys are author IDs, and the values are Author entities. Its type\nis noted as {Author}.\nInside a Book entity, we have authors, which is a positional collection of author IDs of type\n[String]. Inside an Author entity, we have books, which is a collection of book IDs of\ntype [String].\n NOTE For the notation for collections and index types, a positional collection of\nStrings is noted as [String]. An index of Books is noted as {Book}. In the context of\na data model, the index keys are always strings.\n--- Page 75 ---\n3.1 Designing a data model 47\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: UserManagement\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian\nCC Book i n d a : m S e tr : i n S g tring email: String CC Me * mber\ntitle : String encryptedPassword: String\nbookIsbns: [String] email: String\npublicationYear: Number\nencryptedPassword: String\nisbn: String *\nisBlocked: Boolean\nauthorIds: [String]\nbookLendings: [BookLending]\nbookItems: [BookItem] *\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.3 Library management relation model. Dashed lines (e.g., between Book and Author) denote\nindirect relations, [String] denotes a positional collection of strings, and {Book} denotes an index of\nBooks.\nThere is a dashed line between Book and Author, which means that the relation between\nBook and Author is indirect. To access the collection of Author entities from a Book entity,\nwe’ll use the authorById index defined in the Catalog entity.\nJoe I like your data entity diagram.\nTheo Thank you.\nJoe Can you tell me what the three kinds of data aggregations are in your diagram\n(and, in fact, in any data entity diagram)?\nTheo Let’s see...we have positional collections like authors in Book. We have\nindexes like booksByIsbn in Catalog. I can’t find the third one.\nJoe The third kind of data aggregation is what we’ve called, until now, an “entity”\n(like Library, Catalog, Book, etc.), and the common term for entity in com-\nputer science is record.",
        "sections_found": []
      },
      "accurate_page_range": "56-75"
    },
    {
      "text": "- 3.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "3 Basic data manipulation",
      "raw_line": "- 3.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 22,
      "chapter_info": {
        "page": 76,
        "title": "Basic data manipulation",
        "pattern_matched": "Chapter 3",
        "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
      },
      "chapter_sections": {
        "start_page": 76,
        "end_page": 101,
        "content": "\n--- Page 76 ---\n48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to say that a data entity diagram consists only of records, positional\ncollections, and indexes?\nJoe That’s correct. Can you make a similar statement about the relations between\nentities?\nTheo The relations in a data entity diagram are either composition (solid line with a\nfull diamond) or association (dashed line with an empty diamond). Both types\nof relations can be either one-to-one, one-to-many, or many-to-many.\nJoe Excellent!\nTIP A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes. The relation between records is either composition or\nassociation.\n3.2 Representing records as maps\nSo far, we’ve illustrated the benefits we gain from the separation between code and\ndata at a high-system level. There’s a separation of concerns between code and data,\nand each part has clear constraints:\n Code consists of static functions that receive data as an explicit argument.\n Data entities are modeled as records, and the relations between records are\nrepresented by positional collections and indexes.\nNow comes the question of the representation of the data. DOP has nothing special\ntosay about collections and indexes. However, it’s strongly opinionated about the\nrepresentation of records: records should be represented by generic data structures\nsuch as maps.\nThis applies to both OOP and FP languages. In dynamically-typed languages like\nJavaScript, Python, and Ruby, data representation feels natural. While in statically-\ntyped languages like Java and C#, it is a bit more cumbersome.\nTheo I’m really curious to know how we represent positional collections, indexes,\nand records in DOP.\nJoe Let’s start with positional collections. DOP has nothing special to say about the\nrepresentation of collections. They can be linked lists, arrays, vectors, sets, or\nother collections best suited for the use case.\nTheo It’s like in OOP.\nJoe Right! For now, to keep things simple, we’ll use arrays to represent positional\ncollections.\nTheo What about indexes?\nJoe Indexes are represented as homogeneous string maps.\nTheo What do you mean by a homogeneous map?\n--- Page 77 ---\n3.2 Representing records as maps 49\nJoe I mean that all the values of the map are of the same kind. For example, in a\nBook index, all the values are Book, and in an author index, all the values are\nAuthor, and so forth.\nTheo Again, it’s like in OOP.\n NOTE A homogeneous map is a map where all the values are of the same type. A hetero-\ngeneous map is a map where the values are of different types.\nJoe Now, here’s the big surprise. In DOP, records are represented as maps, more\nprecisely, heterogeneous string maps.\nJoe goes to the whiteboard and begins to draw. When he’s finished, he shows Theo the dia-\ngram in figure 3.4.\nRecord Heterogeneous map\nLinked list\nArray\nData representation Collection\nSet\nVector\nFigure 3.4 The building blocks\nIndex Homogeneous map\nof data representation\nTheo stays silent for a while. He is shocked to hear that the data entities of a system can be\nrepresented as a generic data structure, where the field names and value types are not\nspecified in a class. Then, Theo asks Joe:\nTheo What are the benefits of this folly?\nJoe Flexibility and genericity.\nTheo Could you explain, please?\nJoe I’ll explain in a moment, but before that, I’d like to show you what an instance\nof a record in a DOP system looks like.\nTheo OK.\nJoe Let’s take as an example, Watchmen, by Alan Moore and Dave Gibbons, which is\nmy favorite graphic novel. This masterpiece was published in 1987. I’m going\nto assume that, in a physical library, there are two copies of this book, whose ID\nis nyc-central-lib, and that one of the two copies is currently out. Here’s\nhow I’d represent the Book record for Watchmen in DOP.\nJoe comes closer to Theo’s laptop. He opens a text editor (not an IDE!) and types the Book\nrecord for Theo.\n--- Page 78 ---\n50 CHAPTER 3 Basic data manipulation\nListing3.1 An instance of a Book record represented as a map\n{\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\nTheo looks at the laptop screen. He has a question.\nTheo How am I supposed to instantiate the Book record for Watchmen programmat-\nically?\nJoe It depends on the facilities that your programming language offers to instantiate\nmaps. With dynamic languages like JavaScript, Ruby, or Python, it’s straight-\nforward, because we can use literals for maps and arrays. Here, let me show\nyou how.\nJoe jots down the JavaScript code that creates an instance of a Book record, which rep-\nresents as a map in JavaScript. He shows the code to Theo.\nListing3.2 A Book record represented as a map in JavaScript\nvar watchmenBook = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n--- Page 79 ---\n3.2 Representing records as maps 51\nTheo And, if I’m in Java?\nJoe It’s a bit more tedious, but still doable with the immutable Map and List static\nfactory methods.\n NOTE See “Creating Immutable Lists, Sets, and Maps” at http://mng.bz/voGm for\nmore information on this Java core library.\nJoe types the Java code to create an instance of a Book record represented as a map. He\nshows Theo the Java code.\nListing3.3 A Book record represented as a map in Java\nMap watchmen = Map.of(\n\"isbn\", \"978-1779501127\",\n\"title\", \"Watchmen\",\n\"publicationYear\", 1987,\n\"authors\", List.of(\"alan-moore\", \"dave-gibbons\"),\n\"bookItems\", List.of(\nMap.of(\n\"id\", \"book-item-1\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", true\n),\nMap.of (\n\"id\", \"book-item-2\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", false\n)\n)\n);\nTIP In DOP, we represent a record as a heterogeneous string map.\nTheo I’d definitely prefer to create a Book record using a Book class and a BookItem\nclass.\nTheo opens his IDE. He types the JavaScript code to represent a Book record as an instance\nof a Book class.\nListing3.4 A Book record as an instance of a Book class in JavaScript\nclass Book {\nisbn;\ntitle;\npublicationYear;\nauthors;\nbookItems;\nconstructor(isbn, title, publicationYear, authors, bookItems) {\nthis.isbn = isbn;\nthis.title = title;\nthis.publicationYear = publicationYear;\nthis.authors = authors;\nthis.bookItems = bookItems;\n--- Page 80 ---\n52 CHAPTER 3 Basic data manipulation\n}\n}\nclass BookItem {\nid;\nlibId;\nisLent;\nconstructor(id, libId, isLent) {\nthis.id = id;\nthis.libId = libId;\nthis.isLent = isLent;\n}\n}\nvar watchmenBook = new Book(\"978-1779501127\",\n\"Watchmen\",\n1987,\n[\"alan-moore\", \"dave-gibbons\"],\n[new BookItem(\"book-item-1\", \"nyc-central-lib\", true),\nnew BookItem(\"book-item-2\", \"nyc-central-lib\", false)]);\nJoe Theo, why do you prefer classes over maps for representing records?\nTheo It makes the data shape of the record part of my program. As a result, the IDE\ncan auto-complete field names, and errors are caught at compile time.\nJoe Fair enough. Can I show you some drawbacks for this approach?\nTheo Sure.\nJoe Imagine that you want to display the information about a book in the context\nof search results. In that case, instead of author IDs, you want to display\nauthor names, and you don’t need the book item information. How would\nyou handle that?\nTheo I’d create a class BookInSearchResults without a bookItems member and\nwith an authorNames member instead of the authorIds member of the Book\nclass. Also, I would need to write a copy constructor that receives a Book object.\nJoe In classic OOP, the fact that data is instantiated only via classes brings safety.\nBut this safety comes at the cost of flexibility.\nTIP There’s a tradeoff between flexibility and safety in a data model.\nTheo So, how can it be different?\nJoe In the DOP approach, where records are represented as maps, we don’t need\nto create a class for each variation of the data. We’re free to add, remove, and\nrename record fields dynamically. Our data model is flexible.\nTheo Interesting!\nTIP In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\nJoe Now, let me talk about genericity. How would you serialize the content of a\nBook object to JSON?\n--- Page 81 ---\n3.2 Representing records as maps 53\nTIP In DOP, records are manipulated with generic functions.\nTheo Oh no! I remember that while working on the Klafim prototype, I had a night-\nmare about JSON serialization when I was developing the first version of the\nLibrary Management System.\nJoe Well, in DOP, serializing a record to JSON is super easy.\nTheo Does it require the usage of reflection in order to go over the fields of the\nrecord like the Gson Java library does?\n NOTE See https://github.com/google/gson for more information on Gson.\nJoe Not at all! Remember that in DOP, a record is nothing more than data. We can\nwrite a generic JSON serialization function that works with any record. It can\nbe a Book, an Author, a BookItem, or anything else.\nTheo Amazing!\nTIP In DOP, you get JSON serialization for free.\nJoe Actually, as I’ll show you in a moment, lots of data manipulation stuff can be\ndone using generic functions.\nTheo Are the generic functions part of the language?\nJoe It depends on the functions and on the language. For example, JavaScript pro-\nvides a JSON serialization function called JSON.stringify out of the box, but\nnone for omitting multiple keys or for renaming keys.\nTheo That’s annoying.\nJoe Not so much; there are third-party libraries that provide data-manipulation facil-\nities. A popular data manipulation library in the JavaScript ecosystem is Lodash.\n NOTE See https://lodash.com/ to find out more about Lodash.\nTheo What about other languages?\nJoe Lodash has been ported to Java, C#, Python, and Ruby. Let me bookmark some\nsites for you.\nJoe bookmarks these sites for Theo:\n https://javalibs.com/artifact/com.github.javadev/underscore-lodash for Java\n https://www.nuget.org/packages/lodash/ for C#\n https://github.com/dgilland/pydash for Python\n https://rudash-website.now.sh/ for Ruby\n NOTE Throughout the book, we use Lodash to show how to manipulate data with\ngeneric functions, but there is nothing special about Lodash. The exact same approach\ncould be implemented via other data manipulation libraries or custom code.\nTheo Cool!\nJoe Actually, Lodash and its rich set of data manipulation functions can be ported\nto any language. That’s why it’s so beneficial to represent records as maps.\n--- Page 82 ---\n54 CHAPTER 3 Basic data manipulation\nTIP DOP compromises on data safety to gain flexibility and genericity.\nAt the whiteboard, Joe quickly sketches the tradeoffs (see table 3.1).\nTable 3.1 The tradeoff among safety, flexibility, and genericity\nOOP DOP\nSafety High Low\nFlexibility Low High\nGenericity Low High\n3.3 Manipulating data with generic functions\nJoe Now let me show you how to manipulate data in DOP with generic functions.\nTheo Yes, I’m quite curious to see how you’ll implement the search functionality of\nthe Library Management System.\nJoe OK. First, let’s instantiate a Catalog record for the catalog data of a library,\nwhere we have a single book, Watchmen.\nJoe instantiates a Catalog record according to Theo’s data model in figure 3.3. Here’s\nwhat Joe shows to Theo.\nListing3.5 A Catalog record\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n--- Page 83 ---\n3.3 Manipulating data with generic functions 55\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\nTheo I see the two indexes we talked about, booksByIsbn and authorsById. How\ndo you differentiate a record from an index in DOP?\nJoe In an entity diagram, there’s a clear distinction between records and indexes.\nBut in our code, both are plain data.\nTheo I guess that’s why this approach is called data-oriented programming.\nJoe See how straightforward it is to visualize any part of the system data inside a\nprogram? The reason is that data is represented as data!\nTIP In DOP, data is represented as data.\nTheo That sounds like a lapalissade.1\nJoe Oh, does it? I’m not so sure! In OOP, data is usually represented by objects,\nwhich makes it more challenging to visualize data inside a program.\nTIP In DOP, we can visualize any part of the system data.\nTheo How would you retrieve the title of a specific book from the catalog data?\nJoe Great question! In fact, in a DOP system, every piece of information has an\ninformation path from which we can retrieve the information.\nTheo Information path?\nJoe For example, the information path to the title of the Watchmen book in the\ncatalog is [\"booksByIsbn\", \"978-1779501127\", \"title\"].\nTheo Ah, I see. So, is an information path sort of like a file path, but that names in\nan information path correspond to nested entities?\nJoe You’re exactly right. And once we have the path of a piece of information, we\ncan retrieve the information with Lodash’s _.get function.\nJoe types a few characters on Theo’s laptop. Theo is amazed at how little code is needed to\nget the book title.\nListing3.6 Retrieving the title of a book from its information path\n_.get(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"])\n// → \"Watchmen\"\nTheo Neat. I wonder how hard it would be to implement a function like _.get\nmyself.\n1 A lapalissade is an obvious truth—a truism or tautology—that produces a comical effect.\n--- Page 84 ---\n56 CHAPTER 3 Basic data manipulation\nAfter a few minutes of trial and error, Theo is able to produce his implementation. He\nshows Joe the code.\nListing3.7 Custom implementation of get\nfunction get(m, path) {\nvar res = m;\nfor(var i = 0; i < path.length; i++) {\nWe could use\nvar key = path[i];\nforEach instead\nres = res[key];\nof a for loop.\n}\nreturn res;\n}\nAfter testing Theo’s implementation of get, Joe compliments Theo. He’s grateful that\nTheo is catching on so quickly.\nListing3.8 Testing the custom implementation of get\nget(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nJoe Well done!\nTheo I wonder if a function like _.get works smoothly in a statically-typed language\nlike Java?\nJoe It depends on whether you only need to pass the value around or to access the\nvalue concretely.\nTheo I don’t follow.\nJoe Imagine that once you get the title of a book, you want to convert the string\ninto an uppercase string. You need to do a static cast to String, right? Here,\nlet me show you an example that casts a field value to a string, then we can\nmanipulate it as a string.\nListing3.9 Casting a field value to a string\n((String)watchmen.get(\"title\")).toUpperCase()\nTheo That makes sense. The values of the map are of different types, so the compiler\ndeclares it as a Map<String,Object>. The information of the type of the field\nis lost.\nJoe It’s a bit annoying, but quite often our code just passes the data around. In that\ncase, we don’t have to deal with static casting. Moreover, in a language like C#,\nwhen using the dynamic data type, type casting can be avoided.2,3\n2 See http://mng.bz/4jo5 for the C# documentation on the built-in reference to dynamic types.\n3 See appendix A for details about dynamic fields and type casting in C#.\n--- Page 85 ---\n3.3 Manipulating data with generic functions 57\nTIP In statically-typed languages, we sometimes need to statically cast the field values.\nTheo What about performance?\nJoe In most programming languages, maps are quite efficient. Accessing a field\nin a map is slightly slower than accessing a class member. Usually, it’s not\nsignificant.\nTIP There’s no significant performance hit for accessing a field in a map instead of as\na class member.\nTheo Let’s get back to this idea of information path. It works in OOP too. I could\naccess the title of the Watchmen book with catalogData.booksByIsbn[\"978-\n1779501127\"].title. I’d use class members for record fields and strings for\nindex keys.\nJoe There’s a fundamental difference, though. When records are represented as\nmaps, the information can be retrieved via its information path using a generic\nfunction like _.get. But when records are represented as objects, you need to\nwrite specific code for each type of information path.\nTheo What do you mean by specific code? What’s specific in catalogData.books-\nByIsbn[\"978-1779501127\"].title?\nJoe In a statically-typed language like Java, you’d need to import the class defini-\ntions for Catalog and Book.\nTheo And, in a dynamically-typed language like JavaScript...?\nJoe Even in JavaScript, when you represent records with objects instantiated from\nclasses, you can’t easily write a function that receives a path as an argument\nand display the information that corresponds to this path. You would have to\nwrite specific code for each kind of path. You’d access class members with dot\nnotation and map fields with bracket notation.\nTheo Would you say that in DOP, the information path is a first-class citizen?\nJoe Absolutely! The information path can be stored in a variable and passed as an\nargument to a function.\nTIP In DOP, you can retrieve every piece of information via a path and a generic\nfunction.\nJoe goes to the whiteboard. He draws a diagram like that in figure 3.5, which shows the\ncatalog data as a tree.\nJoe You see, Theo, each piece of information is accessible via a path made of\nstrings and integers. For example, the path of Alan Moore’s first book is\n[\"catalog\", \"authorsById\", \"alan-moore\", \"bookIsbns\", 0].\n--- Page 86 ---\n58 CHAPTER 3 Basic data manipulation\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 3.5 The catalog data as a tree\n3.4 Calculating search results\nTheo Interesting. I’m starting to feel the power of expression of DOP!\nJoe Wait, that’s just the beginning. Let me show you how simple it is to write code\nthat retrieves book information and displays it in search results. Can you tell\nme exactly what information has to appear in the search results?\nTheo Searching for book information should return isbn, title, and author-\nNames.\nJoe And what would a BookInfo record look like for Watchmen?\nTheo quickly enters the code on his laptop. He then shows it to Joe.\nListing3.10 A BookInfo record for Watchmen in the context of search result\n{\n\"title\": \"Watchmen\",\n\"isbn\": \"978-1779501127\",\n\"authorNames\": [\n\"Alan Moore\",\n\"Dave Gibbons\",\n]\n}\n--- Page 87 ---\n3.4 Calculating search results 59\nJoe Now I’ll show you step by step how to write a function that returns search\nresults matching a title in JSON format. I’ll use generic data manipulation\nfunctions from Lodash.\nTheo I’m ready!\nJoe Let’s start with an authorNames function that calculates the author names of a\nBook record by looking at the authorsById index. Could you tell me what’s\nthe information path for the name of an author whose ID is authorId?\nTheo It’s [\"authorsById\", authorId, \"name\"].\nJoe Now, let me show you how to retrieve the name of several authors using _.map.\nJoe types the code to map the author IDs to the author names. Theo nonchalantly peeks\nover Joe’s shoulder.\nListing3.11 Mapping author IDs to author names\n_.map([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\nTheo What’s this _.map function? It smells like functional programming! You said I\nwouldn’t have to learn FP to implement DOP!\nJoe No need to learn functional programming in order to use _.map, which is a\nfunction that transforms the values of a collection. You can implement it with\na simple for loop.\nTheo spends a couple of minutes in front of his computer figuring out how to implement\n_.map. Now he’s got it!\nListing3.12 Custom implementation of map\nfunction map(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nres[i] = f(coll[i]);\nforEach instead\n}\nof a for loop.\nreturn res;\n}\nAfter testing Theo’s implementation of map, Joe shows Theo the test. Joe again compli-\nments Theo.\nListing3.13 Testing the custom implementation of map\nmap([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\n--- Page 88 ---\n60 CHAPTER 3 Basic data manipulation\nJoe Well done!\nTheo You were right! It wasn’t hard.\nJoe Now, let’s implement authorNames using _.map.\nIt takes a few minutes for Theo to come up with the implementation of authorNames.\nWhen he’s finished, he turns his laptop to Joe.\nListing3.14 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nJoe We also need a bookInfo function that converts a Book record into a Book-\nInfo record. Let me show you the code for that.\nListing3.15 Converting a Book record into a BookInfo record\nfunction bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": authorNames(catalogData, book)\n};\nThere’s no need to create\nreturn bookInfo;\na class for bookInfo.\n}\nTheo Looking at the code, I see that a BookInfo record has three fields: title,\nisbn, and authorNames. Is there a way to get this information without looking\nat the code?\nJoe You can either add it to the data entity diagram or write it in the documenta-\ntion of the bookInfo function, or both.\nTheo I have to get used to the idea that in DOP, the record field information is not\npart of the program.\nJoe Indeed, it’s not part of the program, but it gives us a lot of flexibility.\nTheo Is there any way for me to have my cake and eat it too?\nJoe Yes, and someday I’ll show you how to make record field information part of a\nDOP program (see chapters 7 and 12).\nTheo Sounds intriguing!\nJoe Now that we have all the pieces in place, we can write our searchBooksBy-\nTitle function, which returns the book information about the books that\nmatch the query. First, we find the Book records that match the query with\n_.filter and then we transform each Book record into a BookInfo record\nwith _.map and bookInfo.\n--- Page 89 ---\n3.4 Calculating search results 61\nListing3.16 Searching books that match a query\nfunction searchBooksByTitle(catalogData, query) {\nvar allBooks = _.values(_.get(catalogData, \"booksByIsbn\"));\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\nThe includes JavaScript\n});\nfunction checks whether\na string includes a string\nvar bookInfos = _.map(matchingBooks, function(book) { as a substring.\nreturn bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\nTheo You’re using Lodash functions without any explanation again!\nJoe Sorry about that. I am so used to basic data manipulation functions that I con-\nsider them as part of the language. What functions are new to you?\nTheo _.values and _.filter\nJoe Well, _.values returns a collection made of the values of a map, and _.filter\nreturns a collection made of the values that satisfy a predicate.\nTheo _.values seems trivial. Let me try to implement _.filter.\nThe implementation of _.filter takes a bit more time. Eventually, Theo manages to get\nit right, then he is able to test it.\nListing3.17 Custom implementation of filter\nfunction filter(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nif(f(coll[i])) {\nforEach instead\nres.push(coll[i]);\nof a for loop.\n}\n}\nreturn res;\n}\nListing3.18 Testing the custom implementation of filter\nfilter([\"Watchmen\", \"Batman\"], function (title) {\nreturn title.includes(\"Watch\");\n});\n// → [\"Watchmen\"]\nTheo To me, it’s a bit weird that to access the title of a book record, I need to write\n_.get(book, \"title\"). I’d expect it to be book.title in dot notation or\nbook[\"title\"] in bracket notation.\nJoe Remember that book is a record that’s not represented as an object. It’s a map.\nIndeed, in JavaScript, you can write _.get(book, \"title\"), book.title, or\nbook[\"title\"]. But I prefer to use Lodash’s _.get function. In some lan-\nguages, the dot and the bracket notations might not work on maps.\n--- Page 90 ---\n62 CHAPTER 3 Basic data manipulation\nTheo Being language-agnostic has a price!\nJoe Right, would you like to test searchBooksByTitle?\nTheo Absolutely! Let me call searchBooksByTitle to search the books whose title\ncontain the string Watch.\nListing3.19 Testing searchBooksByTitle\nsearchBooksByTitle(catalogData, \"Wat\");\n//[\n// {\n// \"authorNames\": [\n// \"Alan Moore\",\n// \"Dave Gibbons\"\n// ],\n// \"isbn\": \"978-1779501127\",\n// \"title\": \"Watchmen\"\n// }\n//]\nTheo It seems to work! Are we done with the search implementation?\nJoe Almost. The searchBooksByTitle function we wrote is going to be part of the\nCatalog module, and it returns a collection of records. We have to write a\nfunction that’s part of the Library module, and that returns a JSON string.\nTheo You told me earlier that JSON serialization was straightforward in DOP.\nJoe Correct. The code for searchBooksByTitleJSON retrieves the Catalog record,\npasses it to searchBooksByTitle, and converts the results to JSON with\nJSON.stringify. That’s part of JavaScript. Here, let me show you.\nListing3.20 Implementation of searching books in a library as JSON\nfunction searchBooksByTitleJSON(libraryData, query) {\nvar results = searchBooksByTitle(_.get(libraryData, \"catalog\"), query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\nJoe In order to test our code, we need to create a Library record that contains our\nCatalog record. Could you do that for me, please?\nTheo Should the Library record contain all the Library fields (name, address,\nand UserManagement)?\nJoe That’s not necessary. For now, we only need the catalog field, then the test\nfor searching books.\nListing3.21 A Library record\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n--- Page 91 ---\n3.4 Calculating search results 63\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nListing3.22 Test for searching books in a library as JSON\nsearchBooksByTitleJSON(libraryData, \"Wat\");\nTheo How are we going to combine the four functions that we’ve written so far?\nJoe The functions authorNames, bookInfo, and searchBooksByTitle go into\nthe Catalog module, and searchBooksByTitleJSON goes into the Library\nmodule.\nTheo looks at the resulting code of the two modules, Library and Catalog. He’s quite\namazed by its conciseness.\nListing3.23 Calculating search results for Library and Catalog\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\n--- Page 92 ---\n64 CHAPTER 3 Basic data manipulation\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nThere’s no need\nreturn bookInfo;\nto create a class\n}\nfor bookInfo.\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nWhen _.filter is\nvar matchingBooks = _.filter(allBooks,\npassed a map, it\nfunction(book) {\ngoes over the values\nreturn _.get(book, \"title\").includes(query);\nof the map.\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nConverts data\nreturn resultsJSON;\nto JSON (part\n}\nof JavaScript)\n}\nAfter testing the final code in listing 3.24, Theo looks again at the source code from list-\ning 3.23. After a few seconds, he feels like he’s having another Aha! moment.\nListing3.24 Search results in JSON\nLibrary.searchBooksByTitleJSON(libraryData, \"Watchmen\");\n// → \"[{\\\"title\\\":\\\"Watchmen\\\",\\\"isbn\\\":\\\"978-1779501127\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}]\"\nTheo The important thing is not that the code is concise, but that the code contains\nno abstractions. It’s just data manipulation!\nJoe responds with a smile that says, “You got it, my friend!”\nJoe It reminds me of what my first meditation teacher told me 10 years ago:\nmeditation guides the mind to grasp the reality as it is without the abstractions\ncreated by our thoughts.\nTIP In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\n--- Page 93 ---\n3.5 Handling records of different types 65\n3.5 Handling records of different types\nWe’ve seen how DOP enables us to treat records as first-class citizens that can be\nmanipulated in a flexible way using generic functions. But if a record is nothing more\nthan an aggregation of fields, how do we know what the type of the record is? DOP has\na surprising answer to this question.\nTheo I have a question. If a record is nothing more than a map, how do you know\nthe type of the record?\nJoe That’s a great question with a surprising answer.\nTheo I’m curious.\nJoe Most of the time, there’s no need to know the record type.\nTheo What! What do you mean?\nJoe I mean that what matters most are the values of the fields. For example, take a\nlook at the Catalog.authorNames source code. It operates on a Book record,\nbut the only thing that matters is the value of the authorIds field.\nDoubtful, Theo looks at the source code for Catalog.authorNames. This is what Theo sees.\nListing3.25 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nTheo What about differentiating between various user types like Member versus\nLibrarian? I mean, they both have email and encryptedPassword. How do\nyou know if a record represents a Member or a Librarian?\nJoe Simple. You check to see if the record is found in the librariansByEmail\nindex or in the membersByEmail index of the Catalog.\nTheo Could you be more specific?\nJoe Sure! Let me write what the user management data of our tiny library might\nlook like, assuming we have one librarian and one member. To keep things\nsimple, I’m encrypting passwords through naive base-64 encoding for the User-\nManagement record.\nListing3.26 A UserManagement record\nvar userManagementData = {\n\"librariansByEmail\": {\n\"franck@gmail.com\" : { The base-64\nencoding of\n\"email\": \"franck@gmail.com\",\n\"mypassword\"\n\"encryptedPassword\": \"bXlwYXNzd29yZA==\"\n}\n},\n--- Page 94 ---\n66 CHAPTER 3 Basic data manipulation\n\"membersByEmail\": {\n\"samantha@gmail.com\": {\n\"email\": \"samantha@gmail.com\",\n\"encryptedPassword\": \"c2VjcmV0\",\nThe base-64\n\"isBlocked\": false,\nencoding of\n\"bookLendings\": [\n\"secret\"\n{\n\"bookItemId\": \"book-item-1\",\n\"bookIsbn\": \"978-1779501127\",\n\"lendingDate\": \"2020-04-23\"\n}\n]\n}\n}\n}\nTIP Most of the time, there’s no need to know the record type.\nTheo This morning, you told me you’d show me the code for UserManagement\n.isLibrarian function this afternoon.\nJoe So, here we are. It’s afternoon, and I’m going to fulfill my promise.\nJoe implements isLibrarian. With a slight pause, he then issues the test for isLibrarian.\nListing3.27 Checking if a user is a librarian\nfunction isLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nListing3.28 Testing isLibrarian\nisLibrarian(userManagementData, \"franck@gmail.com\");\n// → true\nTheo I’m assuming that _.has is a function that checks whether a key exists in a\nmap. Right?\nJoe Correct.\nTheo OK. You simply check whether the librariansByEmail map contains the\nemail field.\nJoe Yep.\nTheo Would you use the same pattern to check whether a member is a Super mem-\nber or a VIP member?\nJoe Sure. We could have SuperMembersByEmail and VIPMembersByEmail indexes.\nBut there’s a better way.\nTheo How?\nJoe When a member is a VIP member, we add a field, isVIP, with the value true to\nits record. To check if a member is a VIP member, we check whether the\nisVIP field is set to true in the member record. Here’s how I would code\nisVIPMember.\n--- Page 95 ---\n3.5 Handling records of different types 67\nListing3.29 Checking whether a member is a VIP member\nfunction isVIPMember(userManagement, email) {\nreturn _.get(userManagement, [\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nTheo I see that you access the isVIP field via its information path, [\"membersBy-\nEmail\", email, \"isVIP\"].\nJoe Yes, I think it makes the code crystal clear.\nTheo I agree. I guess we can do the same for isSuperMember and set an isSuper\nfield to true when a member is a Super member?\nJoe Yes, just like this.\nJoe assembles all the pieces in a UserManagement class. He then shows the code to Theo.\nListing3.30 The code of UserManagement module\nclass UserManagement {\nisLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nisVIPMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nisSuperMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isSuper\"]) == true;\n}\n}\nTheo looks at the UserManagement module code for a couple of seconds. Suddenly, an\nidea comes to his mind.\nTheo Why not have a type field in member record whose value would be either VIP\nor Super?\nJoe I assume that, according to the product requirements, a member can be both a\nVIP and a Super member.\nTheo Hmm...then the types field could be a collection containing VIP or Super\nor both.\nJoe In some situations, having a types field is helpful, but I find it simpler to have\na Boolean field for each feature that the record supports.\nTheo Is there a name for fields like isVIP and isSuper?\nJoe I call them feature fields.\nTIP Instead of maintaining type information about a record, use a feature field (e.g.,\nisVIP).\n--- Page 96 ---\n68 CHAPTER 3 Basic data manipulation\nTheo Can we use feature fields to differentiate between librarians and members?\nJoe You mean having an isLibrarian and an isMember field?\nTheo Yes, and having a common User record type for both librarians and members.\nJoe We can, but I think it’s simpler to have different record types for librarians and\nmembers: Librarian for librarians and Member for members.\nTheo Why?\nJoe Because there’s a clear distinction between librarians and members in terms of\ndata. For example, members can have book lendings but librarians don’t.\nTheo I agree. Now, we need to mention the two Member feature fields in our entity\ndiagram.\nWith that, Theo adds these fields to his diagram on the whiteboard. When he’s finished, he\nshows Joe his additions (figure 3.6).\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: Catalog\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian *\nCC Book id: String email: String CC Member\nname: String\ntitle : String encryptedPassword: String email: String\nbookIsbns: [String]\npublicationYear: Number encryptedPassword: String\nisbn: String * isBlocked: Boolean\nauthorIds: [String] bookLendings: [BookLending]\nbookItems: [BookItem] * isVIP: Boolean\nisSuper: Boolean\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.6 A library management data model with the Member feature fields isVIP and isSuper\nJoe Do you like the data model that we have designed together?\nTheo I find it quite simple and clear.\n--- Page 97 ---\nSummary 69\nJoe That’s the main goal of DOP.\nTheo Also, I’m pleasantly surprised how easy it is to adapt to changing requirements,\nboth in terms of code and the data model.\nJoe I suppose you’re also happy to get rid of complex class hierarchy diagrams.\nTheo Absolutely! Also, I think I’ve found an interesting connection between DOP\nand meditation.\nJoe Really?\nTheo When we were eating at Simple, you told me that meditation helped you expe-\nrience reality as it is without the filter of your thoughts.\nJoe Right.\nTheo From what you taught me today, I understand that in DOP, we are encouraged\nto treat data as data without the filter of our classes.\nJoe Clever! I never noticed that connection between those two disciplines that are\nso important for me. I guess you’d like to continue your journey in the realm\nof DOP.\nTheo Definitely. Let’s meet again tomorrow.\nJoe Unfortunately, tomorrow I’m taking my family to the beach to celebrate the\ntwelfth birthday of my eldest daughter, Aurelia.\nTheo Happy birthday, Aurelia!\nJoe We could meet again next Monday, if that’s OK with you.\nTheo With pleasure!\nSummary\n DOP principle #2 is to represent data entities with generic data structures.\n We refer to maps that have strings as keys as string maps.\n Representing data as data means representing records with string maps.\n By positional collection, we mean a collection where the elements are in order\n(like a list or an array).\n A positional collection of Strings is noted as [String].\n By index, we mean a collection where the elements are accessible via a key (like\na hash map or a dictionary).\n An index of Books is noted as {Book}.\n In the context of a data model, the index keys are always strings.\n A record is a data structure that groups together related data items. It’s a collec-\ntion of fields, possibly of different data types.\n A homogeneous map is a map where all the values are of the same type.\n A heterogeneous map is a map where the values are of different types.\n In DOP, we represent a record as a heterogeneous string map.\n A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes.\n The relation between records in a data entity diagram is either composition or\nassociation.\n--- Page 98 ---\n70 CHAPTER 3 Basic data manipulation\n The data part of a DOP system is flexible, and each piece of information is\naccessible via its information path.\n There is a tradeoff between flexibility and safety in a data model.\n DOP compromises on data safety to gain flexibility and genericity.\n In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\n We manipulate data with generic functions.\n Generic functions are provided either by the language itself or by third-party\nlibraries like Lodash.\n JSON serialization is implemented in terms of a generic function.\n On the one hand, we’ve lost the safety of accessing record fields via members\ndefined at compile time. On the other hand, we’ve liberated data from the lim-\nitation of classes and objects. Data is represented as data!\n The weak dependency between code and data makes it is easier to adapt to\nchanging requirements.\n When data is represented as data, it is straightforward to visualize system data.\n Usually, we do not need to maintain type information about a record.\n We can visualize any part of the system data.\n In statically-typed languages, we sometimes need to statically cast the field values.\n Instead of maintaining type information about a record, we use a feature field.\n There is no significant performance hit for accessing a field in a map instead of\na class member.\n In DOP, you can retrieve every piece of information via an information path and\na generic function.\n In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\nLodash functions introduced in this chapter\nFunction Description\nget(map, path) Gets the value of map at path\nhas(map, path) Checks if map has a field at path\nmerge(mapA, mapB) Creates a map resulting from the recursive merges between mapA and mapB\nvalues(map) Creates an array of values of map\nfilter(coll, pred) Iterates over elements of coll, returning an array of all elements for which\npred returns true\nmap(coll, f) Creates an array of values by running each element in coll through f\n--- Page 99 ---\nState management\nTime travel\nThis chapter covers\n A multi-version approach to state management\n The calculation phase of a mutation\n The commit phase of a mutation\n Keeping a history of previous state versions\nSo far, we have seen how DOP handles queries via generic functions that access sys-\ntem data, which is represented as a hash map. In this chapter, we illustrate how\nDOP deals with mutations (requests that change the system state). Instead of updat-\ning the state in place, we maintain multiple versions of the system data. At a specific\npoint in time, the system state refers to a specific version of the system data. This\nchapter is a deep dive in the third principle of DOP.\nPRINCIPLE #3 Data is immutable.\nThe maintenance of multiple versions of the system data requires the data to be\nimmutable. This is made efficient both in terms of computation and memory via a\n71\n--- Page 100 ---\n72 CHAPTER 4 State management\ntechnique called structural sharing, where parts of the data that are common between\ntwo versions are shared instead of being copied. In DOP, a mutation is split into two\ndistinct phases:\n In the calculation phase, we compute the next version of the system data.\n In the commit phase, we move the system state forward so that it refers to the\nversion of the system data computed by the calculation phase.\nThis distinction between calculation and commit phases allows us to reduce the part\nof our system that is stateful to its bare minimum. Only the code of the commit phase\nis stateful, while the code in the calculation phase of a mutation is stateless and is\nmade of generic functions similar to the code of a query. The implementation of the\ncommit phase is common to all mutations. As a consequence, inside the commit\nphase, we have the ability to ensure that the state always refers to a valid version of the\nsystem data.\nAnother benefit of this state management approach is that we can keep track of\nthe history of previous versions of the system data. Restoring the system to a previous\nstate (if needed) becomes straightforward. Table 4.1 shows the two phases.\nTable 4.1 The two phases of a mutation\nPhase Responsibility State Implementation\nCalculation Computes the next version of system data Stateless Specific\nCommit Moves the system state forward Stateful Common\nIn this chapter, we assume that no mutations occur concurrently in our system. In the\nnext chapter, we will deal with concurrency control.\n4.1 Multiple versions of the system data\nWhen Joe comes in to the office on Monday, he tells Theo that he needs to exercise before\nstarting to work with his mind. Theo and Joe go for a walk around the block, and the dis-\ncussion turns toward version control systems. They discuss how Git keeps track of the\nwhole commit history and how easy and fast it is to restore the code to a previous state.\nWhen Theo tells Joe that Git’s ability to “time travel” reminds him one of his favorite mov-\nies, Back to the Future, Joe shares that a month ago he watched the Back to the Future trilogy\nwith Neriah, his 14-year-old son.\nTheir walk complete, they arrive back at Theo’s office. Theo and Joe partake of the\nespresso machine in the kitchen before they begin today’s lesson.\nJoe So far, we’ve seen how we manage queries that retrieve information from the\nsystem in DOP. Now I’m going to show you how we manage mutations. By a\nmutation, I mean an operation that changes the state of the system.\n NOTE A mutation is an operation that changes the state of the system.\n--- Page 101 ---\n4.1 Multiple versions of the system data 73\nTheo Is there a fundamental difference between queries and mutations in DOP?\nAfter all, the whole state of the system is represented as a hash map. I could\neasily write code that modifies part of the hash map, and it would be similar to\nthe code that retrieves information from the hash map.\nJoe You could mutate the data in place, but then it would be challenging to ensure\nthat the code of a mutation doesn’t put the system into an invalid date. You\nwould also lose the ability to track previous versions of the system state.\nTheo I see. So, how do you handle mutations in DOP?\nJoe We adopt a multi-version state approach, similar to what a version control sys-\ntem like Git does; we manage different versions of the system data. At a specific\npoint in time, the state of the system refers to a version of the system data. After\na mutation is executed, we move the reference forward.\nTheo I’m confused. Is the system state mutable or immutable?\nJoe The data is immutable, but the state reference is mutable.\nTIP The data is immutable, but the state reference is mutable.\nNoticing the look of confusion on Theo’s face, Joe draws a quick diagram on the white-\nboard. He then shows Theo figure 4.1, hoping that it will clear up Theo’s perplexity.\nAfter mutation B After mutation C\nData V10 Data V10\nMutationA MutationA\nData V11 Data V11\nMutation B Mutation B\nSystem State Data V12 Data V12\nMutation C\nSystem State Data V13\nFigure 4.1 After mutation B is executed, the system state refers to Data V12. After\nmutation C is executed, the system state refers to Data V13.\nTheo Does that mean that before the code of a mutation runs, we make a copy of the\nsystem data?\nJoe No, that would be inefficient, as we would have to do a deep copy of the data.",
        "sections_found": []
      },
      "accurate_page_range": "76-101"
    },
    {
      "text": "- 3.1 Designing a data model",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "3 Basic data manipulation",
      "raw_line": "- 3.1 Designing a data model (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 23,
      "chapter_info": {
        "page": 76,
        "title": "Basic data manipulation",
        "pattern_matched": "Chapter 3",
        "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
      },
      "chapter_sections": {
        "start_page": 76,
        "end_page": 101,
        "content": "\n--- Page 76 ---\n48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to say that a data entity diagram consists only of records, positional\ncollections, and indexes?\nJoe That’s correct. Can you make a similar statement about the relations between\nentities?\nTheo The relations in a data entity diagram are either composition (solid line with a\nfull diamond) or association (dashed line with an empty diamond). Both types\nof relations can be either one-to-one, one-to-many, or many-to-many.\nJoe Excellent!\nTIP A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes. The relation between records is either composition or\nassociation.\n3.2 Representing records as maps\nSo far, we’ve illustrated the benefits we gain from the separation between code and\ndata at a high-system level. There’s a separation of concerns between code and data,\nand each part has clear constraints:\n Code consists of static functions that receive data as an explicit argument.\n Data entities are modeled as records, and the relations between records are\nrepresented by positional collections and indexes.\nNow comes the question of the representation of the data. DOP has nothing special\ntosay about collections and indexes. However, it’s strongly opinionated about the\nrepresentation of records: records should be represented by generic data structures\nsuch as maps.\nThis applies to both OOP and FP languages. In dynamically-typed languages like\nJavaScript, Python, and Ruby, data representation feels natural. While in statically-\ntyped languages like Java and C#, it is a bit more cumbersome.\nTheo I’m really curious to know how we represent positional collections, indexes,\nand records in DOP.\nJoe Let’s start with positional collections. DOP has nothing special to say about the\nrepresentation of collections. They can be linked lists, arrays, vectors, sets, or\nother collections best suited for the use case.\nTheo It’s like in OOP.\nJoe Right! For now, to keep things simple, we’ll use arrays to represent positional\ncollections.\nTheo What about indexes?\nJoe Indexes are represented as homogeneous string maps.\nTheo What do you mean by a homogeneous map?\n--- Page 77 ---\n3.2 Representing records as maps 49\nJoe I mean that all the values of the map are of the same kind. For example, in a\nBook index, all the values are Book, and in an author index, all the values are\nAuthor, and so forth.\nTheo Again, it’s like in OOP.\n NOTE A homogeneous map is a map where all the values are of the same type. A hetero-\ngeneous map is a map where the values are of different types.\nJoe Now, here’s the big surprise. In DOP, records are represented as maps, more\nprecisely, heterogeneous string maps.\nJoe goes to the whiteboard and begins to draw. When he’s finished, he shows Theo the dia-\ngram in figure 3.4.\nRecord Heterogeneous map\nLinked list\nArray\nData representation Collection\nSet\nVector\nFigure 3.4 The building blocks\nIndex Homogeneous map\nof data representation\nTheo stays silent for a while. He is shocked to hear that the data entities of a system can be\nrepresented as a generic data structure, where the field names and value types are not\nspecified in a class. Then, Theo asks Joe:\nTheo What are the benefits of this folly?\nJoe Flexibility and genericity.\nTheo Could you explain, please?\nJoe I’ll explain in a moment, but before that, I’d like to show you what an instance\nof a record in a DOP system looks like.\nTheo OK.\nJoe Let’s take as an example, Watchmen, by Alan Moore and Dave Gibbons, which is\nmy favorite graphic novel. This masterpiece was published in 1987. I’m going\nto assume that, in a physical library, there are two copies of this book, whose ID\nis nyc-central-lib, and that one of the two copies is currently out. Here’s\nhow I’d represent the Book record for Watchmen in DOP.\nJoe comes closer to Theo’s laptop. He opens a text editor (not an IDE!) and types the Book\nrecord for Theo.\n--- Page 78 ---\n50 CHAPTER 3 Basic data manipulation\nListing3.1 An instance of a Book record represented as a map\n{\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\nTheo looks at the laptop screen. He has a question.\nTheo How am I supposed to instantiate the Book record for Watchmen programmat-\nically?\nJoe It depends on the facilities that your programming language offers to instantiate\nmaps. With dynamic languages like JavaScript, Ruby, or Python, it’s straight-\nforward, because we can use literals for maps and arrays. Here, let me show\nyou how.\nJoe jots down the JavaScript code that creates an instance of a Book record, which rep-\nresents as a map in JavaScript. He shows the code to Theo.\nListing3.2 A Book record represented as a map in JavaScript\nvar watchmenBook = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n--- Page 79 ---\n3.2 Representing records as maps 51\nTheo And, if I’m in Java?\nJoe It’s a bit more tedious, but still doable with the immutable Map and List static\nfactory methods.\n NOTE See “Creating Immutable Lists, Sets, and Maps” at http://mng.bz/voGm for\nmore information on this Java core library.\nJoe types the Java code to create an instance of a Book record represented as a map. He\nshows Theo the Java code.\nListing3.3 A Book record represented as a map in Java\nMap watchmen = Map.of(\n\"isbn\", \"978-1779501127\",\n\"title\", \"Watchmen\",\n\"publicationYear\", 1987,\n\"authors\", List.of(\"alan-moore\", \"dave-gibbons\"),\n\"bookItems\", List.of(\nMap.of(\n\"id\", \"book-item-1\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", true\n),\nMap.of (\n\"id\", \"book-item-2\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", false\n)\n)\n);\nTIP In DOP, we represent a record as a heterogeneous string map.\nTheo I’d definitely prefer to create a Book record using a Book class and a BookItem\nclass.\nTheo opens his IDE. He types the JavaScript code to represent a Book record as an instance\nof a Book class.\nListing3.4 A Book record as an instance of a Book class in JavaScript\nclass Book {\nisbn;\ntitle;\npublicationYear;\nauthors;\nbookItems;\nconstructor(isbn, title, publicationYear, authors, bookItems) {\nthis.isbn = isbn;\nthis.title = title;\nthis.publicationYear = publicationYear;\nthis.authors = authors;\nthis.bookItems = bookItems;\n--- Page 80 ---\n52 CHAPTER 3 Basic data manipulation\n}\n}\nclass BookItem {\nid;\nlibId;\nisLent;\nconstructor(id, libId, isLent) {\nthis.id = id;\nthis.libId = libId;\nthis.isLent = isLent;\n}\n}\nvar watchmenBook = new Book(\"978-1779501127\",\n\"Watchmen\",\n1987,\n[\"alan-moore\", \"dave-gibbons\"],\n[new BookItem(\"book-item-1\", \"nyc-central-lib\", true),\nnew BookItem(\"book-item-2\", \"nyc-central-lib\", false)]);\nJoe Theo, why do you prefer classes over maps for representing records?\nTheo It makes the data shape of the record part of my program. As a result, the IDE\ncan auto-complete field names, and errors are caught at compile time.\nJoe Fair enough. Can I show you some drawbacks for this approach?\nTheo Sure.\nJoe Imagine that you want to display the information about a book in the context\nof search results. In that case, instead of author IDs, you want to display\nauthor names, and you don’t need the book item information. How would\nyou handle that?\nTheo I’d create a class BookInSearchResults without a bookItems member and\nwith an authorNames member instead of the authorIds member of the Book\nclass. Also, I would need to write a copy constructor that receives a Book object.\nJoe In classic OOP, the fact that data is instantiated only via classes brings safety.\nBut this safety comes at the cost of flexibility.\nTIP There’s a tradeoff between flexibility and safety in a data model.\nTheo So, how can it be different?\nJoe In the DOP approach, where records are represented as maps, we don’t need\nto create a class for each variation of the data. We’re free to add, remove, and\nrename record fields dynamically. Our data model is flexible.\nTheo Interesting!\nTIP In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\nJoe Now, let me talk about genericity. How would you serialize the content of a\nBook object to JSON?\n--- Page 81 ---\n3.2 Representing records as maps 53\nTIP In DOP, records are manipulated with generic functions.\nTheo Oh no! I remember that while working on the Klafim prototype, I had a night-\nmare about JSON serialization when I was developing the first version of the\nLibrary Management System.\nJoe Well, in DOP, serializing a record to JSON is super easy.\nTheo Does it require the usage of reflection in order to go over the fields of the\nrecord like the Gson Java library does?\n NOTE See https://github.com/google/gson for more information on Gson.\nJoe Not at all! Remember that in DOP, a record is nothing more than data. We can\nwrite a generic JSON serialization function that works with any record. It can\nbe a Book, an Author, a BookItem, or anything else.\nTheo Amazing!\nTIP In DOP, you get JSON serialization for free.\nJoe Actually, as I’ll show you in a moment, lots of data manipulation stuff can be\ndone using generic functions.\nTheo Are the generic functions part of the language?\nJoe It depends on the functions and on the language. For example, JavaScript pro-\nvides a JSON serialization function called JSON.stringify out of the box, but\nnone for omitting multiple keys or for renaming keys.\nTheo That’s annoying.\nJoe Not so much; there are third-party libraries that provide data-manipulation facil-\nities. A popular data manipulation library in the JavaScript ecosystem is Lodash.\n NOTE See https://lodash.com/ to find out more about Lodash.\nTheo What about other languages?\nJoe Lodash has been ported to Java, C#, Python, and Ruby. Let me bookmark some\nsites for you.\nJoe bookmarks these sites for Theo:\n https://javalibs.com/artifact/com.github.javadev/underscore-lodash for Java\n https://www.nuget.org/packages/lodash/ for C#\n https://github.com/dgilland/pydash for Python\n https://rudash-website.now.sh/ for Ruby\n NOTE Throughout the book, we use Lodash to show how to manipulate data with\ngeneric functions, but there is nothing special about Lodash. The exact same approach\ncould be implemented via other data manipulation libraries or custom code.\nTheo Cool!\nJoe Actually, Lodash and its rich set of data manipulation functions can be ported\nto any language. That’s why it’s so beneficial to represent records as maps.\n--- Page 82 ---\n54 CHAPTER 3 Basic data manipulation\nTIP DOP compromises on data safety to gain flexibility and genericity.\nAt the whiteboard, Joe quickly sketches the tradeoffs (see table 3.1).\nTable 3.1 The tradeoff among safety, flexibility, and genericity\nOOP DOP\nSafety High Low\nFlexibility Low High\nGenericity Low High\n3.3 Manipulating data with generic functions\nJoe Now let me show you how to manipulate data in DOP with generic functions.\nTheo Yes, I’m quite curious to see how you’ll implement the search functionality of\nthe Library Management System.\nJoe OK. First, let’s instantiate a Catalog record for the catalog data of a library,\nwhere we have a single book, Watchmen.\nJoe instantiates a Catalog record according to Theo’s data model in figure 3.3. Here’s\nwhat Joe shows to Theo.\nListing3.5 A Catalog record\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n--- Page 83 ---\n3.3 Manipulating data with generic functions 55\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\nTheo I see the two indexes we talked about, booksByIsbn and authorsById. How\ndo you differentiate a record from an index in DOP?\nJoe In an entity diagram, there’s a clear distinction between records and indexes.\nBut in our code, both are plain data.\nTheo I guess that’s why this approach is called data-oriented programming.\nJoe See how straightforward it is to visualize any part of the system data inside a\nprogram? The reason is that data is represented as data!\nTIP In DOP, data is represented as data.\nTheo That sounds like a lapalissade.1\nJoe Oh, does it? I’m not so sure! In OOP, data is usually represented by objects,\nwhich makes it more challenging to visualize data inside a program.\nTIP In DOP, we can visualize any part of the system data.\nTheo How would you retrieve the title of a specific book from the catalog data?\nJoe Great question! In fact, in a DOP system, every piece of information has an\ninformation path from which we can retrieve the information.\nTheo Information path?\nJoe For example, the information path to the title of the Watchmen book in the\ncatalog is [\"booksByIsbn\", \"978-1779501127\", \"title\"].\nTheo Ah, I see. So, is an information path sort of like a file path, but that names in\nan information path correspond to nested entities?\nJoe You’re exactly right. And once we have the path of a piece of information, we\ncan retrieve the information with Lodash’s _.get function.\nJoe types a few characters on Theo’s laptop. Theo is amazed at how little code is needed to\nget the book title.\nListing3.6 Retrieving the title of a book from its information path\n_.get(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"])\n// → \"Watchmen\"\nTheo Neat. I wonder how hard it would be to implement a function like _.get\nmyself.\n1 A lapalissade is an obvious truth—a truism or tautology—that produces a comical effect.\n--- Page 84 ---\n56 CHAPTER 3 Basic data manipulation\nAfter a few minutes of trial and error, Theo is able to produce his implementation. He\nshows Joe the code.\nListing3.7 Custom implementation of get\nfunction get(m, path) {\nvar res = m;\nfor(var i = 0; i < path.length; i++) {\nWe could use\nvar key = path[i];\nforEach instead\nres = res[key];\nof a for loop.\n}\nreturn res;\n}\nAfter testing Theo’s implementation of get, Joe compliments Theo. He’s grateful that\nTheo is catching on so quickly.\nListing3.8 Testing the custom implementation of get\nget(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nJoe Well done!\nTheo I wonder if a function like _.get works smoothly in a statically-typed language\nlike Java?\nJoe It depends on whether you only need to pass the value around or to access the\nvalue concretely.\nTheo I don’t follow.\nJoe Imagine that once you get the title of a book, you want to convert the string\ninto an uppercase string. You need to do a static cast to String, right? Here,\nlet me show you an example that casts a field value to a string, then we can\nmanipulate it as a string.\nListing3.9 Casting a field value to a string\n((String)watchmen.get(\"title\")).toUpperCase()\nTheo That makes sense. The values of the map are of different types, so the compiler\ndeclares it as a Map<String,Object>. The information of the type of the field\nis lost.\nJoe It’s a bit annoying, but quite often our code just passes the data around. In that\ncase, we don’t have to deal with static casting. Moreover, in a language like C#,\nwhen using the dynamic data type, type casting can be avoided.2,3\n2 See http://mng.bz/4jo5 for the C# documentation on the built-in reference to dynamic types.\n3 See appendix A for details about dynamic fields and type casting in C#.\n--- Page 85 ---\n3.3 Manipulating data with generic functions 57\nTIP In statically-typed languages, we sometimes need to statically cast the field values.\nTheo What about performance?\nJoe In most programming languages, maps are quite efficient. Accessing a field\nin a map is slightly slower than accessing a class member. Usually, it’s not\nsignificant.\nTIP There’s no significant performance hit for accessing a field in a map instead of as\na class member.\nTheo Let’s get back to this idea of information path. It works in OOP too. I could\naccess the title of the Watchmen book with catalogData.booksByIsbn[\"978-\n1779501127\"].title. I’d use class members for record fields and strings for\nindex keys.\nJoe There’s a fundamental difference, though. When records are represented as\nmaps, the information can be retrieved via its information path using a generic\nfunction like _.get. But when records are represented as objects, you need to\nwrite specific code for each type of information path.\nTheo What do you mean by specific code? What’s specific in catalogData.books-\nByIsbn[\"978-1779501127\"].title?\nJoe In a statically-typed language like Java, you’d need to import the class defini-\ntions for Catalog and Book.\nTheo And, in a dynamically-typed language like JavaScript...?\nJoe Even in JavaScript, when you represent records with objects instantiated from\nclasses, you can’t easily write a function that receives a path as an argument\nand display the information that corresponds to this path. You would have to\nwrite specific code for each kind of path. You’d access class members with dot\nnotation and map fields with bracket notation.\nTheo Would you say that in DOP, the information path is a first-class citizen?\nJoe Absolutely! The information path can be stored in a variable and passed as an\nargument to a function.\nTIP In DOP, you can retrieve every piece of information via a path and a generic\nfunction.\nJoe goes to the whiteboard. He draws a diagram like that in figure 3.5, which shows the\ncatalog data as a tree.\nJoe You see, Theo, each piece of information is accessible via a path made of\nstrings and integers. For example, the path of Alan Moore’s first book is\n[\"catalog\", \"authorsById\", \"alan-moore\", \"bookIsbns\", 0].\n--- Page 86 ---\n58 CHAPTER 3 Basic data manipulation\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 3.5 The catalog data as a tree\n3.4 Calculating search results\nTheo Interesting. I’m starting to feel the power of expression of DOP!\nJoe Wait, that’s just the beginning. Let me show you how simple it is to write code\nthat retrieves book information and displays it in search results. Can you tell\nme exactly what information has to appear in the search results?\nTheo Searching for book information should return isbn, title, and author-\nNames.\nJoe And what would a BookInfo record look like for Watchmen?\nTheo quickly enters the code on his laptop. He then shows it to Joe.\nListing3.10 A BookInfo record for Watchmen in the context of search result\n{\n\"title\": \"Watchmen\",\n\"isbn\": \"978-1779501127\",\n\"authorNames\": [\n\"Alan Moore\",\n\"Dave Gibbons\",\n]\n}\n--- Page 87 ---\n3.4 Calculating search results 59\nJoe Now I’ll show you step by step how to write a function that returns search\nresults matching a title in JSON format. I’ll use generic data manipulation\nfunctions from Lodash.\nTheo I’m ready!\nJoe Let’s start with an authorNames function that calculates the author names of a\nBook record by looking at the authorsById index. Could you tell me what’s\nthe information path for the name of an author whose ID is authorId?\nTheo It’s [\"authorsById\", authorId, \"name\"].\nJoe Now, let me show you how to retrieve the name of several authors using _.map.\nJoe types the code to map the author IDs to the author names. Theo nonchalantly peeks\nover Joe’s shoulder.\nListing3.11 Mapping author IDs to author names\n_.map([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\nTheo What’s this _.map function? It smells like functional programming! You said I\nwouldn’t have to learn FP to implement DOP!\nJoe No need to learn functional programming in order to use _.map, which is a\nfunction that transforms the values of a collection. You can implement it with\na simple for loop.\nTheo spends a couple of minutes in front of his computer figuring out how to implement\n_.map. Now he’s got it!\nListing3.12 Custom implementation of map\nfunction map(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nres[i] = f(coll[i]);\nforEach instead\n}\nof a for loop.\nreturn res;\n}\nAfter testing Theo’s implementation of map, Joe shows Theo the test. Joe again compli-\nments Theo.\nListing3.13 Testing the custom implementation of map\nmap([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\n--- Page 88 ---\n60 CHAPTER 3 Basic data manipulation\nJoe Well done!\nTheo You were right! It wasn’t hard.\nJoe Now, let’s implement authorNames using _.map.\nIt takes a few minutes for Theo to come up with the implementation of authorNames.\nWhen he’s finished, he turns his laptop to Joe.\nListing3.14 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nJoe We also need a bookInfo function that converts a Book record into a Book-\nInfo record. Let me show you the code for that.\nListing3.15 Converting a Book record into a BookInfo record\nfunction bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": authorNames(catalogData, book)\n};\nThere’s no need to create\nreturn bookInfo;\na class for bookInfo.\n}\nTheo Looking at the code, I see that a BookInfo record has three fields: title,\nisbn, and authorNames. Is there a way to get this information without looking\nat the code?\nJoe You can either add it to the data entity diagram or write it in the documenta-\ntion of the bookInfo function, or both.\nTheo I have to get used to the idea that in DOP, the record field information is not\npart of the program.\nJoe Indeed, it’s not part of the program, but it gives us a lot of flexibility.\nTheo Is there any way for me to have my cake and eat it too?\nJoe Yes, and someday I’ll show you how to make record field information part of a\nDOP program (see chapters 7 and 12).\nTheo Sounds intriguing!\nJoe Now that we have all the pieces in place, we can write our searchBooksBy-\nTitle function, which returns the book information about the books that\nmatch the query. First, we find the Book records that match the query with\n_.filter and then we transform each Book record into a BookInfo record\nwith _.map and bookInfo.\n--- Page 89 ---\n3.4 Calculating search results 61\nListing3.16 Searching books that match a query\nfunction searchBooksByTitle(catalogData, query) {\nvar allBooks = _.values(_.get(catalogData, \"booksByIsbn\"));\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\nThe includes JavaScript\n});\nfunction checks whether\na string includes a string\nvar bookInfos = _.map(matchingBooks, function(book) { as a substring.\nreturn bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\nTheo You’re using Lodash functions without any explanation again!\nJoe Sorry about that. I am so used to basic data manipulation functions that I con-\nsider them as part of the language. What functions are new to you?\nTheo _.values and _.filter\nJoe Well, _.values returns a collection made of the values of a map, and _.filter\nreturns a collection made of the values that satisfy a predicate.\nTheo _.values seems trivial. Let me try to implement _.filter.\nThe implementation of _.filter takes a bit more time. Eventually, Theo manages to get\nit right, then he is able to test it.\nListing3.17 Custom implementation of filter\nfunction filter(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nif(f(coll[i])) {\nforEach instead\nres.push(coll[i]);\nof a for loop.\n}\n}\nreturn res;\n}\nListing3.18 Testing the custom implementation of filter\nfilter([\"Watchmen\", \"Batman\"], function (title) {\nreturn title.includes(\"Watch\");\n});\n// → [\"Watchmen\"]\nTheo To me, it’s a bit weird that to access the title of a book record, I need to write\n_.get(book, \"title\"). I’d expect it to be book.title in dot notation or\nbook[\"title\"] in bracket notation.\nJoe Remember that book is a record that’s not represented as an object. It’s a map.\nIndeed, in JavaScript, you can write _.get(book, \"title\"), book.title, or\nbook[\"title\"]. But I prefer to use Lodash’s _.get function. In some lan-\nguages, the dot and the bracket notations might not work on maps.\n--- Page 90 ---\n62 CHAPTER 3 Basic data manipulation\nTheo Being language-agnostic has a price!\nJoe Right, would you like to test searchBooksByTitle?\nTheo Absolutely! Let me call searchBooksByTitle to search the books whose title\ncontain the string Watch.\nListing3.19 Testing searchBooksByTitle\nsearchBooksByTitle(catalogData, \"Wat\");\n//[\n// {\n// \"authorNames\": [\n// \"Alan Moore\",\n// \"Dave Gibbons\"\n// ],\n// \"isbn\": \"978-1779501127\",\n// \"title\": \"Watchmen\"\n// }\n//]\nTheo It seems to work! Are we done with the search implementation?\nJoe Almost. The searchBooksByTitle function we wrote is going to be part of the\nCatalog module, and it returns a collection of records. We have to write a\nfunction that’s part of the Library module, and that returns a JSON string.\nTheo You told me earlier that JSON serialization was straightforward in DOP.\nJoe Correct. The code for searchBooksByTitleJSON retrieves the Catalog record,\npasses it to searchBooksByTitle, and converts the results to JSON with\nJSON.stringify. That’s part of JavaScript. Here, let me show you.\nListing3.20 Implementation of searching books in a library as JSON\nfunction searchBooksByTitleJSON(libraryData, query) {\nvar results = searchBooksByTitle(_.get(libraryData, \"catalog\"), query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\nJoe In order to test our code, we need to create a Library record that contains our\nCatalog record. Could you do that for me, please?\nTheo Should the Library record contain all the Library fields (name, address,\nand UserManagement)?\nJoe That’s not necessary. For now, we only need the catalog field, then the test\nfor searching books.\nListing3.21 A Library record\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n--- Page 91 ---\n3.4 Calculating search results 63\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nListing3.22 Test for searching books in a library as JSON\nsearchBooksByTitleJSON(libraryData, \"Wat\");\nTheo How are we going to combine the four functions that we’ve written so far?\nJoe The functions authorNames, bookInfo, and searchBooksByTitle go into\nthe Catalog module, and searchBooksByTitleJSON goes into the Library\nmodule.\nTheo looks at the resulting code of the two modules, Library and Catalog. He’s quite\namazed by its conciseness.\nListing3.23 Calculating search results for Library and Catalog\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\n--- Page 92 ---\n64 CHAPTER 3 Basic data manipulation\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nThere’s no need\nreturn bookInfo;\nto create a class\n}\nfor bookInfo.\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nWhen _.filter is\nvar matchingBooks = _.filter(allBooks,\npassed a map, it\nfunction(book) {\ngoes over the values\nreturn _.get(book, \"title\").includes(query);\nof the map.\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nConverts data\nreturn resultsJSON;\nto JSON (part\n}\nof JavaScript)\n}\nAfter testing the final code in listing 3.24, Theo looks again at the source code from list-\ning 3.23. After a few seconds, he feels like he’s having another Aha! moment.\nListing3.24 Search results in JSON\nLibrary.searchBooksByTitleJSON(libraryData, \"Watchmen\");\n// → \"[{\\\"title\\\":\\\"Watchmen\\\",\\\"isbn\\\":\\\"978-1779501127\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}]\"\nTheo The important thing is not that the code is concise, but that the code contains\nno abstractions. It’s just data manipulation!\nJoe responds with a smile that says, “You got it, my friend!”\nJoe It reminds me of what my first meditation teacher told me 10 years ago:\nmeditation guides the mind to grasp the reality as it is without the abstractions\ncreated by our thoughts.\nTIP In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\n--- Page 93 ---\n3.5 Handling records of different types 65\n3.5 Handling records of different types\nWe’ve seen how DOP enables us to treat records as first-class citizens that can be\nmanipulated in a flexible way using generic functions. But if a record is nothing more\nthan an aggregation of fields, how do we know what the type of the record is? DOP has\na surprising answer to this question.\nTheo I have a question. If a record is nothing more than a map, how do you know\nthe type of the record?\nJoe That’s a great question with a surprising answer.\nTheo I’m curious.\nJoe Most of the time, there’s no need to know the record type.\nTheo What! What do you mean?\nJoe I mean that what matters most are the values of the fields. For example, take a\nlook at the Catalog.authorNames source code. It operates on a Book record,\nbut the only thing that matters is the value of the authorIds field.\nDoubtful, Theo looks at the source code for Catalog.authorNames. This is what Theo sees.\nListing3.25 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nTheo What about differentiating between various user types like Member versus\nLibrarian? I mean, they both have email and encryptedPassword. How do\nyou know if a record represents a Member or a Librarian?\nJoe Simple. You check to see if the record is found in the librariansByEmail\nindex or in the membersByEmail index of the Catalog.\nTheo Could you be more specific?\nJoe Sure! Let me write what the user management data of our tiny library might\nlook like, assuming we have one librarian and one member. To keep things\nsimple, I’m encrypting passwords through naive base-64 encoding for the User-\nManagement record.\nListing3.26 A UserManagement record\nvar userManagementData = {\n\"librariansByEmail\": {\n\"franck@gmail.com\" : { The base-64\nencoding of\n\"email\": \"franck@gmail.com\",\n\"mypassword\"\n\"encryptedPassword\": \"bXlwYXNzd29yZA==\"\n}\n},\n--- Page 94 ---\n66 CHAPTER 3 Basic data manipulation\n\"membersByEmail\": {\n\"samantha@gmail.com\": {\n\"email\": \"samantha@gmail.com\",\n\"encryptedPassword\": \"c2VjcmV0\",\nThe base-64\n\"isBlocked\": false,\nencoding of\n\"bookLendings\": [\n\"secret\"\n{\n\"bookItemId\": \"book-item-1\",\n\"bookIsbn\": \"978-1779501127\",\n\"lendingDate\": \"2020-04-23\"\n}\n]\n}\n}\n}\nTIP Most of the time, there’s no need to know the record type.\nTheo This morning, you told me you’d show me the code for UserManagement\n.isLibrarian function this afternoon.\nJoe So, here we are. It’s afternoon, and I’m going to fulfill my promise.\nJoe implements isLibrarian. With a slight pause, he then issues the test for isLibrarian.\nListing3.27 Checking if a user is a librarian\nfunction isLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nListing3.28 Testing isLibrarian\nisLibrarian(userManagementData, \"franck@gmail.com\");\n// → true\nTheo I’m assuming that _.has is a function that checks whether a key exists in a\nmap. Right?\nJoe Correct.\nTheo OK. You simply check whether the librariansByEmail map contains the\nemail field.\nJoe Yep.\nTheo Would you use the same pattern to check whether a member is a Super mem-\nber or a VIP member?\nJoe Sure. We could have SuperMembersByEmail and VIPMembersByEmail indexes.\nBut there’s a better way.\nTheo How?\nJoe When a member is a VIP member, we add a field, isVIP, with the value true to\nits record. To check if a member is a VIP member, we check whether the\nisVIP field is set to true in the member record. Here’s how I would code\nisVIPMember.\n--- Page 95 ---\n3.5 Handling records of different types 67\nListing3.29 Checking whether a member is a VIP member\nfunction isVIPMember(userManagement, email) {\nreturn _.get(userManagement, [\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nTheo I see that you access the isVIP field via its information path, [\"membersBy-\nEmail\", email, \"isVIP\"].\nJoe Yes, I think it makes the code crystal clear.\nTheo I agree. I guess we can do the same for isSuperMember and set an isSuper\nfield to true when a member is a Super member?\nJoe Yes, just like this.\nJoe assembles all the pieces in a UserManagement class. He then shows the code to Theo.\nListing3.30 The code of UserManagement module\nclass UserManagement {\nisLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nisVIPMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nisSuperMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isSuper\"]) == true;\n}\n}\nTheo looks at the UserManagement module code for a couple of seconds. Suddenly, an\nidea comes to his mind.\nTheo Why not have a type field in member record whose value would be either VIP\nor Super?\nJoe I assume that, according to the product requirements, a member can be both a\nVIP and a Super member.\nTheo Hmm...then the types field could be a collection containing VIP or Super\nor both.\nJoe In some situations, having a types field is helpful, but I find it simpler to have\na Boolean field for each feature that the record supports.\nTheo Is there a name for fields like isVIP and isSuper?\nJoe I call them feature fields.\nTIP Instead of maintaining type information about a record, use a feature field (e.g.,\nisVIP).\n--- Page 96 ---\n68 CHAPTER 3 Basic data manipulation\nTheo Can we use feature fields to differentiate between librarians and members?\nJoe You mean having an isLibrarian and an isMember field?\nTheo Yes, and having a common User record type for both librarians and members.\nJoe We can, but I think it’s simpler to have different record types for librarians and\nmembers: Librarian for librarians and Member for members.\nTheo Why?\nJoe Because there’s a clear distinction between librarians and members in terms of\ndata. For example, members can have book lendings but librarians don’t.\nTheo I agree. Now, we need to mention the two Member feature fields in our entity\ndiagram.\nWith that, Theo adds these fields to his diagram on the whiteboard. When he’s finished, he\nshows Joe his additions (figure 3.6).\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: Catalog\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian *\nCC Book id: String email: String CC Member\nname: String\ntitle : String encryptedPassword: String email: String\nbookIsbns: [String]\npublicationYear: Number encryptedPassword: String\nisbn: String * isBlocked: Boolean\nauthorIds: [String] bookLendings: [BookLending]\nbookItems: [BookItem] * isVIP: Boolean\nisSuper: Boolean\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.6 A library management data model with the Member feature fields isVIP and isSuper\nJoe Do you like the data model that we have designed together?\nTheo I find it quite simple and clear.\n--- Page 97 ---\nSummary 69\nJoe That’s the main goal of DOP.\nTheo Also, I’m pleasantly surprised how easy it is to adapt to changing requirements,\nboth in terms of code and the data model.\nJoe I suppose you’re also happy to get rid of complex class hierarchy diagrams.\nTheo Absolutely! Also, I think I’ve found an interesting connection between DOP\nand meditation.\nJoe Really?\nTheo When we were eating at Simple, you told me that meditation helped you expe-\nrience reality as it is without the filter of your thoughts.\nJoe Right.\nTheo From what you taught me today, I understand that in DOP, we are encouraged\nto treat data as data without the filter of our classes.\nJoe Clever! I never noticed that connection between those two disciplines that are\nso important for me. I guess you’d like to continue your journey in the realm\nof DOP.\nTheo Definitely. Let’s meet again tomorrow.\nJoe Unfortunately, tomorrow I’m taking my family to the beach to celebrate the\ntwelfth birthday of my eldest daughter, Aurelia.\nTheo Happy birthday, Aurelia!\nJoe We could meet again next Monday, if that’s OK with you.\nTheo With pleasure!\nSummary\n DOP principle #2 is to represent data entities with generic data structures.\n We refer to maps that have strings as keys as string maps.\n Representing data as data means representing records with string maps.\n By positional collection, we mean a collection where the elements are in order\n(like a list or an array).\n A positional collection of Strings is noted as [String].\n By index, we mean a collection where the elements are accessible via a key (like\na hash map or a dictionary).\n An index of Books is noted as {Book}.\n In the context of a data model, the index keys are always strings.\n A record is a data structure that groups together related data items. It’s a collec-\ntion of fields, possibly of different data types.\n A homogeneous map is a map where all the values are of the same type.\n A heterogeneous map is a map where the values are of different types.\n In DOP, we represent a record as a heterogeneous string map.\n A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes.\n The relation between records in a data entity diagram is either composition or\nassociation.\n--- Page 98 ---\n70 CHAPTER 3 Basic data manipulation\n The data part of a DOP system is flexible, and each piece of information is\naccessible via its information path.\n There is a tradeoff between flexibility and safety in a data model.\n DOP compromises on data safety to gain flexibility and genericity.\n In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\n We manipulate data with generic functions.\n Generic functions are provided either by the language itself or by third-party\nlibraries like Lodash.\n JSON serialization is implemented in terms of a generic function.\n On the one hand, we’ve lost the safety of accessing record fields via members\ndefined at compile time. On the other hand, we’ve liberated data from the lim-\nitation of classes and objects. Data is represented as data!\n The weak dependency between code and data makes it is easier to adapt to\nchanging requirements.\n When data is represented as data, it is straightforward to visualize system data.\n Usually, we do not need to maintain type information about a record.\n We can visualize any part of the system data.\n In statically-typed languages, we sometimes need to statically cast the field values.\n Instead of maintaining type information about a record, we use a feature field.\n There is no significant performance hit for accessing a field in a map instead of\na class member.\n In DOP, you can retrieve every piece of information via an information path and\na generic function.\n In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\nLodash functions introduced in this chapter\nFunction Description\nget(map, path) Gets the value of map at path\nhas(map, path) Checks if map has a field at path\nmerge(mapA, mapB) Creates a map resulting from the recursive merges between mapA and mapB\nvalues(map) Creates an array of values of map\nfilter(coll, pred) Iterates over elements of coll, returning an array of all elements for which\npred returns true\nmap(coll, f) Creates an array of values by running each element in coll through f\n--- Page 99 ---\nState management\nTime travel\nThis chapter covers\n A multi-version approach to state management\n The calculation phase of a mutation\n The commit phase of a mutation\n Keeping a history of previous state versions\nSo far, we have seen how DOP handles queries via generic functions that access sys-\ntem data, which is represented as a hash map. In this chapter, we illustrate how\nDOP deals with mutations (requests that change the system state). Instead of updat-\ning the state in place, we maintain multiple versions of the system data. At a specific\npoint in time, the system state refers to a specific version of the system data. This\nchapter is a deep dive in the third principle of DOP.\nPRINCIPLE #3 Data is immutable.\nThe maintenance of multiple versions of the system data requires the data to be\nimmutable. This is made efficient both in terms of computation and memory via a\n71\n--- Page 100 ---\n72 CHAPTER 4 State management\ntechnique called structural sharing, where parts of the data that are common between\ntwo versions are shared instead of being copied. In DOP, a mutation is split into two\ndistinct phases:\n In the calculation phase, we compute the next version of the system data.\n In the commit phase, we move the system state forward so that it refers to the\nversion of the system data computed by the calculation phase.\nThis distinction between calculation and commit phases allows us to reduce the part\nof our system that is stateful to its bare minimum. Only the code of the commit phase\nis stateful, while the code in the calculation phase of a mutation is stateless and is\nmade of generic functions similar to the code of a query. The implementation of the\ncommit phase is common to all mutations. As a consequence, inside the commit\nphase, we have the ability to ensure that the state always refers to a valid version of the\nsystem data.\nAnother benefit of this state management approach is that we can keep track of\nthe history of previous versions of the system data. Restoring the system to a previous\nstate (if needed) becomes straightforward. Table 4.1 shows the two phases.\nTable 4.1 The two phases of a mutation\nPhase Responsibility State Implementation\nCalculation Computes the next version of system data Stateless Specific\nCommit Moves the system state forward Stateful Common\nIn this chapter, we assume that no mutations occur concurrently in our system. In the\nnext chapter, we will deal with concurrency control.\n4.1 Multiple versions of the system data\nWhen Joe comes in to the office on Monday, he tells Theo that he needs to exercise before\nstarting to work with his mind. Theo and Joe go for a walk around the block, and the dis-\ncussion turns toward version control systems. They discuss how Git keeps track of the\nwhole commit history and how easy and fast it is to restore the code to a previous state.\nWhen Theo tells Joe that Git’s ability to “time travel” reminds him one of his favorite mov-\nies, Back to the Future, Joe shares that a month ago he watched the Back to the Future trilogy\nwith Neriah, his 14-year-old son.\nTheir walk complete, they arrive back at Theo’s office. Theo and Joe partake of the\nespresso machine in the kitchen before they begin today’s lesson.\nJoe So far, we’ve seen how we manage queries that retrieve information from the\nsystem in DOP. Now I’m going to show you how we manage mutations. By a\nmutation, I mean an operation that changes the state of the system.\n NOTE A mutation is an operation that changes the state of the system.\n--- Page 101 ---\n4.1 Multiple versions of the system data 73\nTheo Is there a fundamental difference between queries and mutations in DOP?\nAfter all, the whole state of the system is represented as a hash map. I could\neasily write code that modifies part of the hash map, and it would be similar to\nthe code that retrieves information from the hash map.\nJoe You could mutate the data in place, but then it would be challenging to ensure\nthat the code of a mutation doesn’t put the system into an invalid date. You\nwould also lose the ability to track previous versions of the system state.\nTheo I see. So, how do you handle mutations in DOP?\nJoe We adopt a multi-version state approach, similar to what a version control sys-\ntem like Git does; we manage different versions of the system data. At a specific\npoint in time, the state of the system refers to a version of the system data. After\na mutation is executed, we move the reference forward.\nTheo I’m confused. Is the system state mutable or immutable?\nJoe The data is immutable, but the state reference is mutable.\nTIP The data is immutable, but the state reference is mutable.\nNoticing the look of confusion on Theo’s face, Joe draws a quick diagram on the white-\nboard. He then shows Theo figure 4.1, hoping that it will clear up Theo’s perplexity.\nAfter mutation B After mutation C\nData V10 Data V10\nMutationA MutationA\nData V11 Data V11\nMutation B Mutation B\nSystem State Data V12 Data V12\nMutation C\nSystem State Data V13\nFigure 4.1 After mutation B is executed, the system state refers to Data V12. After\nmutation C is executed, the system state refers to Data V13.\nTheo Does that mean that before the code of a mutation runs, we make a copy of the\nsystem data?\nJoe No, that would be inefficient, as we would have to do a deep copy of the data.",
        "sections_found": []
      },
      "accurate_page_range": "76-101"
    },
    {
      "text": "- 3.2 Representing records as maps",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "3 Basic data manipulation",
      "raw_line": "- 3.2 Representing records as maps (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 24,
      "chapter_info": {
        "page": 76,
        "title": "Basic data manipulation",
        "pattern_matched": "Chapter 3",
        "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
      },
      "chapter_sections": {
        "start_page": 76,
        "end_page": 101,
        "content": "\n--- Page 76 ---\n48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to say that a data entity diagram consists only of records, positional\ncollections, and indexes?\nJoe That’s correct. Can you make a similar statement about the relations between\nentities?\nTheo The relations in a data entity diagram are either composition (solid line with a\nfull diamond) or association (dashed line with an empty diamond). Both types\nof relations can be either one-to-one, one-to-many, or many-to-many.\nJoe Excellent!\nTIP A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes. The relation between records is either composition or\nassociation.\n3.2 Representing records as maps\nSo far, we’ve illustrated the benefits we gain from the separation between code and\ndata at a high-system level. There’s a separation of concerns between code and data,\nand each part has clear constraints:\n Code consists of static functions that receive data as an explicit argument.\n Data entities are modeled as records, and the relations between records are\nrepresented by positional collections and indexes.\nNow comes the question of the representation of the data. DOP has nothing special\ntosay about collections and indexes. However, it’s strongly opinionated about the\nrepresentation of records: records should be represented by generic data structures\nsuch as maps.\nThis applies to both OOP and FP languages. In dynamically-typed languages like\nJavaScript, Python, and Ruby, data representation feels natural. While in statically-\ntyped languages like Java and C#, it is a bit more cumbersome.\nTheo I’m really curious to know how we represent positional collections, indexes,\nand records in DOP.\nJoe Let’s start with positional collections. DOP has nothing special to say about the\nrepresentation of collections. They can be linked lists, arrays, vectors, sets, or\nother collections best suited for the use case.\nTheo It’s like in OOP.\nJoe Right! For now, to keep things simple, we’ll use arrays to represent positional\ncollections.\nTheo What about indexes?\nJoe Indexes are represented as homogeneous string maps.\nTheo What do you mean by a homogeneous map?\n--- Page 77 ---\n3.2 Representing records as maps 49\nJoe I mean that all the values of the map are of the same kind. For example, in a\nBook index, all the values are Book, and in an author index, all the values are\nAuthor, and so forth.\nTheo Again, it’s like in OOP.\n NOTE A homogeneous map is a map where all the values are of the same type. A hetero-\ngeneous map is a map where the values are of different types.\nJoe Now, here’s the big surprise. In DOP, records are represented as maps, more\nprecisely, heterogeneous string maps.\nJoe goes to the whiteboard and begins to draw. When he’s finished, he shows Theo the dia-\ngram in figure 3.4.\nRecord Heterogeneous map\nLinked list\nArray\nData representation Collection\nSet\nVector\nFigure 3.4 The building blocks\nIndex Homogeneous map\nof data representation\nTheo stays silent for a while. He is shocked to hear that the data entities of a system can be\nrepresented as a generic data structure, where the field names and value types are not\nspecified in a class. Then, Theo asks Joe:\nTheo What are the benefits of this folly?\nJoe Flexibility and genericity.\nTheo Could you explain, please?\nJoe I’ll explain in a moment, but before that, I’d like to show you what an instance\nof a record in a DOP system looks like.\nTheo OK.\nJoe Let’s take as an example, Watchmen, by Alan Moore and Dave Gibbons, which is\nmy favorite graphic novel. This masterpiece was published in 1987. I’m going\nto assume that, in a physical library, there are two copies of this book, whose ID\nis nyc-central-lib, and that one of the two copies is currently out. Here’s\nhow I’d represent the Book record for Watchmen in DOP.\nJoe comes closer to Theo’s laptop. He opens a text editor (not an IDE!) and types the Book\nrecord for Theo.\n--- Page 78 ---\n50 CHAPTER 3 Basic data manipulation\nListing3.1 An instance of a Book record represented as a map\n{\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\nTheo looks at the laptop screen. He has a question.\nTheo How am I supposed to instantiate the Book record for Watchmen programmat-\nically?\nJoe It depends on the facilities that your programming language offers to instantiate\nmaps. With dynamic languages like JavaScript, Ruby, or Python, it’s straight-\nforward, because we can use literals for maps and arrays. Here, let me show\nyou how.\nJoe jots down the JavaScript code that creates an instance of a Book record, which rep-\nresents as a map in JavaScript. He shows the code to Theo.\nListing3.2 A Book record represented as a map in JavaScript\nvar watchmenBook = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n--- Page 79 ---\n3.2 Representing records as maps 51\nTheo And, if I’m in Java?\nJoe It’s a bit more tedious, but still doable with the immutable Map and List static\nfactory methods.\n NOTE See “Creating Immutable Lists, Sets, and Maps” at http://mng.bz/voGm for\nmore information on this Java core library.\nJoe types the Java code to create an instance of a Book record represented as a map. He\nshows Theo the Java code.\nListing3.3 A Book record represented as a map in Java\nMap watchmen = Map.of(\n\"isbn\", \"978-1779501127\",\n\"title\", \"Watchmen\",\n\"publicationYear\", 1987,\n\"authors\", List.of(\"alan-moore\", \"dave-gibbons\"),\n\"bookItems\", List.of(\nMap.of(\n\"id\", \"book-item-1\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", true\n),\nMap.of (\n\"id\", \"book-item-2\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", false\n)\n)\n);\nTIP In DOP, we represent a record as a heterogeneous string map.\nTheo I’d definitely prefer to create a Book record using a Book class and a BookItem\nclass.\nTheo opens his IDE. He types the JavaScript code to represent a Book record as an instance\nof a Book class.\nListing3.4 A Book record as an instance of a Book class in JavaScript\nclass Book {\nisbn;\ntitle;\npublicationYear;\nauthors;\nbookItems;\nconstructor(isbn, title, publicationYear, authors, bookItems) {\nthis.isbn = isbn;\nthis.title = title;\nthis.publicationYear = publicationYear;\nthis.authors = authors;\nthis.bookItems = bookItems;\n--- Page 80 ---\n52 CHAPTER 3 Basic data manipulation\n}\n}\nclass BookItem {\nid;\nlibId;\nisLent;\nconstructor(id, libId, isLent) {\nthis.id = id;\nthis.libId = libId;\nthis.isLent = isLent;\n}\n}\nvar watchmenBook = new Book(\"978-1779501127\",\n\"Watchmen\",\n1987,\n[\"alan-moore\", \"dave-gibbons\"],\n[new BookItem(\"book-item-1\", \"nyc-central-lib\", true),\nnew BookItem(\"book-item-2\", \"nyc-central-lib\", false)]);\nJoe Theo, why do you prefer classes over maps for representing records?\nTheo It makes the data shape of the record part of my program. As a result, the IDE\ncan auto-complete field names, and errors are caught at compile time.\nJoe Fair enough. Can I show you some drawbacks for this approach?\nTheo Sure.\nJoe Imagine that you want to display the information about a book in the context\nof search results. In that case, instead of author IDs, you want to display\nauthor names, and you don’t need the book item information. How would\nyou handle that?\nTheo I’d create a class BookInSearchResults without a bookItems member and\nwith an authorNames member instead of the authorIds member of the Book\nclass. Also, I would need to write a copy constructor that receives a Book object.\nJoe In classic OOP, the fact that data is instantiated only via classes brings safety.\nBut this safety comes at the cost of flexibility.\nTIP There’s a tradeoff between flexibility and safety in a data model.\nTheo So, how can it be different?\nJoe In the DOP approach, where records are represented as maps, we don’t need\nto create a class for each variation of the data. We’re free to add, remove, and\nrename record fields dynamically. Our data model is flexible.\nTheo Interesting!\nTIP In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\nJoe Now, let me talk about genericity. How would you serialize the content of a\nBook object to JSON?\n--- Page 81 ---\n3.2 Representing records as maps 53\nTIP In DOP, records are manipulated with generic functions.\nTheo Oh no! I remember that while working on the Klafim prototype, I had a night-\nmare about JSON serialization when I was developing the first version of the\nLibrary Management System.\nJoe Well, in DOP, serializing a record to JSON is super easy.\nTheo Does it require the usage of reflection in order to go over the fields of the\nrecord like the Gson Java library does?\n NOTE See https://github.com/google/gson for more information on Gson.\nJoe Not at all! Remember that in DOP, a record is nothing more than data. We can\nwrite a generic JSON serialization function that works with any record. It can\nbe a Book, an Author, a BookItem, or anything else.\nTheo Amazing!\nTIP In DOP, you get JSON serialization for free.\nJoe Actually, as I’ll show you in a moment, lots of data manipulation stuff can be\ndone using generic functions.\nTheo Are the generic functions part of the language?\nJoe It depends on the functions and on the language. For example, JavaScript pro-\nvides a JSON serialization function called JSON.stringify out of the box, but\nnone for omitting multiple keys or for renaming keys.\nTheo That’s annoying.\nJoe Not so much; there are third-party libraries that provide data-manipulation facil-\nities. A popular data manipulation library in the JavaScript ecosystem is Lodash.\n NOTE See https://lodash.com/ to find out more about Lodash.\nTheo What about other languages?\nJoe Lodash has been ported to Java, C#, Python, and Ruby. Let me bookmark some\nsites for you.\nJoe bookmarks these sites for Theo:\n https://javalibs.com/artifact/com.github.javadev/underscore-lodash for Java\n https://www.nuget.org/packages/lodash/ for C#\n https://github.com/dgilland/pydash for Python\n https://rudash-website.now.sh/ for Ruby\n NOTE Throughout the book, we use Lodash to show how to manipulate data with\ngeneric functions, but there is nothing special about Lodash. The exact same approach\ncould be implemented via other data manipulation libraries or custom code.\nTheo Cool!\nJoe Actually, Lodash and its rich set of data manipulation functions can be ported\nto any language. That’s why it’s so beneficial to represent records as maps.\n--- Page 82 ---\n54 CHAPTER 3 Basic data manipulation\nTIP DOP compromises on data safety to gain flexibility and genericity.\nAt the whiteboard, Joe quickly sketches the tradeoffs (see table 3.1).\nTable 3.1 The tradeoff among safety, flexibility, and genericity\nOOP DOP\nSafety High Low\nFlexibility Low High\nGenericity Low High\n3.3 Manipulating data with generic functions\nJoe Now let me show you how to manipulate data in DOP with generic functions.\nTheo Yes, I’m quite curious to see how you’ll implement the search functionality of\nthe Library Management System.\nJoe OK. First, let’s instantiate a Catalog record for the catalog data of a library,\nwhere we have a single book, Watchmen.\nJoe instantiates a Catalog record according to Theo’s data model in figure 3.3. Here’s\nwhat Joe shows to Theo.\nListing3.5 A Catalog record\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n--- Page 83 ---\n3.3 Manipulating data with generic functions 55\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\nTheo I see the two indexes we talked about, booksByIsbn and authorsById. How\ndo you differentiate a record from an index in DOP?\nJoe In an entity diagram, there’s a clear distinction between records and indexes.\nBut in our code, both are plain data.\nTheo I guess that’s why this approach is called data-oriented programming.\nJoe See how straightforward it is to visualize any part of the system data inside a\nprogram? The reason is that data is represented as data!\nTIP In DOP, data is represented as data.\nTheo That sounds like a lapalissade.1\nJoe Oh, does it? I’m not so sure! In OOP, data is usually represented by objects,\nwhich makes it more challenging to visualize data inside a program.\nTIP In DOP, we can visualize any part of the system data.\nTheo How would you retrieve the title of a specific book from the catalog data?\nJoe Great question! In fact, in a DOP system, every piece of information has an\ninformation path from which we can retrieve the information.\nTheo Information path?\nJoe For example, the information path to the title of the Watchmen book in the\ncatalog is [\"booksByIsbn\", \"978-1779501127\", \"title\"].\nTheo Ah, I see. So, is an information path sort of like a file path, but that names in\nan information path correspond to nested entities?\nJoe You’re exactly right. And once we have the path of a piece of information, we\ncan retrieve the information with Lodash’s _.get function.\nJoe types a few characters on Theo’s laptop. Theo is amazed at how little code is needed to\nget the book title.\nListing3.6 Retrieving the title of a book from its information path\n_.get(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"])\n// → \"Watchmen\"\nTheo Neat. I wonder how hard it would be to implement a function like _.get\nmyself.\n1 A lapalissade is an obvious truth—a truism or tautology—that produces a comical effect.\n--- Page 84 ---\n56 CHAPTER 3 Basic data manipulation\nAfter a few minutes of trial and error, Theo is able to produce his implementation. He\nshows Joe the code.\nListing3.7 Custom implementation of get\nfunction get(m, path) {\nvar res = m;\nfor(var i = 0; i < path.length; i++) {\nWe could use\nvar key = path[i];\nforEach instead\nres = res[key];\nof a for loop.\n}\nreturn res;\n}\nAfter testing Theo’s implementation of get, Joe compliments Theo. He’s grateful that\nTheo is catching on so quickly.\nListing3.8 Testing the custom implementation of get\nget(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nJoe Well done!\nTheo I wonder if a function like _.get works smoothly in a statically-typed language\nlike Java?\nJoe It depends on whether you only need to pass the value around or to access the\nvalue concretely.\nTheo I don’t follow.\nJoe Imagine that once you get the title of a book, you want to convert the string\ninto an uppercase string. You need to do a static cast to String, right? Here,\nlet me show you an example that casts a field value to a string, then we can\nmanipulate it as a string.\nListing3.9 Casting a field value to a string\n((String)watchmen.get(\"title\")).toUpperCase()\nTheo That makes sense. The values of the map are of different types, so the compiler\ndeclares it as a Map<String,Object>. The information of the type of the field\nis lost.\nJoe It’s a bit annoying, but quite often our code just passes the data around. In that\ncase, we don’t have to deal with static casting. Moreover, in a language like C#,\nwhen using the dynamic data type, type casting can be avoided.2,3\n2 See http://mng.bz/4jo5 for the C# documentation on the built-in reference to dynamic types.\n3 See appendix A for details about dynamic fields and type casting in C#.\n--- Page 85 ---\n3.3 Manipulating data with generic functions 57\nTIP In statically-typed languages, we sometimes need to statically cast the field values.\nTheo What about performance?\nJoe In most programming languages, maps are quite efficient. Accessing a field\nin a map is slightly slower than accessing a class member. Usually, it’s not\nsignificant.\nTIP There’s no significant performance hit for accessing a field in a map instead of as\na class member.\nTheo Let’s get back to this idea of information path. It works in OOP too. I could\naccess the title of the Watchmen book with catalogData.booksByIsbn[\"978-\n1779501127\"].title. I’d use class members for record fields and strings for\nindex keys.\nJoe There’s a fundamental difference, though. When records are represented as\nmaps, the information can be retrieved via its information path using a generic\nfunction like _.get. But when records are represented as objects, you need to\nwrite specific code for each type of information path.\nTheo What do you mean by specific code? What’s specific in catalogData.books-\nByIsbn[\"978-1779501127\"].title?\nJoe In a statically-typed language like Java, you’d need to import the class defini-\ntions for Catalog and Book.\nTheo And, in a dynamically-typed language like JavaScript...?\nJoe Even in JavaScript, when you represent records with objects instantiated from\nclasses, you can’t easily write a function that receives a path as an argument\nand display the information that corresponds to this path. You would have to\nwrite specific code for each kind of path. You’d access class members with dot\nnotation and map fields with bracket notation.\nTheo Would you say that in DOP, the information path is a first-class citizen?\nJoe Absolutely! The information path can be stored in a variable and passed as an\nargument to a function.\nTIP In DOP, you can retrieve every piece of information via a path and a generic\nfunction.\nJoe goes to the whiteboard. He draws a diagram like that in figure 3.5, which shows the\ncatalog data as a tree.\nJoe You see, Theo, each piece of information is accessible via a path made of\nstrings and integers. For example, the path of Alan Moore’s first book is\n[\"catalog\", \"authorsById\", \"alan-moore\", \"bookIsbns\", 0].\n--- Page 86 ---\n58 CHAPTER 3 Basic data manipulation\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 3.5 The catalog data as a tree\n3.4 Calculating search results\nTheo Interesting. I’m starting to feel the power of expression of DOP!\nJoe Wait, that’s just the beginning. Let me show you how simple it is to write code\nthat retrieves book information and displays it in search results. Can you tell\nme exactly what information has to appear in the search results?\nTheo Searching for book information should return isbn, title, and author-\nNames.\nJoe And what would a BookInfo record look like for Watchmen?\nTheo quickly enters the code on his laptop. He then shows it to Joe.\nListing3.10 A BookInfo record for Watchmen in the context of search result\n{\n\"title\": \"Watchmen\",\n\"isbn\": \"978-1779501127\",\n\"authorNames\": [\n\"Alan Moore\",\n\"Dave Gibbons\",\n]\n}\n--- Page 87 ---\n3.4 Calculating search results 59\nJoe Now I’ll show you step by step how to write a function that returns search\nresults matching a title in JSON format. I’ll use generic data manipulation\nfunctions from Lodash.\nTheo I’m ready!\nJoe Let’s start with an authorNames function that calculates the author names of a\nBook record by looking at the authorsById index. Could you tell me what’s\nthe information path for the name of an author whose ID is authorId?\nTheo It’s [\"authorsById\", authorId, \"name\"].\nJoe Now, let me show you how to retrieve the name of several authors using _.map.\nJoe types the code to map the author IDs to the author names. Theo nonchalantly peeks\nover Joe’s shoulder.\nListing3.11 Mapping author IDs to author names\n_.map([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\nTheo What’s this _.map function? It smells like functional programming! You said I\nwouldn’t have to learn FP to implement DOP!\nJoe No need to learn functional programming in order to use _.map, which is a\nfunction that transforms the values of a collection. You can implement it with\na simple for loop.\nTheo spends a couple of minutes in front of his computer figuring out how to implement\n_.map. Now he’s got it!\nListing3.12 Custom implementation of map\nfunction map(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nres[i] = f(coll[i]);\nforEach instead\n}\nof a for loop.\nreturn res;\n}\nAfter testing Theo’s implementation of map, Joe shows Theo the test. Joe again compli-\nments Theo.\nListing3.13 Testing the custom implementation of map\nmap([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\n--- Page 88 ---\n60 CHAPTER 3 Basic data manipulation\nJoe Well done!\nTheo You were right! It wasn’t hard.\nJoe Now, let’s implement authorNames using _.map.\nIt takes a few minutes for Theo to come up with the implementation of authorNames.\nWhen he’s finished, he turns his laptop to Joe.\nListing3.14 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nJoe We also need a bookInfo function that converts a Book record into a Book-\nInfo record. Let me show you the code for that.\nListing3.15 Converting a Book record into a BookInfo record\nfunction bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": authorNames(catalogData, book)\n};\nThere’s no need to create\nreturn bookInfo;\na class for bookInfo.\n}\nTheo Looking at the code, I see that a BookInfo record has three fields: title,\nisbn, and authorNames. Is there a way to get this information without looking\nat the code?\nJoe You can either add it to the data entity diagram or write it in the documenta-\ntion of the bookInfo function, or both.\nTheo I have to get used to the idea that in DOP, the record field information is not\npart of the program.\nJoe Indeed, it’s not part of the program, but it gives us a lot of flexibility.\nTheo Is there any way for me to have my cake and eat it too?\nJoe Yes, and someday I’ll show you how to make record field information part of a\nDOP program (see chapters 7 and 12).\nTheo Sounds intriguing!\nJoe Now that we have all the pieces in place, we can write our searchBooksBy-\nTitle function, which returns the book information about the books that\nmatch the query. First, we find the Book records that match the query with\n_.filter and then we transform each Book record into a BookInfo record\nwith _.map and bookInfo.\n--- Page 89 ---\n3.4 Calculating search results 61\nListing3.16 Searching books that match a query\nfunction searchBooksByTitle(catalogData, query) {\nvar allBooks = _.values(_.get(catalogData, \"booksByIsbn\"));\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\nThe includes JavaScript\n});\nfunction checks whether\na string includes a string\nvar bookInfos = _.map(matchingBooks, function(book) { as a substring.\nreturn bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\nTheo You’re using Lodash functions without any explanation again!\nJoe Sorry about that. I am so used to basic data manipulation functions that I con-\nsider them as part of the language. What functions are new to you?\nTheo _.values and _.filter\nJoe Well, _.values returns a collection made of the values of a map, and _.filter\nreturns a collection made of the values that satisfy a predicate.\nTheo _.values seems trivial. Let me try to implement _.filter.\nThe implementation of _.filter takes a bit more time. Eventually, Theo manages to get\nit right, then he is able to test it.\nListing3.17 Custom implementation of filter\nfunction filter(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nif(f(coll[i])) {\nforEach instead\nres.push(coll[i]);\nof a for loop.\n}\n}\nreturn res;\n}\nListing3.18 Testing the custom implementation of filter\nfilter([\"Watchmen\", \"Batman\"], function (title) {\nreturn title.includes(\"Watch\");\n});\n// → [\"Watchmen\"]\nTheo To me, it’s a bit weird that to access the title of a book record, I need to write\n_.get(book, \"title\"). I’d expect it to be book.title in dot notation or\nbook[\"title\"] in bracket notation.\nJoe Remember that book is a record that’s not represented as an object. It’s a map.\nIndeed, in JavaScript, you can write _.get(book, \"title\"), book.title, or\nbook[\"title\"]. But I prefer to use Lodash’s _.get function. In some lan-\nguages, the dot and the bracket notations might not work on maps.\n--- Page 90 ---\n62 CHAPTER 3 Basic data manipulation\nTheo Being language-agnostic has a price!\nJoe Right, would you like to test searchBooksByTitle?\nTheo Absolutely! Let me call searchBooksByTitle to search the books whose title\ncontain the string Watch.\nListing3.19 Testing searchBooksByTitle\nsearchBooksByTitle(catalogData, \"Wat\");\n//[\n// {\n// \"authorNames\": [\n// \"Alan Moore\",\n// \"Dave Gibbons\"\n// ],\n// \"isbn\": \"978-1779501127\",\n// \"title\": \"Watchmen\"\n// }\n//]\nTheo It seems to work! Are we done with the search implementation?\nJoe Almost. The searchBooksByTitle function we wrote is going to be part of the\nCatalog module, and it returns a collection of records. We have to write a\nfunction that’s part of the Library module, and that returns a JSON string.\nTheo You told me earlier that JSON serialization was straightforward in DOP.\nJoe Correct. The code for searchBooksByTitleJSON retrieves the Catalog record,\npasses it to searchBooksByTitle, and converts the results to JSON with\nJSON.stringify. That’s part of JavaScript. Here, let me show you.\nListing3.20 Implementation of searching books in a library as JSON\nfunction searchBooksByTitleJSON(libraryData, query) {\nvar results = searchBooksByTitle(_.get(libraryData, \"catalog\"), query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\nJoe In order to test our code, we need to create a Library record that contains our\nCatalog record. Could you do that for me, please?\nTheo Should the Library record contain all the Library fields (name, address,\nand UserManagement)?\nJoe That’s not necessary. For now, we only need the catalog field, then the test\nfor searching books.\nListing3.21 A Library record\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n--- Page 91 ---\n3.4 Calculating search results 63\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nListing3.22 Test for searching books in a library as JSON\nsearchBooksByTitleJSON(libraryData, \"Wat\");\nTheo How are we going to combine the four functions that we’ve written so far?\nJoe The functions authorNames, bookInfo, and searchBooksByTitle go into\nthe Catalog module, and searchBooksByTitleJSON goes into the Library\nmodule.\nTheo looks at the resulting code of the two modules, Library and Catalog. He’s quite\namazed by its conciseness.\nListing3.23 Calculating search results for Library and Catalog\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\n--- Page 92 ---\n64 CHAPTER 3 Basic data manipulation\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nThere’s no need\nreturn bookInfo;\nto create a class\n}\nfor bookInfo.\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nWhen _.filter is\nvar matchingBooks = _.filter(allBooks,\npassed a map, it\nfunction(book) {\ngoes over the values\nreturn _.get(book, \"title\").includes(query);\nof the map.\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nConverts data\nreturn resultsJSON;\nto JSON (part\n}\nof JavaScript)\n}\nAfter testing the final code in listing 3.24, Theo looks again at the source code from list-\ning 3.23. After a few seconds, he feels like he’s having another Aha! moment.\nListing3.24 Search results in JSON\nLibrary.searchBooksByTitleJSON(libraryData, \"Watchmen\");\n// → \"[{\\\"title\\\":\\\"Watchmen\\\",\\\"isbn\\\":\\\"978-1779501127\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}]\"\nTheo The important thing is not that the code is concise, but that the code contains\nno abstractions. It’s just data manipulation!\nJoe responds with a smile that says, “You got it, my friend!”\nJoe It reminds me of what my first meditation teacher told me 10 years ago:\nmeditation guides the mind to grasp the reality as it is without the abstractions\ncreated by our thoughts.\nTIP In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\n--- Page 93 ---\n3.5 Handling records of different types 65\n3.5 Handling records of different types\nWe’ve seen how DOP enables us to treat records as first-class citizens that can be\nmanipulated in a flexible way using generic functions. But if a record is nothing more\nthan an aggregation of fields, how do we know what the type of the record is? DOP has\na surprising answer to this question.\nTheo I have a question. If a record is nothing more than a map, how do you know\nthe type of the record?\nJoe That’s a great question with a surprising answer.\nTheo I’m curious.\nJoe Most of the time, there’s no need to know the record type.\nTheo What! What do you mean?\nJoe I mean that what matters most are the values of the fields. For example, take a\nlook at the Catalog.authorNames source code. It operates on a Book record,\nbut the only thing that matters is the value of the authorIds field.\nDoubtful, Theo looks at the source code for Catalog.authorNames. This is what Theo sees.\nListing3.25 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nTheo What about differentiating between various user types like Member versus\nLibrarian? I mean, they both have email and encryptedPassword. How do\nyou know if a record represents a Member or a Librarian?\nJoe Simple. You check to see if the record is found in the librariansByEmail\nindex or in the membersByEmail index of the Catalog.\nTheo Could you be more specific?\nJoe Sure! Let me write what the user management data of our tiny library might\nlook like, assuming we have one librarian and one member. To keep things\nsimple, I’m encrypting passwords through naive base-64 encoding for the User-\nManagement record.\nListing3.26 A UserManagement record\nvar userManagementData = {\n\"librariansByEmail\": {\n\"franck@gmail.com\" : { The base-64\nencoding of\n\"email\": \"franck@gmail.com\",\n\"mypassword\"\n\"encryptedPassword\": \"bXlwYXNzd29yZA==\"\n}\n},\n--- Page 94 ---\n66 CHAPTER 3 Basic data manipulation\n\"membersByEmail\": {\n\"samantha@gmail.com\": {\n\"email\": \"samantha@gmail.com\",\n\"encryptedPassword\": \"c2VjcmV0\",\nThe base-64\n\"isBlocked\": false,\nencoding of\n\"bookLendings\": [\n\"secret\"\n{\n\"bookItemId\": \"book-item-1\",\n\"bookIsbn\": \"978-1779501127\",\n\"lendingDate\": \"2020-04-23\"\n}\n]\n}\n}\n}\nTIP Most of the time, there’s no need to know the record type.\nTheo This morning, you told me you’d show me the code for UserManagement\n.isLibrarian function this afternoon.\nJoe So, here we are. It’s afternoon, and I’m going to fulfill my promise.\nJoe implements isLibrarian. With a slight pause, he then issues the test for isLibrarian.\nListing3.27 Checking if a user is a librarian\nfunction isLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nListing3.28 Testing isLibrarian\nisLibrarian(userManagementData, \"franck@gmail.com\");\n// → true\nTheo I’m assuming that _.has is a function that checks whether a key exists in a\nmap. Right?\nJoe Correct.\nTheo OK. You simply check whether the librariansByEmail map contains the\nemail field.\nJoe Yep.\nTheo Would you use the same pattern to check whether a member is a Super mem-\nber or a VIP member?\nJoe Sure. We could have SuperMembersByEmail and VIPMembersByEmail indexes.\nBut there’s a better way.\nTheo How?\nJoe When a member is a VIP member, we add a field, isVIP, with the value true to\nits record. To check if a member is a VIP member, we check whether the\nisVIP field is set to true in the member record. Here’s how I would code\nisVIPMember.\n--- Page 95 ---\n3.5 Handling records of different types 67\nListing3.29 Checking whether a member is a VIP member\nfunction isVIPMember(userManagement, email) {\nreturn _.get(userManagement, [\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nTheo I see that you access the isVIP field via its information path, [\"membersBy-\nEmail\", email, \"isVIP\"].\nJoe Yes, I think it makes the code crystal clear.\nTheo I agree. I guess we can do the same for isSuperMember and set an isSuper\nfield to true when a member is a Super member?\nJoe Yes, just like this.\nJoe assembles all the pieces in a UserManagement class. He then shows the code to Theo.\nListing3.30 The code of UserManagement module\nclass UserManagement {\nisLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nisVIPMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nisSuperMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isSuper\"]) == true;\n}\n}\nTheo looks at the UserManagement module code for a couple of seconds. Suddenly, an\nidea comes to his mind.\nTheo Why not have a type field in member record whose value would be either VIP\nor Super?\nJoe I assume that, according to the product requirements, a member can be both a\nVIP and a Super member.\nTheo Hmm...then the types field could be a collection containing VIP or Super\nor both.\nJoe In some situations, having a types field is helpful, but I find it simpler to have\na Boolean field for each feature that the record supports.\nTheo Is there a name for fields like isVIP and isSuper?\nJoe I call them feature fields.\nTIP Instead of maintaining type information about a record, use a feature field (e.g.,\nisVIP).\n--- Page 96 ---\n68 CHAPTER 3 Basic data manipulation\nTheo Can we use feature fields to differentiate between librarians and members?\nJoe You mean having an isLibrarian and an isMember field?\nTheo Yes, and having a common User record type for both librarians and members.\nJoe We can, but I think it’s simpler to have different record types for librarians and\nmembers: Librarian for librarians and Member for members.\nTheo Why?\nJoe Because there’s a clear distinction between librarians and members in terms of\ndata. For example, members can have book lendings but librarians don’t.\nTheo I agree. Now, we need to mention the two Member feature fields in our entity\ndiagram.\nWith that, Theo adds these fields to his diagram on the whiteboard. When he’s finished, he\nshows Joe his additions (figure 3.6).\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: Catalog\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian *\nCC Book id: String email: String CC Member\nname: String\ntitle : String encryptedPassword: String email: String\nbookIsbns: [String]\npublicationYear: Number encryptedPassword: String\nisbn: String * isBlocked: Boolean\nauthorIds: [String] bookLendings: [BookLending]\nbookItems: [BookItem] * isVIP: Boolean\nisSuper: Boolean\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.6 A library management data model with the Member feature fields isVIP and isSuper\nJoe Do you like the data model that we have designed together?\nTheo I find it quite simple and clear.\n--- Page 97 ---\nSummary 69\nJoe That’s the main goal of DOP.\nTheo Also, I’m pleasantly surprised how easy it is to adapt to changing requirements,\nboth in terms of code and the data model.\nJoe I suppose you’re also happy to get rid of complex class hierarchy diagrams.\nTheo Absolutely! Also, I think I’ve found an interesting connection between DOP\nand meditation.\nJoe Really?\nTheo When we were eating at Simple, you told me that meditation helped you expe-\nrience reality as it is without the filter of your thoughts.\nJoe Right.\nTheo From what you taught me today, I understand that in DOP, we are encouraged\nto treat data as data without the filter of our classes.\nJoe Clever! I never noticed that connection between those two disciplines that are\nso important for me. I guess you’d like to continue your journey in the realm\nof DOP.\nTheo Definitely. Let’s meet again tomorrow.\nJoe Unfortunately, tomorrow I’m taking my family to the beach to celebrate the\ntwelfth birthday of my eldest daughter, Aurelia.\nTheo Happy birthday, Aurelia!\nJoe We could meet again next Monday, if that’s OK with you.\nTheo With pleasure!\nSummary\n DOP principle #2 is to represent data entities with generic data structures.\n We refer to maps that have strings as keys as string maps.\n Representing data as data means representing records with string maps.\n By positional collection, we mean a collection where the elements are in order\n(like a list or an array).\n A positional collection of Strings is noted as [String].\n By index, we mean a collection where the elements are accessible via a key (like\na hash map or a dictionary).\n An index of Books is noted as {Book}.\n In the context of a data model, the index keys are always strings.\n A record is a data structure that groups together related data items. It’s a collec-\ntion of fields, possibly of different data types.\n A homogeneous map is a map where all the values are of the same type.\n A heterogeneous map is a map where the values are of different types.\n In DOP, we represent a record as a heterogeneous string map.\n A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes.\n The relation between records in a data entity diagram is either composition or\nassociation.\n--- Page 98 ---\n70 CHAPTER 3 Basic data manipulation\n The data part of a DOP system is flexible, and each piece of information is\naccessible via its information path.\n There is a tradeoff between flexibility and safety in a data model.\n DOP compromises on data safety to gain flexibility and genericity.\n In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\n We manipulate data with generic functions.\n Generic functions are provided either by the language itself or by third-party\nlibraries like Lodash.\n JSON serialization is implemented in terms of a generic function.\n On the one hand, we’ve lost the safety of accessing record fields via members\ndefined at compile time. On the other hand, we’ve liberated data from the lim-\nitation of classes and objects. Data is represented as data!\n The weak dependency between code and data makes it is easier to adapt to\nchanging requirements.\n When data is represented as data, it is straightforward to visualize system data.\n Usually, we do not need to maintain type information about a record.\n We can visualize any part of the system data.\n In statically-typed languages, we sometimes need to statically cast the field values.\n Instead of maintaining type information about a record, we use a feature field.\n There is no significant performance hit for accessing a field in a map instead of\na class member.\n In DOP, you can retrieve every piece of information via an information path and\na generic function.\n In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\nLodash functions introduced in this chapter\nFunction Description\nget(map, path) Gets the value of map at path\nhas(map, path) Checks if map has a field at path\nmerge(mapA, mapB) Creates a map resulting from the recursive merges between mapA and mapB\nvalues(map) Creates an array of values of map\nfilter(coll, pred) Iterates over elements of coll, returning an array of all elements for which\npred returns true\nmap(coll, f) Creates an array of values by running each element in coll through f\n--- Page 99 ---\nState management\nTime travel\nThis chapter covers\n A multi-version approach to state management\n The calculation phase of a mutation\n The commit phase of a mutation\n Keeping a history of previous state versions\nSo far, we have seen how DOP handles queries via generic functions that access sys-\ntem data, which is represented as a hash map. In this chapter, we illustrate how\nDOP deals with mutations (requests that change the system state). Instead of updat-\ning the state in place, we maintain multiple versions of the system data. At a specific\npoint in time, the system state refers to a specific version of the system data. This\nchapter is a deep dive in the third principle of DOP.\nPRINCIPLE #3 Data is immutable.\nThe maintenance of multiple versions of the system data requires the data to be\nimmutable. This is made efficient both in terms of computation and memory via a\n71\n--- Page 100 ---\n72 CHAPTER 4 State management\ntechnique called structural sharing, where parts of the data that are common between\ntwo versions are shared instead of being copied. In DOP, a mutation is split into two\ndistinct phases:\n In the calculation phase, we compute the next version of the system data.\n In the commit phase, we move the system state forward so that it refers to the\nversion of the system data computed by the calculation phase.\nThis distinction between calculation and commit phases allows us to reduce the part\nof our system that is stateful to its bare minimum. Only the code of the commit phase\nis stateful, while the code in the calculation phase of a mutation is stateless and is\nmade of generic functions similar to the code of a query. The implementation of the\ncommit phase is common to all mutations. As a consequence, inside the commit\nphase, we have the ability to ensure that the state always refers to a valid version of the\nsystem data.\nAnother benefit of this state management approach is that we can keep track of\nthe history of previous versions of the system data. Restoring the system to a previous\nstate (if needed) becomes straightforward. Table 4.1 shows the two phases.\nTable 4.1 The two phases of a mutation\nPhase Responsibility State Implementation\nCalculation Computes the next version of system data Stateless Specific\nCommit Moves the system state forward Stateful Common\nIn this chapter, we assume that no mutations occur concurrently in our system. In the\nnext chapter, we will deal with concurrency control.\n4.1 Multiple versions of the system data\nWhen Joe comes in to the office on Monday, he tells Theo that he needs to exercise before\nstarting to work with his mind. Theo and Joe go for a walk around the block, and the dis-\ncussion turns toward version control systems. They discuss how Git keeps track of the\nwhole commit history and how easy and fast it is to restore the code to a previous state.\nWhen Theo tells Joe that Git’s ability to “time travel” reminds him one of his favorite mov-\nies, Back to the Future, Joe shares that a month ago he watched the Back to the Future trilogy\nwith Neriah, his 14-year-old son.\nTheir walk complete, they arrive back at Theo’s office. Theo and Joe partake of the\nespresso machine in the kitchen before they begin today’s lesson.\nJoe So far, we’ve seen how we manage queries that retrieve information from the\nsystem in DOP. Now I’m going to show you how we manage mutations. By a\nmutation, I mean an operation that changes the state of the system.\n NOTE A mutation is an operation that changes the state of the system.\n--- Page 101 ---\n4.1 Multiple versions of the system data 73\nTheo Is there a fundamental difference between queries and mutations in DOP?\nAfter all, the whole state of the system is represented as a hash map. I could\neasily write code that modifies part of the hash map, and it would be similar to\nthe code that retrieves information from the hash map.\nJoe You could mutate the data in place, but then it would be challenging to ensure\nthat the code of a mutation doesn’t put the system into an invalid date. You\nwould also lose the ability to track previous versions of the system state.\nTheo I see. So, how do you handle mutations in DOP?\nJoe We adopt a multi-version state approach, similar to what a version control sys-\ntem like Git does; we manage different versions of the system data. At a specific\npoint in time, the state of the system refers to a version of the system data. After\na mutation is executed, we move the reference forward.\nTheo I’m confused. Is the system state mutable or immutable?\nJoe The data is immutable, but the state reference is mutable.\nTIP The data is immutable, but the state reference is mutable.\nNoticing the look of confusion on Theo’s face, Joe draws a quick diagram on the white-\nboard. He then shows Theo figure 4.1, hoping that it will clear up Theo’s perplexity.\nAfter mutation B After mutation C\nData V10 Data V10\nMutationA MutationA\nData V11 Data V11\nMutation B Mutation B\nSystem State Data V12 Data V12\nMutation C\nSystem State Data V13\nFigure 4.1 After mutation B is executed, the system state refers to Data V12. After\nmutation C is executed, the system state refers to Data V13.\nTheo Does that mean that before the code of a mutation runs, we make a copy of the\nsystem data?\nJoe No, that would be inefficient, as we would have to do a deep copy of the data.",
        "sections_found": []
      },
      "accurate_page_range": "76-101"
    },
    {
      "text": "- 3.3 Manipulating data with generic functions",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "3 Basic data manipulation",
      "raw_line": "- 3.3 Manipulating data with generic functions (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 25,
      "chapter_info": {
        "page": 76,
        "title": "Basic data manipulation",
        "pattern_matched": "Chapter 3",
        "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
      },
      "chapter_sections": {
        "start_page": 76,
        "end_page": 101,
        "content": "\n--- Page 76 ---\n48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to say that a data entity diagram consists only of records, positional\ncollections, and indexes?\nJoe That’s correct. Can you make a similar statement about the relations between\nentities?\nTheo The relations in a data entity diagram are either composition (solid line with a\nfull diamond) or association (dashed line with an empty diamond). Both types\nof relations can be either one-to-one, one-to-many, or many-to-many.\nJoe Excellent!\nTIP A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes. The relation between records is either composition or\nassociation.\n3.2 Representing records as maps\nSo far, we’ve illustrated the benefits we gain from the separation between code and\ndata at a high-system level. There’s a separation of concerns between code and data,\nand each part has clear constraints:\n Code consists of static functions that receive data as an explicit argument.\n Data entities are modeled as records, and the relations between records are\nrepresented by positional collections and indexes.\nNow comes the question of the representation of the data. DOP has nothing special\ntosay about collections and indexes. However, it’s strongly opinionated about the\nrepresentation of records: records should be represented by generic data structures\nsuch as maps.\nThis applies to both OOP and FP languages. In dynamically-typed languages like\nJavaScript, Python, and Ruby, data representation feels natural. While in statically-\ntyped languages like Java and C#, it is a bit more cumbersome.\nTheo I’m really curious to know how we represent positional collections, indexes,\nand records in DOP.\nJoe Let’s start with positional collections. DOP has nothing special to say about the\nrepresentation of collections. They can be linked lists, arrays, vectors, sets, or\nother collections best suited for the use case.\nTheo It’s like in OOP.\nJoe Right! For now, to keep things simple, we’ll use arrays to represent positional\ncollections.\nTheo What about indexes?\nJoe Indexes are represented as homogeneous string maps.\nTheo What do you mean by a homogeneous map?\n--- Page 77 ---\n3.2 Representing records as maps 49\nJoe I mean that all the values of the map are of the same kind. For example, in a\nBook index, all the values are Book, and in an author index, all the values are\nAuthor, and so forth.\nTheo Again, it’s like in OOP.\n NOTE A homogeneous map is a map where all the values are of the same type. A hetero-\ngeneous map is a map where the values are of different types.\nJoe Now, here’s the big surprise. In DOP, records are represented as maps, more\nprecisely, heterogeneous string maps.\nJoe goes to the whiteboard and begins to draw. When he’s finished, he shows Theo the dia-\ngram in figure 3.4.\nRecord Heterogeneous map\nLinked list\nArray\nData representation Collection\nSet\nVector\nFigure 3.4 The building blocks\nIndex Homogeneous map\nof data representation\nTheo stays silent for a while. He is shocked to hear that the data entities of a system can be\nrepresented as a generic data structure, where the field names and value types are not\nspecified in a class. Then, Theo asks Joe:\nTheo What are the benefits of this folly?\nJoe Flexibility and genericity.\nTheo Could you explain, please?\nJoe I’ll explain in a moment, but before that, I’d like to show you what an instance\nof a record in a DOP system looks like.\nTheo OK.\nJoe Let’s take as an example, Watchmen, by Alan Moore and Dave Gibbons, which is\nmy favorite graphic novel. This masterpiece was published in 1987. I’m going\nto assume that, in a physical library, there are two copies of this book, whose ID\nis nyc-central-lib, and that one of the two copies is currently out. Here’s\nhow I’d represent the Book record for Watchmen in DOP.\nJoe comes closer to Theo’s laptop. He opens a text editor (not an IDE!) and types the Book\nrecord for Theo.\n--- Page 78 ---\n50 CHAPTER 3 Basic data manipulation\nListing3.1 An instance of a Book record represented as a map\n{\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\nTheo looks at the laptop screen. He has a question.\nTheo How am I supposed to instantiate the Book record for Watchmen programmat-\nically?\nJoe It depends on the facilities that your programming language offers to instantiate\nmaps. With dynamic languages like JavaScript, Ruby, or Python, it’s straight-\nforward, because we can use literals for maps and arrays. Here, let me show\nyou how.\nJoe jots down the JavaScript code that creates an instance of a Book record, which rep-\nresents as a map in JavaScript. He shows the code to Theo.\nListing3.2 A Book record represented as a map in JavaScript\nvar watchmenBook = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n--- Page 79 ---\n3.2 Representing records as maps 51\nTheo And, if I’m in Java?\nJoe It’s a bit more tedious, but still doable with the immutable Map and List static\nfactory methods.\n NOTE See “Creating Immutable Lists, Sets, and Maps” at http://mng.bz/voGm for\nmore information on this Java core library.\nJoe types the Java code to create an instance of a Book record represented as a map. He\nshows Theo the Java code.\nListing3.3 A Book record represented as a map in Java\nMap watchmen = Map.of(\n\"isbn\", \"978-1779501127\",\n\"title\", \"Watchmen\",\n\"publicationYear\", 1987,\n\"authors\", List.of(\"alan-moore\", \"dave-gibbons\"),\n\"bookItems\", List.of(\nMap.of(\n\"id\", \"book-item-1\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", true\n),\nMap.of (\n\"id\", \"book-item-2\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", false\n)\n)\n);\nTIP In DOP, we represent a record as a heterogeneous string map.\nTheo I’d definitely prefer to create a Book record using a Book class and a BookItem\nclass.\nTheo opens his IDE. He types the JavaScript code to represent a Book record as an instance\nof a Book class.\nListing3.4 A Book record as an instance of a Book class in JavaScript\nclass Book {\nisbn;\ntitle;\npublicationYear;\nauthors;\nbookItems;\nconstructor(isbn, title, publicationYear, authors, bookItems) {\nthis.isbn = isbn;\nthis.title = title;\nthis.publicationYear = publicationYear;\nthis.authors = authors;\nthis.bookItems = bookItems;\n--- Page 80 ---\n52 CHAPTER 3 Basic data manipulation\n}\n}\nclass BookItem {\nid;\nlibId;\nisLent;\nconstructor(id, libId, isLent) {\nthis.id = id;\nthis.libId = libId;\nthis.isLent = isLent;\n}\n}\nvar watchmenBook = new Book(\"978-1779501127\",\n\"Watchmen\",\n1987,\n[\"alan-moore\", \"dave-gibbons\"],\n[new BookItem(\"book-item-1\", \"nyc-central-lib\", true),\nnew BookItem(\"book-item-2\", \"nyc-central-lib\", false)]);\nJoe Theo, why do you prefer classes over maps for representing records?\nTheo It makes the data shape of the record part of my program. As a result, the IDE\ncan auto-complete field names, and errors are caught at compile time.\nJoe Fair enough. Can I show you some drawbacks for this approach?\nTheo Sure.\nJoe Imagine that you want to display the information about a book in the context\nof search results. In that case, instead of author IDs, you want to display\nauthor names, and you don’t need the book item information. How would\nyou handle that?\nTheo I’d create a class BookInSearchResults without a bookItems member and\nwith an authorNames member instead of the authorIds member of the Book\nclass. Also, I would need to write a copy constructor that receives a Book object.\nJoe In classic OOP, the fact that data is instantiated only via classes brings safety.\nBut this safety comes at the cost of flexibility.\nTIP There’s a tradeoff between flexibility and safety in a data model.\nTheo So, how can it be different?\nJoe In the DOP approach, where records are represented as maps, we don’t need\nto create a class for each variation of the data. We’re free to add, remove, and\nrename record fields dynamically. Our data model is flexible.\nTheo Interesting!\nTIP In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\nJoe Now, let me talk about genericity. How would you serialize the content of a\nBook object to JSON?\n--- Page 81 ---\n3.2 Representing records as maps 53\nTIP In DOP, records are manipulated with generic functions.\nTheo Oh no! I remember that while working on the Klafim prototype, I had a night-\nmare about JSON serialization when I was developing the first version of the\nLibrary Management System.\nJoe Well, in DOP, serializing a record to JSON is super easy.\nTheo Does it require the usage of reflection in order to go over the fields of the\nrecord like the Gson Java library does?\n NOTE See https://github.com/google/gson for more information on Gson.\nJoe Not at all! Remember that in DOP, a record is nothing more than data. We can\nwrite a generic JSON serialization function that works with any record. It can\nbe a Book, an Author, a BookItem, or anything else.\nTheo Amazing!\nTIP In DOP, you get JSON serialization for free.\nJoe Actually, as I’ll show you in a moment, lots of data manipulation stuff can be\ndone using generic functions.\nTheo Are the generic functions part of the language?\nJoe It depends on the functions and on the language. For example, JavaScript pro-\nvides a JSON serialization function called JSON.stringify out of the box, but\nnone for omitting multiple keys or for renaming keys.\nTheo That’s annoying.\nJoe Not so much; there are third-party libraries that provide data-manipulation facil-\nities. A popular data manipulation library in the JavaScript ecosystem is Lodash.\n NOTE See https://lodash.com/ to find out more about Lodash.\nTheo What about other languages?\nJoe Lodash has been ported to Java, C#, Python, and Ruby. Let me bookmark some\nsites for you.\nJoe bookmarks these sites for Theo:\n https://javalibs.com/artifact/com.github.javadev/underscore-lodash for Java\n https://www.nuget.org/packages/lodash/ for C#\n https://github.com/dgilland/pydash for Python\n https://rudash-website.now.sh/ for Ruby\n NOTE Throughout the book, we use Lodash to show how to manipulate data with\ngeneric functions, but there is nothing special about Lodash. The exact same approach\ncould be implemented via other data manipulation libraries or custom code.\nTheo Cool!\nJoe Actually, Lodash and its rich set of data manipulation functions can be ported\nto any language. That’s why it’s so beneficial to represent records as maps.\n--- Page 82 ---\n54 CHAPTER 3 Basic data manipulation\nTIP DOP compromises on data safety to gain flexibility and genericity.\nAt the whiteboard, Joe quickly sketches the tradeoffs (see table 3.1).\nTable 3.1 The tradeoff among safety, flexibility, and genericity\nOOP DOP\nSafety High Low\nFlexibility Low High\nGenericity Low High\n3.3 Manipulating data with generic functions\nJoe Now let me show you how to manipulate data in DOP with generic functions.\nTheo Yes, I’m quite curious to see how you’ll implement the search functionality of\nthe Library Management System.\nJoe OK. First, let’s instantiate a Catalog record for the catalog data of a library,\nwhere we have a single book, Watchmen.\nJoe instantiates a Catalog record according to Theo’s data model in figure 3.3. Here’s\nwhat Joe shows to Theo.\nListing3.5 A Catalog record\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n--- Page 83 ---\n3.3 Manipulating data with generic functions 55\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\nTheo I see the two indexes we talked about, booksByIsbn and authorsById. How\ndo you differentiate a record from an index in DOP?\nJoe In an entity diagram, there’s a clear distinction between records and indexes.\nBut in our code, both are plain data.\nTheo I guess that’s why this approach is called data-oriented programming.\nJoe See how straightforward it is to visualize any part of the system data inside a\nprogram? The reason is that data is represented as data!\nTIP In DOP, data is represented as data.\nTheo That sounds like a lapalissade.1\nJoe Oh, does it? I’m not so sure! In OOP, data is usually represented by objects,\nwhich makes it more challenging to visualize data inside a program.\nTIP In DOP, we can visualize any part of the system data.\nTheo How would you retrieve the title of a specific book from the catalog data?\nJoe Great question! In fact, in a DOP system, every piece of information has an\ninformation path from which we can retrieve the information.\nTheo Information path?\nJoe For example, the information path to the title of the Watchmen book in the\ncatalog is [\"booksByIsbn\", \"978-1779501127\", \"title\"].\nTheo Ah, I see. So, is an information path sort of like a file path, but that names in\nan information path correspond to nested entities?\nJoe You’re exactly right. And once we have the path of a piece of information, we\ncan retrieve the information with Lodash’s _.get function.\nJoe types a few characters on Theo’s laptop. Theo is amazed at how little code is needed to\nget the book title.\nListing3.6 Retrieving the title of a book from its information path\n_.get(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"])\n// → \"Watchmen\"\nTheo Neat. I wonder how hard it would be to implement a function like _.get\nmyself.\n1 A lapalissade is an obvious truth—a truism or tautology—that produces a comical effect.\n--- Page 84 ---\n56 CHAPTER 3 Basic data manipulation\nAfter a few minutes of trial and error, Theo is able to produce his implementation. He\nshows Joe the code.\nListing3.7 Custom implementation of get\nfunction get(m, path) {\nvar res = m;\nfor(var i = 0; i < path.length; i++) {\nWe could use\nvar key = path[i];\nforEach instead\nres = res[key];\nof a for loop.\n}\nreturn res;\n}\nAfter testing Theo’s implementation of get, Joe compliments Theo. He’s grateful that\nTheo is catching on so quickly.\nListing3.8 Testing the custom implementation of get\nget(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nJoe Well done!\nTheo I wonder if a function like _.get works smoothly in a statically-typed language\nlike Java?\nJoe It depends on whether you only need to pass the value around or to access the\nvalue concretely.\nTheo I don’t follow.\nJoe Imagine that once you get the title of a book, you want to convert the string\ninto an uppercase string. You need to do a static cast to String, right? Here,\nlet me show you an example that casts a field value to a string, then we can\nmanipulate it as a string.\nListing3.9 Casting a field value to a string\n((String)watchmen.get(\"title\")).toUpperCase()\nTheo That makes sense. The values of the map are of different types, so the compiler\ndeclares it as a Map<String,Object>. The information of the type of the field\nis lost.\nJoe It’s a bit annoying, but quite often our code just passes the data around. In that\ncase, we don’t have to deal with static casting. Moreover, in a language like C#,\nwhen using the dynamic data type, type casting can be avoided.2,3\n2 See http://mng.bz/4jo5 for the C# documentation on the built-in reference to dynamic types.\n3 See appendix A for details about dynamic fields and type casting in C#.\n--- Page 85 ---\n3.3 Manipulating data with generic functions 57\nTIP In statically-typed languages, we sometimes need to statically cast the field values.\nTheo What about performance?\nJoe In most programming languages, maps are quite efficient. Accessing a field\nin a map is slightly slower than accessing a class member. Usually, it’s not\nsignificant.\nTIP There’s no significant performance hit for accessing a field in a map instead of as\na class member.\nTheo Let’s get back to this idea of information path. It works in OOP too. I could\naccess the title of the Watchmen book with catalogData.booksByIsbn[\"978-\n1779501127\"].title. I’d use class members for record fields and strings for\nindex keys.\nJoe There’s a fundamental difference, though. When records are represented as\nmaps, the information can be retrieved via its information path using a generic\nfunction like _.get. But when records are represented as objects, you need to\nwrite specific code for each type of information path.\nTheo What do you mean by specific code? What’s specific in catalogData.books-\nByIsbn[\"978-1779501127\"].title?\nJoe In a statically-typed language like Java, you’d need to import the class defini-\ntions for Catalog and Book.\nTheo And, in a dynamically-typed language like JavaScript...?\nJoe Even in JavaScript, when you represent records with objects instantiated from\nclasses, you can’t easily write a function that receives a path as an argument\nand display the information that corresponds to this path. You would have to\nwrite specific code for each kind of path. You’d access class members with dot\nnotation and map fields with bracket notation.\nTheo Would you say that in DOP, the information path is a first-class citizen?\nJoe Absolutely! The information path can be stored in a variable and passed as an\nargument to a function.\nTIP In DOP, you can retrieve every piece of information via a path and a generic\nfunction.\nJoe goes to the whiteboard. He draws a diagram like that in figure 3.5, which shows the\ncatalog data as a tree.\nJoe You see, Theo, each piece of information is accessible via a path made of\nstrings and integers. For example, the path of Alan Moore’s first book is\n[\"catalog\", \"authorsById\", \"alan-moore\", \"bookIsbns\", 0].\n--- Page 86 ---\n58 CHAPTER 3 Basic data manipulation\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 3.5 The catalog data as a tree\n3.4 Calculating search results\nTheo Interesting. I’m starting to feel the power of expression of DOP!\nJoe Wait, that’s just the beginning. Let me show you how simple it is to write code\nthat retrieves book information and displays it in search results. Can you tell\nme exactly what information has to appear in the search results?\nTheo Searching for book information should return isbn, title, and author-\nNames.\nJoe And what would a BookInfo record look like for Watchmen?\nTheo quickly enters the code on his laptop. He then shows it to Joe.\nListing3.10 A BookInfo record for Watchmen in the context of search result\n{\n\"title\": \"Watchmen\",\n\"isbn\": \"978-1779501127\",\n\"authorNames\": [\n\"Alan Moore\",\n\"Dave Gibbons\",\n]\n}\n--- Page 87 ---\n3.4 Calculating search results 59\nJoe Now I’ll show you step by step how to write a function that returns search\nresults matching a title in JSON format. I’ll use generic data manipulation\nfunctions from Lodash.\nTheo I’m ready!\nJoe Let’s start with an authorNames function that calculates the author names of a\nBook record by looking at the authorsById index. Could you tell me what’s\nthe information path for the name of an author whose ID is authorId?\nTheo It’s [\"authorsById\", authorId, \"name\"].\nJoe Now, let me show you how to retrieve the name of several authors using _.map.\nJoe types the code to map the author IDs to the author names. Theo nonchalantly peeks\nover Joe’s shoulder.\nListing3.11 Mapping author IDs to author names\n_.map([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\nTheo What’s this _.map function? It smells like functional programming! You said I\nwouldn’t have to learn FP to implement DOP!\nJoe No need to learn functional programming in order to use _.map, which is a\nfunction that transforms the values of a collection. You can implement it with\na simple for loop.\nTheo spends a couple of minutes in front of his computer figuring out how to implement\n_.map. Now he’s got it!\nListing3.12 Custom implementation of map\nfunction map(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nres[i] = f(coll[i]);\nforEach instead\n}\nof a for loop.\nreturn res;\n}\nAfter testing Theo’s implementation of map, Joe shows Theo the test. Joe again compli-\nments Theo.\nListing3.13 Testing the custom implementation of map\nmap([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\n--- Page 88 ---\n60 CHAPTER 3 Basic data manipulation\nJoe Well done!\nTheo You were right! It wasn’t hard.\nJoe Now, let’s implement authorNames using _.map.\nIt takes a few minutes for Theo to come up with the implementation of authorNames.\nWhen he’s finished, he turns his laptop to Joe.\nListing3.14 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nJoe We also need a bookInfo function that converts a Book record into a Book-\nInfo record. Let me show you the code for that.\nListing3.15 Converting a Book record into a BookInfo record\nfunction bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": authorNames(catalogData, book)\n};\nThere’s no need to create\nreturn bookInfo;\na class for bookInfo.\n}\nTheo Looking at the code, I see that a BookInfo record has three fields: title,\nisbn, and authorNames. Is there a way to get this information without looking\nat the code?\nJoe You can either add it to the data entity diagram or write it in the documenta-\ntion of the bookInfo function, or both.\nTheo I have to get used to the idea that in DOP, the record field information is not\npart of the program.\nJoe Indeed, it’s not part of the program, but it gives us a lot of flexibility.\nTheo Is there any way for me to have my cake and eat it too?\nJoe Yes, and someday I’ll show you how to make record field information part of a\nDOP program (see chapters 7 and 12).\nTheo Sounds intriguing!\nJoe Now that we have all the pieces in place, we can write our searchBooksBy-\nTitle function, which returns the book information about the books that\nmatch the query. First, we find the Book records that match the query with\n_.filter and then we transform each Book record into a BookInfo record\nwith _.map and bookInfo.\n--- Page 89 ---\n3.4 Calculating search results 61\nListing3.16 Searching books that match a query\nfunction searchBooksByTitle(catalogData, query) {\nvar allBooks = _.values(_.get(catalogData, \"booksByIsbn\"));\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\nThe includes JavaScript\n});\nfunction checks whether\na string includes a string\nvar bookInfos = _.map(matchingBooks, function(book) { as a substring.\nreturn bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\nTheo You’re using Lodash functions without any explanation again!\nJoe Sorry about that. I am so used to basic data manipulation functions that I con-\nsider them as part of the language. What functions are new to you?\nTheo _.values and _.filter\nJoe Well, _.values returns a collection made of the values of a map, and _.filter\nreturns a collection made of the values that satisfy a predicate.\nTheo _.values seems trivial. Let me try to implement _.filter.\nThe implementation of _.filter takes a bit more time. Eventually, Theo manages to get\nit right, then he is able to test it.\nListing3.17 Custom implementation of filter\nfunction filter(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nif(f(coll[i])) {\nforEach instead\nres.push(coll[i]);\nof a for loop.\n}\n}\nreturn res;\n}\nListing3.18 Testing the custom implementation of filter\nfilter([\"Watchmen\", \"Batman\"], function (title) {\nreturn title.includes(\"Watch\");\n});\n// → [\"Watchmen\"]\nTheo To me, it’s a bit weird that to access the title of a book record, I need to write\n_.get(book, \"title\"). I’d expect it to be book.title in dot notation or\nbook[\"title\"] in bracket notation.\nJoe Remember that book is a record that’s not represented as an object. It’s a map.\nIndeed, in JavaScript, you can write _.get(book, \"title\"), book.title, or\nbook[\"title\"]. But I prefer to use Lodash’s _.get function. In some lan-\nguages, the dot and the bracket notations might not work on maps.\n--- Page 90 ---\n62 CHAPTER 3 Basic data manipulation\nTheo Being language-agnostic has a price!\nJoe Right, would you like to test searchBooksByTitle?\nTheo Absolutely! Let me call searchBooksByTitle to search the books whose title\ncontain the string Watch.\nListing3.19 Testing searchBooksByTitle\nsearchBooksByTitle(catalogData, \"Wat\");\n//[\n// {\n// \"authorNames\": [\n// \"Alan Moore\",\n// \"Dave Gibbons\"\n// ],\n// \"isbn\": \"978-1779501127\",\n// \"title\": \"Watchmen\"\n// }\n//]\nTheo It seems to work! Are we done with the search implementation?\nJoe Almost. The searchBooksByTitle function we wrote is going to be part of the\nCatalog module, and it returns a collection of records. We have to write a\nfunction that’s part of the Library module, and that returns a JSON string.\nTheo You told me earlier that JSON serialization was straightforward in DOP.\nJoe Correct. The code for searchBooksByTitleJSON retrieves the Catalog record,\npasses it to searchBooksByTitle, and converts the results to JSON with\nJSON.stringify. That’s part of JavaScript. Here, let me show you.\nListing3.20 Implementation of searching books in a library as JSON\nfunction searchBooksByTitleJSON(libraryData, query) {\nvar results = searchBooksByTitle(_.get(libraryData, \"catalog\"), query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\nJoe In order to test our code, we need to create a Library record that contains our\nCatalog record. Could you do that for me, please?\nTheo Should the Library record contain all the Library fields (name, address,\nand UserManagement)?\nJoe That’s not necessary. For now, we only need the catalog field, then the test\nfor searching books.\nListing3.21 A Library record\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n--- Page 91 ---\n3.4 Calculating search results 63\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nListing3.22 Test for searching books in a library as JSON\nsearchBooksByTitleJSON(libraryData, \"Wat\");\nTheo How are we going to combine the four functions that we’ve written so far?\nJoe The functions authorNames, bookInfo, and searchBooksByTitle go into\nthe Catalog module, and searchBooksByTitleJSON goes into the Library\nmodule.\nTheo looks at the resulting code of the two modules, Library and Catalog. He’s quite\namazed by its conciseness.\nListing3.23 Calculating search results for Library and Catalog\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\n--- Page 92 ---\n64 CHAPTER 3 Basic data manipulation\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nThere’s no need\nreturn bookInfo;\nto create a class\n}\nfor bookInfo.\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nWhen _.filter is\nvar matchingBooks = _.filter(allBooks,\npassed a map, it\nfunction(book) {\ngoes over the values\nreturn _.get(book, \"title\").includes(query);\nof the map.\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nConverts data\nreturn resultsJSON;\nto JSON (part\n}\nof JavaScript)\n}\nAfter testing the final code in listing 3.24, Theo looks again at the source code from list-\ning 3.23. After a few seconds, he feels like he’s having another Aha! moment.\nListing3.24 Search results in JSON\nLibrary.searchBooksByTitleJSON(libraryData, \"Watchmen\");\n// → \"[{\\\"title\\\":\\\"Watchmen\\\",\\\"isbn\\\":\\\"978-1779501127\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}]\"\nTheo The important thing is not that the code is concise, but that the code contains\nno abstractions. It’s just data manipulation!\nJoe responds with a smile that says, “You got it, my friend!”\nJoe It reminds me of what my first meditation teacher told me 10 years ago:\nmeditation guides the mind to grasp the reality as it is without the abstractions\ncreated by our thoughts.\nTIP In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\n--- Page 93 ---\n3.5 Handling records of different types 65\n3.5 Handling records of different types\nWe’ve seen how DOP enables us to treat records as first-class citizens that can be\nmanipulated in a flexible way using generic functions. But if a record is nothing more\nthan an aggregation of fields, how do we know what the type of the record is? DOP has\na surprising answer to this question.\nTheo I have a question. If a record is nothing more than a map, how do you know\nthe type of the record?\nJoe That’s a great question with a surprising answer.\nTheo I’m curious.\nJoe Most of the time, there’s no need to know the record type.\nTheo What! What do you mean?\nJoe I mean that what matters most are the values of the fields. For example, take a\nlook at the Catalog.authorNames source code. It operates on a Book record,\nbut the only thing that matters is the value of the authorIds field.\nDoubtful, Theo looks at the source code for Catalog.authorNames. This is what Theo sees.\nListing3.25 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nTheo What about differentiating between various user types like Member versus\nLibrarian? I mean, they both have email and encryptedPassword. How do\nyou know if a record represents a Member or a Librarian?\nJoe Simple. You check to see if the record is found in the librariansByEmail\nindex or in the membersByEmail index of the Catalog.\nTheo Could you be more specific?\nJoe Sure! Let me write what the user management data of our tiny library might\nlook like, assuming we have one librarian and one member. To keep things\nsimple, I’m encrypting passwords through naive base-64 encoding for the User-\nManagement record.\nListing3.26 A UserManagement record\nvar userManagementData = {\n\"librariansByEmail\": {\n\"franck@gmail.com\" : { The base-64\nencoding of\n\"email\": \"franck@gmail.com\",\n\"mypassword\"\n\"encryptedPassword\": \"bXlwYXNzd29yZA==\"\n}\n},\n--- Page 94 ---\n66 CHAPTER 3 Basic data manipulation\n\"membersByEmail\": {\n\"samantha@gmail.com\": {\n\"email\": \"samantha@gmail.com\",\n\"encryptedPassword\": \"c2VjcmV0\",\nThe base-64\n\"isBlocked\": false,\nencoding of\n\"bookLendings\": [\n\"secret\"\n{\n\"bookItemId\": \"book-item-1\",\n\"bookIsbn\": \"978-1779501127\",\n\"lendingDate\": \"2020-04-23\"\n}\n]\n}\n}\n}\nTIP Most of the time, there’s no need to know the record type.\nTheo This morning, you told me you’d show me the code for UserManagement\n.isLibrarian function this afternoon.\nJoe So, here we are. It’s afternoon, and I’m going to fulfill my promise.\nJoe implements isLibrarian. With a slight pause, he then issues the test for isLibrarian.\nListing3.27 Checking if a user is a librarian\nfunction isLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nListing3.28 Testing isLibrarian\nisLibrarian(userManagementData, \"franck@gmail.com\");\n// → true\nTheo I’m assuming that _.has is a function that checks whether a key exists in a\nmap. Right?\nJoe Correct.\nTheo OK. You simply check whether the librariansByEmail map contains the\nemail field.\nJoe Yep.\nTheo Would you use the same pattern to check whether a member is a Super mem-\nber or a VIP member?\nJoe Sure. We could have SuperMembersByEmail and VIPMembersByEmail indexes.\nBut there’s a better way.\nTheo How?\nJoe When a member is a VIP member, we add a field, isVIP, with the value true to\nits record. To check if a member is a VIP member, we check whether the\nisVIP field is set to true in the member record. Here’s how I would code\nisVIPMember.\n--- Page 95 ---\n3.5 Handling records of different types 67\nListing3.29 Checking whether a member is a VIP member\nfunction isVIPMember(userManagement, email) {\nreturn _.get(userManagement, [\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nTheo I see that you access the isVIP field via its information path, [\"membersBy-\nEmail\", email, \"isVIP\"].\nJoe Yes, I think it makes the code crystal clear.\nTheo I agree. I guess we can do the same for isSuperMember and set an isSuper\nfield to true when a member is a Super member?\nJoe Yes, just like this.\nJoe assembles all the pieces in a UserManagement class. He then shows the code to Theo.\nListing3.30 The code of UserManagement module\nclass UserManagement {\nisLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nisVIPMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nisSuperMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isSuper\"]) == true;\n}\n}\nTheo looks at the UserManagement module code for a couple of seconds. Suddenly, an\nidea comes to his mind.\nTheo Why not have a type field in member record whose value would be either VIP\nor Super?\nJoe I assume that, according to the product requirements, a member can be both a\nVIP and a Super member.\nTheo Hmm...then the types field could be a collection containing VIP or Super\nor both.\nJoe In some situations, having a types field is helpful, but I find it simpler to have\na Boolean field for each feature that the record supports.\nTheo Is there a name for fields like isVIP and isSuper?\nJoe I call them feature fields.\nTIP Instead of maintaining type information about a record, use a feature field (e.g.,\nisVIP).\n--- Page 96 ---\n68 CHAPTER 3 Basic data manipulation\nTheo Can we use feature fields to differentiate between librarians and members?\nJoe You mean having an isLibrarian and an isMember field?\nTheo Yes, and having a common User record type for both librarians and members.\nJoe We can, but I think it’s simpler to have different record types for librarians and\nmembers: Librarian for librarians and Member for members.\nTheo Why?\nJoe Because there’s a clear distinction between librarians and members in terms of\ndata. For example, members can have book lendings but librarians don’t.\nTheo I agree. Now, we need to mention the two Member feature fields in our entity\ndiagram.\nWith that, Theo adds these fields to his diagram on the whiteboard. When he’s finished, he\nshows Joe his additions (figure 3.6).\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: Catalog\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian *\nCC Book id: String email: String CC Member\nname: String\ntitle : String encryptedPassword: String email: String\nbookIsbns: [String]\npublicationYear: Number encryptedPassword: String\nisbn: String * isBlocked: Boolean\nauthorIds: [String] bookLendings: [BookLending]\nbookItems: [BookItem] * isVIP: Boolean\nisSuper: Boolean\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.6 A library management data model with the Member feature fields isVIP and isSuper\nJoe Do you like the data model that we have designed together?\nTheo I find it quite simple and clear.\n--- Page 97 ---\nSummary 69\nJoe That’s the main goal of DOP.\nTheo Also, I’m pleasantly surprised how easy it is to adapt to changing requirements,\nboth in terms of code and the data model.\nJoe I suppose you’re also happy to get rid of complex class hierarchy diagrams.\nTheo Absolutely! Also, I think I’ve found an interesting connection between DOP\nand meditation.\nJoe Really?\nTheo When we were eating at Simple, you told me that meditation helped you expe-\nrience reality as it is without the filter of your thoughts.\nJoe Right.\nTheo From what you taught me today, I understand that in DOP, we are encouraged\nto treat data as data without the filter of our classes.\nJoe Clever! I never noticed that connection between those two disciplines that are\nso important for me. I guess you’d like to continue your journey in the realm\nof DOP.\nTheo Definitely. Let’s meet again tomorrow.\nJoe Unfortunately, tomorrow I’m taking my family to the beach to celebrate the\ntwelfth birthday of my eldest daughter, Aurelia.\nTheo Happy birthday, Aurelia!\nJoe We could meet again next Monday, if that’s OK with you.\nTheo With pleasure!\nSummary\n DOP principle #2 is to represent data entities with generic data structures.\n We refer to maps that have strings as keys as string maps.\n Representing data as data means representing records with string maps.\n By positional collection, we mean a collection where the elements are in order\n(like a list or an array).\n A positional collection of Strings is noted as [String].\n By index, we mean a collection where the elements are accessible via a key (like\na hash map or a dictionary).\n An index of Books is noted as {Book}.\n In the context of a data model, the index keys are always strings.\n A record is a data structure that groups together related data items. It’s a collec-\ntion of fields, possibly of different data types.\n A homogeneous map is a map where all the values are of the same type.\n A heterogeneous map is a map where the values are of different types.\n In DOP, we represent a record as a heterogeneous string map.\n A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes.\n The relation between records in a data entity diagram is either composition or\nassociation.\n--- Page 98 ---\n70 CHAPTER 3 Basic data manipulation\n The data part of a DOP system is flexible, and each piece of information is\naccessible via its information path.\n There is a tradeoff between flexibility and safety in a data model.\n DOP compromises on data safety to gain flexibility and genericity.\n In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\n We manipulate data with generic functions.\n Generic functions are provided either by the language itself or by third-party\nlibraries like Lodash.\n JSON serialization is implemented in terms of a generic function.\n On the one hand, we’ve lost the safety of accessing record fields via members\ndefined at compile time. On the other hand, we’ve liberated data from the lim-\nitation of classes and objects. Data is represented as data!\n The weak dependency between code and data makes it is easier to adapt to\nchanging requirements.\n When data is represented as data, it is straightforward to visualize system data.\n Usually, we do not need to maintain type information about a record.\n We can visualize any part of the system data.\n In statically-typed languages, we sometimes need to statically cast the field values.\n Instead of maintaining type information about a record, we use a feature field.\n There is no significant performance hit for accessing a field in a map instead of\na class member.\n In DOP, you can retrieve every piece of information via an information path and\na generic function.\n In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\nLodash functions introduced in this chapter\nFunction Description\nget(map, path) Gets the value of map at path\nhas(map, path) Checks if map has a field at path\nmerge(mapA, mapB) Creates a map resulting from the recursive merges between mapA and mapB\nvalues(map) Creates an array of values of map\nfilter(coll, pred) Iterates over elements of coll, returning an array of all elements for which\npred returns true\nmap(coll, f) Creates an array of values by running each element in coll through f\n--- Page 99 ---\nState management\nTime travel\nThis chapter covers\n A multi-version approach to state management\n The calculation phase of a mutation\n The commit phase of a mutation\n Keeping a history of previous state versions\nSo far, we have seen how DOP handles queries via generic functions that access sys-\ntem data, which is represented as a hash map. In this chapter, we illustrate how\nDOP deals with mutations (requests that change the system state). Instead of updat-\ning the state in place, we maintain multiple versions of the system data. At a specific\npoint in time, the system state refers to a specific version of the system data. This\nchapter is a deep dive in the third principle of DOP.\nPRINCIPLE #3 Data is immutable.\nThe maintenance of multiple versions of the system data requires the data to be\nimmutable. This is made efficient both in terms of computation and memory via a\n71\n--- Page 100 ---\n72 CHAPTER 4 State management\ntechnique called structural sharing, where parts of the data that are common between\ntwo versions are shared instead of being copied. In DOP, a mutation is split into two\ndistinct phases:\n In the calculation phase, we compute the next version of the system data.\n In the commit phase, we move the system state forward so that it refers to the\nversion of the system data computed by the calculation phase.\nThis distinction between calculation and commit phases allows us to reduce the part\nof our system that is stateful to its bare minimum. Only the code of the commit phase\nis stateful, while the code in the calculation phase of a mutation is stateless and is\nmade of generic functions similar to the code of a query. The implementation of the\ncommit phase is common to all mutations. As a consequence, inside the commit\nphase, we have the ability to ensure that the state always refers to a valid version of the\nsystem data.\nAnother benefit of this state management approach is that we can keep track of\nthe history of previous versions of the system data. Restoring the system to a previous\nstate (if needed) becomes straightforward. Table 4.1 shows the two phases.\nTable 4.1 The two phases of a mutation\nPhase Responsibility State Implementation\nCalculation Computes the next version of system data Stateless Specific\nCommit Moves the system state forward Stateful Common\nIn this chapter, we assume that no mutations occur concurrently in our system. In the\nnext chapter, we will deal with concurrency control.\n4.1 Multiple versions of the system data\nWhen Joe comes in to the office on Monday, he tells Theo that he needs to exercise before\nstarting to work with his mind. Theo and Joe go for a walk around the block, and the dis-\ncussion turns toward version control systems. They discuss how Git keeps track of the\nwhole commit history and how easy and fast it is to restore the code to a previous state.\nWhen Theo tells Joe that Git’s ability to “time travel” reminds him one of his favorite mov-\nies, Back to the Future, Joe shares that a month ago he watched the Back to the Future trilogy\nwith Neriah, his 14-year-old son.\nTheir walk complete, they arrive back at Theo’s office. Theo and Joe partake of the\nespresso machine in the kitchen before they begin today’s lesson.\nJoe So far, we’ve seen how we manage queries that retrieve information from the\nsystem in DOP. Now I’m going to show you how we manage mutations. By a\nmutation, I mean an operation that changes the state of the system.\n NOTE A mutation is an operation that changes the state of the system.\n--- Page 101 ---\n4.1 Multiple versions of the system data 73\nTheo Is there a fundamental difference between queries and mutations in DOP?\nAfter all, the whole state of the system is represented as a hash map. I could\neasily write code that modifies part of the hash map, and it would be similar to\nthe code that retrieves information from the hash map.\nJoe You could mutate the data in place, but then it would be challenging to ensure\nthat the code of a mutation doesn’t put the system into an invalid date. You\nwould also lose the ability to track previous versions of the system state.\nTheo I see. So, how do you handle mutations in DOP?\nJoe We adopt a multi-version state approach, similar to what a version control sys-\ntem like Git does; we manage different versions of the system data. At a specific\npoint in time, the state of the system refers to a version of the system data. After\na mutation is executed, we move the reference forward.\nTheo I’m confused. Is the system state mutable or immutable?\nJoe The data is immutable, but the state reference is mutable.\nTIP The data is immutable, but the state reference is mutable.\nNoticing the look of confusion on Theo’s face, Joe draws a quick diagram on the white-\nboard. He then shows Theo figure 4.1, hoping that it will clear up Theo’s perplexity.\nAfter mutation B After mutation C\nData V10 Data V10\nMutationA MutationA\nData V11 Data V11\nMutation B Mutation B\nSystem State Data V12 Data V12\nMutation C\nSystem State Data V13\nFigure 4.1 After mutation B is executed, the system state refers to Data V12. After\nmutation C is executed, the system state refers to Data V13.\nTheo Does that mean that before the code of a mutation runs, we make a copy of the\nsystem data?\nJoe No, that would be inefficient, as we would have to do a deep copy of the data.",
        "sections_found": []
      },
      "accurate_page_range": "76-101"
    },
    {
      "text": "- 3.4 Calculating search results",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "3 Basic data manipulation",
      "raw_line": "- 3.4 Calculating search results (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 26,
      "chapter_info": {
        "page": 76,
        "title": "Basic data manipulation",
        "pattern_matched": "Chapter 3",
        "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
      },
      "chapter_sections": {
        "start_page": 76,
        "end_page": 101,
        "content": "\n--- Page 76 ---\n48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to say that a data entity diagram consists only of records, positional\ncollections, and indexes?\nJoe That’s correct. Can you make a similar statement about the relations between\nentities?\nTheo The relations in a data entity diagram are either composition (solid line with a\nfull diamond) or association (dashed line with an empty diamond). Both types\nof relations can be either one-to-one, one-to-many, or many-to-many.\nJoe Excellent!\nTIP A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes. The relation between records is either composition or\nassociation.\n3.2 Representing records as maps\nSo far, we’ve illustrated the benefits we gain from the separation between code and\ndata at a high-system level. There’s a separation of concerns between code and data,\nand each part has clear constraints:\n Code consists of static functions that receive data as an explicit argument.\n Data entities are modeled as records, and the relations between records are\nrepresented by positional collections and indexes.\nNow comes the question of the representation of the data. DOP has nothing special\ntosay about collections and indexes. However, it’s strongly opinionated about the\nrepresentation of records: records should be represented by generic data structures\nsuch as maps.\nThis applies to both OOP and FP languages. In dynamically-typed languages like\nJavaScript, Python, and Ruby, data representation feels natural. While in statically-\ntyped languages like Java and C#, it is a bit more cumbersome.\nTheo I’m really curious to know how we represent positional collections, indexes,\nand records in DOP.\nJoe Let’s start with positional collections. DOP has nothing special to say about the\nrepresentation of collections. They can be linked lists, arrays, vectors, sets, or\nother collections best suited for the use case.\nTheo It’s like in OOP.\nJoe Right! For now, to keep things simple, we’ll use arrays to represent positional\ncollections.\nTheo What about indexes?\nJoe Indexes are represented as homogeneous string maps.\nTheo What do you mean by a homogeneous map?\n--- Page 77 ---\n3.2 Representing records as maps 49\nJoe I mean that all the values of the map are of the same kind. For example, in a\nBook index, all the values are Book, and in an author index, all the values are\nAuthor, and so forth.\nTheo Again, it’s like in OOP.\n NOTE A homogeneous map is a map where all the values are of the same type. A hetero-\ngeneous map is a map where the values are of different types.\nJoe Now, here’s the big surprise. In DOP, records are represented as maps, more\nprecisely, heterogeneous string maps.\nJoe goes to the whiteboard and begins to draw. When he’s finished, he shows Theo the dia-\ngram in figure 3.4.\nRecord Heterogeneous map\nLinked list\nArray\nData representation Collection\nSet\nVector\nFigure 3.4 The building blocks\nIndex Homogeneous map\nof data representation\nTheo stays silent for a while. He is shocked to hear that the data entities of a system can be\nrepresented as a generic data structure, where the field names and value types are not\nspecified in a class. Then, Theo asks Joe:\nTheo What are the benefits of this folly?\nJoe Flexibility and genericity.\nTheo Could you explain, please?\nJoe I’ll explain in a moment, but before that, I’d like to show you what an instance\nof a record in a DOP system looks like.\nTheo OK.\nJoe Let’s take as an example, Watchmen, by Alan Moore and Dave Gibbons, which is\nmy favorite graphic novel. This masterpiece was published in 1987. I’m going\nto assume that, in a physical library, there are two copies of this book, whose ID\nis nyc-central-lib, and that one of the two copies is currently out. Here’s\nhow I’d represent the Book record for Watchmen in DOP.\nJoe comes closer to Theo’s laptop. He opens a text editor (not an IDE!) and types the Book\nrecord for Theo.\n--- Page 78 ---\n50 CHAPTER 3 Basic data manipulation\nListing3.1 An instance of a Book record represented as a map\n{\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\nTheo looks at the laptop screen. He has a question.\nTheo How am I supposed to instantiate the Book record for Watchmen programmat-\nically?\nJoe It depends on the facilities that your programming language offers to instantiate\nmaps. With dynamic languages like JavaScript, Ruby, or Python, it’s straight-\nforward, because we can use literals for maps and arrays. Here, let me show\nyou how.\nJoe jots down the JavaScript code that creates an instance of a Book record, which rep-\nresents as a map in JavaScript. He shows the code to Theo.\nListing3.2 A Book record represented as a map in JavaScript\nvar watchmenBook = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n--- Page 79 ---\n3.2 Representing records as maps 51\nTheo And, if I’m in Java?\nJoe It’s a bit more tedious, but still doable with the immutable Map and List static\nfactory methods.\n NOTE See “Creating Immutable Lists, Sets, and Maps” at http://mng.bz/voGm for\nmore information on this Java core library.\nJoe types the Java code to create an instance of a Book record represented as a map. He\nshows Theo the Java code.\nListing3.3 A Book record represented as a map in Java\nMap watchmen = Map.of(\n\"isbn\", \"978-1779501127\",\n\"title\", \"Watchmen\",\n\"publicationYear\", 1987,\n\"authors\", List.of(\"alan-moore\", \"dave-gibbons\"),\n\"bookItems\", List.of(\nMap.of(\n\"id\", \"book-item-1\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", true\n),\nMap.of (\n\"id\", \"book-item-2\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", false\n)\n)\n);\nTIP In DOP, we represent a record as a heterogeneous string map.\nTheo I’d definitely prefer to create a Book record using a Book class and a BookItem\nclass.\nTheo opens his IDE. He types the JavaScript code to represent a Book record as an instance\nof a Book class.\nListing3.4 A Book record as an instance of a Book class in JavaScript\nclass Book {\nisbn;\ntitle;\npublicationYear;\nauthors;\nbookItems;\nconstructor(isbn, title, publicationYear, authors, bookItems) {\nthis.isbn = isbn;\nthis.title = title;\nthis.publicationYear = publicationYear;\nthis.authors = authors;\nthis.bookItems = bookItems;\n--- Page 80 ---\n52 CHAPTER 3 Basic data manipulation\n}\n}\nclass BookItem {\nid;\nlibId;\nisLent;\nconstructor(id, libId, isLent) {\nthis.id = id;\nthis.libId = libId;\nthis.isLent = isLent;\n}\n}\nvar watchmenBook = new Book(\"978-1779501127\",\n\"Watchmen\",\n1987,\n[\"alan-moore\", \"dave-gibbons\"],\n[new BookItem(\"book-item-1\", \"nyc-central-lib\", true),\nnew BookItem(\"book-item-2\", \"nyc-central-lib\", false)]);\nJoe Theo, why do you prefer classes over maps for representing records?\nTheo It makes the data shape of the record part of my program. As a result, the IDE\ncan auto-complete field names, and errors are caught at compile time.\nJoe Fair enough. Can I show you some drawbacks for this approach?\nTheo Sure.\nJoe Imagine that you want to display the information about a book in the context\nof search results. In that case, instead of author IDs, you want to display\nauthor names, and you don’t need the book item information. How would\nyou handle that?\nTheo I’d create a class BookInSearchResults without a bookItems member and\nwith an authorNames member instead of the authorIds member of the Book\nclass. Also, I would need to write a copy constructor that receives a Book object.\nJoe In classic OOP, the fact that data is instantiated only via classes brings safety.\nBut this safety comes at the cost of flexibility.\nTIP There’s a tradeoff between flexibility and safety in a data model.\nTheo So, how can it be different?\nJoe In the DOP approach, where records are represented as maps, we don’t need\nto create a class for each variation of the data. We’re free to add, remove, and\nrename record fields dynamically. Our data model is flexible.\nTheo Interesting!\nTIP In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\nJoe Now, let me talk about genericity. How would you serialize the content of a\nBook object to JSON?\n--- Page 81 ---\n3.2 Representing records as maps 53\nTIP In DOP, records are manipulated with generic functions.\nTheo Oh no! I remember that while working on the Klafim prototype, I had a night-\nmare about JSON serialization when I was developing the first version of the\nLibrary Management System.\nJoe Well, in DOP, serializing a record to JSON is super easy.\nTheo Does it require the usage of reflection in order to go over the fields of the\nrecord like the Gson Java library does?\n NOTE See https://github.com/google/gson for more information on Gson.\nJoe Not at all! Remember that in DOP, a record is nothing more than data. We can\nwrite a generic JSON serialization function that works with any record. It can\nbe a Book, an Author, a BookItem, or anything else.\nTheo Amazing!\nTIP In DOP, you get JSON serialization for free.\nJoe Actually, as I’ll show you in a moment, lots of data manipulation stuff can be\ndone using generic functions.\nTheo Are the generic functions part of the language?\nJoe It depends on the functions and on the language. For example, JavaScript pro-\nvides a JSON serialization function called JSON.stringify out of the box, but\nnone for omitting multiple keys or for renaming keys.\nTheo That’s annoying.\nJoe Not so much; there are third-party libraries that provide data-manipulation facil-\nities. A popular data manipulation library in the JavaScript ecosystem is Lodash.\n NOTE See https://lodash.com/ to find out more about Lodash.\nTheo What about other languages?\nJoe Lodash has been ported to Java, C#, Python, and Ruby. Let me bookmark some\nsites for you.\nJoe bookmarks these sites for Theo:\n https://javalibs.com/artifact/com.github.javadev/underscore-lodash for Java\n https://www.nuget.org/packages/lodash/ for C#\n https://github.com/dgilland/pydash for Python\n https://rudash-website.now.sh/ for Ruby\n NOTE Throughout the book, we use Lodash to show how to manipulate data with\ngeneric functions, but there is nothing special about Lodash. The exact same approach\ncould be implemented via other data manipulation libraries or custom code.\nTheo Cool!\nJoe Actually, Lodash and its rich set of data manipulation functions can be ported\nto any language. That’s why it’s so beneficial to represent records as maps.\n--- Page 82 ---\n54 CHAPTER 3 Basic data manipulation\nTIP DOP compromises on data safety to gain flexibility and genericity.\nAt the whiteboard, Joe quickly sketches the tradeoffs (see table 3.1).\nTable 3.1 The tradeoff among safety, flexibility, and genericity\nOOP DOP\nSafety High Low\nFlexibility Low High\nGenericity Low High\n3.3 Manipulating data with generic functions\nJoe Now let me show you how to manipulate data in DOP with generic functions.\nTheo Yes, I’m quite curious to see how you’ll implement the search functionality of\nthe Library Management System.\nJoe OK. First, let’s instantiate a Catalog record for the catalog data of a library,\nwhere we have a single book, Watchmen.\nJoe instantiates a Catalog record according to Theo’s data model in figure 3.3. Here’s\nwhat Joe shows to Theo.\nListing3.5 A Catalog record\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n--- Page 83 ---\n3.3 Manipulating data with generic functions 55\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\nTheo I see the two indexes we talked about, booksByIsbn and authorsById. How\ndo you differentiate a record from an index in DOP?\nJoe In an entity diagram, there’s a clear distinction between records and indexes.\nBut in our code, both are plain data.\nTheo I guess that’s why this approach is called data-oriented programming.\nJoe See how straightforward it is to visualize any part of the system data inside a\nprogram? The reason is that data is represented as data!\nTIP In DOP, data is represented as data.\nTheo That sounds like a lapalissade.1\nJoe Oh, does it? I’m not so sure! In OOP, data is usually represented by objects,\nwhich makes it more challenging to visualize data inside a program.\nTIP In DOP, we can visualize any part of the system data.\nTheo How would you retrieve the title of a specific book from the catalog data?\nJoe Great question! In fact, in a DOP system, every piece of information has an\ninformation path from which we can retrieve the information.\nTheo Information path?\nJoe For example, the information path to the title of the Watchmen book in the\ncatalog is [\"booksByIsbn\", \"978-1779501127\", \"title\"].\nTheo Ah, I see. So, is an information path sort of like a file path, but that names in\nan information path correspond to nested entities?\nJoe You’re exactly right. And once we have the path of a piece of information, we\ncan retrieve the information with Lodash’s _.get function.\nJoe types a few characters on Theo’s laptop. Theo is amazed at how little code is needed to\nget the book title.\nListing3.6 Retrieving the title of a book from its information path\n_.get(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"])\n// → \"Watchmen\"\nTheo Neat. I wonder how hard it would be to implement a function like _.get\nmyself.\n1 A lapalissade is an obvious truth—a truism or tautology—that produces a comical effect.\n--- Page 84 ---\n56 CHAPTER 3 Basic data manipulation\nAfter a few minutes of trial and error, Theo is able to produce his implementation. He\nshows Joe the code.\nListing3.7 Custom implementation of get\nfunction get(m, path) {\nvar res = m;\nfor(var i = 0; i < path.length; i++) {\nWe could use\nvar key = path[i];\nforEach instead\nres = res[key];\nof a for loop.\n}\nreturn res;\n}\nAfter testing Theo’s implementation of get, Joe compliments Theo. He’s grateful that\nTheo is catching on so quickly.\nListing3.8 Testing the custom implementation of get\nget(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nJoe Well done!\nTheo I wonder if a function like _.get works smoothly in a statically-typed language\nlike Java?\nJoe It depends on whether you only need to pass the value around or to access the\nvalue concretely.\nTheo I don’t follow.\nJoe Imagine that once you get the title of a book, you want to convert the string\ninto an uppercase string. You need to do a static cast to String, right? Here,\nlet me show you an example that casts a field value to a string, then we can\nmanipulate it as a string.\nListing3.9 Casting a field value to a string\n((String)watchmen.get(\"title\")).toUpperCase()\nTheo That makes sense. The values of the map are of different types, so the compiler\ndeclares it as a Map<String,Object>. The information of the type of the field\nis lost.\nJoe It’s a bit annoying, but quite often our code just passes the data around. In that\ncase, we don’t have to deal with static casting. Moreover, in a language like C#,\nwhen using the dynamic data type, type casting can be avoided.2,3\n2 See http://mng.bz/4jo5 for the C# documentation on the built-in reference to dynamic types.\n3 See appendix A for details about dynamic fields and type casting in C#.\n--- Page 85 ---\n3.3 Manipulating data with generic functions 57\nTIP In statically-typed languages, we sometimes need to statically cast the field values.\nTheo What about performance?\nJoe In most programming languages, maps are quite efficient. Accessing a field\nin a map is slightly slower than accessing a class member. Usually, it’s not\nsignificant.\nTIP There’s no significant performance hit for accessing a field in a map instead of as\na class member.\nTheo Let’s get back to this idea of information path. It works in OOP too. I could\naccess the title of the Watchmen book with catalogData.booksByIsbn[\"978-\n1779501127\"].title. I’d use class members for record fields and strings for\nindex keys.\nJoe There’s a fundamental difference, though. When records are represented as\nmaps, the information can be retrieved via its information path using a generic\nfunction like _.get. But when records are represented as objects, you need to\nwrite specific code for each type of information path.\nTheo What do you mean by specific code? What’s specific in catalogData.books-\nByIsbn[\"978-1779501127\"].title?\nJoe In a statically-typed language like Java, you’d need to import the class defini-\ntions for Catalog and Book.\nTheo And, in a dynamically-typed language like JavaScript...?\nJoe Even in JavaScript, when you represent records with objects instantiated from\nclasses, you can’t easily write a function that receives a path as an argument\nand display the information that corresponds to this path. You would have to\nwrite specific code for each kind of path. You’d access class members with dot\nnotation and map fields with bracket notation.\nTheo Would you say that in DOP, the information path is a first-class citizen?\nJoe Absolutely! The information path can be stored in a variable and passed as an\nargument to a function.\nTIP In DOP, you can retrieve every piece of information via a path and a generic\nfunction.\nJoe goes to the whiteboard. He draws a diagram like that in figure 3.5, which shows the\ncatalog data as a tree.\nJoe You see, Theo, each piece of information is accessible via a path made of\nstrings and integers. For example, the path of Alan Moore’s first book is\n[\"catalog\", \"authorsById\", \"alan-moore\", \"bookIsbns\", 0].\n--- Page 86 ---\n58 CHAPTER 3 Basic data manipulation\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 3.5 The catalog data as a tree\n3.4 Calculating search results\nTheo Interesting. I’m starting to feel the power of expression of DOP!\nJoe Wait, that’s just the beginning. Let me show you how simple it is to write code\nthat retrieves book information and displays it in search results. Can you tell\nme exactly what information has to appear in the search results?\nTheo Searching for book information should return isbn, title, and author-\nNames.\nJoe And what would a BookInfo record look like for Watchmen?\nTheo quickly enters the code on his laptop. He then shows it to Joe.\nListing3.10 A BookInfo record for Watchmen in the context of search result\n{\n\"title\": \"Watchmen\",\n\"isbn\": \"978-1779501127\",\n\"authorNames\": [\n\"Alan Moore\",\n\"Dave Gibbons\",\n]\n}\n--- Page 87 ---\n3.4 Calculating search results 59\nJoe Now I’ll show you step by step how to write a function that returns search\nresults matching a title in JSON format. I’ll use generic data manipulation\nfunctions from Lodash.\nTheo I’m ready!\nJoe Let’s start with an authorNames function that calculates the author names of a\nBook record by looking at the authorsById index. Could you tell me what’s\nthe information path for the name of an author whose ID is authorId?\nTheo It’s [\"authorsById\", authorId, \"name\"].\nJoe Now, let me show you how to retrieve the name of several authors using _.map.\nJoe types the code to map the author IDs to the author names. Theo nonchalantly peeks\nover Joe’s shoulder.\nListing3.11 Mapping author IDs to author names\n_.map([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\nTheo What’s this _.map function? It smells like functional programming! You said I\nwouldn’t have to learn FP to implement DOP!\nJoe No need to learn functional programming in order to use _.map, which is a\nfunction that transforms the values of a collection. You can implement it with\na simple for loop.\nTheo spends a couple of minutes in front of his computer figuring out how to implement\n_.map. Now he’s got it!\nListing3.12 Custom implementation of map\nfunction map(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nres[i] = f(coll[i]);\nforEach instead\n}\nof a for loop.\nreturn res;\n}\nAfter testing Theo’s implementation of map, Joe shows Theo the test. Joe again compli-\nments Theo.\nListing3.13 Testing the custom implementation of map\nmap([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\n--- Page 88 ---\n60 CHAPTER 3 Basic data manipulation\nJoe Well done!\nTheo You were right! It wasn’t hard.\nJoe Now, let’s implement authorNames using _.map.\nIt takes a few minutes for Theo to come up with the implementation of authorNames.\nWhen he’s finished, he turns his laptop to Joe.\nListing3.14 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nJoe We also need a bookInfo function that converts a Book record into a Book-\nInfo record. Let me show you the code for that.\nListing3.15 Converting a Book record into a BookInfo record\nfunction bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": authorNames(catalogData, book)\n};\nThere’s no need to create\nreturn bookInfo;\na class for bookInfo.\n}\nTheo Looking at the code, I see that a BookInfo record has three fields: title,\nisbn, and authorNames. Is there a way to get this information without looking\nat the code?\nJoe You can either add it to the data entity diagram or write it in the documenta-\ntion of the bookInfo function, or both.\nTheo I have to get used to the idea that in DOP, the record field information is not\npart of the program.\nJoe Indeed, it’s not part of the program, but it gives us a lot of flexibility.\nTheo Is there any way for me to have my cake and eat it too?\nJoe Yes, and someday I’ll show you how to make record field information part of a\nDOP program (see chapters 7 and 12).\nTheo Sounds intriguing!\nJoe Now that we have all the pieces in place, we can write our searchBooksBy-\nTitle function, which returns the book information about the books that\nmatch the query. First, we find the Book records that match the query with\n_.filter and then we transform each Book record into a BookInfo record\nwith _.map and bookInfo.\n--- Page 89 ---\n3.4 Calculating search results 61\nListing3.16 Searching books that match a query\nfunction searchBooksByTitle(catalogData, query) {\nvar allBooks = _.values(_.get(catalogData, \"booksByIsbn\"));\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\nThe includes JavaScript\n});\nfunction checks whether\na string includes a string\nvar bookInfos = _.map(matchingBooks, function(book) { as a substring.\nreturn bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\nTheo You’re using Lodash functions without any explanation again!\nJoe Sorry about that. I am so used to basic data manipulation functions that I con-\nsider them as part of the language. What functions are new to you?\nTheo _.values and _.filter\nJoe Well, _.values returns a collection made of the values of a map, and _.filter\nreturns a collection made of the values that satisfy a predicate.\nTheo _.values seems trivial. Let me try to implement _.filter.\nThe implementation of _.filter takes a bit more time. Eventually, Theo manages to get\nit right, then he is able to test it.\nListing3.17 Custom implementation of filter\nfunction filter(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nif(f(coll[i])) {\nforEach instead\nres.push(coll[i]);\nof a for loop.\n}\n}\nreturn res;\n}\nListing3.18 Testing the custom implementation of filter\nfilter([\"Watchmen\", \"Batman\"], function (title) {\nreturn title.includes(\"Watch\");\n});\n// → [\"Watchmen\"]\nTheo To me, it’s a bit weird that to access the title of a book record, I need to write\n_.get(book, \"title\"). I’d expect it to be book.title in dot notation or\nbook[\"title\"] in bracket notation.\nJoe Remember that book is a record that’s not represented as an object. It’s a map.\nIndeed, in JavaScript, you can write _.get(book, \"title\"), book.title, or\nbook[\"title\"]. But I prefer to use Lodash’s _.get function. In some lan-\nguages, the dot and the bracket notations might not work on maps.\n--- Page 90 ---\n62 CHAPTER 3 Basic data manipulation\nTheo Being language-agnostic has a price!\nJoe Right, would you like to test searchBooksByTitle?\nTheo Absolutely! Let me call searchBooksByTitle to search the books whose title\ncontain the string Watch.\nListing3.19 Testing searchBooksByTitle\nsearchBooksByTitle(catalogData, \"Wat\");\n//[\n// {\n// \"authorNames\": [\n// \"Alan Moore\",\n// \"Dave Gibbons\"\n// ],\n// \"isbn\": \"978-1779501127\",\n// \"title\": \"Watchmen\"\n// }\n//]\nTheo It seems to work! Are we done with the search implementation?\nJoe Almost. The searchBooksByTitle function we wrote is going to be part of the\nCatalog module, and it returns a collection of records. We have to write a\nfunction that’s part of the Library module, and that returns a JSON string.\nTheo You told me earlier that JSON serialization was straightforward in DOP.\nJoe Correct. The code for searchBooksByTitleJSON retrieves the Catalog record,\npasses it to searchBooksByTitle, and converts the results to JSON with\nJSON.stringify. That’s part of JavaScript. Here, let me show you.\nListing3.20 Implementation of searching books in a library as JSON\nfunction searchBooksByTitleJSON(libraryData, query) {\nvar results = searchBooksByTitle(_.get(libraryData, \"catalog\"), query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\nJoe In order to test our code, we need to create a Library record that contains our\nCatalog record. Could you do that for me, please?\nTheo Should the Library record contain all the Library fields (name, address,\nand UserManagement)?\nJoe That’s not necessary. For now, we only need the catalog field, then the test\nfor searching books.\nListing3.21 A Library record\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n--- Page 91 ---\n3.4 Calculating search results 63\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nListing3.22 Test for searching books in a library as JSON\nsearchBooksByTitleJSON(libraryData, \"Wat\");\nTheo How are we going to combine the four functions that we’ve written so far?\nJoe The functions authorNames, bookInfo, and searchBooksByTitle go into\nthe Catalog module, and searchBooksByTitleJSON goes into the Library\nmodule.\nTheo looks at the resulting code of the two modules, Library and Catalog. He’s quite\namazed by its conciseness.\nListing3.23 Calculating search results for Library and Catalog\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\n--- Page 92 ---\n64 CHAPTER 3 Basic data manipulation\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nThere’s no need\nreturn bookInfo;\nto create a class\n}\nfor bookInfo.\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nWhen _.filter is\nvar matchingBooks = _.filter(allBooks,\npassed a map, it\nfunction(book) {\ngoes over the values\nreturn _.get(book, \"title\").includes(query);\nof the map.\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nConverts data\nreturn resultsJSON;\nto JSON (part\n}\nof JavaScript)\n}\nAfter testing the final code in listing 3.24, Theo looks again at the source code from list-\ning 3.23. After a few seconds, he feels like he’s having another Aha! moment.\nListing3.24 Search results in JSON\nLibrary.searchBooksByTitleJSON(libraryData, \"Watchmen\");\n// → \"[{\\\"title\\\":\\\"Watchmen\\\",\\\"isbn\\\":\\\"978-1779501127\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}]\"\nTheo The important thing is not that the code is concise, but that the code contains\nno abstractions. It’s just data manipulation!\nJoe responds with a smile that says, “You got it, my friend!”\nJoe It reminds me of what my first meditation teacher told me 10 years ago:\nmeditation guides the mind to grasp the reality as it is without the abstractions\ncreated by our thoughts.\nTIP In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\n--- Page 93 ---\n3.5 Handling records of different types 65\n3.5 Handling records of different types\nWe’ve seen how DOP enables us to treat records as first-class citizens that can be\nmanipulated in a flexible way using generic functions. But if a record is nothing more\nthan an aggregation of fields, how do we know what the type of the record is? DOP has\na surprising answer to this question.\nTheo I have a question. If a record is nothing more than a map, how do you know\nthe type of the record?\nJoe That’s a great question with a surprising answer.\nTheo I’m curious.\nJoe Most of the time, there’s no need to know the record type.\nTheo What! What do you mean?\nJoe I mean that what matters most are the values of the fields. For example, take a\nlook at the Catalog.authorNames source code. It operates on a Book record,\nbut the only thing that matters is the value of the authorIds field.\nDoubtful, Theo looks at the source code for Catalog.authorNames. This is what Theo sees.\nListing3.25 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nTheo What about differentiating between various user types like Member versus\nLibrarian? I mean, they both have email and encryptedPassword. How do\nyou know if a record represents a Member or a Librarian?\nJoe Simple. You check to see if the record is found in the librariansByEmail\nindex or in the membersByEmail index of the Catalog.\nTheo Could you be more specific?\nJoe Sure! Let me write what the user management data of our tiny library might\nlook like, assuming we have one librarian and one member. To keep things\nsimple, I’m encrypting passwords through naive base-64 encoding for the User-\nManagement record.\nListing3.26 A UserManagement record\nvar userManagementData = {\n\"librariansByEmail\": {\n\"franck@gmail.com\" : { The base-64\nencoding of\n\"email\": \"franck@gmail.com\",\n\"mypassword\"\n\"encryptedPassword\": \"bXlwYXNzd29yZA==\"\n}\n},\n--- Page 94 ---\n66 CHAPTER 3 Basic data manipulation\n\"membersByEmail\": {\n\"samantha@gmail.com\": {\n\"email\": \"samantha@gmail.com\",\n\"encryptedPassword\": \"c2VjcmV0\",\nThe base-64\n\"isBlocked\": false,\nencoding of\n\"bookLendings\": [\n\"secret\"\n{\n\"bookItemId\": \"book-item-1\",\n\"bookIsbn\": \"978-1779501127\",\n\"lendingDate\": \"2020-04-23\"\n}\n]\n}\n}\n}\nTIP Most of the time, there’s no need to know the record type.\nTheo This morning, you told me you’d show me the code for UserManagement\n.isLibrarian function this afternoon.\nJoe So, here we are. It’s afternoon, and I’m going to fulfill my promise.\nJoe implements isLibrarian. With a slight pause, he then issues the test for isLibrarian.\nListing3.27 Checking if a user is a librarian\nfunction isLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nListing3.28 Testing isLibrarian\nisLibrarian(userManagementData, \"franck@gmail.com\");\n// → true\nTheo I’m assuming that _.has is a function that checks whether a key exists in a\nmap. Right?\nJoe Correct.\nTheo OK. You simply check whether the librariansByEmail map contains the\nemail field.\nJoe Yep.\nTheo Would you use the same pattern to check whether a member is a Super mem-\nber or a VIP member?\nJoe Sure. We could have SuperMembersByEmail and VIPMembersByEmail indexes.\nBut there’s a better way.\nTheo How?\nJoe When a member is a VIP member, we add a field, isVIP, with the value true to\nits record. To check if a member is a VIP member, we check whether the\nisVIP field is set to true in the member record. Here’s how I would code\nisVIPMember.\n--- Page 95 ---\n3.5 Handling records of different types 67\nListing3.29 Checking whether a member is a VIP member\nfunction isVIPMember(userManagement, email) {\nreturn _.get(userManagement, [\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nTheo I see that you access the isVIP field via its information path, [\"membersBy-\nEmail\", email, \"isVIP\"].\nJoe Yes, I think it makes the code crystal clear.\nTheo I agree. I guess we can do the same for isSuperMember and set an isSuper\nfield to true when a member is a Super member?\nJoe Yes, just like this.\nJoe assembles all the pieces in a UserManagement class. He then shows the code to Theo.\nListing3.30 The code of UserManagement module\nclass UserManagement {\nisLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nisVIPMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nisSuperMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isSuper\"]) == true;\n}\n}\nTheo looks at the UserManagement module code for a couple of seconds. Suddenly, an\nidea comes to his mind.\nTheo Why not have a type field in member record whose value would be either VIP\nor Super?\nJoe I assume that, according to the product requirements, a member can be both a\nVIP and a Super member.\nTheo Hmm...then the types field could be a collection containing VIP or Super\nor both.\nJoe In some situations, having a types field is helpful, but I find it simpler to have\na Boolean field for each feature that the record supports.\nTheo Is there a name for fields like isVIP and isSuper?\nJoe I call them feature fields.\nTIP Instead of maintaining type information about a record, use a feature field (e.g.,\nisVIP).\n--- Page 96 ---\n68 CHAPTER 3 Basic data manipulation\nTheo Can we use feature fields to differentiate between librarians and members?\nJoe You mean having an isLibrarian and an isMember field?\nTheo Yes, and having a common User record type for both librarians and members.\nJoe We can, but I think it’s simpler to have different record types for librarians and\nmembers: Librarian for librarians and Member for members.\nTheo Why?\nJoe Because there’s a clear distinction between librarians and members in terms of\ndata. For example, members can have book lendings but librarians don’t.\nTheo I agree. Now, we need to mention the two Member feature fields in our entity\ndiagram.\nWith that, Theo adds these fields to his diagram on the whiteboard. When he’s finished, he\nshows Joe his additions (figure 3.6).\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: Catalog\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian *\nCC Book id: String email: String CC Member\nname: String\ntitle : String encryptedPassword: String email: String\nbookIsbns: [String]\npublicationYear: Number encryptedPassword: String\nisbn: String * isBlocked: Boolean\nauthorIds: [String] bookLendings: [BookLending]\nbookItems: [BookItem] * isVIP: Boolean\nisSuper: Boolean\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.6 A library management data model with the Member feature fields isVIP and isSuper\nJoe Do you like the data model that we have designed together?\nTheo I find it quite simple and clear.\n--- Page 97 ---\nSummary 69\nJoe That’s the main goal of DOP.\nTheo Also, I’m pleasantly surprised how easy it is to adapt to changing requirements,\nboth in terms of code and the data model.\nJoe I suppose you’re also happy to get rid of complex class hierarchy diagrams.\nTheo Absolutely! Also, I think I’ve found an interesting connection between DOP\nand meditation.\nJoe Really?\nTheo When we were eating at Simple, you told me that meditation helped you expe-\nrience reality as it is without the filter of your thoughts.\nJoe Right.\nTheo From what you taught me today, I understand that in DOP, we are encouraged\nto treat data as data without the filter of our classes.\nJoe Clever! I never noticed that connection between those two disciplines that are\nso important for me. I guess you’d like to continue your journey in the realm\nof DOP.\nTheo Definitely. Let’s meet again tomorrow.\nJoe Unfortunately, tomorrow I’m taking my family to the beach to celebrate the\ntwelfth birthday of my eldest daughter, Aurelia.\nTheo Happy birthday, Aurelia!\nJoe We could meet again next Monday, if that’s OK with you.\nTheo With pleasure!\nSummary\n DOP principle #2 is to represent data entities with generic data structures.\n We refer to maps that have strings as keys as string maps.\n Representing data as data means representing records with string maps.\n By positional collection, we mean a collection where the elements are in order\n(like a list or an array).\n A positional collection of Strings is noted as [String].\n By index, we mean a collection where the elements are accessible via a key (like\na hash map or a dictionary).\n An index of Books is noted as {Book}.\n In the context of a data model, the index keys are always strings.\n A record is a data structure that groups together related data items. It’s a collec-\ntion of fields, possibly of different data types.\n A homogeneous map is a map where all the values are of the same type.\n A heterogeneous map is a map where the values are of different types.\n In DOP, we represent a record as a heterogeneous string map.\n A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes.\n The relation between records in a data entity diagram is either composition or\nassociation.\n--- Page 98 ---\n70 CHAPTER 3 Basic data manipulation\n The data part of a DOP system is flexible, and each piece of information is\naccessible via its information path.\n There is a tradeoff between flexibility and safety in a data model.\n DOP compromises on data safety to gain flexibility and genericity.\n In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\n We manipulate data with generic functions.\n Generic functions are provided either by the language itself or by third-party\nlibraries like Lodash.\n JSON serialization is implemented in terms of a generic function.\n On the one hand, we’ve lost the safety of accessing record fields via members\ndefined at compile time. On the other hand, we’ve liberated data from the lim-\nitation of classes and objects. Data is represented as data!\n The weak dependency between code and data makes it is easier to adapt to\nchanging requirements.\n When data is represented as data, it is straightforward to visualize system data.\n Usually, we do not need to maintain type information about a record.\n We can visualize any part of the system data.\n In statically-typed languages, we sometimes need to statically cast the field values.\n Instead of maintaining type information about a record, we use a feature field.\n There is no significant performance hit for accessing a field in a map instead of\na class member.\n In DOP, you can retrieve every piece of information via an information path and\na generic function.\n In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\nLodash functions introduced in this chapter\nFunction Description\nget(map, path) Gets the value of map at path\nhas(map, path) Checks if map has a field at path\nmerge(mapA, mapB) Creates a map resulting from the recursive merges between mapA and mapB\nvalues(map) Creates an array of values of map\nfilter(coll, pred) Iterates over elements of coll, returning an array of all elements for which\npred returns true\nmap(coll, f) Creates an array of values by running each element in coll through f\n--- Page 99 ---\nState management\nTime travel\nThis chapter covers\n A multi-version approach to state management\n The calculation phase of a mutation\n The commit phase of a mutation\n Keeping a history of previous state versions\nSo far, we have seen how DOP handles queries via generic functions that access sys-\ntem data, which is represented as a hash map. In this chapter, we illustrate how\nDOP deals with mutations (requests that change the system state). Instead of updat-\ning the state in place, we maintain multiple versions of the system data. At a specific\npoint in time, the system state refers to a specific version of the system data. This\nchapter is a deep dive in the third principle of DOP.\nPRINCIPLE #3 Data is immutable.\nThe maintenance of multiple versions of the system data requires the data to be\nimmutable. This is made efficient both in terms of computation and memory via a\n71\n--- Page 100 ---\n72 CHAPTER 4 State management\ntechnique called structural sharing, where parts of the data that are common between\ntwo versions are shared instead of being copied. In DOP, a mutation is split into two\ndistinct phases:\n In the calculation phase, we compute the next version of the system data.\n In the commit phase, we move the system state forward so that it refers to the\nversion of the system data computed by the calculation phase.\nThis distinction between calculation and commit phases allows us to reduce the part\nof our system that is stateful to its bare minimum. Only the code of the commit phase\nis stateful, while the code in the calculation phase of a mutation is stateless and is\nmade of generic functions similar to the code of a query. The implementation of the\ncommit phase is common to all mutations. As a consequence, inside the commit\nphase, we have the ability to ensure that the state always refers to a valid version of the\nsystem data.\nAnother benefit of this state management approach is that we can keep track of\nthe history of previous versions of the system data. Restoring the system to a previous\nstate (if needed) becomes straightforward. Table 4.1 shows the two phases.\nTable 4.1 The two phases of a mutation\nPhase Responsibility State Implementation\nCalculation Computes the next version of system data Stateless Specific\nCommit Moves the system state forward Stateful Common\nIn this chapter, we assume that no mutations occur concurrently in our system. In the\nnext chapter, we will deal with concurrency control.\n4.1 Multiple versions of the system data\nWhen Joe comes in to the office on Monday, he tells Theo that he needs to exercise before\nstarting to work with his mind. Theo and Joe go for a walk around the block, and the dis-\ncussion turns toward version control systems. They discuss how Git keeps track of the\nwhole commit history and how easy and fast it is to restore the code to a previous state.\nWhen Theo tells Joe that Git’s ability to “time travel” reminds him one of his favorite mov-\nies, Back to the Future, Joe shares that a month ago he watched the Back to the Future trilogy\nwith Neriah, his 14-year-old son.\nTheir walk complete, they arrive back at Theo’s office. Theo and Joe partake of the\nespresso machine in the kitchen before they begin today’s lesson.\nJoe So far, we’ve seen how we manage queries that retrieve information from the\nsystem in DOP. Now I’m going to show you how we manage mutations. By a\nmutation, I mean an operation that changes the state of the system.\n NOTE A mutation is an operation that changes the state of the system.\n--- Page 101 ---\n4.1 Multiple versions of the system data 73\nTheo Is there a fundamental difference between queries and mutations in DOP?\nAfter all, the whole state of the system is represented as a hash map. I could\neasily write code that modifies part of the hash map, and it would be similar to\nthe code that retrieves information from the hash map.\nJoe You could mutate the data in place, but then it would be challenging to ensure\nthat the code of a mutation doesn’t put the system into an invalid date. You\nwould also lose the ability to track previous versions of the system state.\nTheo I see. So, how do you handle mutations in DOP?\nJoe We adopt a multi-version state approach, similar to what a version control sys-\ntem like Git does; we manage different versions of the system data. At a specific\npoint in time, the state of the system refers to a version of the system data. After\na mutation is executed, we move the reference forward.\nTheo I’m confused. Is the system state mutable or immutable?\nJoe The data is immutable, but the state reference is mutable.\nTIP The data is immutable, but the state reference is mutable.\nNoticing the look of confusion on Theo’s face, Joe draws a quick diagram on the white-\nboard. He then shows Theo figure 4.1, hoping that it will clear up Theo’s perplexity.\nAfter mutation B After mutation C\nData V10 Data V10\nMutationA MutationA\nData V11 Data V11\nMutation B Mutation B\nSystem State Data V12 Data V12\nMutation C\nSystem State Data V13\nFigure 4.1 After mutation B is executed, the system state refers to Data V12. After\nmutation C is executed, the system state refers to Data V13.\nTheo Does that mean that before the code of a mutation runs, we make a copy of the\nsystem data?\nJoe No, that would be inefficient, as we would have to do a deep copy of the data.",
        "sections_found": []
      },
      "accurate_page_range": "76-101"
    },
    {
      "text": "- 3.5 Handling records of different types",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "3 Basic data manipulation",
      "raw_line": "- 3.5 Handling records of different types (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 27,
      "chapter_info": {
        "page": 76,
        "title": "Basic data manipulation",
        "pattern_matched": "Chapter 3",
        "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
      },
      "chapter_sections": {
        "start_page": 76,
        "end_page": 101,
        "content": "\n--- Page 76 ---\n48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to say that a data entity diagram consists only of records, positional\ncollections, and indexes?\nJoe That’s correct. Can you make a similar statement about the relations between\nentities?\nTheo The relations in a data entity diagram are either composition (solid line with a\nfull diamond) or association (dashed line with an empty diamond). Both types\nof relations can be either one-to-one, one-to-many, or many-to-many.\nJoe Excellent!\nTIP A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes. The relation between records is either composition or\nassociation.\n3.2 Representing records as maps\nSo far, we’ve illustrated the benefits we gain from the separation between code and\ndata at a high-system level. There’s a separation of concerns between code and data,\nand each part has clear constraints:\n Code consists of static functions that receive data as an explicit argument.\n Data entities are modeled as records, and the relations between records are\nrepresented by positional collections and indexes.\nNow comes the question of the representation of the data. DOP has nothing special\ntosay about collections and indexes. However, it’s strongly opinionated about the\nrepresentation of records: records should be represented by generic data structures\nsuch as maps.\nThis applies to both OOP and FP languages. In dynamically-typed languages like\nJavaScript, Python, and Ruby, data representation feels natural. While in statically-\ntyped languages like Java and C#, it is a bit more cumbersome.\nTheo I’m really curious to know how we represent positional collections, indexes,\nand records in DOP.\nJoe Let’s start with positional collections. DOP has nothing special to say about the\nrepresentation of collections. They can be linked lists, arrays, vectors, sets, or\nother collections best suited for the use case.\nTheo It’s like in OOP.\nJoe Right! For now, to keep things simple, we’ll use arrays to represent positional\ncollections.\nTheo What about indexes?\nJoe Indexes are represented as homogeneous string maps.\nTheo What do you mean by a homogeneous map?\n--- Page 77 ---\n3.2 Representing records as maps 49\nJoe I mean that all the values of the map are of the same kind. For example, in a\nBook index, all the values are Book, and in an author index, all the values are\nAuthor, and so forth.\nTheo Again, it’s like in OOP.\n NOTE A homogeneous map is a map where all the values are of the same type. A hetero-\ngeneous map is a map where the values are of different types.\nJoe Now, here’s the big surprise. In DOP, records are represented as maps, more\nprecisely, heterogeneous string maps.\nJoe goes to the whiteboard and begins to draw. When he’s finished, he shows Theo the dia-\ngram in figure 3.4.\nRecord Heterogeneous map\nLinked list\nArray\nData representation Collection\nSet\nVector\nFigure 3.4 The building blocks\nIndex Homogeneous map\nof data representation\nTheo stays silent for a while. He is shocked to hear that the data entities of a system can be\nrepresented as a generic data structure, where the field names and value types are not\nspecified in a class. Then, Theo asks Joe:\nTheo What are the benefits of this folly?\nJoe Flexibility and genericity.\nTheo Could you explain, please?\nJoe I’ll explain in a moment, but before that, I’d like to show you what an instance\nof a record in a DOP system looks like.\nTheo OK.\nJoe Let’s take as an example, Watchmen, by Alan Moore and Dave Gibbons, which is\nmy favorite graphic novel. This masterpiece was published in 1987. I’m going\nto assume that, in a physical library, there are two copies of this book, whose ID\nis nyc-central-lib, and that one of the two copies is currently out. Here’s\nhow I’d represent the Book record for Watchmen in DOP.\nJoe comes closer to Theo’s laptop. He opens a text editor (not an IDE!) and types the Book\nrecord for Theo.\n--- Page 78 ---\n50 CHAPTER 3 Basic data manipulation\nListing3.1 An instance of a Book record represented as a map\n{\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\nTheo looks at the laptop screen. He has a question.\nTheo How am I supposed to instantiate the Book record for Watchmen programmat-\nically?\nJoe It depends on the facilities that your programming language offers to instantiate\nmaps. With dynamic languages like JavaScript, Ruby, or Python, it’s straight-\nforward, because we can use literals for maps and arrays. Here, let me show\nyou how.\nJoe jots down the JavaScript code that creates an instance of a Book record, which rep-\nresents as a map in JavaScript. He shows the code to Theo.\nListing3.2 A Book record represented as a map in JavaScript\nvar watchmenBook = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n--- Page 79 ---\n3.2 Representing records as maps 51\nTheo And, if I’m in Java?\nJoe It’s a bit more tedious, but still doable with the immutable Map and List static\nfactory methods.\n NOTE See “Creating Immutable Lists, Sets, and Maps” at http://mng.bz/voGm for\nmore information on this Java core library.\nJoe types the Java code to create an instance of a Book record represented as a map. He\nshows Theo the Java code.\nListing3.3 A Book record represented as a map in Java\nMap watchmen = Map.of(\n\"isbn\", \"978-1779501127\",\n\"title\", \"Watchmen\",\n\"publicationYear\", 1987,\n\"authors\", List.of(\"alan-moore\", \"dave-gibbons\"),\n\"bookItems\", List.of(\nMap.of(\n\"id\", \"book-item-1\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", true\n),\nMap.of (\n\"id\", \"book-item-2\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", false\n)\n)\n);\nTIP In DOP, we represent a record as a heterogeneous string map.\nTheo I’d definitely prefer to create a Book record using a Book class and a BookItem\nclass.\nTheo opens his IDE. He types the JavaScript code to represent a Book record as an instance\nof a Book class.\nListing3.4 A Book record as an instance of a Book class in JavaScript\nclass Book {\nisbn;\ntitle;\npublicationYear;\nauthors;\nbookItems;\nconstructor(isbn, title, publicationYear, authors, bookItems) {\nthis.isbn = isbn;\nthis.title = title;\nthis.publicationYear = publicationYear;\nthis.authors = authors;\nthis.bookItems = bookItems;\n--- Page 80 ---\n52 CHAPTER 3 Basic data manipulation\n}\n}\nclass BookItem {\nid;\nlibId;\nisLent;\nconstructor(id, libId, isLent) {\nthis.id = id;\nthis.libId = libId;\nthis.isLent = isLent;\n}\n}\nvar watchmenBook = new Book(\"978-1779501127\",\n\"Watchmen\",\n1987,\n[\"alan-moore\", \"dave-gibbons\"],\n[new BookItem(\"book-item-1\", \"nyc-central-lib\", true),\nnew BookItem(\"book-item-2\", \"nyc-central-lib\", false)]);\nJoe Theo, why do you prefer classes over maps for representing records?\nTheo It makes the data shape of the record part of my program. As a result, the IDE\ncan auto-complete field names, and errors are caught at compile time.\nJoe Fair enough. Can I show you some drawbacks for this approach?\nTheo Sure.\nJoe Imagine that you want to display the information about a book in the context\nof search results. In that case, instead of author IDs, you want to display\nauthor names, and you don’t need the book item information. How would\nyou handle that?\nTheo I’d create a class BookInSearchResults without a bookItems member and\nwith an authorNames member instead of the authorIds member of the Book\nclass. Also, I would need to write a copy constructor that receives a Book object.\nJoe In classic OOP, the fact that data is instantiated only via classes brings safety.\nBut this safety comes at the cost of flexibility.\nTIP There’s a tradeoff between flexibility and safety in a data model.\nTheo So, how can it be different?\nJoe In the DOP approach, where records are represented as maps, we don’t need\nto create a class for each variation of the data. We’re free to add, remove, and\nrename record fields dynamically. Our data model is flexible.\nTheo Interesting!\nTIP In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\nJoe Now, let me talk about genericity. How would you serialize the content of a\nBook object to JSON?\n--- Page 81 ---\n3.2 Representing records as maps 53\nTIP In DOP, records are manipulated with generic functions.\nTheo Oh no! I remember that while working on the Klafim prototype, I had a night-\nmare about JSON serialization when I was developing the first version of the\nLibrary Management System.\nJoe Well, in DOP, serializing a record to JSON is super easy.\nTheo Does it require the usage of reflection in order to go over the fields of the\nrecord like the Gson Java library does?\n NOTE See https://github.com/google/gson for more information on Gson.\nJoe Not at all! Remember that in DOP, a record is nothing more than data. We can\nwrite a generic JSON serialization function that works with any record. It can\nbe a Book, an Author, a BookItem, or anything else.\nTheo Amazing!\nTIP In DOP, you get JSON serialization for free.\nJoe Actually, as I’ll show you in a moment, lots of data manipulation stuff can be\ndone using generic functions.\nTheo Are the generic functions part of the language?\nJoe It depends on the functions and on the language. For example, JavaScript pro-\nvides a JSON serialization function called JSON.stringify out of the box, but\nnone for omitting multiple keys or for renaming keys.\nTheo That’s annoying.\nJoe Not so much; there are third-party libraries that provide data-manipulation facil-\nities. A popular data manipulation library in the JavaScript ecosystem is Lodash.\n NOTE See https://lodash.com/ to find out more about Lodash.\nTheo What about other languages?\nJoe Lodash has been ported to Java, C#, Python, and Ruby. Let me bookmark some\nsites for you.\nJoe bookmarks these sites for Theo:\n https://javalibs.com/artifact/com.github.javadev/underscore-lodash for Java\n https://www.nuget.org/packages/lodash/ for C#\n https://github.com/dgilland/pydash for Python\n https://rudash-website.now.sh/ for Ruby\n NOTE Throughout the book, we use Lodash to show how to manipulate data with\ngeneric functions, but there is nothing special about Lodash. The exact same approach\ncould be implemented via other data manipulation libraries or custom code.\nTheo Cool!\nJoe Actually, Lodash and its rich set of data manipulation functions can be ported\nto any language. That’s why it’s so beneficial to represent records as maps.\n--- Page 82 ---\n54 CHAPTER 3 Basic data manipulation\nTIP DOP compromises on data safety to gain flexibility and genericity.\nAt the whiteboard, Joe quickly sketches the tradeoffs (see table 3.1).\nTable 3.1 The tradeoff among safety, flexibility, and genericity\nOOP DOP\nSafety High Low\nFlexibility Low High\nGenericity Low High\n3.3 Manipulating data with generic functions\nJoe Now let me show you how to manipulate data in DOP with generic functions.\nTheo Yes, I’m quite curious to see how you’ll implement the search functionality of\nthe Library Management System.\nJoe OK. First, let’s instantiate a Catalog record for the catalog data of a library,\nwhere we have a single book, Watchmen.\nJoe instantiates a Catalog record according to Theo’s data model in figure 3.3. Here’s\nwhat Joe shows to Theo.\nListing3.5 A Catalog record\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n--- Page 83 ---\n3.3 Manipulating data with generic functions 55\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\nTheo I see the two indexes we talked about, booksByIsbn and authorsById. How\ndo you differentiate a record from an index in DOP?\nJoe In an entity diagram, there’s a clear distinction between records and indexes.\nBut in our code, both are plain data.\nTheo I guess that’s why this approach is called data-oriented programming.\nJoe See how straightforward it is to visualize any part of the system data inside a\nprogram? The reason is that data is represented as data!\nTIP In DOP, data is represented as data.\nTheo That sounds like a lapalissade.1\nJoe Oh, does it? I’m not so sure! In OOP, data is usually represented by objects,\nwhich makes it more challenging to visualize data inside a program.\nTIP In DOP, we can visualize any part of the system data.\nTheo How would you retrieve the title of a specific book from the catalog data?\nJoe Great question! In fact, in a DOP system, every piece of information has an\ninformation path from which we can retrieve the information.\nTheo Information path?\nJoe For example, the information path to the title of the Watchmen book in the\ncatalog is [\"booksByIsbn\", \"978-1779501127\", \"title\"].\nTheo Ah, I see. So, is an information path sort of like a file path, but that names in\nan information path correspond to nested entities?\nJoe You’re exactly right. And once we have the path of a piece of information, we\ncan retrieve the information with Lodash’s _.get function.\nJoe types a few characters on Theo’s laptop. Theo is amazed at how little code is needed to\nget the book title.\nListing3.6 Retrieving the title of a book from its information path\n_.get(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"])\n// → \"Watchmen\"\nTheo Neat. I wonder how hard it would be to implement a function like _.get\nmyself.\n1 A lapalissade is an obvious truth—a truism or tautology—that produces a comical effect.\n--- Page 84 ---\n56 CHAPTER 3 Basic data manipulation\nAfter a few minutes of trial and error, Theo is able to produce his implementation. He\nshows Joe the code.\nListing3.7 Custom implementation of get\nfunction get(m, path) {\nvar res = m;\nfor(var i = 0; i < path.length; i++) {\nWe could use\nvar key = path[i];\nforEach instead\nres = res[key];\nof a for loop.\n}\nreturn res;\n}\nAfter testing Theo’s implementation of get, Joe compliments Theo. He’s grateful that\nTheo is catching on so quickly.\nListing3.8 Testing the custom implementation of get\nget(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nJoe Well done!\nTheo I wonder if a function like _.get works smoothly in a statically-typed language\nlike Java?\nJoe It depends on whether you only need to pass the value around or to access the\nvalue concretely.\nTheo I don’t follow.\nJoe Imagine that once you get the title of a book, you want to convert the string\ninto an uppercase string. You need to do a static cast to String, right? Here,\nlet me show you an example that casts a field value to a string, then we can\nmanipulate it as a string.\nListing3.9 Casting a field value to a string\n((String)watchmen.get(\"title\")).toUpperCase()\nTheo That makes sense. The values of the map are of different types, so the compiler\ndeclares it as a Map<String,Object>. The information of the type of the field\nis lost.\nJoe It’s a bit annoying, but quite often our code just passes the data around. In that\ncase, we don’t have to deal with static casting. Moreover, in a language like C#,\nwhen using the dynamic data type, type casting can be avoided.2,3\n2 See http://mng.bz/4jo5 for the C# documentation on the built-in reference to dynamic types.\n3 See appendix A for details about dynamic fields and type casting in C#.\n--- Page 85 ---\n3.3 Manipulating data with generic functions 57\nTIP In statically-typed languages, we sometimes need to statically cast the field values.\nTheo What about performance?\nJoe In most programming languages, maps are quite efficient. Accessing a field\nin a map is slightly slower than accessing a class member. Usually, it’s not\nsignificant.\nTIP There’s no significant performance hit for accessing a field in a map instead of as\na class member.\nTheo Let’s get back to this idea of information path. It works in OOP too. I could\naccess the title of the Watchmen book with catalogData.booksByIsbn[\"978-\n1779501127\"].title. I’d use class members for record fields and strings for\nindex keys.\nJoe There’s a fundamental difference, though. When records are represented as\nmaps, the information can be retrieved via its information path using a generic\nfunction like _.get. But when records are represented as objects, you need to\nwrite specific code for each type of information path.\nTheo What do you mean by specific code? What’s specific in catalogData.books-\nByIsbn[\"978-1779501127\"].title?\nJoe In a statically-typed language like Java, you’d need to import the class defini-\ntions for Catalog and Book.\nTheo And, in a dynamically-typed language like JavaScript...?\nJoe Even in JavaScript, when you represent records with objects instantiated from\nclasses, you can’t easily write a function that receives a path as an argument\nand display the information that corresponds to this path. You would have to\nwrite specific code for each kind of path. You’d access class members with dot\nnotation and map fields with bracket notation.\nTheo Would you say that in DOP, the information path is a first-class citizen?\nJoe Absolutely! The information path can be stored in a variable and passed as an\nargument to a function.\nTIP In DOP, you can retrieve every piece of information via a path and a generic\nfunction.\nJoe goes to the whiteboard. He draws a diagram like that in figure 3.5, which shows the\ncatalog data as a tree.\nJoe You see, Theo, each piece of information is accessible via a path made of\nstrings and integers. For example, the path of Alan Moore’s first book is\n[\"catalog\", \"authorsById\", \"alan-moore\", \"bookIsbns\", 0].\n--- Page 86 ---\n58 CHAPTER 3 Basic data manipulation\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 3.5 The catalog data as a tree\n3.4 Calculating search results\nTheo Interesting. I’m starting to feel the power of expression of DOP!\nJoe Wait, that’s just the beginning. Let me show you how simple it is to write code\nthat retrieves book information and displays it in search results. Can you tell\nme exactly what information has to appear in the search results?\nTheo Searching for book information should return isbn, title, and author-\nNames.\nJoe And what would a BookInfo record look like for Watchmen?\nTheo quickly enters the code on his laptop. He then shows it to Joe.\nListing3.10 A BookInfo record for Watchmen in the context of search result\n{\n\"title\": \"Watchmen\",\n\"isbn\": \"978-1779501127\",\n\"authorNames\": [\n\"Alan Moore\",\n\"Dave Gibbons\",\n]\n}\n--- Page 87 ---\n3.4 Calculating search results 59\nJoe Now I’ll show you step by step how to write a function that returns search\nresults matching a title in JSON format. I’ll use generic data manipulation\nfunctions from Lodash.\nTheo I’m ready!\nJoe Let’s start with an authorNames function that calculates the author names of a\nBook record by looking at the authorsById index. Could you tell me what’s\nthe information path for the name of an author whose ID is authorId?\nTheo It’s [\"authorsById\", authorId, \"name\"].\nJoe Now, let me show you how to retrieve the name of several authors using _.map.\nJoe types the code to map the author IDs to the author names. Theo nonchalantly peeks\nover Joe’s shoulder.\nListing3.11 Mapping author IDs to author names\n_.map([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\nTheo What’s this _.map function? It smells like functional programming! You said I\nwouldn’t have to learn FP to implement DOP!\nJoe No need to learn functional programming in order to use _.map, which is a\nfunction that transforms the values of a collection. You can implement it with\na simple for loop.\nTheo spends a couple of minutes in front of his computer figuring out how to implement\n_.map. Now he’s got it!\nListing3.12 Custom implementation of map\nfunction map(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nres[i] = f(coll[i]);\nforEach instead\n}\nof a for loop.\nreturn res;\n}\nAfter testing Theo’s implementation of map, Joe shows Theo the test. Joe again compli-\nments Theo.\nListing3.13 Testing the custom implementation of map\nmap([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\n--- Page 88 ---\n60 CHAPTER 3 Basic data manipulation\nJoe Well done!\nTheo You were right! It wasn’t hard.\nJoe Now, let’s implement authorNames using _.map.\nIt takes a few minutes for Theo to come up with the implementation of authorNames.\nWhen he’s finished, he turns his laptop to Joe.\nListing3.14 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nJoe We also need a bookInfo function that converts a Book record into a Book-\nInfo record. Let me show you the code for that.\nListing3.15 Converting a Book record into a BookInfo record\nfunction bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": authorNames(catalogData, book)\n};\nThere’s no need to create\nreturn bookInfo;\na class for bookInfo.\n}\nTheo Looking at the code, I see that a BookInfo record has three fields: title,\nisbn, and authorNames. Is there a way to get this information without looking\nat the code?\nJoe You can either add it to the data entity diagram or write it in the documenta-\ntion of the bookInfo function, or both.\nTheo I have to get used to the idea that in DOP, the record field information is not\npart of the program.\nJoe Indeed, it’s not part of the program, but it gives us a lot of flexibility.\nTheo Is there any way for me to have my cake and eat it too?\nJoe Yes, and someday I’ll show you how to make record field information part of a\nDOP program (see chapters 7 and 12).\nTheo Sounds intriguing!\nJoe Now that we have all the pieces in place, we can write our searchBooksBy-\nTitle function, which returns the book information about the books that\nmatch the query. First, we find the Book records that match the query with\n_.filter and then we transform each Book record into a BookInfo record\nwith _.map and bookInfo.\n--- Page 89 ---\n3.4 Calculating search results 61\nListing3.16 Searching books that match a query\nfunction searchBooksByTitle(catalogData, query) {\nvar allBooks = _.values(_.get(catalogData, \"booksByIsbn\"));\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\nThe includes JavaScript\n});\nfunction checks whether\na string includes a string\nvar bookInfos = _.map(matchingBooks, function(book) { as a substring.\nreturn bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\nTheo You’re using Lodash functions without any explanation again!\nJoe Sorry about that. I am so used to basic data manipulation functions that I con-\nsider them as part of the language. What functions are new to you?\nTheo _.values and _.filter\nJoe Well, _.values returns a collection made of the values of a map, and _.filter\nreturns a collection made of the values that satisfy a predicate.\nTheo _.values seems trivial. Let me try to implement _.filter.\nThe implementation of _.filter takes a bit more time. Eventually, Theo manages to get\nit right, then he is able to test it.\nListing3.17 Custom implementation of filter\nfunction filter(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nif(f(coll[i])) {\nforEach instead\nres.push(coll[i]);\nof a for loop.\n}\n}\nreturn res;\n}\nListing3.18 Testing the custom implementation of filter\nfilter([\"Watchmen\", \"Batman\"], function (title) {\nreturn title.includes(\"Watch\");\n});\n// → [\"Watchmen\"]\nTheo To me, it’s a bit weird that to access the title of a book record, I need to write\n_.get(book, \"title\"). I’d expect it to be book.title in dot notation or\nbook[\"title\"] in bracket notation.\nJoe Remember that book is a record that’s not represented as an object. It’s a map.\nIndeed, in JavaScript, you can write _.get(book, \"title\"), book.title, or\nbook[\"title\"]. But I prefer to use Lodash’s _.get function. In some lan-\nguages, the dot and the bracket notations might not work on maps.\n--- Page 90 ---\n62 CHAPTER 3 Basic data manipulation\nTheo Being language-agnostic has a price!\nJoe Right, would you like to test searchBooksByTitle?\nTheo Absolutely! Let me call searchBooksByTitle to search the books whose title\ncontain the string Watch.\nListing3.19 Testing searchBooksByTitle\nsearchBooksByTitle(catalogData, \"Wat\");\n//[\n// {\n// \"authorNames\": [\n// \"Alan Moore\",\n// \"Dave Gibbons\"\n// ],\n// \"isbn\": \"978-1779501127\",\n// \"title\": \"Watchmen\"\n// }\n//]\nTheo It seems to work! Are we done with the search implementation?\nJoe Almost. The searchBooksByTitle function we wrote is going to be part of the\nCatalog module, and it returns a collection of records. We have to write a\nfunction that’s part of the Library module, and that returns a JSON string.\nTheo You told me earlier that JSON serialization was straightforward in DOP.\nJoe Correct. The code for searchBooksByTitleJSON retrieves the Catalog record,\npasses it to searchBooksByTitle, and converts the results to JSON with\nJSON.stringify. That’s part of JavaScript. Here, let me show you.\nListing3.20 Implementation of searching books in a library as JSON\nfunction searchBooksByTitleJSON(libraryData, query) {\nvar results = searchBooksByTitle(_.get(libraryData, \"catalog\"), query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\nJoe In order to test our code, we need to create a Library record that contains our\nCatalog record. Could you do that for me, please?\nTheo Should the Library record contain all the Library fields (name, address,\nand UserManagement)?\nJoe That’s not necessary. For now, we only need the catalog field, then the test\nfor searching books.\nListing3.21 A Library record\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n--- Page 91 ---\n3.4 Calculating search results 63\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nListing3.22 Test for searching books in a library as JSON\nsearchBooksByTitleJSON(libraryData, \"Wat\");\nTheo How are we going to combine the four functions that we’ve written so far?\nJoe The functions authorNames, bookInfo, and searchBooksByTitle go into\nthe Catalog module, and searchBooksByTitleJSON goes into the Library\nmodule.\nTheo looks at the resulting code of the two modules, Library and Catalog. He’s quite\namazed by its conciseness.\nListing3.23 Calculating search results for Library and Catalog\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\n--- Page 92 ---\n64 CHAPTER 3 Basic data manipulation\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nThere’s no need\nreturn bookInfo;\nto create a class\n}\nfor bookInfo.\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nWhen _.filter is\nvar matchingBooks = _.filter(allBooks,\npassed a map, it\nfunction(book) {\ngoes over the values\nreturn _.get(book, \"title\").includes(query);\nof the map.\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nConverts data\nreturn resultsJSON;\nto JSON (part\n}\nof JavaScript)\n}\nAfter testing the final code in listing 3.24, Theo looks again at the source code from list-\ning 3.23. After a few seconds, he feels like he’s having another Aha! moment.\nListing3.24 Search results in JSON\nLibrary.searchBooksByTitleJSON(libraryData, \"Watchmen\");\n// → \"[{\\\"title\\\":\\\"Watchmen\\\",\\\"isbn\\\":\\\"978-1779501127\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}]\"\nTheo The important thing is not that the code is concise, but that the code contains\nno abstractions. It’s just data manipulation!\nJoe responds with a smile that says, “You got it, my friend!”\nJoe It reminds me of what my first meditation teacher told me 10 years ago:\nmeditation guides the mind to grasp the reality as it is without the abstractions\ncreated by our thoughts.\nTIP In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\n--- Page 93 ---\n3.5 Handling records of different types 65\n3.5 Handling records of different types\nWe’ve seen how DOP enables us to treat records as first-class citizens that can be\nmanipulated in a flexible way using generic functions. But if a record is nothing more\nthan an aggregation of fields, how do we know what the type of the record is? DOP has\na surprising answer to this question.\nTheo I have a question. If a record is nothing more than a map, how do you know\nthe type of the record?\nJoe That’s a great question with a surprising answer.\nTheo I’m curious.\nJoe Most of the time, there’s no need to know the record type.\nTheo What! What do you mean?\nJoe I mean that what matters most are the values of the fields. For example, take a\nlook at the Catalog.authorNames source code. It operates on a Book record,\nbut the only thing that matters is the value of the authorIds field.\nDoubtful, Theo looks at the source code for Catalog.authorNames. This is what Theo sees.\nListing3.25 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nTheo What about differentiating between various user types like Member versus\nLibrarian? I mean, they both have email and encryptedPassword. How do\nyou know if a record represents a Member or a Librarian?\nJoe Simple. You check to see if the record is found in the librariansByEmail\nindex or in the membersByEmail index of the Catalog.\nTheo Could you be more specific?\nJoe Sure! Let me write what the user management data of our tiny library might\nlook like, assuming we have one librarian and one member. To keep things\nsimple, I’m encrypting passwords through naive base-64 encoding for the User-\nManagement record.\nListing3.26 A UserManagement record\nvar userManagementData = {\n\"librariansByEmail\": {\n\"franck@gmail.com\" : { The base-64\nencoding of\n\"email\": \"franck@gmail.com\",\n\"mypassword\"\n\"encryptedPassword\": \"bXlwYXNzd29yZA==\"\n}\n},\n--- Page 94 ---\n66 CHAPTER 3 Basic data manipulation\n\"membersByEmail\": {\n\"samantha@gmail.com\": {\n\"email\": \"samantha@gmail.com\",\n\"encryptedPassword\": \"c2VjcmV0\",\nThe base-64\n\"isBlocked\": false,\nencoding of\n\"bookLendings\": [\n\"secret\"\n{\n\"bookItemId\": \"book-item-1\",\n\"bookIsbn\": \"978-1779501127\",\n\"lendingDate\": \"2020-04-23\"\n}\n]\n}\n}\n}\nTIP Most of the time, there’s no need to know the record type.\nTheo This morning, you told me you’d show me the code for UserManagement\n.isLibrarian function this afternoon.\nJoe So, here we are. It’s afternoon, and I’m going to fulfill my promise.\nJoe implements isLibrarian. With a slight pause, he then issues the test for isLibrarian.\nListing3.27 Checking if a user is a librarian\nfunction isLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nListing3.28 Testing isLibrarian\nisLibrarian(userManagementData, \"franck@gmail.com\");\n// → true\nTheo I’m assuming that _.has is a function that checks whether a key exists in a\nmap. Right?\nJoe Correct.\nTheo OK. You simply check whether the librariansByEmail map contains the\nemail field.\nJoe Yep.\nTheo Would you use the same pattern to check whether a member is a Super mem-\nber or a VIP member?\nJoe Sure. We could have SuperMembersByEmail and VIPMembersByEmail indexes.\nBut there’s a better way.\nTheo How?\nJoe When a member is a VIP member, we add a field, isVIP, with the value true to\nits record. To check if a member is a VIP member, we check whether the\nisVIP field is set to true in the member record. Here’s how I would code\nisVIPMember.\n--- Page 95 ---\n3.5 Handling records of different types 67\nListing3.29 Checking whether a member is a VIP member\nfunction isVIPMember(userManagement, email) {\nreturn _.get(userManagement, [\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nTheo I see that you access the isVIP field via its information path, [\"membersBy-\nEmail\", email, \"isVIP\"].\nJoe Yes, I think it makes the code crystal clear.\nTheo I agree. I guess we can do the same for isSuperMember and set an isSuper\nfield to true when a member is a Super member?\nJoe Yes, just like this.\nJoe assembles all the pieces in a UserManagement class. He then shows the code to Theo.\nListing3.30 The code of UserManagement module\nclass UserManagement {\nisLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nisVIPMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nisSuperMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isSuper\"]) == true;\n}\n}\nTheo looks at the UserManagement module code for a couple of seconds. Suddenly, an\nidea comes to his mind.\nTheo Why not have a type field in member record whose value would be either VIP\nor Super?\nJoe I assume that, according to the product requirements, a member can be both a\nVIP and a Super member.\nTheo Hmm...then the types field could be a collection containing VIP or Super\nor both.\nJoe In some situations, having a types field is helpful, but I find it simpler to have\na Boolean field for each feature that the record supports.\nTheo Is there a name for fields like isVIP and isSuper?\nJoe I call them feature fields.\nTIP Instead of maintaining type information about a record, use a feature field (e.g.,\nisVIP).\n--- Page 96 ---\n68 CHAPTER 3 Basic data manipulation\nTheo Can we use feature fields to differentiate between librarians and members?\nJoe You mean having an isLibrarian and an isMember field?\nTheo Yes, and having a common User record type for both librarians and members.\nJoe We can, but I think it’s simpler to have different record types for librarians and\nmembers: Librarian for librarians and Member for members.\nTheo Why?\nJoe Because there’s a clear distinction between librarians and members in terms of\ndata. For example, members can have book lendings but librarians don’t.\nTheo I agree. Now, we need to mention the two Member feature fields in our entity\ndiagram.\nWith that, Theo adds these fields to his diagram on the whiteboard. When he’s finished, he\nshows Joe his additions (figure 3.6).\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: Catalog\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian *\nCC Book id: String email: String CC Member\nname: String\ntitle : String encryptedPassword: String email: String\nbookIsbns: [String]\npublicationYear: Number encryptedPassword: String\nisbn: String * isBlocked: Boolean\nauthorIds: [String] bookLendings: [BookLending]\nbookItems: [BookItem] * isVIP: Boolean\nisSuper: Boolean\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.6 A library management data model with the Member feature fields isVIP and isSuper\nJoe Do you like the data model that we have designed together?\nTheo I find it quite simple and clear.\n--- Page 97 ---\nSummary 69\nJoe That’s the main goal of DOP.\nTheo Also, I’m pleasantly surprised how easy it is to adapt to changing requirements,\nboth in terms of code and the data model.\nJoe I suppose you’re also happy to get rid of complex class hierarchy diagrams.\nTheo Absolutely! Also, I think I’ve found an interesting connection between DOP\nand meditation.\nJoe Really?\nTheo When we were eating at Simple, you told me that meditation helped you expe-\nrience reality as it is without the filter of your thoughts.\nJoe Right.\nTheo From what you taught me today, I understand that in DOP, we are encouraged\nto treat data as data without the filter of our classes.\nJoe Clever! I never noticed that connection between those two disciplines that are\nso important for me. I guess you’d like to continue your journey in the realm\nof DOP.\nTheo Definitely. Let’s meet again tomorrow.\nJoe Unfortunately, tomorrow I’m taking my family to the beach to celebrate the\ntwelfth birthday of my eldest daughter, Aurelia.\nTheo Happy birthday, Aurelia!\nJoe We could meet again next Monday, if that’s OK with you.\nTheo With pleasure!\nSummary\n DOP principle #2 is to represent data entities with generic data structures.\n We refer to maps that have strings as keys as string maps.\n Representing data as data means representing records with string maps.\n By positional collection, we mean a collection where the elements are in order\n(like a list or an array).\n A positional collection of Strings is noted as [String].\n By index, we mean a collection where the elements are accessible via a key (like\na hash map or a dictionary).\n An index of Books is noted as {Book}.\n In the context of a data model, the index keys are always strings.\n A record is a data structure that groups together related data items. It’s a collec-\ntion of fields, possibly of different data types.\n A homogeneous map is a map where all the values are of the same type.\n A heterogeneous map is a map where the values are of different types.\n In DOP, we represent a record as a heterogeneous string map.\n A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes.\n The relation between records in a data entity diagram is either composition or\nassociation.\n--- Page 98 ---\n70 CHAPTER 3 Basic data manipulation\n The data part of a DOP system is flexible, and each piece of information is\naccessible via its information path.\n There is a tradeoff between flexibility and safety in a data model.\n DOP compromises on data safety to gain flexibility and genericity.\n In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\n We manipulate data with generic functions.\n Generic functions are provided either by the language itself or by third-party\nlibraries like Lodash.\n JSON serialization is implemented in terms of a generic function.\n On the one hand, we’ve lost the safety of accessing record fields via members\ndefined at compile time. On the other hand, we’ve liberated data from the lim-\nitation of classes and objects. Data is represented as data!\n The weak dependency between code and data makes it is easier to adapt to\nchanging requirements.\n When data is represented as data, it is straightforward to visualize system data.\n Usually, we do not need to maintain type information about a record.\n We can visualize any part of the system data.\n In statically-typed languages, we sometimes need to statically cast the field values.\n Instead of maintaining type information about a record, we use a feature field.\n There is no significant performance hit for accessing a field in a map instead of\na class member.\n In DOP, you can retrieve every piece of information via an information path and\na generic function.\n In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\nLodash functions introduced in this chapter\nFunction Description\nget(map, path) Gets the value of map at path\nhas(map, path) Checks if map has a field at path\nmerge(mapA, mapB) Creates a map resulting from the recursive merges between mapA and mapB\nvalues(map) Creates an array of values of map\nfilter(coll, pred) Iterates over elements of coll, returning an array of all elements for which\npred returns true\nmap(coll, f) Creates an array of values by running each element in coll through f\n--- Page 99 ---\nState management\nTime travel\nThis chapter covers\n A multi-version approach to state management\n The calculation phase of a mutation\n The commit phase of a mutation\n Keeping a history of previous state versions\nSo far, we have seen how DOP handles queries via generic functions that access sys-\ntem data, which is represented as a hash map. In this chapter, we illustrate how\nDOP deals with mutations (requests that change the system state). Instead of updat-\ning the state in place, we maintain multiple versions of the system data. At a specific\npoint in time, the system state refers to a specific version of the system data. This\nchapter is a deep dive in the third principle of DOP.\nPRINCIPLE #3 Data is immutable.\nThe maintenance of multiple versions of the system data requires the data to be\nimmutable. This is made efficient both in terms of computation and memory via a\n71\n--- Page 100 ---\n72 CHAPTER 4 State management\ntechnique called structural sharing, where parts of the data that are common between\ntwo versions are shared instead of being copied. In DOP, a mutation is split into two\ndistinct phases:\n In the calculation phase, we compute the next version of the system data.\n In the commit phase, we move the system state forward so that it refers to the\nversion of the system data computed by the calculation phase.\nThis distinction between calculation and commit phases allows us to reduce the part\nof our system that is stateful to its bare minimum. Only the code of the commit phase\nis stateful, while the code in the calculation phase of a mutation is stateless and is\nmade of generic functions similar to the code of a query. The implementation of the\ncommit phase is common to all mutations. As a consequence, inside the commit\nphase, we have the ability to ensure that the state always refers to a valid version of the\nsystem data.\nAnother benefit of this state management approach is that we can keep track of\nthe history of previous versions of the system data. Restoring the system to a previous\nstate (if needed) becomes straightforward. Table 4.1 shows the two phases.\nTable 4.1 The two phases of a mutation\nPhase Responsibility State Implementation\nCalculation Computes the next version of system data Stateless Specific\nCommit Moves the system state forward Stateful Common\nIn this chapter, we assume that no mutations occur concurrently in our system. In the\nnext chapter, we will deal with concurrency control.\n4.1 Multiple versions of the system data\nWhen Joe comes in to the office on Monday, he tells Theo that he needs to exercise before\nstarting to work with his mind. Theo and Joe go for a walk around the block, and the dis-\ncussion turns toward version control systems. They discuss how Git keeps track of the\nwhole commit history and how easy and fast it is to restore the code to a previous state.\nWhen Theo tells Joe that Git’s ability to “time travel” reminds him one of his favorite mov-\nies, Back to the Future, Joe shares that a month ago he watched the Back to the Future trilogy\nwith Neriah, his 14-year-old son.\nTheir walk complete, they arrive back at Theo’s office. Theo and Joe partake of the\nespresso machine in the kitchen before they begin today’s lesson.\nJoe So far, we’ve seen how we manage queries that retrieve information from the\nsystem in DOP. Now I’m going to show you how we manage mutations. By a\nmutation, I mean an operation that changes the state of the system.\n NOTE A mutation is an operation that changes the state of the system.\n--- Page 101 ---\n4.1 Multiple versions of the system data 73\nTheo Is there a fundamental difference between queries and mutations in DOP?\nAfter all, the whole state of the system is represented as a hash map. I could\neasily write code that modifies part of the hash map, and it would be similar to\nthe code that retrieves information from the hash map.\nJoe You could mutate the data in place, but then it would be challenging to ensure\nthat the code of a mutation doesn’t put the system into an invalid date. You\nwould also lose the ability to track previous versions of the system state.\nTheo I see. So, how do you handle mutations in DOP?\nJoe We adopt a multi-version state approach, similar to what a version control sys-\ntem like Git does; we manage different versions of the system data. At a specific\npoint in time, the state of the system refers to a version of the system data. After\na mutation is executed, we move the reference forward.\nTheo I’m confused. Is the system state mutable or immutable?\nJoe The data is immutable, but the state reference is mutable.\nTIP The data is immutable, but the state reference is mutable.\nNoticing the look of confusion on Theo’s face, Joe draws a quick diagram on the white-\nboard. He then shows Theo figure 4.1, hoping that it will clear up Theo’s perplexity.\nAfter mutation B After mutation C\nData V10 Data V10\nMutationA MutationA\nData V11 Data V11\nMutation B Mutation B\nSystem State Data V12 Data V12\nMutation C\nSystem State Data V13\nFigure 4.1 After mutation B is executed, the system state refers to Data V12. After\nmutation C is executed, the system state refers to Data V13.\nTheo Does that mean that before the code of a mutation runs, we make a copy of the\nsystem data?\nJoe No, that would be inefficient, as we would have to do a deep copy of the data.",
        "sections_found": []
      },
      "accurate_page_range": "76-101"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "3 Basic data manipulation",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 28,
      "chapter_info": {
        "page": 76,
        "title": "Basic data manipulation",
        "pattern_matched": "Chapter 3",
        "text_preview": "48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to"
      },
      "chapter_sections": {
        "start_page": 76,
        "end_page": 101,
        "content": "\n--- Page 76 ---\n48 CHAPTER 3 Basic data manipulation\n NOTE A record is a data structure that groups together related data items. It’s a col-\nlection of fields, possibly of different data types.\nTheo Is it correct to say that a data entity diagram consists only of records, positional\ncollections, and indexes?\nJoe That’s correct. Can you make a similar statement about the relations between\nentities?\nTheo The relations in a data entity diagram are either composition (solid line with a\nfull diamond) or association (dashed line with an empty diamond). Both types\nof relations can be either one-to-one, one-to-many, or many-to-many.\nJoe Excellent!\nTIP A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes. The relation between records is either composition or\nassociation.\n3.2 Representing records as maps\nSo far, we’ve illustrated the benefits we gain from the separation between code and\ndata at a high-system level. There’s a separation of concerns between code and data,\nand each part has clear constraints:\n Code consists of static functions that receive data as an explicit argument.\n Data entities are modeled as records, and the relations between records are\nrepresented by positional collections and indexes.\nNow comes the question of the representation of the data. DOP has nothing special\ntosay about collections and indexes. However, it’s strongly opinionated about the\nrepresentation of records: records should be represented by generic data structures\nsuch as maps.\nThis applies to both OOP and FP languages. In dynamically-typed languages like\nJavaScript, Python, and Ruby, data representation feels natural. While in statically-\ntyped languages like Java and C#, it is a bit more cumbersome.\nTheo I’m really curious to know how we represent positional collections, indexes,\nand records in DOP.\nJoe Let’s start with positional collections. DOP has nothing special to say about the\nrepresentation of collections. They can be linked lists, arrays, vectors, sets, or\nother collections best suited for the use case.\nTheo It’s like in OOP.\nJoe Right! For now, to keep things simple, we’ll use arrays to represent positional\ncollections.\nTheo What about indexes?\nJoe Indexes are represented as homogeneous string maps.\nTheo What do you mean by a homogeneous map?\n--- Page 77 ---\n3.2 Representing records as maps 49\nJoe I mean that all the values of the map are of the same kind. For example, in a\nBook index, all the values are Book, and in an author index, all the values are\nAuthor, and so forth.\nTheo Again, it’s like in OOP.\n NOTE A homogeneous map is a map where all the values are of the same type. A hetero-\ngeneous map is a map where the values are of different types.\nJoe Now, here’s the big surprise. In DOP, records are represented as maps, more\nprecisely, heterogeneous string maps.\nJoe goes to the whiteboard and begins to draw. When he’s finished, he shows Theo the dia-\ngram in figure 3.4.\nRecord Heterogeneous map\nLinked list\nArray\nData representation Collection\nSet\nVector\nFigure 3.4 The building blocks\nIndex Homogeneous map\nof data representation\nTheo stays silent for a while. He is shocked to hear that the data entities of a system can be\nrepresented as a generic data structure, where the field names and value types are not\nspecified in a class. Then, Theo asks Joe:\nTheo What are the benefits of this folly?\nJoe Flexibility and genericity.\nTheo Could you explain, please?\nJoe I’ll explain in a moment, but before that, I’d like to show you what an instance\nof a record in a DOP system looks like.\nTheo OK.\nJoe Let’s take as an example, Watchmen, by Alan Moore and Dave Gibbons, which is\nmy favorite graphic novel. This masterpiece was published in 1987. I’m going\nto assume that, in a physical library, there are two copies of this book, whose ID\nis nyc-central-lib, and that one of the two copies is currently out. Here’s\nhow I’d represent the Book record for Watchmen in DOP.\nJoe comes closer to Theo’s laptop. He opens a text editor (not an IDE!) and types the Book\nrecord for Theo.\n--- Page 78 ---\n50 CHAPTER 3 Basic data manipulation\nListing3.1 An instance of a Book record represented as a map\n{\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\nTheo looks at the laptop screen. He has a question.\nTheo How am I supposed to instantiate the Book record for Watchmen programmat-\nically?\nJoe It depends on the facilities that your programming language offers to instantiate\nmaps. With dynamic languages like JavaScript, Ruby, or Python, it’s straight-\nforward, because we can use literals for maps and arrays. Here, let me show\nyou how.\nJoe jots down the JavaScript code that creates an instance of a Book record, which rep-\nresents as a map in JavaScript. He shows the code to Theo.\nListing3.2 A Book record represented as a map in JavaScript\nvar watchmenBook = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authors\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n--- Page 79 ---\n3.2 Representing records as maps 51\nTheo And, if I’m in Java?\nJoe It’s a bit more tedious, but still doable with the immutable Map and List static\nfactory methods.\n NOTE See “Creating Immutable Lists, Sets, and Maps” at http://mng.bz/voGm for\nmore information on this Java core library.\nJoe types the Java code to create an instance of a Book record represented as a map. He\nshows Theo the Java code.\nListing3.3 A Book record represented as a map in Java\nMap watchmen = Map.of(\n\"isbn\", \"978-1779501127\",\n\"title\", \"Watchmen\",\n\"publicationYear\", 1987,\n\"authors\", List.of(\"alan-moore\", \"dave-gibbons\"),\n\"bookItems\", List.of(\nMap.of(\n\"id\", \"book-item-1\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", true\n),\nMap.of (\n\"id\", \"book-item-2\",\n\"libId\", \"nyc-central-lib\",\n\"isLent\", false\n)\n)\n);\nTIP In DOP, we represent a record as a heterogeneous string map.\nTheo I’d definitely prefer to create a Book record using a Book class and a BookItem\nclass.\nTheo opens his IDE. He types the JavaScript code to represent a Book record as an instance\nof a Book class.\nListing3.4 A Book record as an instance of a Book class in JavaScript\nclass Book {\nisbn;\ntitle;\npublicationYear;\nauthors;\nbookItems;\nconstructor(isbn, title, publicationYear, authors, bookItems) {\nthis.isbn = isbn;\nthis.title = title;\nthis.publicationYear = publicationYear;\nthis.authors = authors;\nthis.bookItems = bookItems;\n--- Page 80 ---\n52 CHAPTER 3 Basic data manipulation\n}\n}\nclass BookItem {\nid;\nlibId;\nisLent;\nconstructor(id, libId, isLent) {\nthis.id = id;\nthis.libId = libId;\nthis.isLent = isLent;\n}\n}\nvar watchmenBook = new Book(\"978-1779501127\",\n\"Watchmen\",\n1987,\n[\"alan-moore\", \"dave-gibbons\"],\n[new BookItem(\"book-item-1\", \"nyc-central-lib\", true),\nnew BookItem(\"book-item-2\", \"nyc-central-lib\", false)]);\nJoe Theo, why do you prefer classes over maps for representing records?\nTheo It makes the data shape of the record part of my program. As a result, the IDE\ncan auto-complete field names, and errors are caught at compile time.\nJoe Fair enough. Can I show you some drawbacks for this approach?\nTheo Sure.\nJoe Imagine that you want to display the information about a book in the context\nof search results. In that case, instead of author IDs, you want to display\nauthor names, and you don’t need the book item information. How would\nyou handle that?\nTheo I’d create a class BookInSearchResults without a bookItems member and\nwith an authorNames member instead of the authorIds member of the Book\nclass. Also, I would need to write a copy constructor that receives a Book object.\nJoe In classic OOP, the fact that data is instantiated only via classes brings safety.\nBut this safety comes at the cost of flexibility.\nTIP There’s a tradeoff between flexibility and safety in a data model.\nTheo So, how can it be different?\nJoe In the DOP approach, where records are represented as maps, we don’t need\nto create a class for each variation of the data. We’re free to add, remove, and\nrename record fields dynamically. Our data model is flexible.\nTheo Interesting!\nTIP In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\nJoe Now, let me talk about genericity. How would you serialize the content of a\nBook object to JSON?\n--- Page 81 ---\n3.2 Representing records as maps 53\nTIP In DOP, records are manipulated with generic functions.\nTheo Oh no! I remember that while working on the Klafim prototype, I had a night-\nmare about JSON serialization when I was developing the first version of the\nLibrary Management System.\nJoe Well, in DOP, serializing a record to JSON is super easy.\nTheo Does it require the usage of reflection in order to go over the fields of the\nrecord like the Gson Java library does?\n NOTE See https://github.com/google/gson for more information on Gson.\nJoe Not at all! Remember that in DOP, a record is nothing more than data. We can\nwrite a generic JSON serialization function that works with any record. It can\nbe a Book, an Author, a BookItem, or anything else.\nTheo Amazing!\nTIP In DOP, you get JSON serialization for free.\nJoe Actually, as I’ll show you in a moment, lots of data manipulation stuff can be\ndone using generic functions.\nTheo Are the generic functions part of the language?\nJoe It depends on the functions and on the language. For example, JavaScript pro-\nvides a JSON serialization function called JSON.stringify out of the box, but\nnone for omitting multiple keys or for renaming keys.\nTheo That’s annoying.\nJoe Not so much; there are third-party libraries that provide data-manipulation facil-\nities. A popular data manipulation library in the JavaScript ecosystem is Lodash.\n NOTE See https://lodash.com/ to find out more about Lodash.\nTheo What about other languages?\nJoe Lodash has been ported to Java, C#, Python, and Ruby. Let me bookmark some\nsites for you.\nJoe bookmarks these sites for Theo:\n https://javalibs.com/artifact/com.github.javadev/underscore-lodash for Java\n https://www.nuget.org/packages/lodash/ for C#\n https://github.com/dgilland/pydash for Python\n https://rudash-website.now.sh/ for Ruby\n NOTE Throughout the book, we use Lodash to show how to manipulate data with\ngeneric functions, but there is nothing special about Lodash. The exact same approach\ncould be implemented via other data manipulation libraries or custom code.\nTheo Cool!\nJoe Actually, Lodash and its rich set of data manipulation functions can be ported\nto any language. That’s why it’s so beneficial to represent records as maps.\n--- Page 82 ---\n54 CHAPTER 3 Basic data manipulation\nTIP DOP compromises on data safety to gain flexibility and genericity.\nAt the whiteboard, Joe quickly sketches the tradeoffs (see table 3.1).\nTable 3.1 The tradeoff among safety, flexibility, and genericity\nOOP DOP\nSafety High Low\nFlexibility Low High\nGenericity Low High\n3.3 Manipulating data with generic functions\nJoe Now let me show you how to manipulate data in DOP with generic functions.\nTheo Yes, I’m quite curious to see how you’ll implement the search functionality of\nthe Library Management System.\nJoe OK. First, let’s instantiate a Catalog record for the catalog data of a library,\nwhere we have a single book, Watchmen.\nJoe instantiates a Catalog record according to Theo’s data model in figure 3.3. Here’s\nwhat Joe shows to Theo.\nListing3.5 A Catalog record\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n--- Page 83 ---\n3.3 Manipulating data with generic functions 55\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\nTheo I see the two indexes we talked about, booksByIsbn and authorsById. How\ndo you differentiate a record from an index in DOP?\nJoe In an entity diagram, there’s a clear distinction between records and indexes.\nBut in our code, both are plain data.\nTheo I guess that’s why this approach is called data-oriented programming.\nJoe See how straightforward it is to visualize any part of the system data inside a\nprogram? The reason is that data is represented as data!\nTIP In DOP, data is represented as data.\nTheo That sounds like a lapalissade.1\nJoe Oh, does it? I’m not so sure! In OOP, data is usually represented by objects,\nwhich makes it more challenging to visualize data inside a program.\nTIP In DOP, we can visualize any part of the system data.\nTheo How would you retrieve the title of a specific book from the catalog data?\nJoe Great question! In fact, in a DOP system, every piece of information has an\ninformation path from which we can retrieve the information.\nTheo Information path?\nJoe For example, the information path to the title of the Watchmen book in the\ncatalog is [\"booksByIsbn\", \"978-1779501127\", \"title\"].\nTheo Ah, I see. So, is an information path sort of like a file path, but that names in\nan information path correspond to nested entities?\nJoe You’re exactly right. And once we have the path of a piece of information, we\ncan retrieve the information with Lodash’s _.get function.\nJoe types a few characters on Theo’s laptop. Theo is amazed at how little code is needed to\nget the book title.\nListing3.6 Retrieving the title of a book from its information path\n_.get(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"])\n// → \"Watchmen\"\nTheo Neat. I wonder how hard it would be to implement a function like _.get\nmyself.\n1 A lapalissade is an obvious truth—a truism or tautology—that produces a comical effect.\n--- Page 84 ---\n56 CHAPTER 3 Basic data manipulation\nAfter a few minutes of trial and error, Theo is able to produce his implementation. He\nshows Joe the code.\nListing3.7 Custom implementation of get\nfunction get(m, path) {\nvar res = m;\nfor(var i = 0; i < path.length; i++) {\nWe could use\nvar key = path[i];\nforEach instead\nres = res[key];\nof a for loop.\n}\nreturn res;\n}\nAfter testing Theo’s implementation of get, Joe compliments Theo. He’s grateful that\nTheo is catching on so quickly.\nListing3.8 Testing the custom implementation of get\nget(catalogData, [\"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nJoe Well done!\nTheo I wonder if a function like _.get works smoothly in a statically-typed language\nlike Java?\nJoe It depends on whether you only need to pass the value around or to access the\nvalue concretely.\nTheo I don’t follow.\nJoe Imagine that once you get the title of a book, you want to convert the string\ninto an uppercase string. You need to do a static cast to String, right? Here,\nlet me show you an example that casts a field value to a string, then we can\nmanipulate it as a string.\nListing3.9 Casting a field value to a string\n((String)watchmen.get(\"title\")).toUpperCase()\nTheo That makes sense. The values of the map are of different types, so the compiler\ndeclares it as a Map<String,Object>. The information of the type of the field\nis lost.\nJoe It’s a bit annoying, but quite often our code just passes the data around. In that\ncase, we don’t have to deal with static casting. Moreover, in a language like C#,\nwhen using the dynamic data type, type casting can be avoided.2,3\n2 See http://mng.bz/4jo5 for the C# documentation on the built-in reference to dynamic types.\n3 See appendix A for details about dynamic fields and type casting in C#.\n--- Page 85 ---\n3.3 Manipulating data with generic functions 57\nTIP In statically-typed languages, we sometimes need to statically cast the field values.\nTheo What about performance?\nJoe In most programming languages, maps are quite efficient. Accessing a field\nin a map is slightly slower than accessing a class member. Usually, it’s not\nsignificant.\nTIP There’s no significant performance hit for accessing a field in a map instead of as\na class member.\nTheo Let’s get back to this idea of information path. It works in OOP too. I could\naccess the title of the Watchmen book with catalogData.booksByIsbn[\"978-\n1779501127\"].title. I’d use class members for record fields and strings for\nindex keys.\nJoe There’s a fundamental difference, though. When records are represented as\nmaps, the information can be retrieved via its information path using a generic\nfunction like _.get. But when records are represented as objects, you need to\nwrite specific code for each type of information path.\nTheo What do you mean by specific code? What’s specific in catalogData.books-\nByIsbn[\"978-1779501127\"].title?\nJoe In a statically-typed language like Java, you’d need to import the class defini-\ntions for Catalog and Book.\nTheo And, in a dynamically-typed language like JavaScript...?\nJoe Even in JavaScript, when you represent records with objects instantiated from\nclasses, you can’t easily write a function that receives a path as an argument\nand display the information that corresponds to this path. You would have to\nwrite specific code for each kind of path. You’d access class members with dot\nnotation and map fields with bracket notation.\nTheo Would you say that in DOP, the information path is a first-class citizen?\nJoe Absolutely! The information path can be stored in a variable and passed as an\nargument to a function.\nTIP In DOP, you can retrieve every piece of information via a path and a generic\nfunction.\nJoe goes to the whiteboard. He draws a diagram like that in figure 3.5, which shows the\ncatalog data as a tree.\nJoe You see, Theo, each piece of information is accessible via a path made of\nstrings and integers. For example, the path of Alan Moore’s first book is\n[\"catalog\", \"authorsById\", \"alan-moore\", \"bookIsbns\", 0].\n--- Page 86 ---\n58 CHAPTER 3 Basic data manipulation\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 3.5 The catalog data as a tree\n3.4 Calculating search results\nTheo Interesting. I’m starting to feel the power of expression of DOP!\nJoe Wait, that’s just the beginning. Let me show you how simple it is to write code\nthat retrieves book information and displays it in search results. Can you tell\nme exactly what information has to appear in the search results?\nTheo Searching for book information should return isbn, title, and author-\nNames.\nJoe And what would a BookInfo record look like for Watchmen?\nTheo quickly enters the code on his laptop. He then shows it to Joe.\nListing3.10 A BookInfo record for Watchmen in the context of search result\n{\n\"title\": \"Watchmen\",\n\"isbn\": \"978-1779501127\",\n\"authorNames\": [\n\"Alan Moore\",\n\"Dave Gibbons\",\n]\n}\n--- Page 87 ---\n3.4 Calculating search results 59\nJoe Now I’ll show you step by step how to write a function that returns search\nresults matching a title in JSON format. I’ll use generic data manipulation\nfunctions from Lodash.\nTheo I’m ready!\nJoe Let’s start with an authorNames function that calculates the author names of a\nBook record by looking at the authorsById index. Could you tell me what’s\nthe information path for the name of an author whose ID is authorId?\nTheo It’s [\"authorsById\", authorId, \"name\"].\nJoe Now, let me show you how to retrieve the name of several authors using _.map.\nJoe types the code to map the author IDs to the author names. Theo nonchalantly peeks\nover Joe’s shoulder.\nListing3.11 Mapping author IDs to author names\n_.map([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\nTheo What’s this _.map function? It smells like functional programming! You said I\nwouldn’t have to learn FP to implement DOP!\nJoe No need to learn functional programming in order to use _.map, which is a\nfunction that transforms the values of a collection. You can implement it with\na simple for loop.\nTheo spends a couple of minutes in front of his computer figuring out how to implement\n_.map. Now he’s got it!\nListing3.12 Custom implementation of map\nfunction map(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nres[i] = f(coll[i]);\nforEach instead\n}\nof a for loop.\nreturn res;\n}\nAfter testing Theo’s implementation of map, Joe shows Theo the test. Joe again compli-\nments Theo.\nListing3.13 Testing the custom implementation of map\nmap([\"alan-moore\", \"dave-gibbons\"],\nfunction(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n// → [ \"Alan Moore\", \"Dave Gibbons\"]\n--- Page 88 ---\n60 CHAPTER 3 Basic data manipulation\nJoe Well done!\nTheo You were right! It wasn’t hard.\nJoe Now, let’s implement authorNames using _.map.\nIt takes a few minutes for Theo to come up with the implementation of authorNames.\nWhen he’s finished, he turns his laptop to Joe.\nListing3.14 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nJoe We also need a bookInfo function that converts a Book record into a Book-\nInfo record. Let me show you the code for that.\nListing3.15 Converting a Book record into a BookInfo record\nfunction bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": authorNames(catalogData, book)\n};\nThere’s no need to create\nreturn bookInfo;\na class for bookInfo.\n}\nTheo Looking at the code, I see that a BookInfo record has three fields: title,\nisbn, and authorNames. Is there a way to get this information without looking\nat the code?\nJoe You can either add it to the data entity diagram or write it in the documenta-\ntion of the bookInfo function, or both.\nTheo I have to get used to the idea that in DOP, the record field information is not\npart of the program.\nJoe Indeed, it’s not part of the program, but it gives us a lot of flexibility.\nTheo Is there any way for me to have my cake and eat it too?\nJoe Yes, and someday I’ll show you how to make record field information part of a\nDOP program (see chapters 7 and 12).\nTheo Sounds intriguing!\nJoe Now that we have all the pieces in place, we can write our searchBooksBy-\nTitle function, which returns the book information about the books that\nmatch the query. First, we find the Book records that match the query with\n_.filter and then we transform each Book record into a BookInfo record\nwith _.map and bookInfo.\n--- Page 89 ---\n3.4 Calculating search results 61\nListing3.16 Searching books that match a query\nfunction searchBooksByTitle(catalogData, query) {\nvar allBooks = _.values(_.get(catalogData, \"booksByIsbn\"));\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\nThe includes JavaScript\n});\nfunction checks whether\na string includes a string\nvar bookInfos = _.map(matchingBooks, function(book) { as a substring.\nreturn bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\nTheo You’re using Lodash functions without any explanation again!\nJoe Sorry about that. I am so used to basic data manipulation functions that I con-\nsider them as part of the language. What functions are new to you?\nTheo _.values and _.filter\nJoe Well, _.values returns a collection made of the values of a map, and _.filter\nreturns a collection made of the values that satisfy a predicate.\nTheo _.values seems trivial. Let me try to implement _.filter.\nThe implementation of _.filter takes a bit more time. Eventually, Theo manages to get\nit right, then he is able to test it.\nListing3.17 Custom implementation of filter\nfunction filter(coll, f) {\nvar res = [];\nfor(var i = 0; i < coll.length; i++) {\nWe could use\nif(f(coll[i])) {\nforEach instead\nres.push(coll[i]);\nof a for loop.\n}\n}\nreturn res;\n}\nListing3.18 Testing the custom implementation of filter\nfilter([\"Watchmen\", \"Batman\"], function (title) {\nreturn title.includes(\"Watch\");\n});\n// → [\"Watchmen\"]\nTheo To me, it’s a bit weird that to access the title of a book record, I need to write\n_.get(book, \"title\"). I’d expect it to be book.title in dot notation or\nbook[\"title\"] in bracket notation.\nJoe Remember that book is a record that’s not represented as an object. It’s a map.\nIndeed, in JavaScript, you can write _.get(book, \"title\"), book.title, or\nbook[\"title\"]. But I prefer to use Lodash’s _.get function. In some lan-\nguages, the dot and the bracket notations might not work on maps.\n--- Page 90 ---\n62 CHAPTER 3 Basic data manipulation\nTheo Being language-agnostic has a price!\nJoe Right, would you like to test searchBooksByTitle?\nTheo Absolutely! Let me call searchBooksByTitle to search the books whose title\ncontain the string Watch.\nListing3.19 Testing searchBooksByTitle\nsearchBooksByTitle(catalogData, \"Wat\");\n//[\n// {\n// \"authorNames\": [\n// \"Alan Moore\",\n// \"Dave Gibbons\"\n// ],\n// \"isbn\": \"978-1779501127\",\n// \"title\": \"Watchmen\"\n// }\n//]\nTheo It seems to work! Are we done with the search implementation?\nJoe Almost. The searchBooksByTitle function we wrote is going to be part of the\nCatalog module, and it returns a collection of records. We have to write a\nfunction that’s part of the Library module, and that returns a JSON string.\nTheo You told me earlier that JSON serialization was straightforward in DOP.\nJoe Correct. The code for searchBooksByTitleJSON retrieves the Catalog record,\npasses it to searchBooksByTitle, and converts the results to JSON with\nJSON.stringify. That’s part of JavaScript. Here, let me show you.\nListing3.20 Implementation of searching books in a library as JSON\nfunction searchBooksByTitleJSON(libraryData, query) {\nvar results = searchBooksByTitle(_.get(libraryData, \"catalog\"), query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\nJoe In order to test our code, we need to create a Library record that contains our\nCatalog record. Could you do that for me, please?\nTheo Should the Library record contain all the Library fields (name, address,\nand UserManagement)?\nJoe That’s not necessary. For now, we only need the catalog field, then the test\nfor searching books.\nListing3.21 A Library record\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n--- Page 91 ---\n3.4 Calculating search results 63\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nListing3.22 Test for searching books in a library as JSON\nsearchBooksByTitleJSON(libraryData, \"Wat\");\nTheo How are we going to combine the four functions that we’ve written so far?\nJoe The functions authorNames, bookInfo, and searchBooksByTitle go into\nthe Catalog module, and searchBooksByTitleJSON goes into the Library\nmodule.\nTheo looks at the resulting code of the two modules, Library and Catalog. He’s quite\namazed by its conciseness.\nListing3.23 Calculating search results for Library and Catalog\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\n--- Page 92 ---\n64 CHAPTER 3 Basic data manipulation\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nThere’s no need\nreturn bookInfo;\nto create a class\n}\nfor bookInfo.\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nWhen _.filter is\nvar matchingBooks = _.filter(allBooks,\npassed a map, it\nfunction(book) {\ngoes over the values\nreturn _.get(book, \"title\").includes(query);\nof the map.\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nConverts data\nreturn resultsJSON;\nto JSON (part\n}\nof JavaScript)\n}\nAfter testing the final code in listing 3.24, Theo looks again at the source code from list-\ning 3.23. After a few seconds, he feels like he’s having another Aha! moment.\nListing3.24 Search results in JSON\nLibrary.searchBooksByTitleJSON(libraryData, \"Watchmen\");\n// → \"[{\\\"title\\\":\\\"Watchmen\\\",\\\"isbn\\\":\\\"978-1779501127\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}]\"\nTheo The important thing is not that the code is concise, but that the code contains\nno abstractions. It’s just data manipulation!\nJoe responds with a smile that says, “You got it, my friend!”\nJoe It reminds me of what my first meditation teacher told me 10 years ago:\nmeditation guides the mind to grasp the reality as it is without the abstractions\ncreated by our thoughts.\nTIP In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\n--- Page 93 ---\n3.5 Handling records of different types 65\n3.5 Handling records of different types\nWe’ve seen how DOP enables us to treat records as first-class citizens that can be\nmanipulated in a flexible way using generic functions. But if a record is nothing more\nthan an aggregation of fields, how do we know what the type of the record is? DOP has\na surprising answer to this question.\nTheo I have a question. If a record is nothing more than a map, how do you know\nthe type of the record?\nJoe That’s a great question with a surprising answer.\nTheo I’m curious.\nJoe Most of the time, there’s no need to know the record type.\nTheo What! What do you mean?\nJoe I mean that what matters most are the values of the fields. For example, take a\nlook at the Catalog.authorNames source code. It operates on a Book record,\nbut the only thing that matters is the value of the authorIds field.\nDoubtful, Theo looks at the source code for Catalog.authorNames. This is what Theo sees.\nListing3.25 Calculating the author names of a book\nfunction authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nTheo What about differentiating between various user types like Member versus\nLibrarian? I mean, they both have email and encryptedPassword. How do\nyou know if a record represents a Member or a Librarian?\nJoe Simple. You check to see if the record is found in the librariansByEmail\nindex or in the membersByEmail index of the Catalog.\nTheo Could you be more specific?\nJoe Sure! Let me write what the user management data of our tiny library might\nlook like, assuming we have one librarian and one member. To keep things\nsimple, I’m encrypting passwords through naive base-64 encoding for the User-\nManagement record.\nListing3.26 A UserManagement record\nvar userManagementData = {\n\"librariansByEmail\": {\n\"franck@gmail.com\" : { The base-64\nencoding of\n\"email\": \"franck@gmail.com\",\n\"mypassword\"\n\"encryptedPassword\": \"bXlwYXNzd29yZA==\"\n}\n},\n--- Page 94 ---\n66 CHAPTER 3 Basic data manipulation\n\"membersByEmail\": {\n\"samantha@gmail.com\": {\n\"email\": \"samantha@gmail.com\",\n\"encryptedPassword\": \"c2VjcmV0\",\nThe base-64\n\"isBlocked\": false,\nencoding of\n\"bookLendings\": [\n\"secret\"\n{\n\"bookItemId\": \"book-item-1\",\n\"bookIsbn\": \"978-1779501127\",\n\"lendingDate\": \"2020-04-23\"\n}\n]\n}\n}\n}\nTIP Most of the time, there’s no need to know the record type.\nTheo This morning, you told me you’d show me the code for UserManagement\n.isLibrarian function this afternoon.\nJoe So, here we are. It’s afternoon, and I’m going to fulfill my promise.\nJoe implements isLibrarian. With a slight pause, he then issues the test for isLibrarian.\nListing3.27 Checking if a user is a librarian\nfunction isLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nListing3.28 Testing isLibrarian\nisLibrarian(userManagementData, \"franck@gmail.com\");\n// → true\nTheo I’m assuming that _.has is a function that checks whether a key exists in a\nmap. Right?\nJoe Correct.\nTheo OK. You simply check whether the librariansByEmail map contains the\nemail field.\nJoe Yep.\nTheo Would you use the same pattern to check whether a member is a Super mem-\nber or a VIP member?\nJoe Sure. We could have SuperMembersByEmail and VIPMembersByEmail indexes.\nBut there’s a better way.\nTheo How?\nJoe When a member is a VIP member, we add a field, isVIP, with the value true to\nits record. To check if a member is a VIP member, we check whether the\nisVIP field is set to true in the member record. Here’s how I would code\nisVIPMember.\n--- Page 95 ---\n3.5 Handling records of different types 67\nListing3.29 Checking whether a member is a VIP member\nfunction isVIPMember(userManagement, email) {\nreturn _.get(userManagement, [\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nTheo I see that you access the isVIP field via its information path, [\"membersBy-\nEmail\", email, \"isVIP\"].\nJoe Yes, I think it makes the code crystal clear.\nTheo I agree. I guess we can do the same for isSuperMember and set an isSuper\nfield to true when a member is a Super member?\nJoe Yes, just like this.\nJoe assembles all the pieces in a UserManagement class. He then shows the code to Theo.\nListing3.30 The code of UserManagement module\nclass UserManagement {\nisLibrarian(userManagement, email) {\nreturn _.has(_.get(userManagement, \"librariansByEmail\"), email);\n}\nisVIPMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isVIP\"]) == true;\n}\nisSuperMember(userManagement, email) {\nreturn _.get(userManagement,\n[\"membersByEmail\", email, \"isSuper\"]) == true;\n}\n}\nTheo looks at the UserManagement module code for a couple of seconds. Suddenly, an\nidea comes to his mind.\nTheo Why not have a type field in member record whose value would be either VIP\nor Super?\nJoe I assume that, according to the product requirements, a member can be both a\nVIP and a Super member.\nTheo Hmm...then the types field could be a collection containing VIP or Super\nor both.\nJoe In some situations, having a types field is helpful, but I find it simpler to have\na Boolean field for each feature that the record supports.\nTheo Is there a name for fields like isVIP and isSuper?\nJoe I call them feature fields.\nTIP Instead of maintaining type information about a record, use a feature field (e.g.,\nisVIP).\n--- Page 96 ---\n68 CHAPTER 3 Basic data manipulation\nTheo Can we use feature fields to differentiate between librarians and members?\nJoe You mean having an isLibrarian and an isMember field?\nTheo Yes, and having a common User record type for both librarians and members.\nJoe We can, but I think it’s simpler to have different record types for librarians and\nmembers: Librarian for librarians and Member for members.\nTheo Why?\nJoe Because there’s a clear distinction between librarians and members in terms of\ndata. For example, members can have book lendings but librarians don’t.\nTheo I agree. Now, we need to mention the two Member feature fields in our entity\ndiagram.\nWith that, Theo adds these fields to his diagram on the whiteboard. When he’s finished, he\nshows Joe his additions (figure 3.6).\nCC Library\nname: String\naddress: String\ncatalog: Catalog\nuserManagement: Catalog\nCC Catalog CC UserManagement\nbooksByIsbn: {Book} librariansByEmail: {Librarian}\nauthorsById: {Author} membersByEmail: {Member}\n*\n*\n* CC Author CC Librarian *\nCC Book id: String email: String CC Member\nname: String\ntitle : String encryptedPassword: String email: String\nbookIsbns: [String]\npublicationYear: Number encryptedPassword: String\nisbn: String * isBlocked: Boolean\nauthorIds: [String] bookLendings: [BookLending]\nbookItems: [BookItem] * isVIP: Boolean\nisSuper: Boolean\nCC BookLending\nlendingDate: String\nbookItemId: String *\nCC BookItem\nbookIsbn: String\nid: String\nlibId: String\n*\npurchaseDate: String\nisLent: Boolean\nFigure 3.6 A library management data model with the Member feature fields isVIP and isSuper\nJoe Do you like the data model that we have designed together?\nTheo I find it quite simple and clear.\n--- Page 97 ---\nSummary 69\nJoe That’s the main goal of DOP.\nTheo Also, I’m pleasantly surprised how easy it is to adapt to changing requirements,\nboth in terms of code and the data model.\nJoe I suppose you’re also happy to get rid of complex class hierarchy diagrams.\nTheo Absolutely! Also, I think I’ve found an interesting connection between DOP\nand meditation.\nJoe Really?\nTheo When we were eating at Simple, you told me that meditation helped you expe-\nrience reality as it is without the filter of your thoughts.\nJoe Right.\nTheo From what you taught me today, I understand that in DOP, we are encouraged\nto treat data as data without the filter of our classes.\nJoe Clever! I never noticed that connection between those two disciplines that are\nso important for me. I guess you’d like to continue your journey in the realm\nof DOP.\nTheo Definitely. Let’s meet again tomorrow.\nJoe Unfortunately, tomorrow I’m taking my family to the beach to celebrate the\ntwelfth birthday of my eldest daughter, Aurelia.\nTheo Happy birthday, Aurelia!\nJoe We could meet again next Monday, if that’s OK with you.\nTheo With pleasure!\nSummary\n DOP principle #2 is to represent data entities with generic data structures.\n We refer to maps that have strings as keys as string maps.\n Representing data as data means representing records with string maps.\n By positional collection, we mean a collection where the elements are in order\n(like a list or an array).\n A positional collection of Strings is noted as [String].\n By index, we mean a collection where the elements are accessible via a key (like\na hash map or a dictionary).\n An index of Books is noted as {Book}.\n In the context of a data model, the index keys are always strings.\n A record is a data structure that groups together related data items. It’s a collec-\ntion of fields, possibly of different data types.\n A homogeneous map is a map where all the values are of the same type.\n A heterogeneous map is a map where the values are of different types.\n In DOP, we represent a record as a heterogeneous string map.\n A data entity diagram consists of records whose values are either primitives, posi-\ntional collections, or indexes.\n The relation between records in a data entity diagram is either composition or\nassociation.\n--- Page 98 ---\n70 CHAPTER 3 Basic data manipulation\n The data part of a DOP system is flexible, and each piece of information is\naccessible via its information path.\n There is a tradeoff between flexibility and safety in a data model.\n DOP compromises on data safety to gain flexibility and genericity.\n In DOP, the data model is flexible. We’re free to add, remove, and rename\nrecord fields dynamically at run time.\n We manipulate data with generic functions.\n Generic functions are provided either by the language itself or by third-party\nlibraries like Lodash.\n JSON serialization is implemented in terms of a generic function.\n On the one hand, we’ve lost the safety of accessing record fields via members\ndefined at compile time. On the other hand, we’ve liberated data from the lim-\nitation of classes and objects. Data is represented as data!\n The weak dependency between code and data makes it is easier to adapt to\nchanging requirements.\n When data is represented as data, it is straightforward to visualize system data.\n Usually, we do not need to maintain type information about a record.\n We can visualize any part of the system data.\n In statically-typed languages, we sometimes need to statically cast the field values.\n Instead of maintaining type information about a record, we use a feature field.\n There is no significant performance hit for accessing a field in a map instead of\na class member.\n In DOP, you can retrieve every piece of information via an information path and\na generic function.\n In DOP, many parts of our code base tend to be just about data manipulation\nwith no abstractions.\nLodash functions introduced in this chapter\nFunction Description\nget(map, path) Gets the value of map at path\nhas(map, path) Checks if map has a field at path\nmerge(mapA, mapB) Creates a map resulting from the recursive merges between mapA and mapB\nvalues(map) Creates an array of values of map\nfilter(coll, pred) Iterates over elements of coll, returning an array of all elements for which\npred returns true\nmap(coll, f) Creates an array of values by running each element in coll through f\n--- Page 99 ---\nState management\nTime travel\nThis chapter covers\n A multi-version approach to state management\n The calculation phase of a mutation\n The commit phase of a mutation\n Keeping a history of previous state versions\nSo far, we have seen how DOP handles queries via generic functions that access sys-\ntem data, which is represented as a hash map. In this chapter, we illustrate how\nDOP deals with mutations (requests that change the system state). Instead of updat-\ning the state in place, we maintain multiple versions of the system data. At a specific\npoint in time, the system state refers to a specific version of the system data. This\nchapter is a deep dive in the third principle of DOP.\nPRINCIPLE #3 Data is immutable.\nThe maintenance of multiple versions of the system data requires the data to be\nimmutable. This is made efficient both in terms of computation and memory via a\n71\n--- Page 100 ---\n72 CHAPTER 4 State management\ntechnique called structural sharing, where parts of the data that are common between\ntwo versions are shared instead of being copied. In DOP, a mutation is split into two\ndistinct phases:\n In the calculation phase, we compute the next version of the system data.\n In the commit phase, we move the system state forward so that it refers to the\nversion of the system data computed by the calculation phase.\nThis distinction between calculation and commit phases allows us to reduce the part\nof our system that is stateful to its bare minimum. Only the code of the commit phase\nis stateful, while the code in the calculation phase of a mutation is stateless and is\nmade of generic functions similar to the code of a query. The implementation of the\ncommit phase is common to all mutations. As a consequence, inside the commit\nphase, we have the ability to ensure that the state always refers to a valid version of the\nsystem data.\nAnother benefit of this state management approach is that we can keep track of\nthe history of previous versions of the system data. Restoring the system to a previous\nstate (if needed) becomes straightforward. Table 4.1 shows the two phases.\nTable 4.1 The two phases of a mutation\nPhase Responsibility State Implementation\nCalculation Computes the next version of system data Stateless Specific\nCommit Moves the system state forward Stateful Common\nIn this chapter, we assume that no mutations occur concurrently in our system. In the\nnext chapter, we will deal with concurrency control.\n4.1 Multiple versions of the system data\nWhen Joe comes in to the office on Monday, he tells Theo that he needs to exercise before\nstarting to work with his mind. Theo and Joe go for a walk around the block, and the dis-\ncussion turns toward version control systems. They discuss how Git keeps track of the\nwhole commit history and how easy and fast it is to restore the code to a previous state.\nWhen Theo tells Joe that Git’s ability to “time travel” reminds him one of his favorite mov-\nies, Back to the Future, Joe shares that a month ago he watched the Back to the Future trilogy\nwith Neriah, his 14-year-old son.\nTheir walk complete, they arrive back at Theo’s office. Theo and Joe partake of the\nespresso machine in the kitchen before they begin today’s lesson.\nJoe So far, we’ve seen how we manage queries that retrieve information from the\nsystem in DOP. Now I’m going to show you how we manage mutations. By a\nmutation, I mean an operation that changes the state of the system.\n NOTE A mutation is an operation that changes the state of the system.\n--- Page 101 ---\n4.1 Multiple versions of the system data 73\nTheo Is there a fundamental difference between queries and mutations in DOP?\nAfter all, the whole state of the system is represented as a hash map. I could\neasily write code that modifies part of the hash map, and it would be similar to\nthe code that retrieves information from the hash map.\nJoe You could mutate the data in place, but then it would be challenging to ensure\nthat the code of a mutation doesn’t put the system into an invalid date. You\nwould also lose the ability to track previous versions of the system state.\nTheo I see. So, how do you handle mutations in DOP?\nJoe We adopt a multi-version state approach, similar to what a version control sys-\ntem like Git does; we manage different versions of the system data. At a specific\npoint in time, the state of the system refers to a version of the system data. After\na mutation is executed, we move the reference forward.\nTheo I’m confused. Is the system state mutable or immutable?\nJoe The data is immutable, but the state reference is mutable.\nTIP The data is immutable, but the state reference is mutable.\nNoticing the look of confusion on Theo’s face, Joe draws a quick diagram on the white-\nboard. He then shows Theo figure 4.1, hoping that it will clear up Theo’s perplexity.\nAfter mutation B After mutation C\nData V10 Data V10\nMutationA MutationA\nData V11 Data V11\nMutation B Mutation B\nSystem State Data V12 Data V12\nMutation C\nSystem State Data V13\nFigure 4.1 After mutation B is executed, the system state refers to Data V12. After\nmutation C is executed, the system state refers to Data V13.\nTheo Does that mean that before the code of a mutation runs, we make a copy of the\nsystem data?\nJoe No, that would be inefficient, as we would have to do a deep copy of the data.",
        "sections_found": []
      },
      "accurate_page_range": "76-101"
    },
    {
      "text": "- 4.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 29,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 4.1 Multiple versions of the system data",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.1 Multiple versions of the system data (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 30,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 4.2 Structural sharing",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.2 Structural sharing (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 31,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 4.3 Implementing structural sharing",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.3 Implementing structural sharing (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 32,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 4.4 Data safety",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.4 Data safety (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 33,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 4.5 The commit phase of a mutation",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.5 The commit phase of a mutation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 34,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 4.6 Ensuring system state integrity",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.6 Ensuring system state integrity (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 35,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 4.7 Restoring previous states",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- 4.7 Restoring previous states (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 36,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "4 State management",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 37,
      "chapter_info": {
        "page": 102,
        "title": "State management",
        "pattern_matched": "Chapter 4",
        "text_preview": "74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead"
      },
      "chapter_sections": {
        "start_page": 102,
        "end_page": 125,
        "content": "\n--- Page 102 ---\n74 CHAPTER 4 State management\nTheo How does it work then?\nJoe It works by using a technique called structural sharing, where most of the data\nbetween subsequent versions of the state is shared instead of being copied.\nThis technique efficiently creates new versions of the system data, both in\nterms of memory and computation.\nTheo I’m intrigued.\nTIP With structural sharing, it’s efficient (in terms of memory and computation) to\ncreate new versions of data.\nJoe I’ll explain in detail how structural sharing works in a moment.\nTheo takes another look at the diagram in figure 4.1, which illustrates how the system state\nrefers to a version of the system data. Suddenly, a question emerges.\nTheo Are the previous versions of the system data kept?\nJoe In a simple application, previous versions are automatically removed by the\ngarbage collector. But, in some cases, we maintain historical references to pre-\nvious versions of the data.\nTheo What kind of cases?\nJoe For example, if we want to support time travel in our system, as in Git, we can\nmove the system back to a previous version of the state easily.\nTheo Now I understand what you mean by data is immutable, but the state reference\nis mutable!\n4.2 Structural sharing\nAs mentioned in the previous section, structural sharing enables the efficient cre-\nation of new versions of immutable data. In DOP, we use structural sharing in the\ncalculation phase of a mutation to compute the next state of the system based on\nthe current state of the system. Inside the calculation phase, we don’t have to deal\nwith state management; that is delayed to the commit phase. As a consequence, the\ncode involved in the calculation phase of a mutation is stateless and is as simple as\nthe code of a query.\nTheo I’m really intrigued by this more efficient way to create new versions of data.\nHow does it work?\nJoe Let’s take a simple example from our library system. Imagine that you want to\nmodify the value of a field in a book in the catalog; for instance, the publica-\ntion year of Watchmen. Can you tell me the information path for Watchmen’s\npublication year?\nTheo takes a quick look at the catalog data in figure 4.2. Then he answers Joe’s question.\n--- Page 103 ---\n4.2 Structural sharing 75\ncatalog\nbooksByIsbn authorsById\n978-1779501127 alan-moore\ntitle isbn name\nWatchmen 978-1779501127 Alan Moore\nauthorIds publicationYear bookIsbns\n1987\n1 0 0\nbookItems\ndave-gibbons alan-moore 978-1779501127\n1 0 dave-gibbons\nid id name\nbook-item-2 book-item-1 Dave Gibbons\nlibId libId bookIsbns\nla-central-lib nyc-cental-lib\n0\nisLent isLent\n978-1779501127\nfalse true\nFigure 4.2 Visualization of the catalog data. The nodes in the information path to Watchmen’s publication\nyear are marked with a dotted border.\nTheo The information path for Watchmen’s publication year is [\"catalog\", \"books-\nByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Now, let me show how you to use the immutable function _.set that Lodash\nalso provides.\nTheo Wait! What do you mean by an immutable function? When I looked at the\nLodash documentation for _.set on their website, it said that it mutates the\nobject.\nJoe You’re right, but the default Lodash functions are not immutable. In order to\nuse an immutable version of the functions, we need to use the Lodash FP mod-\nule as explained in the Lodash FP guide.\n NOTE See https://lodash.com/docs/4.17.15#set to view Lodash’s documentation\nfor _.set, and see https://github.com/lodash/lodash/wiki/FP-Guide to view the\nLodash FP guide.\nTheo Do the immutable functions have the same signature as the mutable functions?\nJoe By default, the order of the arguments in immutable functions is shuffled.\nThe Lodash FP guide explains how to resolve this. With this piece of code,\n--- Page 104 ---\n76 CHAPTER 4 State management\nthe signature of the immutable functions is exactly the same as the mutable\nfunctions.\nListing4.1 Configuring Lodash so immutable and mutable functions have same signature\n_ = fp.convert({\n\"cap\": false,\n\"curry\": false,\n\"fixed\": false,\n\"immutable\": true,\n\"rearg\": false\n});\nTIP In order to use Lodash immutable functions, we use Lodash’s FP module, and\nwe configure it so that the signature of the immutable functions is the same as in the\nLodash documentation web site.\nTheo So basically, I can still rely on Lodash documentation when using immutable\nversions of the functions.\nJoe Except for the piece in the documentation that says the function mutates the\nobject.\nTheo Of course!\nJoe Now I’ll show you how to write code that creates a version of the library data\nwith the immutable function _.set.\nJoe’s fingers fly across Theo’s keyboard. Theo then looks at Joe’s code, which creates a ver-\nsion of the library data where the Watchmen publication year is set to 1986.\nListing4.2 Using _.set as an immutable function\nvar nextLibraryData = _.set(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1986);\n NOTE A function is said to be immutable when, instead of mutating the data, it cre-\nates a new version of the data without changing the data it receives.\nTheo You told me earlier that structural sharing allowed immutable functions to be\nefficient in terms of memory and computation. Can you tell me what makes\nthem efficient?\nJoe With pleasure, but before that, you have to answer a series of questions. Are\nyou ready?\nTheo Yes, sure...\nJoe What part of the library data is impacted by updating the Watchmen publication\nyear: the UserManagement or the Catalog?\n--- Page 105 ---\n4.2 Structural sharing 77\nTheo Only the Catalog.\nJoe What part of the Catalog?\nTheo Only the booksByIsbn index.\nJoe What part of the booksByIsbn index?\nTheo Only the Book record that holds the information about Watchmen.\nJoe What part of the Book record?\nTheo Only the publicationYear field.\nJoe Perfect! Now, suppose that the current version of the library data looks like\nthis.\nJoe goes to the whiteboard and draws a diagram. Figure 4.3 shows the result.\nLibrary\nCatalog UserManagement\nauthorsByld booksBylsbn ...\n... watchmen\ntitle:Watchmen publicationYear:1987 authorlds\n...\nFigure 4.3 High-level visualization of the current version of Library\nTheo So far, so good...\nJoe Next, let me show you what an immutable function does when you use it to cre-\nate a new version of Library, where the publication year of Watchmen is set to\n1986 instead of 1987.\nJoe updates his diagram on the whiteboard. It now looks like figure 4.4.\n--- Page 106 ---\n78 CHAPTER 4 State management\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.4 Structural sharing provides an efficient way to create a new version of the data.\nNext Library is recursively made of nodes that use the parts of Library that are\ncommon between the two.\nTheo Could you explain?\nJoe The immutable function creates a fresh Library hash map, which recursively\nuses the parts of the current Library that are common between the two ver-\nsions instead of deeply copying them.\nTheo It’s a bit abstract for me.\nJoe The next version of Library uses the same UserManagement hash map as the\nold one. The Catalog inside the next Library uses the same authorsById as\nthe current Catalog. The Watchmen Book record inside the next Catalog uses\nall the fields of the current Book except for the publicationYear field.\nTheo So, in fact, most parts of the data are shared between the two versions. Right?\nJoe Exactly! That’s why this technique is called structural sharing.\nTIP Structural sharing provides an efficient way (both in terms of memory and com-\nputation) to create a new version of the data by recursively sharing the parts that don’t\nneed to change.\nTheo That’s very cool!\nJoe Indeed. Now let’s look at how to write a mutation for adding a member using\nimmutable functions.\n--- Page 107 ---\n4.2 Structural sharing 79\nOnce again, Joe goes to the whiteboard. Figure 4.5 shows the diagram that Joe draws to\nillustrate how structural sharing looks when we add a member.\n«Next»\nLibrary\nLibrary\n«Next»\nUserManagement Catalog\nuserManagement\n«Next»\nmembers librarians ...\nmembers\nFigure 4.5 Adding a member\nwith structural sharing. Most of\nthe data is shared between the\n... member0 member1\ntwo versions.\nTheo Awesome! The Catalog and the librarians hash maps don’t have to be copied!\nJoe Now, in terms of code, we have to write a Library.addMember function that\ndelegates to UserManagement.addMember.\nTheo I guess it’s going to be similar to the code we wrote earlier to implement the\nsearch books query, where Library.searchBooksByTitleJSON delegates to\nCatalog.searchBooksByTitle.\nJoe Similar in the sense that all the functions are static, and they receive the data\nthey manipulate as an argument. But there are two differences. First, a muta-\ntion could fail, for instance, if the member to be added already exists. Second,\nthe code for Library.addMember is a bit more elaborate than the code for\nLibrary.searchBooksByTitleJSON because we have to create a new version\nof Library that refers to the new version of UserManagement. Here, let me\nshow you an example.\nListing4.3 The code for the mutation that adds a member\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nChecks if a member with\nthrow \"Member already exists.\";\nthe same email address\n}\nalready exists\nvar nextUserManagement = _.set(\nuserManagement,\nCreates a new version of\ninfoPath,\nuserManagement that\nmember);\nincludes the member\nreturn nextUserManagement;\n};\n--- Page 108 ---\n80 CHAPTER 4 State management\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library,\n\"userManagement\",\nnextUserManagement);\nCreates a new version of\nreturn nextLibrary;\nlibrary that contains the new\n};\nversion of userManagement\nTheo To me, it’s a bit weird that immutable functions return an updated version of\nthe data instead of changing it in place.\nJoe It was also weird for me when I first encountered immutable data in Clojure\nseven years ago.\nTheo How long did it take you to get used to it?\nJoe A couple of weeks.\n4.3 Implementing structural sharing\nWhen Joe leaves the office, Theo meets Dave near the coffee machine. Dave looks perplexed.\nDave Who’s the guy that just left the office?\nTheo It’s Joe. My DOP mentor.\nDave What’s DOP?\nTheo DOP refers to data-oriented programming.\nDave I never heard that term before.\nTheo It’s not well-known by programmers yet, but it’s quite a powerful programming\nparadigm. From what I’ve seen so far, it makes programming much simpler.\nDave Can you give me an example?\nTheo I just learned about structural sharing and how it makes it possible to create\nnew versions of data, effectively without copying.\nDave How does that work?\nTheo takes Dave to his office and shows him Joe’s diagram on the whiteboard (see figure 4.6).\nIt takes Theo a few minutes to explain to Dave what it does exactly, but in the end, Dave\ngets it.\nDave What does the implementation of structural sharing look like?\nTheo I don’t know. I used the _.set function from Lodash.\nDave It sounds like an interesting challenge.\nTheo Take the challenge if you want. Right now, I’m too tired for this recursive algo-\nrithmic stuff.\n--- Page 109 ---\n4.3 Implementing structural sharing 81\n«Next»\nLibrary\nLibrary\n«Next»\nCatalog UserManagement\nCatalog\n«Next»\nbooksByIsbn ... authorsById\nbooksByIsbn\n«Next»\nwatchmen ...\nwatchmen\n«Next»\npublicationYear:1987 title:Watchmen authorlds\npublicationYear:1986\n...\nFigure 4.6 Structural sharing in action\nThe next day, Theo stops by Dave’s cubicle before heading to his office. Dave, with a touch\nof pride, shows Theo his implementation of structural sharing. Theo is amazed by the fact\nthat it’s only 11 lines of JavaScript code!\nListing4.4 The implementation of structural sharing\nfunction setImmutable(map, path, v) {\nvar modifiedNode = v;\nvar k = path[0];\nvar restOfPath = path.slice(1);\nif (restOfPath.length > 0) {\nmodifiedNode = setImmutable(map[k], restOfPath, v);\n}\nvar res = Object.assign({}, map);\nShallow\nres[k] = modifiedNode;\nclones a map\nreturn res;\nin JavaScript.\n}\nTheo Dave, you’re brilliant!\nDave (smiling) Aw, shucks.\nTheo Oops, I have to go. I’m already late for my session with Joe! Joe is probably wait-\ning in my office, biting his nails.\n--- Page 110 ---\n82 CHAPTER 4 State management\n4.4 Data safety\nJoe is about to start the day’s lesson. Theo asks him a question about yesterday’s material\ninstead.\nTheo Something isn’t clear to me regarding this structural sharing stuff. What hap-\npens if we write code that modifies the data part that’s shared between the two\nversions of the data? Does the change affect both versions?\nJoe Could you please write a code snippet that illustrates your question?\nTheo starts typing on his laptop. He comes up with this code to illustrate modifying a piece\nof data shared between two versions.\nListing4.5 Modifying data that’s shared between two versions\nvar books = {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n};\nvar nextBooks = _.set(books, [\"978-1779501127\", \"publicationYear\"], 1986)\nconsole.log(\"Before:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\nbooks[\"978-1779501127\"][\"authorIds\"][1] = \"dave-chester-gibbons\";\nconsole.log(\"After:\", nextBooks[\"978-1779501127\"][\"authorIds\"][1]);\n// → Before: dave-gibbons\n// → After: dave-chester-gibbons\nTheo My question is, what is the value of isBlocked in updatedMember?\nJoe The answer is that mutating data via the native hash map setter is forbidden.\nAll the data manipulation must be done via immutable functions.\n NOTE All data manipulation must be done with immutable functions. It is forbid-\nden to use the native hash map setter.\nTheo When you say “forbidden,” you mean that it’s up to the developer to make sure\nit doesn’t happen. Right?\nJoe Exactly.\nTheo Is there a way to protect our system from a developer’s mistake?\nJoe Yes, there is a way to ensure the immutability of the data at the level of the data\nstructure. It’s called persistent data structures.\nTheo Are persistent data structures also efficient in terms of memory and computation?\nJoe Actually, the way data is organized inside persistent data structures make them\neven more efficient than immutable functions.\n--- Page 111 ---\n4.5 The commit phase of a mutation 83\nTIP Persistent data structures are immutable at the level of the data. There is no way\nto mutate them, even by mistake.\nTheo Are there libraries providing persistent data structures?\nJoe Definitely. I just happen to have a list of those libraries on my computer.\nJoe, being well-organized for a programmer, quickly brings up his list. He shows it to Theo:\n Immutable.js in JavaScript at https://immutable-js.com/\n Paguro in Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections in C# at http://mng.bz/y4Ke\n Pyrsistent in Python at https://github.com/tobgu/pyrsistent\n Hamster in Ruby at https://github.com/hamstergem/hamster\nTheo Why not use persistent data structures instead of immutable functions?\nJoe The drawback of persistent data structures is that they are not native. This\nmeans that working with them requires conversion from native to persistent\nand from persistent to native.\nTheo What approach would you recommend?\nJoe If you want to play around a bit, then start with immutable functions. But for a\nproduction application, I’d recommend using persistent data structures.\nTheo Too bad the native data structures aren’t persistent!\nJoe That’s one of the reasons why I love Clojure—the native data structures of the\nlanguage are immutable!\n4.5 The commit phase of a mutation\nSo far, we saw how to implement the calculation phase of a mutation. The calculation\nphase is stateless in the sense that it doesn’t make any change to the system. Now, let’s\nsee how to update the state of the system inside the commit phase.\nTheo takes another look at the code for Library.addMember. Something bothers him:\nthis function returns a new state of the library that contains an additional member, but it\ndoesn’t affect the current state of the library.\nListing4.6 The commit phase moves the system state forward\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement,\nmember);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nTheo I see that Library.addMember doesn’t change the state of the library. How\ndoes the library state get updated?\n--- Page 112 ---\n84 CHAPTER 4 State management\nJoe That’s an excellent question. Library.addMember deals only with data calcula-\ntion and is stateless. The state is updated in the commit phase by moving for-\nward the version of the state that the system state refers to.\nTheo What do you mean by that?\nJoe Here’s what happens when we add a member to the system. The calculation\nphase creates a version of the state that has two members. Before the commit\nphase, the system state refers to the version of the state with one member. The\nresponsibility of the commit phase is to move the system state forward so that it\nrefers to the version of the state with two members.\nTIP The responsibility of the commit phase is to move the system state forward to the\nversion of the state returned by the calculation phase.\nJoe draws another illustration on the whiteboard (figure 4.7). He hopes it helps to clear up\nany misunderstanding Theo may have.\nBefore Commit After Commit\nState with one State with one\nSystem State\nmember member\naddMember addMember\nState with two State with two\nSystem State\nmembers members\nFigure 4.7 The commit phase moves the system state forward.\nTheo How is this implemented?\nJoe The code is made of two classes: System, a singleton stateful class that imple-\nments the mutations, and SystemState, a singleton stateful class that manages\nthe system state.\nTheo It sounds to me like classic OOP.\nJoe Right, and this part of the system being stateful is OOP-like.\nTheo I’m happy to see that you still find some utility in OOP.\nJoe Meditation taught me that every part of our universe has a role to play.\nTheo Nice! Could you show me some code?\nJoe Sure.\nJoe thinks for a moment before starting to type. He wants to show the System class and its\nimplementation of the addMember mutation.\nListing4.7 The System class\nclass System {\naddMember(member) {\nvar previous = SystemState.get();\n--- Page 113 ---\n4.6 Ensuring system state integrity 85\nvar next = Library.addMember(previous, member);\nSystemState.commit(previous, next);\nSystemState is covered\n}\nin listing 4.8.\n}\nTheo What does SystemState look like?\nJoe I had a feeling you were going to ask that. Here’s the code for the System-\nState class, which is a stateful class!\nListing4.8 The SystemState class\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nTheo I don’t get the point of SystemState. It’s a simple class with a getter and a\ncommit function, right?\nJoe In a moment, we are going to enrich the code of the SystemState.commit\nmethod so that it provides data validation and history tracking. For now, the\nimportant thing to notice is that the code of the calculation phase is stateless\nand is decoupled from the code of the commit phase, which is stateful.\nTIP The calculation phase is stateless. The commit phase is stateful.\n4.6 Ensuring system state integrity\nTheo Something still bothers me about the way functions manipulate immutable\ndata in the calculation phase. How do we preserve data integrity?\nJoe What do you mean?\nTheo In OOP, data is manipulated only by methods that belong to the same class as\nthe data. It prevents other classes from corrupting the inner state of the class.\nJoe Could you give me an example of an invalid state of the library?\nTheo For example, imagine that the code of a mutation adds a book item to the\nbook lendings of a member without marking the book item as lent in the cata-\nlog. Then the system data would be corrupted.\nJoe In DOP, we have the privilege of ensuring data integrity at the level of the\nwhole system instead of scattering the validation among many classes.\nTheo How does that work?\nJoe The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system data in a central place. At the beginning of the\ncommit phase, there is a step that checks whether the version of the system\n--- Page 114 ---\n86 CHAPTER 4 State management\nstate to be committed is valid. If the data is invalid, the commit is rejected.\nHere let me show you.\nListing4.9 Data validation inside the commit phase\nSystemState.commit = function(previous, next) {\nif(!SystemValidity.validate(previous, next)) { // not implemented for now\nthrow \"The system data to be committed is not valid!\";\n};\nthis.systemData = next;\n};\nTheo It sounds similar to a commit hook in Git.\nJoe I like your analogy!\nTheo Why are you passing the previous state in previous and the next state in next\nto SystemValidity.validate?\nJoe Because it allows SystemValidity.validate to optimize the validation in\nterms of computation. For example, we could validate just the data that has\nchanged.\nTIP In DOP, we validate the system data as a whole. Data validation is decoupled\nfrom data manipulation.\nTheo What does the code of SystemValidity.validate look like?\nJoe Someday, I will show you how to define a data schema and to validate that a\npiece of data conforms to a schema.\n NOTE See chapters 7 and 12 to see how Joe defines this data schema.\n4.7 Restoring previous states\nAnother advantage of the multi-version state approach with immutable data that is\nmanipulated via structural sharing is that we can keep track of the history of all the\nversions of the data without exploding the memory of our program. It allows us, for\ninstance, to restore the system back to an earlier state easily.\nTheo You told me earlier that it was easy to restore the system to a previous state.\nCould you show me how?\nJoe Happily, but before that, I’d like to make sure you understand why keeping\ntrack of all the versions of the data is efficient in terms of memory.\nTheo I think it’s related to the fact that immutable functions use structural sharing,\nand most of the data between subsequent versions of the state is shared.\nTIP Structural sharing allows us to keep many versions of the system state without\nexploding memory use.\nJoe Perfect! Now, I’ll show you how simple it is to undo a mutation. In order to\nimplement an undo mechanism, our SystemState class needs to have two\n--- Page 115 ---\n4.7 Restoring previous states 87\nreferences to the system data: systemData references the current state of the\nsystem, and previousSystemData references the previous state of the system.\nTheo That makes sense.\nJoe In the commit phase, we update both previousSystemData and systemData.\nTheo What does it take to implement an undo mechanism?\nJoe The undo is achieved by having systemData reference the same version of the\nsystem data as previousSystemData.\nTheo Could you walk me through an example?\nJoe To make things simple, I am going to give a number to each version of the sys-\ntem state. It starts at V0, and each time a mutation is committed, the version is\nincremented: V1, V2, V3, and so forth.\nTheo OK.\nJoe Let’s say that currently our system state is at V12 (see figure 4.8). In the\nSystemState object, systemData refers to V12, and previousSystemData\nrefers to V11.\npreviousSystemData\nMutationA Mutation B\nData V10 Data V11 Data V12\nsystemData\nFigure 4.8 When the system state is at V12, systemData refers to V12, and\npreviousSystemData refers to V11.\nTheo So far, so good...\nJoe Now, when a mutation is committed (for instance, adding a member), both\nreferences move forward: systemData refers to V13, and previousSystem-\nData refers to V12.\nJoe erases the whiteboard to make room for another diagram (figure 4.9). When he’s\nthrough with his drawing, he shows it to Theo.\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.9 When a mutation is committed, systemData refers to V13, and\npreviousSystemData refers to V12.\n--- Page 116 ---\n88 CHAPTER 4 State management\nTheo I suppose that when we undo the mutation, both references move backward.\nJoe In theory, yes, but in practice, it’s necessary to maintain a stack of all the state\nreferences. For now, to simplify things, we’ll maintain only a reference to the\nprevious version. As a consequence, when we undo the mutation, both refer-\nences refer to V12. Let me draw another diagram on the whiteboard that shows\nthis state (see figure 4.10).\npreviousSystemData\nMutationA Mutation B Mutation C\nData V10 Data V11 Data V12 Data V13\nsystemData\nFigure 4.10 When a mutation is undone, both systemData and previousSystemData refer\nto V12.\nTheo Could you show me how to implement this undo mechanism?\nJoe Actually, it takes only a couple of changes to the SystemState class. Pay atten-\ntion to the changes in the commit function. Inside systemDataBeforeUpdate,\nwe keep a reference to the current state of the system. If the validation and\nthe conflict resolution succeed, we update both previousSystemData and\nsystemData.\nListing4.10 The SystemState class with undo capability\nclass SystemState {\nsystemData;\npreviousSystemData;\nget() {\nreturn this.systemData;\n}\ncommit(previous, next) {\nvar systemDataBeforeUpdate = this.systemData;\nif(!Consistency.validate(previous, next)) {\nthrow \"The system data to be committed is not valid!\";\n}\nthis.systemData = next;\nthis.previousSystemData = systemDataBeforeUpdate;\n}\nundoLastMutation() {\nthis.systemData = this.previousSystemData;\n}\n}\n--- Page 117 ---\nSummary 89\nTheo I see that implementing System.undoLastMutation is simply a matter of hav-\ning systemData refer the same value as previousSystemData.\nJoe As I told you, if we need to allow multiple undos, the code would be a bit more\ncomplicated, but you get the idea.\nTheo I think so. Although Back to the Future belongs to the realm of science fiction, in\nDOP, time travel is real.\nSummary\n DOP principle #3 states that data is immutable.\n A mutation is an operation that changes the state of the system.\n In a multi-version approach to state management, mutations are split into cal-\nculation and commit phases.\n All data manipulation must be done via immutable functions. It is forbidden to\nuse the native hash map setter.\n Structural sharing allows us to create new versions of data efficiently (in terms of\nmemory and computation), where data that is common between the two ver-\nsions is shared instead of being copied.\n Structural sharing creates a new version of the data by recursively sharing the\nparts that don’t need to change.\n A mutation is split in two phases: calculation and commit.\n A function is said to be immutable when, instead of mutating the data, it creates\na new version of the data without changing the data it receives.\n During the calculation phase, data is manipulated with immutable functions that\nuse structural sharing.\n The calculation phase is stateless.\n During the commit phase, we update the system state.\n The responsibility of the commit phase is to move the system state forward to\nthe version of the state returned by the calculation phase.\n The data is immutable, but the state reference is mutable.\n The commit phase is stateful.\n We validate the system data as a whole. Data validation is decoupled from data\nmanipulation.\n The fact that the code for the commit phase is common to all the mutations\nallows us to validate the system state in a central place before we update the\nstate.\n Keeping the history of the versions of the system data is memory efficient due to\nstructural sharing.\n Restoring the system to one of its previous states is straightforward due to the\nclear separation between the calculation phase and the commit phase.\n--- Page 118 ---\n90 CHAPTER 4 State management\n In order to use Lodash immutable functions, we use the Lodash FP module\n(https://github.com/lodash/lodash/wiki/FP-Guide).\nLodash functions introduced in this chapter\nFunction Description\nset(map, path, value) Creates a map with the same fields as map with the addition of a\n<path, value> field\n--- Page 119 ---\nBasic concurrency control\nConflicts at home\nThis chapter covers\n Managing concurrent mutations with a lock-free\noptimistic concurrency control strategy\n Supporting high throughput of reads and writes\n Reconciliation between concurrent mutations\nThe changes required for system manage concurrency are only in the commit\nphase. They involve a reconciliation algorithm that is universal, in the sense that it\ncan be used in any system where data is represented as an immutable hash map.\nThe implementation of the reconciliation algorithm is efficient because subse-\nquent versions of the system state are created via structural sharing.\nIn the previous chapter, we illustrated the multiversion approach to state man-\nagement, where a mutation is split into two distinct phases: the calculation phase\nthat deals only with computation, and the commit phase that moves the state ref-\nerence forward. Usually, in a production system, mutations occur concurrently.\nMoving the state forward naively like we did in the previous chapter is not appro-\npriate. In the present chapter, we are going to learn how to handle concurrent\nmutations.\n91\n--- Page 120 ---\n92 CHAPTER 5 Basic concurrency control\nIn DOP, because only the code of the commit phase is stateful, that allows us to use\nan optimistic concurrency control strategy that doesn’t involve any locking mechanism. As\na consequence, the throughput of reads and writes is high. The modifications to the\ncode are not trivial, as we have to implement an algorithm that reconciles concurrent\nmutations. But the modifications impact only the commit phase. The code for the cal-\nculation phase stays the same as in the previous chapter.\n NOTE This chapter requires more of an effort to grasp. The flow of the reconcilia-\ntion algorithm is definitely not trivial, and the implementation involves a nontrivial\nrecursion.\n5.1 Optimistic concurrency control\nThis morning, before getting to work, Theo takes Joe to the fitness room in the office and,\nwhile running on the step machine, the two men talk about their personal lives again. Joe\ntalks about a fight he had last night with Kay, who thinks that he pays more attention to his\nwork than to his family. Theo recounts the painful conflict he had with Jane, his wife,\nabout house budget management. They went to see a therapist, an expert in Imago Rela-\ntionship Therapy. Imago allowed them to transform their conflict into an opportunity to\ngrow and heal.\nJoe’s ears perk up when he hears the word conflict because today’s lesson is going to be\nabout resolving conflicts and concurrent mutations. A different kind of conflict, though....\nAfter a shower and a healthy breakfast, Theo and Joe get down to work.\nJoe Yesterday, I showed you how to manage state with immutable data, assuming\nthat no mutations occur concurrently. Today, I am going to show you how to\ndeal with concurrency control in DOP.\nTheo I’m curious to discover what kind of lock mechanisms you use in DOP to syn-\nchronize concurrent mutations.\nJoe In fact, we don’t use any lock mechanism!\nTheo Why not?\nJoe Locks hit performance, and if you’re not careful, your system could get into a\ndeadlock.\nTheo So, how do you handle possible conflicts between concurrent mutations in\nDOP?\nJoe In DOP, we use a lock-free strategy called optimistic concurrency control. It’s a\nstrategy that allows databases like Elasticsearch to be highly scalable.\n NOTE See https://www.elastic.co/elasticsearch/ to find out more about Elastic-\nsearch.\nTheo You sound like my couples therapist and her anger-free, optimistic conflict\nresolution strategy.\nJoe Optimistic concurrency control and DOP fit together well. As you will see in a\nmoment, optimistic concurrency control is super efficient when the system\ndata is immutable.\n--- Page 121 ---\n5.1 Optimistic concurrency control 93\nTIP Optimistic concurrency control with immutable data is super efficient.\nTheo How does it work?\nJoe Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTIP Optimistic concurrency control occurs when we let mutations ask forgiveness\ninstead of permission.\nTheo What do you mean?\nJoe The calculation phase does its calculation as if it were the only mutation run-\nning. The commit phase is responsible for reconciling concurrent mutations\nwhen they don’t conflict or for aborting the mutation.\nTIP The calculation phase does its calculation as if it were the only mutation running.\nThe commit phase is responsible for trying to reconcile concurrent mutations.\nTheo That sounds quite challenging to implement.\nJoe Dealing with state is never trivial. But the good news is that the code for the\nreconciliation logic in the commit phase is universal.\nTheo Does that mean that the same code for the commit phase can be used in any\nDOP system?\nJoe Definitely. The code that implements the commit phase assumes nothing\nabout the details of the system except that the system data is represented as an\nimmutable map.\nTIP The implementation of the commit phase in optimistic concurrency control is\nuniversal. It can be used in any system where the data is represented by an immutable\nhash map.\nTheo That’s awesome!\nJoe Another cool thing is that handling concurrency doesn’t require any changes\nto the code in the calculation phase. From the calculation phase perspective,\nthe next version of the system data is computed in isolation as if no other muta-\ntions were running concurrently.\nJoe stands up to illustrate what he means on the whiteboard. While Theo looks at the draw-\ning in figure 5.1, Joe summarizes the information in table 5.1.\nTable 5.1 The two phases of a mutation with optimistic concurrency control\nPhase Responsibility State Implementation\nCalculation Compute next state in isolation Stateless Specific\nCommit Reconcile and update system state Stateful Common\n--- Page 122 ---\n94 CHAPTER 5 Basic concurrency control\nCalculation phase\nCapturesystem state\nComputenext version\nCommit phase\nYes No\nConcurrent mutations?\nYes No\nConflict?\nUpdatesystem state\nAbortmutation Reconcilemutations\nUpdatesystem state\nFigure 5.1 The logic flow\nof optimistic concurrency\ncontrol\n5.2 Reconciliation between concurrent mutations\nTheo Could you give me some examples of conflicting concurrent mutations?\nJoe Sure. One example would be two members trying to borrow the same book\ncopy. Another example might be when two librarians update the publication\nyear of the same book.\nTheo You mentioned that the code for the reconciliation logic in the commit phase\nis universal. What do you mean exactly by reconciliation logic?\nJoe It’s quite similar to what could happen in Git when you merge a branch back\ninto the main branch.\nTheo I love it when the main branch stays the same.\nJoe Yes, it’s nice when the merge has no conflicts and can be done automatically.\nDo you remember how Git handles the merge in that case?\nTheo Git does a fast-forward; it updates the main branch to be the same as the merge\nbranch.\nJoe Right! And what happens when you discover that, meanwhile, another devel-\noper has committed their code to the main branch?\nTheo Then Git does a three-way merge, trying to combine all the changes from the\ntwo merge branches with the main branch.\nJoe Does it always go smoothly?\nTheo Usually, yes, but it’s possible that two developers have modified the same line\nin the same file. I then have to manually resolve the conflict. I hate when that\nhappens!\nTIP In a production system, multiple mutations run concurrently. Before updating\nthe state, we need to reconcile the conflicts between possible concurrent mutations.\n--- Page 123 ---\n5.2 Reconciliation between concurrent mutations 95\nJoe In DOP, the reconciliation algorithm in the commit phase is quite similar to a\nmerge in Git, except instead of a manual conflict resolution, we abort the\nmutation. There are three possibilities to reconcile between possible concur-\nrent mutations: fast-forward, three-way merge, or abort.\nJoe goes to the whiteboard again. He draws the two diagrams shown in figures 5.2 and 5.3.\nYes No\nState has stayed the same\nYes No\nConcurrent mutations compatible?\nFast forward\n3-way Merge Abort\nFigure 5.2 The\nreconciliation flow\nThe version during\nthe Commit phase\ncurrent\nprevious\nnext\nThe base version\nfor the Calculation\nThe version Figure 5.3 When the commit phase\nphase\nreturned by the starts, there are three versions of the\nCalculation phase system state.\nTheo Could you explain in more detail?\nJoe When the commit phase of a mutation starts, we have three versions of the sys-\ntem state: previous, which is the version on which the calculation phase based\nits computation; current, which is the current version during the commit\nphase; and next, which is the version returned by the calculation phase.\nTheo Why would current be different than previous?\nJoe It happens when other mutations have run concurrently with our mutation.\nTheo I see.\nJoe If we are in a situation where the current state is the same as the previous state,\nit means that no mutations run concurrently. Therefore, as in Git, we can\nsafely fast-forward and update the state of the system with the next version.\nTheo What if the state has not stayed the same?\nJoe Then it means that mutations have run concurrently. We have to check for\nconflicts in a way similar to the three-way merge used by Git. The difference is\nthat instead of comparing lines, we compare fields of the system hash map.\nTheo Could you explain that?\n--- Page 124 ---\n96 CHAPTER 5 Basic concurrency control\nJoe We calculate the diff between previous and next and between previous and\ncurrent. If the two diffs have no fields in common, then there is no conflict\nbetween the mutations that have run concurrently. We can safely apply the\nchanges from previous to next into current.\nJoe makes his explanation visual with another diagram on the whiteboard. He then shows\nfigure 5.4 to Theo.\ndiffPreviousCurrent diffPreviousNext\ncurrent\nprevious merged\ndiffPreviousNext\nnext\nFigure 5.4 In a three-way merge, we calculate the diff between previous and\nnext, and we apply it to current.\nTheo What if there is a conflict?\nJoe Then we abort the mutation.\nTheo Aborting a user request seems unacceptable.\nJoe In fact, in a user-facing system, conflicting concurrent mutations are fairly rare.\nThat’s why it’s OK to abort and let the user run the mutation again. Here, let\nme draft a table to show you the differences between Git and DOP (table 5.2).\nTable 5.2 The analogy between Git and data-oriented programming\nData-oriented programming Git\nConcurrent mutations Different branches\nA version of the system data A commit\nState A reference\nCalculation phase Branching\nValidation Precommit hook\nReconciliation Merge\nFast-forward Fast-forward\nThree-way merge Three-way merge\nAbort Manual conflict resolution\nHash map Tree (folder)\nLeaf node Blob (file)\nData field Line of code\n--- Page 125 ---\n5.3 Reducing collections 97\nTheo Great! That helps, but in cases where two mutations update the same field of\nthe same entity, I think it’s fair enough to let the user know that the request\ncan’t be processed.\nTIP In a user-facing system, conflicting concurrent mutations are fairly rare.\n5.3 Reducing collections\nJoe Are you ready to challenge your mind with the implementation of the diff\nalgorithm?\nTheo Let’s take a short coffee break before, if you don’t mind. Then, I’ll be ready to\ntackle anything.\nAfter enjoying large mug of hot coffee and a few butter cookies, Theo and Joe are back to\nwork. Their discussion on the diff algorithm continues.\nJoe In the implementation of the diff algorithm, we’re going to reduce collections.\nTheo I heard about reducing collections in a talk about FP, but I don’t remember\nthe details. Could you remind me how this works?\nJoe Imagine you want to calculate the sum of the elements in a collection of num-\nbers. With Lodash’s _.reduce, it would look like this.\nListing5.1 Summing numbers with _.reduce\n_.reduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nTheo I don’t understand.\nJoe goes to the whiteboard and writes the description of _.reduce. Theo waits patiently\nuntil Joe puts the pen down before looking at the description.\nDescription of _.reduce\n_.reduce receives three arguments:\n coll—A collection of elements\n f—A function that receives two arguments\n initVal—A value\nLogic flow:\n1 Initialize currentRes with initVal.\n2 For each element x of coll, update currentRes with f(currentRes, x).\n3 Return currentRes.",
        "sections_found": []
      },
      "accurate_page_range": "102-125"
    },
    {
      "text": "- 5.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "5 Basic concurrency control",
      "raw_line": "- 5.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 38,
      "chapter_info": {
        "page": 126,
        "title": "Basic concurrency control",
        "pattern_matched": "Chapter 5",
        "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
      },
      "chapter_sections": {
        "start_page": 126,
        "end_page": 151,
        "content": "\n--- Page 126 ---\n98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. It means that the first call to f will be f(0, 1). Then,\nwe’ll have f(f(0, 1), 2) and, finally, f(f(f(0, 1), 2), 3).\nJoe I like your manual expansion, Theo! Let’s make it visual.\nNow Theo goes to the whiteboard and draws a diagram. Figure 5.5 shows what that looks like.\nf\nf a\n2\nf a\n1\na 0 initVal Figure 5.5 Visualization\nof _.reduce\nTheo It’s much clearer now. I think that by implementing my custom version of\n_.reduce, it will make things 100% clear.\nIt takes Theo much less time than he expected to implement reduce(). In no time at all,\nhe shows Joe the code.\nListing5.2 Custom implementation of _.reduce\nfunction reduce(coll, f, initVal) {\nvar currentRes = initVal;\nfor (var i = 0; i < coll.length; i++) {\nWe could use\ncurrentRes = f(currentRes, coll[i])\nforEach instead\n}\nof a for loop.\nreturn currentRes;\n}\nAfter checking that Theo’s code works as expected (see listing 5.3), Joe is proud of Theo.\nHe seems to be catching on better than he anticipated.\nListing5.3 Testing the custom implementation of reduce()\nreduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nJoe Well done!\n--- Page 127 ---\n5.4 Structural difference 99\n5.4 Structural difference\n NOTE This section deals with the implementation of a structural diff algorithm. Feel\nfree to skip this section if you don’t want to challenge your mind right now with the\ndetails of a sophisticated use of recursion. It won’t prevent you from enjoying the rest\nof the book. You can come back to this section later.\nTheo How do you calculate the diff between various versions of the system state?\nJoe That’s the most challenging part of the reconciliation algorithm. We need to\nimplement a structural diff algorithm for hash maps.\nTheo In what sense is the diff structural?\nJoe The structural diff algorithm looks at the structure of the hash maps and\nignores the order of the fields.\nTheo Could you give me an example?\nJoe Let’s start with maps without nested fields. Basically, there are three kinds of\ndiffs: field replacement, field addition, and field deletion. In order to make\nthings not too complicated, for now, we’ll deal only with replacement and\naddition.\nJoe once again goes to the whiteboard and draws table 5.3, representing the three kinds of\ndiffs. Theo is thinking the whiteboard is really starting to fill up today.\nTable 5.3 Kinds of structural differences between maps without nested fields\nKind First map Second map Diff\nReplacement {\"a\": 1} {\"a\": 2} {\"a\": 2}\nAddition {\"a\": 1} {\"a\": 1, \"b\": 2} {\"b\": 2}\nDeletion {\"a\": 1, \"b\": 2} {\"a\": 1} Not supported\nTheo I notice that the order of the maps matters a lot. What about nested fields?\nJoe It’s the same idea, but the nesting makes it a bit more difficult to grasp.\nJoe changes several of the columns in table 5.3. When he’s through, he shows Theo the\nnested fields in table 5.4.\nTable 5.4 Kinds of structural differences between maps with nested fields\nKind First map Second map Diff\nReplacement { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 2 \"x\": 2\n} } }\n} } }\n--- Page 128 ---\n100 CHAPTER 5 Basic concurrency control\nTable 5.4 Kinds of structural differences between maps with nested fields (continued)\nKind First map Second map Diff\nAddition { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 1, \"y\": 2\n} \"y\": 2, }\n} } }\n}\nDeletion { { Not supported\n\"a\": { \"a\": {\n\"x\": 1, \"y\": 2\n\"y\": 2, }\n} }\n}\n NOTE The version of the structural diff algorithm illustrated in this chapter does\nnot deal with deletions. Dealing with deletions is definitely possible, but it requires a\nmore complicated algorithm.\nTheo As you said, it’s harder to grasp. What about arrays?\nJoe We compare the elements of the arrays in order: if they are equal, the diff is\nnull; if they differ, the diff has the value of the second array.\nJoe summarizes the various kinds of diffs in another table on the whiteboard. Theo looks\nat the result in table 5.5.\nTable 5.5 Kinds of structural differences between arrays without nested elements\nKind First array Second array Diff\nReplacement [1] [2] [2]\nAddition [1] [1, 2] [null, 2]\nDeletion [1, 2] [1] Not supported\nTheo This usage of null is a bit weird but OK. Is it complicated to implement the\nstructural diff algorithm?\nJoe Definitely! It took a good dose of mental gymnastics to come up with these 30\nlines of code.\nJoe downloads the code from one his personal repositories. Theo, with thumb and forefin-\ngers touching his chin and his forehead slightly tilted, studies the code.\nListing5.4 The implementation of a structural diff\nfunction diffObjects(data1, data2) {\n_.isArray checks whether\nvar emptyObject = _.isArray(data1) ? [] : {};\nits argument is an array.\nif(data1 == data2) {\n--- Page 129 ---\n5.4 Structural difference 101\nreturn emptyObject;\n_.union creates an\n} array of unique\nvar keys = _.union(_.keys(data1), _.keys(data2)); values from two\nreturn _.reduce(keys, arrays (like union of\nfunction (acc, k) { two sets in Maths).\nvar res = diff(\n_.get(data1, k),\n_.isObject checks\n_.get(data2, k));\nwhether its argument\nif((_.isObject(res) && _.isEmpty(res)) ||\nis a collection (either\na map or an array).\n(res == \"no-diff\")) {\nreturn acc;\n_.isEmpty }\nchecks return _.set(acc, [k], res);\nwhether its },\nargument\nemptyObject);\nis an empty\n} \"no-diff\" is how\ncollection.\nwe mark that\nfunction diff(data1, data2) { two values are\nif(_.isObject(data1) && _.isObject(data2)) { the same.\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"no-diff\";\n}\nTheo Wow! It involves a recursion inside a reduce! I’m sure Dave will love this, but\nI’m too tired to understand this code right now. Let’s focus on what it does\ninstead of how it does it.\nIn order familiarize himself with the structural diff algorithm, Theo runs the algorithm\nwith examples from the table that Joe drew on the whiteboard. While Theo occupies his\nfingers with more and more complicated examples, his mind wanders in the realm of\nperformance.\nListing5.5 An example of usage of a structural diff\nvar data1 = {\n\"a\": {\n\"x\": 1,\n\"y\": [2, 3],\n\"z\": 4\n}\n};\nvar data2 = {\n\"a\": {\n\"x\": 2,\n\"y\": [2, 4],\n\"z\": 4\n}\n}\n--- Page 130 ---\n102 CHAPTER 5 Basic concurrency control\ndiff(data1, data2);\n//{\n// \"a\": {\n// \"x\": 2,\n// \"y\": [\n// undefined,\n// 4\n// ]\n// }\n//}\nTheo What about the performance of the structural diff algorithm? It seems that the\nalgorithm goes over the leaves of both pieces of data?\nJoe In the general case, that’s true. But, in the case of system data that’s manipu-\nlated with structural sharing, the code is much more efficient.\nTheo What do you mean?\nJoe With structural sharing, most of the nested objects are shared between two ver-\nsions of the system state. Therefore, most of the time, when the code enters\ndiffObjects, it will immediately return because data1 and data2 are the same.\nTIP Calculating the diff between two versions of the state is efficient because two\nhash maps created via structural sharing from the same hash map have most of their\nnodes in common.\nTheo Another benefit of immutable data... Let me see how the diff algorithm\nbehaves with concurrent mutations. I think I’ll start with a tiny library with no\nusers and a catalog with a single book, Watchmen.\nListing5.6 The data for a tiny library\nvar library = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\n--- Page 131 ---\n5.4 Structural difference 103\nJoe I suggest that we start with nonconflicting mutations. What do you suggest?\nTheo A mutation that updates the publication year of Watchmen and a mutation that\nupdates both the title of Watchmen and the name of the author of Watchmen.\nOn his laptop, Theo creates three versions of the library. He shows Joe his code, where one\nmutation updates the publication year of Watchmen, and the other one updates the title of\nWatchmen and the author’s name.\nListing5.7 Two nonconflicting mutations\nvar previous = library;\nvar next = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"],\n1986);\nvar libraryWithUpdatedTitle = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"],\n\"The Watchmen\");\nvar current = _.set(\nlibraryWithUpdatedTitle,\n[\"catalog\", \"authorsById\", \"dave-gibbons\", \"name\"],\n\"David Chester Gibbons\");\nTheo I’m curious to see what the diff between previous and current looks like.\nJoe Run the code and you’ll see.\nTheo runs the code snippets for the structural diff between previous and next and for\nthe structural diff between previous and current. His curiosity satisfied, Theo finds it’s\nall beginning to make sense.\nListing5.8 Structural diff between maps with a single difference\ndiff(previous, next);\n//{\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"publicationYear\": 1986\n// }\n// }\n// }\n//}\nListing5.9 Structural diff between maps with two differences\ndiff(previous, current);\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\",\n--- Page 132 ---\n104 CHAPTER 5 Basic concurrency control\n// }\n// },\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\n//\nJoe Can you give me the information path of the single field in the structural diff\nbetween previous and next?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Right. And what are the information paths of the fields in the structural diff\nbetween previous and current?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"] for the book\ntitle and [\"authorsById\", \"dave-gibbons\", \"name\"] for the author’s name.\nJoe Perfect! Now, can you figure out how to detect conflicting mutations by\ninspecting the information paths of the structural diffs?\nTheo We need to check if they have an information path in common or not.\nJoe Exactly! If they have, it means the mutations are conflicting.\nTheo But I have no idea how to write code that retrieves the information paths of a\nnested map.\nJoe Once again, it’s a nontrivial piece of code that involves a recursion inside a\nreduce. Let me download another piece of code from my repository and show\nit to you.\nListing5.10 Calculating the information paths of a (nested) map\nfunction informationPaths (obj, path = []) {\nreturn _.reduce(obj,\nfunction(acc, v, k) {\nif (_.isObject(v)) {\nreturn _.concat(acc,\ninformationPaths(v,\n_.concat(path, k)));\n}\nreturn _.concat(acc, [_.concat(path, k)]);\n},\n[]);\n}\nTheo Let me see if your code works as expected with the structural diffs of the\nmutations.\nTheo tests Joe’s code with two code snippets. The first shows the information paths of the\nstructural diff between previous and next, and the second shows the information paths\nof the structural diff between previous and current.\n--- Page 133 ---\n5.4 Structural difference 105\nListing5.11 Fields that differ between previous and next\ninformationPaths(diff(previous, next));\n// → [\"catalog.booksByIsbn.978-1779501127.publicationYear\"]\nListing5.12 Fields that differ between previous and current\ninformationPaths(diff(previous, current));\n// [\n// [\n// \"catalog\",\n// \"booksByIsbn\",\n// \"978-1779501127\",\n// \"title\"\n// ],\n// [\n// \"authorsById\",\n// \"dave-gibbons\",\n// \"name\"\n// ]\n//]\nTheo Nice! I assume that Lodash has a function that checks whether two arrays have\nan element in common.\nJoe Almost. There is _.intersection, which returns an array of the unique values\nthat are in two given arrays. For our purpose, though, we need to check\nwhether the intersection is empty. Here, look at this example.\nListing5.13 Checking whether two diff maps have a common information path\nfunction havePathInCommon(diff1, diff2) {\nreturn !_.isEmpty(_.intersection(informationPaths(diff1),\ninformationPaths(diff2)));\n}\nTheo You told me earlier that in the case of nonconflicting mutations, we can\nsafely patch the changes induced by the transition from previous to next\ninto current. How do you implement that?\nJoe We do a recursive merge between current and the diff between previous and\nnext.\nTheo Does Lodash provide an immutable version of recursive merge?\nJoe Yes, here’s another example. Take a look at this code.\nListing5.14 Applying a patch\n_.merge(current, (diff(previous, next)));\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\"\n// }\n// },\n--- Page 134 ---\n106 CHAPTER 5 Basic concurrency control\n// \"catalog\": {\n// \"authorsById\": {\n// \"alan-moore\": {\n// \"bookIsbns\": [\"978-1779501127\"]\n// \"name\": \"Alan Moore\"\n// },\n// \"dave-gibbons\": {\n// \"bookIsbns\": [\"978-1779501127\"],\n// \"name\": \"Dave Gibbons\"\n// },\n// },\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n// \"isbn\": \"978-1779501127\",\n// \"publicationYear\": 1986,\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\nTheo Could it be as simple as this?\nJoe Indeed.\n5.5 Implementing the reconciliation algorithm\nJoe All the pieces are now in place to implement our reconciliation algorithm.\nTheo What kind of changes are required?\nJoe It only requires changes in the code of SystemState.commit. Here, look at\nthis example on my laptop.\nListing5.15 The SystemState class\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nvar nextSystemData = SystemConsistency.reconcile(\nthis.systemData,\nSystemConsistency class is\nprevious,\nimplemented in listing 5.16.\nnext);\nif(!SystemValidity.validate(previous, nextSystemData)) {\nthrow \"The system data to be committed is not valid!\";\n};\n--- Page 135 ---\n5.5 Implementing the reconciliation algorithm 107\nthis.systemData = nextSystemData;\n}\n}\nTheo How does SystemConsistency do the reconciliation?\nJoe The SystemConsistency class starts the reconciliation process by comparing\nprevious and current. If they are the same, then we fast-forward and return\nnext. Look at this code for SystemConsistency.\nListing5.16 The reconciliation flow in action\nclass SystemConsistency {\nstatic threeWayMerge(current, previous, next) {\nvar previousToCurrent = diff(previous, current);\nvar previousToNext = diff(previous, next);\nif(havePathInCommon(previousToCurrent, previousToNext)) { When the system\nreturn _.merge(current, previousToNext); state is the same\n} as the state used\nthrow \"Conflicting concurrent mutations.\"; by the calculation\n} phase, we fast-\nstatic reconcile(current, previous, next) { forward.\nif(current == previous) {\nreturn next;\n}\nreturn SystemConsistency.threeWayMerge(current,\nprevious,\nnext);\n}\n}\nTheo Wait a minute! Why do you compare previous and current by reference?\nYou should be comparing them by value, right? And, it would be quite expen-\nsive to compare all the leaves of the two nested hash maps!\nJoe That’s another benefit of immutable data. When the data is not mutated, it is\nsafe to compare references. If they are the same, we know for sure that the data\nis the same.\nTIP When data is immutable, it is safe to compare by reference, which is super fast.\nWhen the references are the same, it means that the data is the same.\nTheo What about the implementation of the three-way merge algorithm?\nJoe When previous differs from current, it means that concurrent mutations\nhave run. In order to determine whether there is a conflict, we calculate two\ndiffs: the diff between previous and current and the diff between previous\nand next. If the intersection between the two diffs is empty, it means there is\nno conflict. We can safely patch the changes between previous to next into\ncurrent.\nTheo takes a closer look at the code for the SystemConsistency class in listing 5.16. He\ntries to figure out if the code is thread-safe or not.\n--- Page 136 ---\n108 CHAPTER 5 Basic concurrency control\nTheo I think the code for SystemConsistency class is not thread-safe! If there’s a\ncontext switch between checking whether the system has changed in the\nSystemConsistency class and the updating of the state in SystemData class, a\nmutation might override the changes of a previous mutation.\nJoe You are totally right! The code works fine in a single-threaded environment\nlike JavaScript, where concurrency is handled via an event loop. However, in a\nmulti-threaded environment, the code needs to be refined in order to be\nthread-safe. I’ll show you some day.\n NOTE The SystemConsistency class is not thread-safe. We will make it thread-safe\nin chapter 8.\nTheo I think I understand why you called it optimistic concurrency control. It’s\nbecause we assume that conflicts don’t occur too often. Right?\nJoe Correct! It makes me wonder what your therapist would say about conflicts that\ncannot be resolved. Are there some cases where it’s not possible to reconcile\nthe couple?\nTheo I don’t think she ever mentioned such a possibility.\nJoe She must be a very optimistic person.\nSummary\n Optimistic concurrency control allows mutations to ask forgiveness instead of\npermission.\n Optimistic concurrency control is lock-free.\n Managing concurrent mutations of our system state with optimistic concurrency\ncontrol allows our system to support a high throughput of reads and writes.\n Optimistic concurrency control with immutable data is super efficient.\n Before updating the state, we need to reconcile the conflicts between possible con-\ncurrent mutations.\n We reconcile between concurrent mutations in a way that is similar to how Git han-\ndles a merge between two branches: either a fast-forward or a three-way merge.\n The changes required to let our system manage concurrency are only in the\ncommit phase.\n The calculation phase does its calculation as if it were the only mutation running.\n The commit phase is responsible for trying to reconcile concurrent mutations.\n The reconciliation algorithm is universal in the sense that it can be used in any sys-\ntem where the system data is represented as an immutable hash map.\n The implementation of the reconciliation algorithm is efficient, as it leverages\nthe fact that subsequent versions of the system state are created via structural\nsharing.\n In a user-facing system, conflicting concurrent mutations are fairly rare.\n When we cannot safely reconcile between concurrent mutations, we abort the\nmutation and ask the user to try again.\n--- Page 137 ---\nSummary 109\n Calculating the structural diff between two versions of the state is efficient because\ntwo hash maps created via structural sharing from the same hash map have most\nof their nodes in common.\n When data is immutable, it is safe to compare by reference, which is fast. When\nthe references are the same, it means that the data is the same.\n There are three kinds of structural differences between two nested hash maps:\nreplacement, addition, and deletion.\n Our structural diff algorithm supports replacements and additions but not\ndeletions.\nLodash functions introduced in this chapter\nFunction Description\nconcat(arrA, arrB) Creates an new array, concatenating arrA and arrB\nintersection(arrA, arrB) Creates an array of unique values both in arrA and arrB\nunion(arrA, arrB) Creates an array of unique values from arrA and arrB\nfind(coll, pred) Iterates over elements of coll, returning the first element for\nwhich pred returns true\nisEmpty(coll) Checks if coll is empty\nreduce(coll, f, initVal) Reduces coll to a value that is the accumulated result of running\neach element in coll through f, where each successive invoca-\ntion is supplied the return value of the previous\nisArray(coll) Checks if coll is an array\nisObject(coll) Checks if coll is a collection\n--- Page 138 ---\nUnit tests\nProgramming at a coffee shop\nThis chapter covers\n Generation of the minimal data input for a\ntest case\n Comparison of the output of a function with\nthe expected output\n Guidance about the quality and the quantity\nof the test cases\nIn a data-oriented system, our code deals mainly with data manipulation: most of\nour functions receive data and return data. As a consequence, it’s quite easy to\nwrite unit tests to check whether our code behaves as expected. A unit test is made\nof test cases that generate data input and compare the data output of the function\nwith the expected data output. In this chapter, we write unit tests for the queries\nand mutations that we wrote in the previous chapters.\n6.1 The simplicity of data-oriented test cases\nTheo and Joe are seated around a large wooden table in a corner of “La vie est belle,” a\nnice little French coffee shop, located near the Golden Gate Bridge. Theo orders a café\nau lait with a croissant, and Joe orders a tight espresso with a pain au chocolat. Instead\nof the usual general discussions about programming and life when they’re out of the\n110\n--- Page 139 ---\n6.1 The simplicity of data-oriented test cases 111\noffice, Joe leads the discussion towards a very concrete topic—unit tests. Theo asks Joe for\nan explanation.\nTheo Are unit tests such a simple topic that we can tackle it here in a coffee shop?\nJoe Unit tests in general, no. But unit tests for data-oriented code, yes!\nTheo Why does that make a difference?\nJoe The vast majority of the code base of a data-oriented system deals with data\nmanipulation.\nTheo Yeah. I noticed that almost all the functions we wrote so far receive data and\nreturn data.\nTIP Most of the code in a data-oriented system deals with data manipulation.\nJoe Writing a test case for functions that deal with data is only about generating\ndata input and expected output, and comparing the output of the function\nwith the expected output.\nThe steps of a test case\n1 Generate data input: dataIn\n2 Generate expected output: dataOut\n3 Compare the output of the function with the expected output: f(dataIn) and\ndataOut\nTheo That’s it?\nJoe Yes. As you’ll see in a moment, in DOP, there’s usually no need for mock\nfunctions.\nTheo I understand how to compare primitive values like strings or numbers, but I’m\nnot sure how I would compare data collections like maps.\nJoe You compare field by field.\nTheo Recursively?\nJoe Yes!\nTheo Oh no! I’m not able to write any recursive code in a coffee shop. I need the\ncalm of my office for that kind of stuff.\nJoe Don’t worry. In DOP, data is represented in a generic way. There is a generic\nfunction in Lodash called _.isEqual for recursive comparison of data collec-\ntions. It works with both maps and arrays.\nJoe opens his laptop. He is able to convince Theo by executing a few code snippets with\n_.isEqual to compare an equal data collection with a non-equal one.\nListing6.1 Comparing an equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n--- Page 140 ---\n112 CHAPTER 6 Unit tests\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n});\n// → true\nListing6.2 Comparing a non-equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"bad-isbn\"]\n});\n// → false\nTheo Nice!\nJoe Most of the test cases in DOP follow this pattern.\nTheo decides he wants to try this out. He fires up his laptop and types a few lines of\npseudocode.\nListing6.3 The general pattern of a data-oriented test case\nvar dataIn = {\n// input\n};\nvar dataOut = {\n// expected output\n};\n_.isEqual(f(dataIn), dataOut);\nTIP It’s straightforward to write unit tests for code that deals with data manipulation.\nTheo Indeed, this looks like something we can tackle in a coffee shop!\n6.2 Unit tests for data manipulation code\nA waiter in an elegant bow tie brings Theo his croissant and Joe his pain au chocolat. The\ntwo friends momentarily interrupt their discussion to savor their French pastries. When\nthey’re done, they ask the waiter to bring them their drinks. Meanwhile, they resume the\ndiscussion.\nJoe Do you remember the code flow of the implementation of the search query?\nTheo Let me look again at the code that implements the search query.\nTheo brings up the implementation of the search query on his laptop. Noticing that Joe is\nchewing on his nails again, he quickly checks out the code.\n--- Page 141 ---\n6.2 Unit tests for data manipulation code 113\nListing6.4 The code involved in the implementation of the search query\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\n}\n6.2.1 The tree of function calls\nThe waiter brings Theo his café au lait and Joe his tight espresso. They continue their dis-\ncussion while enjoying their coffees.\nJoe Before writing a unit test for a code flow, I find it useful to visualize the tree of\nfunction calls of the code flow.\nTheo What do you mean by a tree of function calls?\nJoe Here, I’ll draw the tree of function calls for the Library.searchBooksBy-\nTitleJSON code flow.\nJoe puts down his espresso and takes a napkin from the dispenser. He carefully places it\nflat on the table and starts to draw. When he is done, he shows the illustration to Theo (see\nfigure 6.1).\n--- Page 142 ---\n114 CHAPTER 6 Unit tests\nLibrary.searchBooksByTitleJSON\n_.get JSON.stringify Catalog.searchBooksByTitle\n_.get _.map _.filter Catalog.bookInfo\n_.get Catalog.authorNames\n_.get _.map\nFigure 6.1 The tree of function calls for the search query code flow\nTheo Nice! Can you teach me how to draw a tree of function calls like that?\nJoe Sure. The root of the tree is the name of the function for which you draw the\ntree, in our case, Library.searchBooksByTitleJSON. The children of a\nnode in the tree are the names of the functions called by the function. For exam-\nple, if you look again at the code for Library.searchBooksByTitleJSON (list-\ning 6.4), you’ll see that it calls Catalog.searchBooksByTitle, _.get, and\nJSON.stringify.\nTheo How long would I continue to recursively expand the tree?\nJoe You continue until you reach a function that doesn’t belong to the code base\nof your application. Those nodes are the leaves of our tree; for example, the\nfunctions from Lodash: _.get, _.map, and so forth.\nTheo What if the code of a function doesn’t call any other functions?\nJoe A function that doesn’t call any other function would be a leaf in the tree.\nTheo What about functions that are called inside anonymous functions like Catalog\n.bookInfo?\nJoe Catalog.bookInfo appears in the code of Catalog.searchBooksByTitle.\nTherefore, it is considered to be a child node of Catalog.searchBooksBy-\nTitle. The fact that it is nested inside an anonymous function is not relevant\nin the context of the tree of function calls.\n NOTE A tree of function calls for a function f is a tree where the root is f, and the\nchildren of a node g in the tree are the functions called by g. The leaves of the tree are\nfunctions that are not part of the code base of the application. These are functions\nthat don’t call any other functions.\nTheo It’s very cool to visualize my code as a tree, but I don’t see how it relates to\nunittests.\n--- Page 143 ---\n6.2 Unit tests for data manipulation code 115\nJoe The tree of function calls guides us about the quality and the quantity of test\ncases we should write.\nTheo How?\nJoe You’ll see in a moment.\n6.2.2 Unit tests for functions down the tree\nJoe Let’s start from the function that appears in the deepest node in our tree:\nCatalog.authorNames. Take a look at the code for Catalog.authorNames\nand tell me what are the input and the output of Catalog.authorNames.\nJoe turns his laptop so Theo can a closer look at the code. Theo takes a sip of his café au\nlait as he looks over what’s on Joe’s laptop.\nListing6.5 The code of Catalog.authorNames\nCatalog.authorNames = function (catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n};\nTheo The input of Catalog.authorNames is catalogData and authorIds. The\noutput is authorNames.\nJoe Would you do me a favor and express it visually?\nTheo Sure.\nIt’s Theo’s turn to grab a napkin. He draws a small rectangle with two inward arrows and\none outward arrow as in figure 6.2.\ncatalogData authorIds\nCatalog.authorNames()\nFigure 6.2 Visualization of the input\nauthorNames and output of Catalog.authorNames\nJoe Excellent! Now, how many combinations of input would you include in the\nunit test for Catalog.authorNames?\nTheo Let me see.\nTheo reaches for another napkin. This time he creates a table to gather his thoughts\n(table 6.1).\n--- Page 144 ---\n116 CHAPTER 6 Unit tests\nTable 6.1 The table of test cases for Catalog.authorNames\ncatalogData authorIds authorNames\nCatalog with two authors Empty array Empty array\nCatalog with two authors Array with one author ID Array with one author name\nCatalog with two authors Array with two author IDs Array with two author names\nTheo To begin with, I would have a catalogData with two author IDs and call\nCatalog.authorNames with three arguments: an empty array, an array with a\nsingle author ID, and an array with two author IDs.\nJoe How would you generate the catalogData?\nTheo Exactly as we generated it before.\nTurning to his laptop, Theo writes the code for catalogData. He shows it to Joe.\nListing6.6 A complete catalogData map\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\n--- Page 145 ---\n6.2 Unit tests for data manipulation code 117\nJoe You could use your big catalogData map for the unit test, but you could also\nuse a smaller map in the context of Catalog.authorNames. You can get rid of\nthe booksByIsbn field of the catalogData and the bookIsbns fields of the\nauthors.\nJoe deletes a few lines from catalogData and gets a much smaller map. He shows the revi-\nsion to Theo.\nListing6.7 A minimal version of catalogData\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nTheo Wait a minute! This catalogData is not valid.\nJoe In DOP, data validity depends on the context. In the context of Library\n.searchBooksByTitleJSON and Catalog.searchBooksByTitle, the mini-\nmal version of catalogData is indeed not valid. However, in the context of\nCatalog.bookInfo and Catalog.authorNames, it is perfectly valid. The reason\nis that those two functions access only the authorsById field of catalogData.\nTIP The validity of the data depends on the context.\nTheo Why is it better to use a minimal version of the data in a test case?\nJoe For a very simple reason—the smaller the data, the easier it is to manipulate.\nTIP The smaller the data, the easier it is to manipulate.\nTheo I’ll appreciate that when I write the unit tests!\nJoe Definitely! One last thing before we start coding: how would you check that the\noutput of Catalog.authorNames is as expected?\nTheo I would check that the value returned by Catalog.authorNames is an array\nwith the expected author names.\nJoe How would you handle the array comparison?\nTheo Let me think. I want to compare by value, not by reference. I guess I’ll have to\ncheck that the array is of the expected size and then check member by mem-\nber, recursively.\nJoe That’s too much of a mental burden when you’re in a coffee shop. As I showed\nyou earlier (see listing 6.1), we can recursively compare two data collections by\nvalue with _.isEqual from Lodash.\n--- Page 146 ---\n118 CHAPTER 6 Unit tests\nTIP We can compare the output and the expected output of our functions with\n_.isEqual.\nTheo Sounds good! Let me write the test cases.\nTheo starts typing on his laptop. After a few minutes, he has some test cases for Catalog\n.authorNames, each made from a function call to Catalog.authorNames wrapped in\n_.isEqual.\nListing6.8 Unit test for Catalog.authorNames\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(\ncatalogData,\n[\"alan-moore\"]),\n[\"Alan Moore\"]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\", \"dave-gibbons\"]),\n[\"Alan Moore\", \"Dave Gibbons\"]);\nJoe Well done! Can you think of more test cases?\nTheo Yes. There are test cases where the author ID doesn’t appear in the catalog\ndata, and test cases with empty catalog data. With minimal catalog data and\n_.isEqual, it’s really easy to write lots of test cases!\nTheo really enjoys this challenge. He creates a few more test cases to present to Joe.\nListing6.9 More test cases for Catalog.authorNames\n_.isEqual(Catalog.authorNames({}, []), []);\n_.isEqual(Catalog.authorNames({}, [\"alan-moore\"]), [undefined]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\",\n\"albert-einstein\"]), [\"Alan Moore\", undefined]);\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(catalogData, [\"albert-einstein\"]),\n[undefined]);\nTheo How do I run these unit tests?\nJoe You use your preferred test framework.\n--- Page 147 ---\n6.2 Unit tests for data manipulation code 119\n NOTE We don’t deal here with test runners and test frameworks. We deal only with\nthe logic of the test cases.\n6.2.3 Unit tests for nodes in the tree\nTheo I’m curious to see what unit tests for an upper node in the tree of function calls\nlook like.\nJoe Sure. Let’s write a unit test for Catalog.bookInfo. How many test cases would\nyou have for Catalog.bookInfo?\nListing6.10 The code of Catalog.bookInfo\nCatalog.bookInfo = function (catalogData, book) {\nreturn {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\n};\nTheo takes another look at the code for Catalog.bookInfo on his laptop. Then, reaching\nfor another napkin, he draws a diagram of its input and output (see figure 6.3).\ncatalogData book\nCatalog.bookInfo()\nFigure 6.3 Visualization of the input\nbookInfo and output of Catalog.bookInfo\nTheo I would have a similar number of test cases for Catalog.authorNames: a book\nwith a single author, with two authors, with existing authors, with non-existent\nauthors, with...\nJoe Whoa! That’s not necessary. Given that we have already written unit tests for\nCatalog.authorNames, we don’t need to check all the cases again. We simply\nneed to write a minimal test case to confirm that the code works.\nTIP When we write a unit test for a function, we assume that the functions called by\nthis function are covered by unit tests and work as expected. It significantly reduces\nthe quantity of test cases in our unit tests.\nTheo That makes sense.\nJoe How would you write a minimal test case for Catalog.bookInfo?\nTheo once again takes a look at the code for Catalog.bookInfo (see listing 6.10). Now he\ncan answer Joe’s question.\n--- Page 148 ---\n120 CHAPTER 6 Unit tests\nTheo I would use the same catalog data as for Catalog.authorNames and a book\nrecord. I’d test that the function behaves as expected by comparing its return\nvalue with a book info record using _.isEqual. Here, let me show you.\nIt takes Theo a bit more time to write the unit test. The reason is that the input and the\noutput of Catalog.authorNames are both records. Dealing with a record is more complex\nthan dealing with an array of strings (as it was the case for Catalog.authorNames). Theo\nappreciates the fact that _.isEqual saves him from writing code that compares the two\nmaps property by property. When he’s through, he shows the result to Joe and takes a nap-\nkin to wipe his forehead.\nListing6.11 Unit test for Catalog.bookInfo\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nvar book = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n};\nvar expectedResult = {\n\"authorNames\": [\"Alan Moore\", \"Dave Gibbons\"],\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n};\nvar result = Catalog.bookInfo(catalogData, book);\n_.isEqual(result, expectedResult);\nJoe Perfect! Now, how would you compare the kind of unit tests for Catalog\n.bookInfo with the unit tests for Catalog.authorNames?\nTheo On one hand, there is only a single test case in the unit test for Catalog.book-\nInfo. On the other hand, the data involved in the test case is more complex\nthan the data involved in the test cases for Catalog.authorNames.\nJoe Exactly! Functions that appear in a deep node in the tree of function calls tend\nto require more test cases, but the data involved in the test cases is less complex.\nTIP Functions that appear in a lower level in the tree of function calls tend to\ninvolve less complex data than functions that appear in a higher level in the tree\n(see table 6.2).\n--- Page 149 ---\n6.3 Unit tests for queries 121\nTable 6.2 The correlation between the depth of a function in the tree of function calls and the\nquality and quantity of the test cases\nDepth in the tree Complexity of the data Number of test cases\nLower Higher Lower\nHigher Lower Higher\n6.3 Unit tests for queries\nIn the previous section, we saw how to write unit tests for utility functions like Catalog\n.bookInfo and Catalog.authorNames. Now, we are going to see how to write unit tests\nfor the nodes of a query tree of function calls that are close to the root of the tree.\nJoe Theo, how would you write a unit test for the code of the entry point of the\nsearch query?\nTo recall the particulars, Theo checks the code for Library.searchBooksByTitleJSON.\nAlthough Joe was right about today’s topic being easy enough to enjoy the ambience of a\ncoffee shop, he has been doing quite a lot of coding this morning.\nListing6.12 The code of Library.searchBooksByTitleJSON\nLibrary.searchBooksByTitleJSON = function (libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n};\nHe then takes a moment to think about how he’d write a unit test for that code. After\nanother Aha! moment, now he’s got it.\nTheo The inputs of Library.searchBooksByTitleJSON are library data and a\nquery string, and the output is a JSON string (see figure 6.4). So, I would cre-\nate a library data record with a single book and write tests with query strings\nthat match the name of the book and ones that don’t match.\nlibraryData query\nLibrary.searchBooksByTitleJSON()\nFigure 6.4 The input and output of\nresultsJSON Library.searchBooksByTitleJSON\nJoe What about the expected results of the test cases?\n--- Page 150 ---\n122 CHAPTER 6 Unit tests\nTheo In cases where the query string matches, the expected result is a JSON string\nwith the book info. In cases where the query string doesn’t match, the\nexpected result is a JSON string with an empty array.\nJoe Hmm...\nTheo What?\nJoe I don’t like your answer.\nTheo Why?\nJoe Because your test case relies on a string comparison instead of a data comparison.\nTheo What difference does it make? After all, the strings I’m comparing come from\nthe serialization of data.\nJoe It’s inherently much more complex to compare JSON strings than it is to com-\npare data. For example, two different strings might be the serialization of the\nsame piece of data.\nTheo Really? How?\nJoe Take a look at these two strings. They are the serialization of the same data.\nThey’re different strings because the fields appear in a different order, but in\nfact, they serialize the same data!\nJoe turns his laptop to Theo. As Theo looks at the code, he realizes that, once again, Joe\niscorrect.\nListing6.13 Two different strings that serialize the same data\nvar stringA = \"{\\\"title\\\":\\\"Watchmen\\\",\\\"publicationYear\\\":1987}\";\nvar stringB = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nTIP Avoid using a string comparison in unit tests for functions that deal with data.\nTheo I see.... Well, what can I do instead?\nJoe Instead of comparing the output of Library.searchBooksByTitleJSON with\na string, you could deserialize the output and compare it to the expected data.\nTheo What do you mean by deserialize a string?\nJoe Deserializing a string s, for example, means to generate a piece of data whose\nserialization is s.\nTheo Is there a Lodash function for string deserialization?\nJoe Actually, there is a native JavaScript function for string deserialization; it’s\ncalled JSON.parse.\nJoe retrieves his laptop and shows Theo an example of string deserialization. The code\nillustrates a common usage of JSON.parse.\nListing6.14 Example of string deserialization\nvar myString = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nvar myData = JSON.parse(myString);\n--- Page 151 ---\n6.3 Unit tests for queries 123\n_.get(myData, \"title\");\n// → \"Watchmen\"\nTheo Cool! Let me try writing a unit test for Library.searchBooksByTitleJSON\nusing JSON.parse.\nIt doesn’t take Theo too much time to come up with a piece of code. Using his laptop, he\ninputs the unit test.\nListing6.15 Unit test for Library.searchBooksByTitleJSON\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Watchmen\")),\n[bookInfo]);\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Batman\")),\n[]);\nJoe Well done! I think you’re ready to move on to the last piece of the puzzle and\nwrite the unit test for Catalog.searchBooksByTitle.",
        "sections_found": []
      },
      "accurate_page_range": "126-151"
    },
    {
      "text": "- 5.1 Optimistic concurrency control",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "5 Basic concurrency control",
      "raw_line": "- 5.1 Optimistic concurrency control (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 39,
      "chapter_info": {
        "page": 126,
        "title": "Basic concurrency control",
        "pattern_matched": "Chapter 5",
        "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
      },
      "chapter_sections": {
        "start_page": 126,
        "end_page": 151,
        "content": "\n--- Page 126 ---\n98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. It means that the first call to f will be f(0, 1). Then,\nwe’ll have f(f(0, 1), 2) and, finally, f(f(f(0, 1), 2), 3).\nJoe I like your manual expansion, Theo! Let’s make it visual.\nNow Theo goes to the whiteboard and draws a diagram. Figure 5.5 shows what that looks like.\nf\nf a\n2\nf a\n1\na 0 initVal Figure 5.5 Visualization\nof _.reduce\nTheo It’s much clearer now. I think that by implementing my custom version of\n_.reduce, it will make things 100% clear.\nIt takes Theo much less time than he expected to implement reduce(). In no time at all,\nhe shows Joe the code.\nListing5.2 Custom implementation of _.reduce\nfunction reduce(coll, f, initVal) {\nvar currentRes = initVal;\nfor (var i = 0; i < coll.length; i++) {\nWe could use\ncurrentRes = f(currentRes, coll[i])\nforEach instead\n}\nof a for loop.\nreturn currentRes;\n}\nAfter checking that Theo’s code works as expected (see listing 5.3), Joe is proud of Theo.\nHe seems to be catching on better than he anticipated.\nListing5.3 Testing the custom implementation of reduce()\nreduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nJoe Well done!\n--- Page 127 ---\n5.4 Structural difference 99\n5.4 Structural difference\n NOTE This section deals with the implementation of a structural diff algorithm. Feel\nfree to skip this section if you don’t want to challenge your mind right now with the\ndetails of a sophisticated use of recursion. It won’t prevent you from enjoying the rest\nof the book. You can come back to this section later.\nTheo How do you calculate the diff between various versions of the system state?\nJoe That’s the most challenging part of the reconciliation algorithm. We need to\nimplement a structural diff algorithm for hash maps.\nTheo In what sense is the diff structural?\nJoe The structural diff algorithm looks at the structure of the hash maps and\nignores the order of the fields.\nTheo Could you give me an example?\nJoe Let’s start with maps without nested fields. Basically, there are three kinds of\ndiffs: field replacement, field addition, and field deletion. In order to make\nthings not too complicated, for now, we’ll deal only with replacement and\naddition.\nJoe once again goes to the whiteboard and draws table 5.3, representing the three kinds of\ndiffs. Theo is thinking the whiteboard is really starting to fill up today.\nTable 5.3 Kinds of structural differences between maps without nested fields\nKind First map Second map Diff\nReplacement {\"a\": 1} {\"a\": 2} {\"a\": 2}\nAddition {\"a\": 1} {\"a\": 1, \"b\": 2} {\"b\": 2}\nDeletion {\"a\": 1, \"b\": 2} {\"a\": 1} Not supported\nTheo I notice that the order of the maps matters a lot. What about nested fields?\nJoe It’s the same idea, but the nesting makes it a bit more difficult to grasp.\nJoe changes several of the columns in table 5.3. When he’s through, he shows Theo the\nnested fields in table 5.4.\nTable 5.4 Kinds of structural differences between maps with nested fields\nKind First map Second map Diff\nReplacement { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 2 \"x\": 2\n} } }\n} } }\n--- Page 128 ---\n100 CHAPTER 5 Basic concurrency control\nTable 5.4 Kinds of structural differences between maps with nested fields (continued)\nKind First map Second map Diff\nAddition { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 1, \"y\": 2\n} \"y\": 2, }\n} } }\n}\nDeletion { { Not supported\n\"a\": { \"a\": {\n\"x\": 1, \"y\": 2\n\"y\": 2, }\n} }\n}\n NOTE The version of the structural diff algorithm illustrated in this chapter does\nnot deal with deletions. Dealing with deletions is definitely possible, but it requires a\nmore complicated algorithm.\nTheo As you said, it’s harder to grasp. What about arrays?\nJoe We compare the elements of the arrays in order: if they are equal, the diff is\nnull; if they differ, the diff has the value of the second array.\nJoe summarizes the various kinds of diffs in another table on the whiteboard. Theo looks\nat the result in table 5.5.\nTable 5.5 Kinds of structural differences between arrays without nested elements\nKind First array Second array Diff\nReplacement [1] [2] [2]\nAddition [1] [1, 2] [null, 2]\nDeletion [1, 2] [1] Not supported\nTheo This usage of null is a bit weird but OK. Is it complicated to implement the\nstructural diff algorithm?\nJoe Definitely! It took a good dose of mental gymnastics to come up with these 30\nlines of code.\nJoe downloads the code from one his personal repositories. Theo, with thumb and forefin-\ngers touching his chin and his forehead slightly tilted, studies the code.\nListing5.4 The implementation of a structural diff\nfunction diffObjects(data1, data2) {\n_.isArray checks whether\nvar emptyObject = _.isArray(data1) ? [] : {};\nits argument is an array.\nif(data1 == data2) {\n--- Page 129 ---\n5.4 Structural difference 101\nreturn emptyObject;\n_.union creates an\n} array of unique\nvar keys = _.union(_.keys(data1), _.keys(data2)); values from two\nreturn _.reduce(keys, arrays (like union of\nfunction (acc, k) { two sets in Maths).\nvar res = diff(\n_.get(data1, k),\n_.isObject checks\n_.get(data2, k));\nwhether its argument\nif((_.isObject(res) && _.isEmpty(res)) ||\nis a collection (either\na map or an array).\n(res == \"no-diff\")) {\nreturn acc;\n_.isEmpty }\nchecks return _.set(acc, [k], res);\nwhether its },\nargument\nemptyObject);\nis an empty\n} \"no-diff\" is how\ncollection.\nwe mark that\nfunction diff(data1, data2) { two values are\nif(_.isObject(data1) && _.isObject(data2)) { the same.\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"no-diff\";\n}\nTheo Wow! It involves a recursion inside a reduce! I’m sure Dave will love this, but\nI’m too tired to understand this code right now. Let’s focus on what it does\ninstead of how it does it.\nIn order familiarize himself with the structural diff algorithm, Theo runs the algorithm\nwith examples from the table that Joe drew on the whiteboard. While Theo occupies his\nfingers with more and more complicated examples, his mind wanders in the realm of\nperformance.\nListing5.5 An example of usage of a structural diff\nvar data1 = {\n\"a\": {\n\"x\": 1,\n\"y\": [2, 3],\n\"z\": 4\n}\n};\nvar data2 = {\n\"a\": {\n\"x\": 2,\n\"y\": [2, 4],\n\"z\": 4\n}\n}\n--- Page 130 ---\n102 CHAPTER 5 Basic concurrency control\ndiff(data1, data2);\n//{\n// \"a\": {\n// \"x\": 2,\n// \"y\": [\n// undefined,\n// 4\n// ]\n// }\n//}\nTheo What about the performance of the structural diff algorithm? It seems that the\nalgorithm goes over the leaves of both pieces of data?\nJoe In the general case, that’s true. But, in the case of system data that’s manipu-\nlated with structural sharing, the code is much more efficient.\nTheo What do you mean?\nJoe With structural sharing, most of the nested objects are shared between two ver-\nsions of the system state. Therefore, most of the time, when the code enters\ndiffObjects, it will immediately return because data1 and data2 are the same.\nTIP Calculating the diff between two versions of the state is efficient because two\nhash maps created via structural sharing from the same hash map have most of their\nnodes in common.\nTheo Another benefit of immutable data... Let me see how the diff algorithm\nbehaves with concurrent mutations. I think I’ll start with a tiny library with no\nusers and a catalog with a single book, Watchmen.\nListing5.6 The data for a tiny library\nvar library = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\n--- Page 131 ---\n5.4 Structural difference 103\nJoe I suggest that we start with nonconflicting mutations. What do you suggest?\nTheo A mutation that updates the publication year of Watchmen and a mutation that\nupdates both the title of Watchmen and the name of the author of Watchmen.\nOn his laptop, Theo creates three versions of the library. He shows Joe his code, where one\nmutation updates the publication year of Watchmen, and the other one updates the title of\nWatchmen and the author’s name.\nListing5.7 Two nonconflicting mutations\nvar previous = library;\nvar next = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"],\n1986);\nvar libraryWithUpdatedTitle = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"],\n\"The Watchmen\");\nvar current = _.set(\nlibraryWithUpdatedTitle,\n[\"catalog\", \"authorsById\", \"dave-gibbons\", \"name\"],\n\"David Chester Gibbons\");\nTheo I’m curious to see what the diff between previous and current looks like.\nJoe Run the code and you’ll see.\nTheo runs the code snippets for the structural diff between previous and next and for\nthe structural diff between previous and current. His curiosity satisfied, Theo finds it’s\nall beginning to make sense.\nListing5.8 Structural diff between maps with a single difference\ndiff(previous, next);\n//{\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"publicationYear\": 1986\n// }\n// }\n// }\n//}\nListing5.9 Structural diff between maps with two differences\ndiff(previous, current);\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\",\n--- Page 132 ---\n104 CHAPTER 5 Basic concurrency control\n// }\n// },\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\n//\nJoe Can you give me the information path of the single field in the structural diff\nbetween previous and next?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Right. And what are the information paths of the fields in the structural diff\nbetween previous and current?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"] for the book\ntitle and [\"authorsById\", \"dave-gibbons\", \"name\"] for the author’s name.\nJoe Perfect! Now, can you figure out how to detect conflicting mutations by\ninspecting the information paths of the structural diffs?\nTheo We need to check if they have an information path in common or not.\nJoe Exactly! If they have, it means the mutations are conflicting.\nTheo But I have no idea how to write code that retrieves the information paths of a\nnested map.\nJoe Once again, it’s a nontrivial piece of code that involves a recursion inside a\nreduce. Let me download another piece of code from my repository and show\nit to you.\nListing5.10 Calculating the information paths of a (nested) map\nfunction informationPaths (obj, path = []) {\nreturn _.reduce(obj,\nfunction(acc, v, k) {\nif (_.isObject(v)) {\nreturn _.concat(acc,\ninformationPaths(v,\n_.concat(path, k)));\n}\nreturn _.concat(acc, [_.concat(path, k)]);\n},\n[]);\n}\nTheo Let me see if your code works as expected with the structural diffs of the\nmutations.\nTheo tests Joe’s code with two code snippets. The first shows the information paths of the\nstructural diff between previous and next, and the second shows the information paths\nof the structural diff between previous and current.\n--- Page 133 ---\n5.4 Structural difference 105\nListing5.11 Fields that differ between previous and next\ninformationPaths(diff(previous, next));\n// → [\"catalog.booksByIsbn.978-1779501127.publicationYear\"]\nListing5.12 Fields that differ between previous and current\ninformationPaths(diff(previous, current));\n// [\n// [\n// \"catalog\",\n// \"booksByIsbn\",\n// \"978-1779501127\",\n// \"title\"\n// ],\n// [\n// \"authorsById\",\n// \"dave-gibbons\",\n// \"name\"\n// ]\n//]\nTheo Nice! I assume that Lodash has a function that checks whether two arrays have\nan element in common.\nJoe Almost. There is _.intersection, which returns an array of the unique values\nthat are in two given arrays. For our purpose, though, we need to check\nwhether the intersection is empty. Here, look at this example.\nListing5.13 Checking whether two diff maps have a common information path\nfunction havePathInCommon(diff1, diff2) {\nreturn !_.isEmpty(_.intersection(informationPaths(diff1),\ninformationPaths(diff2)));\n}\nTheo You told me earlier that in the case of nonconflicting mutations, we can\nsafely patch the changes induced by the transition from previous to next\ninto current. How do you implement that?\nJoe We do a recursive merge between current and the diff between previous and\nnext.\nTheo Does Lodash provide an immutable version of recursive merge?\nJoe Yes, here’s another example. Take a look at this code.\nListing5.14 Applying a patch\n_.merge(current, (diff(previous, next)));\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\"\n// }\n// },\n--- Page 134 ---\n106 CHAPTER 5 Basic concurrency control\n// \"catalog\": {\n// \"authorsById\": {\n// \"alan-moore\": {\n// \"bookIsbns\": [\"978-1779501127\"]\n// \"name\": \"Alan Moore\"\n// },\n// \"dave-gibbons\": {\n// \"bookIsbns\": [\"978-1779501127\"],\n// \"name\": \"Dave Gibbons\"\n// },\n// },\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n// \"isbn\": \"978-1779501127\",\n// \"publicationYear\": 1986,\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\nTheo Could it be as simple as this?\nJoe Indeed.\n5.5 Implementing the reconciliation algorithm\nJoe All the pieces are now in place to implement our reconciliation algorithm.\nTheo What kind of changes are required?\nJoe It only requires changes in the code of SystemState.commit. Here, look at\nthis example on my laptop.\nListing5.15 The SystemState class\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nvar nextSystemData = SystemConsistency.reconcile(\nthis.systemData,\nSystemConsistency class is\nprevious,\nimplemented in listing 5.16.\nnext);\nif(!SystemValidity.validate(previous, nextSystemData)) {\nthrow \"The system data to be committed is not valid!\";\n};\n--- Page 135 ---\n5.5 Implementing the reconciliation algorithm 107\nthis.systemData = nextSystemData;\n}\n}\nTheo How does SystemConsistency do the reconciliation?\nJoe The SystemConsistency class starts the reconciliation process by comparing\nprevious and current. If they are the same, then we fast-forward and return\nnext. Look at this code for SystemConsistency.\nListing5.16 The reconciliation flow in action\nclass SystemConsistency {\nstatic threeWayMerge(current, previous, next) {\nvar previousToCurrent = diff(previous, current);\nvar previousToNext = diff(previous, next);\nif(havePathInCommon(previousToCurrent, previousToNext)) { When the system\nreturn _.merge(current, previousToNext); state is the same\n} as the state used\nthrow \"Conflicting concurrent mutations.\"; by the calculation\n} phase, we fast-\nstatic reconcile(current, previous, next) { forward.\nif(current == previous) {\nreturn next;\n}\nreturn SystemConsistency.threeWayMerge(current,\nprevious,\nnext);\n}\n}\nTheo Wait a minute! Why do you compare previous and current by reference?\nYou should be comparing them by value, right? And, it would be quite expen-\nsive to compare all the leaves of the two nested hash maps!\nJoe That’s another benefit of immutable data. When the data is not mutated, it is\nsafe to compare references. If they are the same, we know for sure that the data\nis the same.\nTIP When data is immutable, it is safe to compare by reference, which is super fast.\nWhen the references are the same, it means that the data is the same.\nTheo What about the implementation of the three-way merge algorithm?\nJoe When previous differs from current, it means that concurrent mutations\nhave run. In order to determine whether there is a conflict, we calculate two\ndiffs: the diff between previous and current and the diff between previous\nand next. If the intersection between the two diffs is empty, it means there is\nno conflict. We can safely patch the changes between previous to next into\ncurrent.\nTheo takes a closer look at the code for the SystemConsistency class in listing 5.16. He\ntries to figure out if the code is thread-safe or not.\n--- Page 136 ---\n108 CHAPTER 5 Basic concurrency control\nTheo I think the code for SystemConsistency class is not thread-safe! If there’s a\ncontext switch between checking whether the system has changed in the\nSystemConsistency class and the updating of the state in SystemData class, a\nmutation might override the changes of a previous mutation.\nJoe You are totally right! The code works fine in a single-threaded environment\nlike JavaScript, where concurrency is handled via an event loop. However, in a\nmulti-threaded environment, the code needs to be refined in order to be\nthread-safe. I’ll show you some day.\n NOTE The SystemConsistency class is not thread-safe. We will make it thread-safe\nin chapter 8.\nTheo I think I understand why you called it optimistic concurrency control. It’s\nbecause we assume that conflicts don’t occur too often. Right?\nJoe Correct! It makes me wonder what your therapist would say about conflicts that\ncannot be resolved. Are there some cases where it’s not possible to reconcile\nthe couple?\nTheo I don’t think she ever mentioned such a possibility.\nJoe She must be a very optimistic person.\nSummary\n Optimistic concurrency control allows mutations to ask forgiveness instead of\npermission.\n Optimistic concurrency control is lock-free.\n Managing concurrent mutations of our system state with optimistic concurrency\ncontrol allows our system to support a high throughput of reads and writes.\n Optimistic concurrency control with immutable data is super efficient.\n Before updating the state, we need to reconcile the conflicts between possible con-\ncurrent mutations.\n We reconcile between concurrent mutations in a way that is similar to how Git han-\ndles a merge between two branches: either a fast-forward or a three-way merge.\n The changes required to let our system manage concurrency are only in the\ncommit phase.\n The calculation phase does its calculation as if it were the only mutation running.\n The commit phase is responsible for trying to reconcile concurrent mutations.\n The reconciliation algorithm is universal in the sense that it can be used in any sys-\ntem where the system data is represented as an immutable hash map.\n The implementation of the reconciliation algorithm is efficient, as it leverages\nthe fact that subsequent versions of the system state are created via structural\nsharing.\n In a user-facing system, conflicting concurrent mutations are fairly rare.\n When we cannot safely reconcile between concurrent mutations, we abort the\nmutation and ask the user to try again.\n--- Page 137 ---\nSummary 109\n Calculating the structural diff between two versions of the state is efficient because\ntwo hash maps created via structural sharing from the same hash map have most\nof their nodes in common.\n When data is immutable, it is safe to compare by reference, which is fast. When\nthe references are the same, it means that the data is the same.\n There are three kinds of structural differences between two nested hash maps:\nreplacement, addition, and deletion.\n Our structural diff algorithm supports replacements and additions but not\ndeletions.\nLodash functions introduced in this chapter\nFunction Description\nconcat(arrA, arrB) Creates an new array, concatenating arrA and arrB\nintersection(arrA, arrB) Creates an array of unique values both in arrA and arrB\nunion(arrA, arrB) Creates an array of unique values from arrA and arrB\nfind(coll, pred) Iterates over elements of coll, returning the first element for\nwhich pred returns true\nisEmpty(coll) Checks if coll is empty\nreduce(coll, f, initVal) Reduces coll to a value that is the accumulated result of running\neach element in coll through f, where each successive invoca-\ntion is supplied the return value of the previous\nisArray(coll) Checks if coll is an array\nisObject(coll) Checks if coll is a collection\n--- Page 138 ---\nUnit tests\nProgramming at a coffee shop\nThis chapter covers\n Generation of the minimal data input for a\ntest case\n Comparison of the output of a function with\nthe expected output\n Guidance about the quality and the quantity\nof the test cases\nIn a data-oriented system, our code deals mainly with data manipulation: most of\nour functions receive data and return data. As a consequence, it’s quite easy to\nwrite unit tests to check whether our code behaves as expected. A unit test is made\nof test cases that generate data input and compare the data output of the function\nwith the expected data output. In this chapter, we write unit tests for the queries\nand mutations that we wrote in the previous chapters.\n6.1 The simplicity of data-oriented test cases\nTheo and Joe are seated around a large wooden table in a corner of “La vie est belle,” a\nnice little French coffee shop, located near the Golden Gate Bridge. Theo orders a café\nau lait with a croissant, and Joe orders a tight espresso with a pain au chocolat. Instead\nof the usual general discussions about programming and life when they’re out of the\n110\n--- Page 139 ---\n6.1 The simplicity of data-oriented test cases 111\noffice, Joe leads the discussion towards a very concrete topic—unit tests. Theo asks Joe for\nan explanation.\nTheo Are unit tests such a simple topic that we can tackle it here in a coffee shop?\nJoe Unit tests in general, no. But unit tests for data-oriented code, yes!\nTheo Why does that make a difference?\nJoe The vast majority of the code base of a data-oriented system deals with data\nmanipulation.\nTheo Yeah. I noticed that almost all the functions we wrote so far receive data and\nreturn data.\nTIP Most of the code in a data-oriented system deals with data manipulation.\nJoe Writing a test case for functions that deal with data is only about generating\ndata input and expected output, and comparing the output of the function\nwith the expected output.\nThe steps of a test case\n1 Generate data input: dataIn\n2 Generate expected output: dataOut\n3 Compare the output of the function with the expected output: f(dataIn) and\ndataOut\nTheo That’s it?\nJoe Yes. As you’ll see in a moment, in DOP, there’s usually no need for mock\nfunctions.\nTheo I understand how to compare primitive values like strings or numbers, but I’m\nnot sure how I would compare data collections like maps.\nJoe You compare field by field.\nTheo Recursively?\nJoe Yes!\nTheo Oh no! I’m not able to write any recursive code in a coffee shop. I need the\ncalm of my office for that kind of stuff.\nJoe Don’t worry. In DOP, data is represented in a generic way. There is a generic\nfunction in Lodash called _.isEqual for recursive comparison of data collec-\ntions. It works with both maps and arrays.\nJoe opens his laptop. He is able to convince Theo by executing a few code snippets with\n_.isEqual to compare an equal data collection with a non-equal one.\nListing6.1 Comparing an equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n--- Page 140 ---\n112 CHAPTER 6 Unit tests\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n});\n// → true\nListing6.2 Comparing a non-equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"bad-isbn\"]\n});\n// → false\nTheo Nice!\nJoe Most of the test cases in DOP follow this pattern.\nTheo decides he wants to try this out. He fires up his laptop and types a few lines of\npseudocode.\nListing6.3 The general pattern of a data-oriented test case\nvar dataIn = {\n// input\n};\nvar dataOut = {\n// expected output\n};\n_.isEqual(f(dataIn), dataOut);\nTIP It’s straightforward to write unit tests for code that deals with data manipulation.\nTheo Indeed, this looks like something we can tackle in a coffee shop!\n6.2 Unit tests for data manipulation code\nA waiter in an elegant bow tie brings Theo his croissant and Joe his pain au chocolat. The\ntwo friends momentarily interrupt their discussion to savor their French pastries. When\nthey’re done, they ask the waiter to bring them their drinks. Meanwhile, they resume the\ndiscussion.\nJoe Do you remember the code flow of the implementation of the search query?\nTheo Let me look again at the code that implements the search query.\nTheo brings up the implementation of the search query on his laptop. Noticing that Joe is\nchewing on his nails again, he quickly checks out the code.\n--- Page 141 ---\n6.2 Unit tests for data manipulation code 113\nListing6.4 The code involved in the implementation of the search query\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\n}\n6.2.1 The tree of function calls\nThe waiter brings Theo his café au lait and Joe his tight espresso. They continue their dis-\ncussion while enjoying their coffees.\nJoe Before writing a unit test for a code flow, I find it useful to visualize the tree of\nfunction calls of the code flow.\nTheo What do you mean by a tree of function calls?\nJoe Here, I’ll draw the tree of function calls for the Library.searchBooksBy-\nTitleJSON code flow.\nJoe puts down his espresso and takes a napkin from the dispenser. He carefully places it\nflat on the table and starts to draw. When he is done, he shows the illustration to Theo (see\nfigure 6.1).\n--- Page 142 ---\n114 CHAPTER 6 Unit tests\nLibrary.searchBooksByTitleJSON\n_.get JSON.stringify Catalog.searchBooksByTitle\n_.get _.map _.filter Catalog.bookInfo\n_.get Catalog.authorNames\n_.get _.map\nFigure 6.1 The tree of function calls for the search query code flow\nTheo Nice! Can you teach me how to draw a tree of function calls like that?\nJoe Sure. The root of the tree is the name of the function for which you draw the\ntree, in our case, Library.searchBooksByTitleJSON. The children of a\nnode in the tree are the names of the functions called by the function. For exam-\nple, if you look again at the code for Library.searchBooksByTitleJSON (list-\ning 6.4), you’ll see that it calls Catalog.searchBooksByTitle, _.get, and\nJSON.stringify.\nTheo How long would I continue to recursively expand the tree?\nJoe You continue until you reach a function that doesn’t belong to the code base\nof your application. Those nodes are the leaves of our tree; for example, the\nfunctions from Lodash: _.get, _.map, and so forth.\nTheo What if the code of a function doesn’t call any other functions?\nJoe A function that doesn’t call any other function would be a leaf in the tree.\nTheo What about functions that are called inside anonymous functions like Catalog\n.bookInfo?\nJoe Catalog.bookInfo appears in the code of Catalog.searchBooksByTitle.\nTherefore, it is considered to be a child node of Catalog.searchBooksBy-\nTitle. The fact that it is nested inside an anonymous function is not relevant\nin the context of the tree of function calls.\n NOTE A tree of function calls for a function f is a tree where the root is f, and the\nchildren of a node g in the tree are the functions called by g. The leaves of the tree are\nfunctions that are not part of the code base of the application. These are functions\nthat don’t call any other functions.\nTheo It’s very cool to visualize my code as a tree, but I don’t see how it relates to\nunittests.\n--- Page 143 ---\n6.2 Unit tests for data manipulation code 115\nJoe The tree of function calls guides us about the quality and the quantity of test\ncases we should write.\nTheo How?\nJoe You’ll see in a moment.\n6.2.2 Unit tests for functions down the tree\nJoe Let’s start from the function that appears in the deepest node in our tree:\nCatalog.authorNames. Take a look at the code for Catalog.authorNames\nand tell me what are the input and the output of Catalog.authorNames.\nJoe turns his laptop so Theo can a closer look at the code. Theo takes a sip of his café au\nlait as he looks over what’s on Joe’s laptop.\nListing6.5 The code of Catalog.authorNames\nCatalog.authorNames = function (catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n};\nTheo The input of Catalog.authorNames is catalogData and authorIds. The\noutput is authorNames.\nJoe Would you do me a favor and express it visually?\nTheo Sure.\nIt’s Theo’s turn to grab a napkin. He draws a small rectangle with two inward arrows and\none outward arrow as in figure 6.2.\ncatalogData authorIds\nCatalog.authorNames()\nFigure 6.2 Visualization of the input\nauthorNames and output of Catalog.authorNames\nJoe Excellent! Now, how many combinations of input would you include in the\nunit test for Catalog.authorNames?\nTheo Let me see.\nTheo reaches for another napkin. This time he creates a table to gather his thoughts\n(table 6.1).\n--- Page 144 ---\n116 CHAPTER 6 Unit tests\nTable 6.1 The table of test cases for Catalog.authorNames\ncatalogData authorIds authorNames\nCatalog with two authors Empty array Empty array\nCatalog with two authors Array with one author ID Array with one author name\nCatalog with two authors Array with two author IDs Array with two author names\nTheo To begin with, I would have a catalogData with two author IDs and call\nCatalog.authorNames with three arguments: an empty array, an array with a\nsingle author ID, and an array with two author IDs.\nJoe How would you generate the catalogData?\nTheo Exactly as we generated it before.\nTurning to his laptop, Theo writes the code for catalogData. He shows it to Joe.\nListing6.6 A complete catalogData map\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\n--- Page 145 ---\n6.2 Unit tests for data manipulation code 117\nJoe You could use your big catalogData map for the unit test, but you could also\nuse a smaller map in the context of Catalog.authorNames. You can get rid of\nthe booksByIsbn field of the catalogData and the bookIsbns fields of the\nauthors.\nJoe deletes a few lines from catalogData and gets a much smaller map. He shows the revi-\nsion to Theo.\nListing6.7 A minimal version of catalogData\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nTheo Wait a minute! This catalogData is not valid.\nJoe In DOP, data validity depends on the context. In the context of Library\n.searchBooksByTitleJSON and Catalog.searchBooksByTitle, the mini-\nmal version of catalogData is indeed not valid. However, in the context of\nCatalog.bookInfo and Catalog.authorNames, it is perfectly valid. The reason\nis that those two functions access only the authorsById field of catalogData.\nTIP The validity of the data depends on the context.\nTheo Why is it better to use a minimal version of the data in a test case?\nJoe For a very simple reason—the smaller the data, the easier it is to manipulate.\nTIP The smaller the data, the easier it is to manipulate.\nTheo I’ll appreciate that when I write the unit tests!\nJoe Definitely! One last thing before we start coding: how would you check that the\noutput of Catalog.authorNames is as expected?\nTheo I would check that the value returned by Catalog.authorNames is an array\nwith the expected author names.\nJoe How would you handle the array comparison?\nTheo Let me think. I want to compare by value, not by reference. I guess I’ll have to\ncheck that the array is of the expected size and then check member by mem-\nber, recursively.\nJoe That’s too much of a mental burden when you’re in a coffee shop. As I showed\nyou earlier (see listing 6.1), we can recursively compare two data collections by\nvalue with _.isEqual from Lodash.\n--- Page 146 ---\n118 CHAPTER 6 Unit tests\nTIP We can compare the output and the expected output of our functions with\n_.isEqual.\nTheo Sounds good! Let me write the test cases.\nTheo starts typing on his laptop. After a few minutes, he has some test cases for Catalog\n.authorNames, each made from a function call to Catalog.authorNames wrapped in\n_.isEqual.\nListing6.8 Unit test for Catalog.authorNames\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(\ncatalogData,\n[\"alan-moore\"]),\n[\"Alan Moore\"]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\", \"dave-gibbons\"]),\n[\"Alan Moore\", \"Dave Gibbons\"]);\nJoe Well done! Can you think of more test cases?\nTheo Yes. There are test cases where the author ID doesn’t appear in the catalog\ndata, and test cases with empty catalog data. With minimal catalog data and\n_.isEqual, it’s really easy to write lots of test cases!\nTheo really enjoys this challenge. He creates a few more test cases to present to Joe.\nListing6.9 More test cases for Catalog.authorNames\n_.isEqual(Catalog.authorNames({}, []), []);\n_.isEqual(Catalog.authorNames({}, [\"alan-moore\"]), [undefined]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\",\n\"albert-einstein\"]), [\"Alan Moore\", undefined]);\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(catalogData, [\"albert-einstein\"]),\n[undefined]);\nTheo How do I run these unit tests?\nJoe You use your preferred test framework.\n--- Page 147 ---\n6.2 Unit tests for data manipulation code 119\n NOTE We don’t deal here with test runners and test frameworks. We deal only with\nthe logic of the test cases.\n6.2.3 Unit tests for nodes in the tree\nTheo I’m curious to see what unit tests for an upper node in the tree of function calls\nlook like.\nJoe Sure. Let’s write a unit test for Catalog.bookInfo. How many test cases would\nyou have for Catalog.bookInfo?\nListing6.10 The code of Catalog.bookInfo\nCatalog.bookInfo = function (catalogData, book) {\nreturn {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\n};\nTheo takes another look at the code for Catalog.bookInfo on his laptop. Then, reaching\nfor another napkin, he draws a diagram of its input and output (see figure 6.3).\ncatalogData book\nCatalog.bookInfo()\nFigure 6.3 Visualization of the input\nbookInfo and output of Catalog.bookInfo\nTheo I would have a similar number of test cases for Catalog.authorNames: a book\nwith a single author, with two authors, with existing authors, with non-existent\nauthors, with...\nJoe Whoa! That’s not necessary. Given that we have already written unit tests for\nCatalog.authorNames, we don’t need to check all the cases again. We simply\nneed to write a minimal test case to confirm that the code works.\nTIP When we write a unit test for a function, we assume that the functions called by\nthis function are covered by unit tests and work as expected. It significantly reduces\nthe quantity of test cases in our unit tests.\nTheo That makes sense.\nJoe How would you write a minimal test case for Catalog.bookInfo?\nTheo once again takes a look at the code for Catalog.bookInfo (see listing 6.10). Now he\ncan answer Joe’s question.\n--- Page 148 ---\n120 CHAPTER 6 Unit tests\nTheo I would use the same catalog data as for Catalog.authorNames and a book\nrecord. I’d test that the function behaves as expected by comparing its return\nvalue with a book info record using _.isEqual. Here, let me show you.\nIt takes Theo a bit more time to write the unit test. The reason is that the input and the\noutput of Catalog.authorNames are both records. Dealing with a record is more complex\nthan dealing with an array of strings (as it was the case for Catalog.authorNames). Theo\nappreciates the fact that _.isEqual saves him from writing code that compares the two\nmaps property by property. When he’s through, he shows the result to Joe and takes a nap-\nkin to wipe his forehead.\nListing6.11 Unit test for Catalog.bookInfo\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nvar book = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n};\nvar expectedResult = {\n\"authorNames\": [\"Alan Moore\", \"Dave Gibbons\"],\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n};\nvar result = Catalog.bookInfo(catalogData, book);\n_.isEqual(result, expectedResult);\nJoe Perfect! Now, how would you compare the kind of unit tests for Catalog\n.bookInfo with the unit tests for Catalog.authorNames?\nTheo On one hand, there is only a single test case in the unit test for Catalog.book-\nInfo. On the other hand, the data involved in the test case is more complex\nthan the data involved in the test cases for Catalog.authorNames.\nJoe Exactly! Functions that appear in a deep node in the tree of function calls tend\nto require more test cases, but the data involved in the test cases is less complex.\nTIP Functions that appear in a lower level in the tree of function calls tend to\ninvolve less complex data than functions that appear in a higher level in the tree\n(see table 6.2).\n--- Page 149 ---\n6.3 Unit tests for queries 121\nTable 6.2 The correlation between the depth of a function in the tree of function calls and the\nquality and quantity of the test cases\nDepth in the tree Complexity of the data Number of test cases\nLower Higher Lower\nHigher Lower Higher\n6.3 Unit tests for queries\nIn the previous section, we saw how to write unit tests for utility functions like Catalog\n.bookInfo and Catalog.authorNames. Now, we are going to see how to write unit tests\nfor the nodes of a query tree of function calls that are close to the root of the tree.\nJoe Theo, how would you write a unit test for the code of the entry point of the\nsearch query?\nTo recall the particulars, Theo checks the code for Library.searchBooksByTitleJSON.\nAlthough Joe was right about today’s topic being easy enough to enjoy the ambience of a\ncoffee shop, he has been doing quite a lot of coding this morning.\nListing6.12 The code of Library.searchBooksByTitleJSON\nLibrary.searchBooksByTitleJSON = function (libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n};\nHe then takes a moment to think about how he’d write a unit test for that code. After\nanother Aha! moment, now he’s got it.\nTheo The inputs of Library.searchBooksByTitleJSON are library data and a\nquery string, and the output is a JSON string (see figure 6.4). So, I would cre-\nate a library data record with a single book and write tests with query strings\nthat match the name of the book and ones that don’t match.\nlibraryData query\nLibrary.searchBooksByTitleJSON()\nFigure 6.4 The input and output of\nresultsJSON Library.searchBooksByTitleJSON\nJoe What about the expected results of the test cases?\n--- Page 150 ---\n122 CHAPTER 6 Unit tests\nTheo In cases where the query string matches, the expected result is a JSON string\nwith the book info. In cases where the query string doesn’t match, the\nexpected result is a JSON string with an empty array.\nJoe Hmm...\nTheo What?\nJoe I don’t like your answer.\nTheo Why?\nJoe Because your test case relies on a string comparison instead of a data comparison.\nTheo What difference does it make? After all, the strings I’m comparing come from\nthe serialization of data.\nJoe It’s inherently much more complex to compare JSON strings than it is to com-\npare data. For example, two different strings might be the serialization of the\nsame piece of data.\nTheo Really? How?\nJoe Take a look at these two strings. They are the serialization of the same data.\nThey’re different strings because the fields appear in a different order, but in\nfact, they serialize the same data!\nJoe turns his laptop to Theo. As Theo looks at the code, he realizes that, once again, Joe\niscorrect.\nListing6.13 Two different strings that serialize the same data\nvar stringA = \"{\\\"title\\\":\\\"Watchmen\\\",\\\"publicationYear\\\":1987}\";\nvar stringB = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nTIP Avoid using a string comparison in unit tests for functions that deal with data.\nTheo I see.... Well, what can I do instead?\nJoe Instead of comparing the output of Library.searchBooksByTitleJSON with\na string, you could deserialize the output and compare it to the expected data.\nTheo What do you mean by deserialize a string?\nJoe Deserializing a string s, for example, means to generate a piece of data whose\nserialization is s.\nTheo Is there a Lodash function for string deserialization?\nJoe Actually, there is a native JavaScript function for string deserialization; it’s\ncalled JSON.parse.\nJoe retrieves his laptop and shows Theo an example of string deserialization. The code\nillustrates a common usage of JSON.parse.\nListing6.14 Example of string deserialization\nvar myString = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nvar myData = JSON.parse(myString);\n--- Page 151 ---\n6.3 Unit tests for queries 123\n_.get(myData, \"title\");\n// → \"Watchmen\"\nTheo Cool! Let me try writing a unit test for Library.searchBooksByTitleJSON\nusing JSON.parse.\nIt doesn’t take Theo too much time to come up with a piece of code. Using his laptop, he\ninputs the unit test.\nListing6.15 Unit test for Library.searchBooksByTitleJSON\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Watchmen\")),\n[bookInfo]);\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Batman\")),\n[]);\nJoe Well done! I think you’re ready to move on to the last piece of the puzzle and\nwrite the unit test for Catalog.searchBooksByTitle.",
        "sections_found": []
      },
      "accurate_page_range": "126-151"
    },
    {
      "text": "- 5.2 Reconciliation between concurrent mutations",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "5 Basic concurrency control",
      "raw_line": "- 5.2 Reconciliation between concurrent mutations (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 40,
      "chapter_info": {
        "page": 126,
        "title": "Basic concurrency control",
        "pattern_matched": "Chapter 5",
        "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
      },
      "chapter_sections": {
        "start_page": 126,
        "end_page": 151,
        "content": "\n--- Page 126 ---\n98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. It means that the first call to f will be f(0, 1). Then,\nwe’ll have f(f(0, 1), 2) and, finally, f(f(f(0, 1), 2), 3).\nJoe I like your manual expansion, Theo! Let’s make it visual.\nNow Theo goes to the whiteboard and draws a diagram. Figure 5.5 shows what that looks like.\nf\nf a\n2\nf a\n1\na 0 initVal Figure 5.5 Visualization\nof _.reduce\nTheo It’s much clearer now. I think that by implementing my custom version of\n_.reduce, it will make things 100% clear.\nIt takes Theo much less time than he expected to implement reduce(). In no time at all,\nhe shows Joe the code.\nListing5.2 Custom implementation of _.reduce\nfunction reduce(coll, f, initVal) {\nvar currentRes = initVal;\nfor (var i = 0; i < coll.length; i++) {\nWe could use\ncurrentRes = f(currentRes, coll[i])\nforEach instead\n}\nof a for loop.\nreturn currentRes;\n}\nAfter checking that Theo’s code works as expected (see listing 5.3), Joe is proud of Theo.\nHe seems to be catching on better than he anticipated.\nListing5.3 Testing the custom implementation of reduce()\nreduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nJoe Well done!\n--- Page 127 ---\n5.4 Structural difference 99\n5.4 Structural difference\n NOTE This section deals with the implementation of a structural diff algorithm. Feel\nfree to skip this section if you don’t want to challenge your mind right now with the\ndetails of a sophisticated use of recursion. It won’t prevent you from enjoying the rest\nof the book. You can come back to this section later.\nTheo How do you calculate the diff between various versions of the system state?\nJoe That’s the most challenging part of the reconciliation algorithm. We need to\nimplement a structural diff algorithm for hash maps.\nTheo In what sense is the diff structural?\nJoe The structural diff algorithm looks at the structure of the hash maps and\nignores the order of the fields.\nTheo Could you give me an example?\nJoe Let’s start with maps without nested fields. Basically, there are three kinds of\ndiffs: field replacement, field addition, and field deletion. In order to make\nthings not too complicated, for now, we’ll deal only with replacement and\naddition.\nJoe once again goes to the whiteboard and draws table 5.3, representing the three kinds of\ndiffs. Theo is thinking the whiteboard is really starting to fill up today.\nTable 5.3 Kinds of structural differences between maps without nested fields\nKind First map Second map Diff\nReplacement {\"a\": 1} {\"a\": 2} {\"a\": 2}\nAddition {\"a\": 1} {\"a\": 1, \"b\": 2} {\"b\": 2}\nDeletion {\"a\": 1, \"b\": 2} {\"a\": 1} Not supported\nTheo I notice that the order of the maps matters a lot. What about nested fields?\nJoe It’s the same idea, but the nesting makes it a bit more difficult to grasp.\nJoe changes several of the columns in table 5.3. When he’s through, he shows Theo the\nnested fields in table 5.4.\nTable 5.4 Kinds of structural differences between maps with nested fields\nKind First map Second map Diff\nReplacement { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 2 \"x\": 2\n} } }\n} } }\n--- Page 128 ---\n100 CHAPTER 5 Basic concurrency control\nTable 5.4 Kinds of structural differences between maps with nested fields (continued)\nKind First map Second map Diff\nAddition { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 1, \"y\": 2\n} \"y\": 2, }\n} } }\n}\nDeletion { { Not supported\n\"a\": { \"a\": {\n\"x\": 1, \"y\": 2\n\"y\": 2, }\n} }\n}\n NOTE The version of the structural diff algorithm illustrated in this chapter does\nnot deal with deletions. Dealing with deletions is definitely possible, but it requires a\nmore complicated algorithm.\nTheo As you said, it’s harder to grasp. What about arrays?\nJoe We compare the elements of the arrays in order: if they are equal, the diff is\nnull; if they differ, the diff has the value of the second array.\nJoe summarizes the various kinds of diffs in another table on the whiteboard. Theo looks\nat the result in table 5.5.\nTable 5.5 Kinds of structural differences between arrays without nested elements\nKind First array Second array Diff\nReplacement [1] [2] [2]\nAddition [1] [1, 2] [null, 2]\nDeletion [1, 2] [1] Not supported\nTheo This usage of null is a bit weird but OK. Is it complicated to implement the\nstructural diff algorithm?\nJoe Definitely! It took a good dose of mental gymnastics to come up with these 30\nlines of code.\nJoe downloads the code from one his personal repositories. Theo, with thumb and forefin-\ngers touching his chin and his forehead slightly tilted, studies the code.\nListing5.4 The implementation of a structural diff\nfunction diffObjects(data1, data2) {\n_.isArray checks whether\nvar emptyObject = _.isArray(data1) ? [] : {};\nits argument is an array.\nif(data1 == data2) {\n--- Page 129 ---\n5.4 Structural difference 101\nreturn emptyObject;\n_.union creates an\n} array of unique\nvar keys = _.union(_.keys(data1), _.keys(data2)); values from two\nreturn _.reduce(keys, arrays (like union of\nfunction (acc, k) { two sets in Maths).\nvar res = diff(\n_.get(data1, k),\n_.isObject checks\n_.get(data2, k));\nwhether its argument\nif((_.isObject(res) && _.isEmpty(res)) ||\nis a collection (either\na map or an array).\n(res == \"no-diff\")) {\nreturn acc;\n_.isEmpty }\nchecks return _.set(acc, [k], res);\nwhether its },\nargument\nemptyObject);\nis an empty\n} \"no-diff\" is how\ncollection.\nwe mark that\nfunction diff(data1, data2) { two values are\nif(_.isObject(data1) && _.isObject(data2)) { the same.\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"no-diff\";\n}\nTheo Wow! It involves a recursion inside a reduce! I’m sure Dave will love this, but\nI’m too tired to understand this code right now. Let’s focus on what it does\ninstead of how it does it.\nIn order familiarize himself with the structural diff algorithm, Theo runs the algorithm\nwith examples from the table that Joe drew on the whiteboard. While Theo occupies his\nfingers with more and more complicated examples, his mind wanders in the realm of\nperformance.\nListing5.5 An example of usage of a structural diff\nvar data1 = {\n\"a\": {\n\"x\": 1,\n\"y\": [2, 3],\n\"z\": 4\n}\n};\nvar data2 = {\n\"a\": {\n\"x\": 2,\n\"y\": [2, 4],\n\"z\": 4\n}\n}\n--- Page 130 ---\n102 CHAPTER 5 Basic concurrency control\ndiff(data1, data2);\n//{\n// \"a\": {\n// \"x\": 2,\n// \"y\": [\n// undefined,\n// 4\n// ]\n// }\n//}\nTheo What about the performance of the structural diff algorithm? It seems that the\nalgorithm goes over the leaves of both pieces of data?\nJoe In the general case, that’s true. But, in the case of system data that’s manipu-\nlated with structural sharing, the code is much more efficient.\nTheo What do you mean?\nJoe With structural sharing, most of the nested objects are shared between two ver-\nsions of the system state. Therefore, most of the time, when the code enters\ndiffObjects, it will immediately return because data1 and data2 are the same.\nTIP Calculating the diff between two versions of the state is efficient because two\nhash maps created via structural sharing from the same hash map have most of their\nnodes in common.\nTheo Another benefit of immutable data... Let me see how the diff algorithm\nbehaves with concurrent mutations. I think I’ll start with a tiny library with no\nusers and a catalog with a single book, Watchmen.\nListing5.6 The data for a tiny library\nvar library = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\n--- Page 131 ---\n5.4 Structural difference 103\nJoe I suggest that we start with nonconflicting mutations. What do you suggest?\nTheo A mutation that updates the publication year of Watchmen and a mutation that\nupdates both the title of Watchmen and the name of the author of Watchmen.\nOn his laptop, Theo creates three versions of the library. He shows Joe his code, where one\nmutation updates the publication year of Watchmen, and the other one updates the title of\nWatchmen and the author’s name.\nListing5.7 Two nonconflicting mutations\nvar previous = library;\nvar next = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"],\n1986);\nvar libraryWithUpdatedTitle = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"],\n\"The Watchmen\");\nvar current = _.set(\nlibraryWithUpdatedTitle,\n[\"catalog\", \"authorsById\", \"dave-gibbons\", \"name\"],\n\"David Chester Gibbons\");\nTheo I’m curious to see what the diff between previous and current looks like.\nJoe Run the code and you’ll see.\nTheo runs the code snippets for the structural diff between previous and next and for\nthe structural diff between previous and current. His curiosity satisfied, Theo finds it’s\nall beginning to make sense.\nListing5.8 Structural diff between maps with a single difference\ndiff(previous, next);\n//{\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"publicationYear\": 1986\n// }\n// }\n// }\n//}\nListing5.9 Structural diff between maps with two differences\ndiff(previous, current);\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\",\n--- Page 132 ---\n104 CHAPTER 5 Basic concurrency control\n// }\n// },\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\n//\nJoe Can you give me the information path of the single field in the structural diff\nbetween previous and next?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Right. And what are the information paths of the fields in the structural diff\nbetween previous and current?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"] for the book\ntitle and [\"authorsById\", \"dave-gibbons\", \"name\"] for the author’s name.\nJoe Perfect! Now, can you figure out how to detect conflicting mutations by\ninspecting the information paths of the structural diffs?\nTheo We need to check if they have an information path in common or not.\nJoe Exactly! If they have, it means the mutations are conflicting.\nTheo But I have no idea how to write code that retrieves the information paths of a\nnested map.\nJoe Once again, it’s a nontrivial piece of code that involves a recursion inside a\nreduce. Let me download another piece of code from my repository and show\nit to you.\nListing5.10 Calculating the information paths of a (nested) map\nfunction informationPaths (obj, path = []) {\nreturn _.reduce(obj,\nfunction(acc, v, k) {\nif (_.isObject(v)) {\nreturn _.concat(acc,\ninformationPaths(v,\n_.concat(path, k)));\n}\nreturn _.concat(acc, [_.concat(path, k)]);\n},\n[]);\n}\nTheo Let me see if your code works as expected with the structural diffs of the\nmutations.\nTheo tests Joe’s code with two code snippets. The first shows the information paths of the\nstructural diff between previous and next, and the second shows the information paths\nof the structural diff between previous and current.\n--- Page 133 ---\n5.4 Structural difference 105\nListing5.11 Fields that differ between previous and next\ninformationPaths(diff(previous, next));\n// → [\"catalog.booksByIsbn.978-1779501127.publicationYear\"]\nListing5.12 Fields that differ between previous and current\ninformationPaths(diff(previous, current));\n// [\n// [\n// \"catalog\",\n// \"booksByIsbn\",\n// \"978-1779501127\",\n// \"title\"\n// ],\n// [\n// \"authorsById\",\n// \"dave-gibbons\",\n// \"name\"\n// ]\n//]\nTheo Nice! I assume that Lodash has a function that checks whether two arrays have\nan element in common.\nJoe Almost. There is _.intersection, which returns an array of the unique values\nthat are in two given arrays. For our purpose, though, we need to check\nwhether the intersection is empty. Here, look at this example.\nListing5.13 Checking whether two diff maps have a common information path\nfunction havePathInCommon(diff1, diff2) {\nreturn !_.isEmpty(_.intersection(informationPaths(diff1),\ninformationPaths(diff2)));\n}\nTheo You told me earlier that in the case of nonconflicting mutations, we can\nsafely patch the changes induced by the transition from previous to next\ninto current. How do you implement that?\nJoe We do a recursive merge between current and the diff between previous and\nnext.\nTheo Does Lodash provide an immutable version of recursive merge?\nJoe Yes, here’s another example. Take a look at this code.\nListing5.14 Applying a patch\n_.merge(current, (diff(previous, next)));\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\"\n// }\n// },\n--- Page 134 ---\n106 CHAPTER 5 Basic concurrency control\n// \"catalog\": {\n// \"authorsById\": {\n// \"alan-moore\": {\n// \"bookIsbns\": [\"978-1779501127\"]\n// \"name\": \"Alan Moore\"\n// },\n// \"dave-gibbons\": {\n// \"bookIsbns\": [\"978-1779501127\"],\n// \"name\": \"Dave Gibbons\"\n// },\n// },\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n// \"isbn\": \"978-1779501127\",\n// \"publicationYear\": 1986,\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\nTheo Could it be as simple as this?\nJoe Indeed.\n5.5 Implementing the reconciliation algorithm\nJoe All the pieces are now in place to implement our reconciliation algorithm.\nTheo What kind of changes are required?\nJoe It only requires changes in the code of SystemState.commit. Here, look at\nthis example on my laptop.\nListing5.15 The SystemState class\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nvar nextSystemData = SystemConsistency.reconcile(\nthis.systemData,\nSystemConsistency class is\nprevious,\nimplemented in listing 5.16.\nnext);\nif(!SystemValidity.validate(previous, nextSystemData)) {\nthrow \"The system data to be committed is not valid!\";\n};\n--- Page 135 ---\n5.5 Implementing the reconciliation algorithm 107\nthis.systemData = nextSystemData;\n}\n}\nTheo How does SystemConsistency do the reconciliation?\nJoe The SystemConsistency class starts the reconciliation process by comparing\nprevious and current. If they are the same, then we fast-forward and return\nnext. Look at this code for SystemConsistency.\nListing5.16 The reconciliation flow in action\nclass SystemConsistency {\nstatic threeWayMerge(current, previous, next) {\nvar previousToCurrent = diff(previous, current);\nvar previousToNext = diff(previous, next);\nif(havePathInCommon(previousToCurrent, previousToNext)) { When the system\nreturn _.merge(current, previousToNext); state is the same\n} as the state used\nthrow \"Conflicting concurrent mutations.\"; by the calculation\n} phase, we fast-\nstatic reconcile(current, previous, next) { forward.\nif(current == previous) {\nreturn next;\n}\nreturn SystemConsistency.threeWayMerge(current,\nprevious,\nnext);\n}\n}\nTheo Wait a minute! Why do you compare previous and current by reference?\nYou should be comparing them by value, right? And, it would be quite expen-\nsive to compare all the leaves of the two nested hash maps!\nJoe That’s another benefit of immutable data. When the data is not mutated, it is\nsafe to compare references. If they are the same, we know for sure that the data\nis the same.\nTIP When data is immutable, it is safe to compare by reference, which is super fast.\nWhen the references are the same, it means that the data is the same.\nTheo What about the implementation of the three-way merge algorithm?\nJoe When previous differs from current, it means that concurrent mutations\nhave run. In order to determine whether there is a conflict, we calculate two\ndiffs: the diff between previous and current and the diff between previous\nand next. If the intersection between the two diffs is empty, it means there is\nno conflict. We can safely patch the changes between previous to next into\ncurrent.\nTheo takes a closer look at the code for the SystemConsistency class in listing 5.16. He\ntries to figure out if the code is thread-safe or not.\n--- Page 136 ---\n108 CHAPTER 5 Basic concurrency control\nTheo I think the code for SystemConsistency class is not thread-safe! If there’s a\ncontext switch between checking whether the system has changed in the\nSystemConsistency class and the updating of the state in SystemData class, a\nmutation might override the changes of a previous mutation.\nJoe You are totally right! The code works fine in a single-threaded environment\nlike JavaScript, where concurrency is handled via an event loop. However, in a\nmulti-threaded environment, the code needs to be refined in order to be\nthread-safe. I’ll show you some day.\n NOTE The SystemConsistency class is not thread-safe. We will make it thread-safe\nin chapter 8.\nTheo I think I understand why you called it optimistic concurrency control. It’s\nbecause we assume that conflicts don’t occur too often. Right?\nJoe Correct! It makes me wonder what your therapist would say about conflicts that\ncannot be resolved. Are there some cases where it’s not possible to reconcile\nthe couple?\nTheo I don’t think she ever mentioned such a possibility.\nJoe She must be a very optimistic person.\nSummary\n Optimistic concurrency control allows mutations to ask forgiveness instead of\npermission.\n Optimistic concurrency control is lock-free.\n Managing concurrent mutations of our system state with optimistic concurrency\ncontrol allows our system to support a high throughput of reads and writes.\n Optimistic concurrency control with immutable data is super efficient.\n Before updating the state, we need to reconcile the conflicts between possible con-\ncurrent mutations.\n We reconcile between concurrent mutations in a way that is similar to how Git han-\ndles a merge between two branches: either a fast-forward or a three-way merge.\n The changes required to let our system manage concurrency are only in the\ncommit phase.\n The calculation phase does its calculation as if it were the only mutation running.\n The commit phase is responsible for trying to reconcile concurrent mutations.\n The reconciliation algorithm is universal in the sense that it can be used in any sys-\ntem where the system data is represented as an immutable hash map.\n The implementation of the reconciliation algorithm is efficient, as it leverages\nthe fact that subsequent versions of the system state are created via structural\nsharing.\n In a user-facing system, conflicting concurrent mutations are fairly rare.\n When we cannot safely reconcile between concurrent mutations, we abort the\nmutation and ask the user to try again.\n--- Page 137 ---\nSummary 109\n Calculating the structural diff between two versions of the state is efficient because\ntwo hash maps created via structural sharing from the same hash map have most\nof their nodes in common.\n When data is immutable, it is safe to compare by reference, which is fast. When\nthe references are the same, it means that the data is the same.\n There are three kinds of structural differences between two nested hash maps:\nreplacement, addition, and deletion.\n Our structural diff algorithm supports replacements and additions but not\ndeletions.\nLodash functions introduced in this chapter\nFunction Description\nconcat(arrA, arrB) Creates an new array, concatenating arrA and arrB\nintersection(arrA, arrB) Creates an array of unique values both in arrA and arrB\nunion(arrA, arrB) Creates an array of unique values from arrA and arrB\nfind(coll, pred) Iterates over elements of coll, returning the first element for\nwhich pred returns true\nisEmpty(coll) Checks if coll is empty\nreduce(coll, f, initVal) Reduces coll to a value that is the accumulated result of running\neach element in coll through f, where each successive invoca-\ntion is supplied the return value of the previous\nisArray(coll) Checks if coll is an array\nisObject(coll) Checks if coll is a collection\n--- Page 138 ---\nUnit tests\nProgramming at a coffee shop\nThis chapter covers\n Generation of the minimal data input for a\ntest case\n Comparison of the output of a function with\nthe expected output\n Guidance about the quality and the quantity\nof the test cases\nIn a data-oriented system, our code deals mainly with data manipulation: most of\nour functions receive data and return data. As a consequence, it’s quite easy to\nwrite unit tests to check whether our code behaves as expected. A unit test is made\nof test cases that generate data input and compare the data output of the function\nwith the expected data output. In this chapter, we write unit tests for the queries\nand mutations that we wrote in the previous chapters.\n6.1 The simplicity of data-oriented test cases\nTheo and Joe are seated around a large wooden table in a corner of “La vie est belle,” a\nnice little French coffee shop, located near the Golden Gate Bridge. Theo orders a café\nau lait with a croissant, and Joe orders a tight espresso with a pain au chocolat. Instead\nof the usual general discussions about programming and life when they’re out of the\n110\n--- Page 139 ---\n6.1 The simplicity of data-oriented test cases 111\noffice, Joe leads the discussion towards a very concrete topic—unit tests. Theo asks Joe for\nan explanation.\nTheo Are unit tests such a simple topic that we can tackle it here in a coffee shop?\nJoe Unit tests in general, no. But unit tests for data-oriented code, yes!\nTheo Why does that make a difference?\nJoe The vast majority of the code base of a data-oriented system deals with data\nmanipulation.\nTheo Yeah. I noticed that almost all the functions we wrote so far receive data and\nreturn data.\nTIP Most of the code in a data-oriented system deals with data manipulation.\nJoe Writing a test case for functions that deal with data is only about generating\ndata input and expected output, and comparing the output of the function\nwith the expected output.\nThe steps of a test case\n1 Generate data input: dataIn\n2 Generate expected output: dataOut\n3 Compare the output of the function with the expected output: f(dataIn) and\ndataOut\nTheo That’s it?\nJoe Yes. As you’ll see in a moment, in DOP, there’s usually no need for mock\nfunctions.\nTheo I understand how to compare primitive values like strings or numbers, but I’m\nnot sure how I would compare data collections like maps.\nJoe You compare field by field.\nTheo Recursively?\nJoe Yes!\nTheo Oh no! I’m not able to write any recursive code in a coffee shop. I need the\ncalm of my office for that kind of stuff.\nJoe Don’t worry. In DOP, data is represented in a generic way. There is a generic\nfunction in Lodash called _.isEqual for recursive comparison of data collec-\ntions. It works with both maps and arrays.\nJoe opens his laptop. He is able to convince Theo by executing a few code snippets with\n_.isEqual to compare an equal data collection with a non-equal one.\nListing6.1 Comparing an equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n--- Page 140 ---\n112 CHAPTER 6 Unit tests\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n});\n// → true\nListing6.2 Comparing a non-equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"bad-isbn\"]\n});\n// → false\nTheo Nice!\nJoe Most of the test cases in DOP follow this pattern.\nTheo decides he wants to try this out. He fires up his laptop and types a few lines of\npseudocode.\nListing6.3 The general pattern of a data-oriented test case\nvar dataIn = {\n// input\n};\nvar dataOut = {\n// expected output\n};\n_.isEqual(f(dataIn), dataOut);\nTIP It’s straightforward to write unit tests for code that deals with data manipulation.\nTheo Indeed, this looks like something we can tackle in a coffee shop!\n6.2 Unit tests for data manipulation code\nA waiter in an elegant bow tie brings Theo his croissant and Joe his pain au chocolat. The\ntwo friends momentarily interrupt their discussion to savor their French pastries. When\nthey’re done, they ask the waiter to bring them their drinks. Meanwhile, they resume the\ndiscussion.\nJoe Do you remember the code flow of the implementation of the search query?\nTheo Let me look again at the code that implements the search query.\nTheo brings up the implementation of the search query on his laptop. Noticing that Joe is\nchewing on his nails again, he quickly checks out the code.\n--- Page 141 ---\n6.2 Unit tests for data manipulation code 113\nListing6.4 The code involved in the implementation of the search query\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\n}\n6.2.1 The tree of function calls\nThe waiter brings Theo his café au lait and Joe his tight espresso. They continue their dis-\ncussion while enjoying their coffees.\nJoe Before writing a unit test for a code flow, I find it useful to visualize the tree of\nfunction calls of the code flow.\nTheo What do you mean by a tree of function calls?\nJoe Here, I’ll draw the tree of function calls for the Library.searchBooksBy-\nTitleJSON code flow.\nJoe puts down his espresso and takes a napkin from the dispenser. He carefully places it\nflat on the table and starts to draw. When he is done, he shows the illustration to Theo (see\nfigure 6.1).\n--- Page 142 ---\n114 CHAPTER 6 Unit tests\nLibrary.searchBooksByTitleJSON\n_.get JSON.stringify Catalog.searchBooksByTitle\n_.get _.map _.filter Catalog.bookInfo\n_.get Catalog.authorNames\n_.get _.map\nFigure 6.1 The tree of function calls for the search query code flow\nTheo Nice! Can you teach me how to draw a tree of function calls like that?\nJoe Sure. The root of the tree is the name of the function for which you draw the\ntree, in our case, Library.searchBooksByTitleJSON. The children of a\nnode in the tree are the names of the functions called by the function. For exam-\nple, if you look again at the code for Library.searchBooksByTitleJSON (list-\ning 6.4), you’ll see that it calls Catalog.searchBooksByTitle, _.get, and\nJSON.stringify.\nTheo How long would I continue to recursively expand the tree?\nJoe You continue until you reach a function that doesn’t belong to the code base\nof your application. Those nodes are the leaves of our tree; for example, the\nfunctions from Lodash: _.get, _.map, and so forth.\nTheo What if the code of a function doesn’t call any other functions?\nJoe A function that doesn’t call any other function would be a leaf in the tree.\nTheo What about functions that are called inside anonymous functions like Catalog\n.bookInfo?\nJoe Catalog.bookInfo appears in the code of Catalog.searchBooksByTitle.\nTherefore, it is considered to be a child node of Catalog.searchBooksBy-\nTitle. The fact that it is nested inside an anonymous function is not relevant\nin the context of the tree of function calls.\n NOTE A tree of function calls for a function f is a tree where the root is f, and the\nchildren of a node g in the tree are the functions called by g. The leaves of the tree are\nfunctions that are not part of the code base of the application. These are functions\nthat don’t call any other functions.\nTheo It’s very cool to visualize my code as a tree, but I don’t see how it relates to\nunittests.\n--- Page 143 ---\n6.2 Unit tests for data manipulation code 115\nJoe The tree of function calls guides us about the quality and the quantity of test\ncases we should write.\nTheo How?\nJoe You’ll see in a moment.\n6.2.2 Unit tests for functions down the tree\nJoe Let’s start from the function that appears in the deepest node in our tree:\nCatalog.authorNames. Take a look at the code for Catalog.authorNames\nand tell me what are the input and the output of Catalog.authorNames.\nJoe turns his laptop so Theo can a closer look at the code. Theo takes a sip of his café au\nlait as he looks over what’s on Joe’s laptop.\nListing6.5 The code of Catalog.authorNames\nCatalog.authorNames = function (catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n};\nTheo The input of Catalog.authorNames is catalogData and authorIds. The\noutput is authorNames.\nJoe Would you do me a favor and express it visually?\nTheo Sure.\nIt’s Theo’s turn to grab a napkin. He draws a small rectangle with two inward arrows and\none outward arrow as in figure 6.2.\ncatalogData authorIds\nCatalog.authorNames()\nFigure 6.2 Visualization of the input\nauthorNames and output of Catalog.authorNames\nJoe Excellent! Now, how many combinations of input would you include in the\nunit test for Catalog.authorNames?\nTheo Let me see.\nTheo reaches for another napkin. This time he creates a table to gather his thoughts\n(table 6.1).\n--- Page 144 ---\n116 CHAPTER 6 Unit tests\nTable 6.1 The table of test cases for Catalog.authorNames\ncatalogData authorIds authorNames\nCatalog with two authors Empty array Empty array\nCatalog with two authors Array with one author ID Array with one author name\nCatalog with two authors Array with two author IDs Array with two author names\nTheo To begin with, I would have a catalogData with two author IDs and call\nCatalog.authorNames with three arguments: an empty array, an array with a\nsingle author ID, and an array with two author IDs.\nJoe How would you generate the catalogData?\nTheo Exactly as we generated it before.\nTurning to his laptop, Theo writes the code for catalogData. He shows it to Joe.\nListing6.6 A complete catalogData map\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\n--- Page 145 ---\n6.2 Unit tests for data manipulation code 117\nJoe You could use your big catalogData map for the unit test, but you could also\nuse a smaller map in the context of Catalog.authorNames. You can get rid of\nthe booksByIsbn field of the catalogData and the bookIsbns fields of the\nauthors.\nJoe deletes a few lines from catalogData and gets a much smaller map. He shows the revi-\nsion to Theo.\nListing6.7 A minimal version of catalogData\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nTheo Wait a minute! This catalogData is not valid.\nJoe In DOP, data validity depends on the context. In the context of Library\n.searchBooksByTitleJSON and Catalog.searchBooksByTitle, the mini-\nmal version of catalogData is indeed not valid. However, in the context of\nCatalog.bookInfo and Catalog.authorNames, it is perfectly valid. The reason\nis that those two functions access only the authorsById field of catalogData.\nTIP The validity of the data depends on the context.\nTheo Why is it better to use a minimal version of the data in a test case?\nJoe For a very simple reason—the smaller the data, the easier it is to manipulate.\nTIP The smaller the data, the easier it is to manipulate.\nTheo I’ll appreciate that when I write the unit tests!\nJoe Definitely! One last thing before we start coding: how would you check that the\noutput of Catalog.authorNames is as expected?\nTheo I would check that the value returned by Catalog.authorNames is an array\nwith the expected author names.\nJoe How would you handle the array comparison?\nTheo Let me think. I want to compare by value, not by reference. I guess I’ll have to\ncheck that the array is of the expected size and then check member by mem-\nber, recursively.\nJoe That’s too much of a mental burden when you’re in a coffee shop. As I showed\nyou earlier (see listing 6.1), we can recursively compare two data collections by\nvalue with _.isEqual from Lodash.\n--- Page 146 ---\n118 CHAPTER 6 Unit tests\nTIP We can compare the output and the expected output of our functions with\n_.isEqual.\nTheo Sounds good! Let me write the test cases.\nTheo starts typing on his laptop. After a few minutes, he has some test cases for Catalog\n.authorNames, each made from a function call to Catalog.authorNames wrapped in\n_.isEqual.\nListing6.8 Unit test for Catalog.authorNames\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(\ncatalogData,\n[\"alan-moore\"]),\n[\"Alan Moore\"]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\", \"dave-gibbons\"]),\n[\"Alan Moore\", \"Dave Gibbons\"]);\nJoe Well done! Can you think of more test cases?\nTheo Yes. There are test cases where the author ID doesn’t appear in the catalog\ndata, and test cases with empty catalog data. With minimal catalog data and\n_.isEqual, it’s really easy to write lots of test cases!\nTheo really enjoys this challenge. He creates a few more test cases to present to Joe.\nListing6.9 More test cases for Catalog.authorNames\n_.isEqual(Catalog.authorNames({}, []), []);\n_.isEqual(Catalog.authorNames({}, [\"alan-moore\"]), [undefined]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\",\n\"albert-einstein\"]), [\"Alan Moore\", undefined]);\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(catalogData, [\"albert-einstein\"]),\n[undefined]);\nTheo How do I run these unit tests?\nJoe You use your preferred test framework.\n--- Page 147 ---\n6.2 Unit tests for data manipulation code 119\n NOTE We don’t deal here with test runners and test frameworks. We deal only with\nthe logic of the test cases.\n6.2.3 Unit tests for nodes in the tree\nTheo I’m curious to see what unit tests for an upper node in the tree of function calls\nlook like.\nJoe Sure. Let’s write a unit test for Catalog.bookInfo. How many test cases would\nyou have for Catalog.bookInfo?\nListing6.10 The code of Catalog.bookInfo\nCatalog.bookInfo = function (catalogData, book) {\nreturn {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\n};\nTheo takes another look at the code for Catalog.bookInfo on his laptop. Then, reaching\nfor another napkin, he draws a diagram of its input and output (see figure 6.3).\ncatalogData book\nCatalog.bookInfo()\nFigure 6.3 Visualization of the input\nbookInfo and output of Catalog.bookInfo\nTheo I would have a similar number of test cases for Catalog.authorNames: a book\nwith a single author, with two authors, with existing authors, with non-existent\nauthors, with...\nJoe Whoa! That’s not necessary. Given that we have already written unit tests for\nCatalog.authorNames, we don’t need to check all the cases again. We simply\nneed to write a minimal test case to confirm that the code works.\nTIP When we write a unit test for a function, we assume that the functions called by\nthis function are covered by unit tests and work as expected. It significantly reduces\nthe quantity of test cases in our unit tests.\nTheo That makes sense.\nJoe How would you write a minimal test case for Catalog.bookInfo?\nTheo once again takes a look at the code for Catalog.bookInfo (see listing 6.10). Now he\ncan answer Joe’s question.\n--- Page 148 ---\n120 CHAPTER 6 Unit tests\nTheo I would use the same catalog data as for Catalog.authorNames and a book\nrecord. I’d test that the function behaves as expected by comparing its return\nvalue with a book info record using _.isEqual. Here, let me show you.\nIt takes Theo a bit more time to write the unit test. The reason is that the input and the\noutput of Catalog.authorNames are both records. Dealing with a record is more complex\nthan dealing with an array of strings (as it was the case for Catalog.authorNames). Theo\nappreciates the fact that _.isEqual saves him from writing code that compares the two\nmaps property by property. When he’s through, he shows the result to Joe and takes a nap-\nkin to wipe his forehead.\nListing6.11 Unit test for Catalog.bookInfo\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nvar book = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n};\nvar expectedResult = {\n\"authorNames\": [\"Alan Moore\", \"Dave Gibbons\"],\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n};\nvar result = Catalog.bookInfo(catalogData, book);\n_.isEqual(result, expectedResult);\nJoe Perfect! Now, how would you compare the kind of unit tests for Catalog\n.bookInfo with the unit tests for Catalog.authorNames?\nTheo On one hand, there is only a single test case in the unit test for Catalog.book-\nInfo. On the other hand, the data involved in the test case is more complex\nthan the data involved in the test cases for Catalog.authorNames.\nJoe Exactly! Functions that appear in a deep node in the tree of function calls tend\nto require more test cases, but the data involved in the test cases is less complex.\nTIP Functions that appear in a lower level in the tree of function calls tend to\ninvolve less complex data than functions that appear in a higher level in the tree\n(see table 6.2).\n--- Page 149 ---\n6.3 Unit tests for queries 121\nTable 6.2 The correlation between the depth of a function in the tree of function calls and the\nquality and quantity of the test cases\nDepth in the tree Complexity of the data Number of test cases\nLower Higher Lower\nHigher Lower Higher\n6.3 Unit tests for queries\nIn the previous section, we saw how to write unit tests for utility functions like Catalog\n.bookInfo and Catalog.authorNames. Now, we are going to see how to write unit tests\nfor the nodes of a query tree of function calls that are close to the root of the tree.\nJoe Theo, how would you write a unit test for the code of the entry point of the\nsearch query?\nTo recall the particulars, Theo checks the code for Library.searchBooksByTitleJSON.\nAlthough Joe was right about today’s topic being easy enough to enjoy the ambience of a\ncoffee shop, he has been doing quite a lot of coding this morning.\nListing6.12 The code of Library.searchBooksByTitleJSON\nLibrary.searchBooksByTitleJSON = function (libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n};\nHe then takes a moment to think about how he’d write a unit test for that code. After\nanother Aha! moment, now he’s got it.\nTheo The inputs of Library.searchBooksByTitleJSON are library data and a\nquery string, and the output is a JSON string (see figure 6.4). So, I would cre-\nate a library data record with a single book and write tests with query strings\nthat match the name of the book and ones that don’t match.\nlibraryData query\nLibrary.searchBooksByTitleJSON()\nFigure 6.4 The input and output of\nresultsJSON Library.searchBooksByTitleJSON\nJoe What about the expected results of the test cases?\n--- Page 150 ---\n122 CHAPTER 6 Unit tests\nTheo In cases where the query string matches, the expected result is a JSON string\nwith the book info. In cases where the query string doesn’t match, the\nexpected result is a JSON string with an empty array.\nJoe Hmm...\nTheo What?\nJoe I don’t like your answer.\nTheo Why?\nJoe Because your test case relies on a string comparison instead of a data comparison.\nTheo What difference does it make? After all, the strings I’m comparing come from\nthe serialization of data.\nJoe It’s inherently much more complex to compare JSON strings than it is to com-\npare data. For example, two different strings might be the serialization of the\nsame piece of data.\nTheo Really? How?\nJoe Take a look at these two strings. They are the serialization of the same data.\nThey’re different strings because the fields appear in a different order, but in\nfact, they serialize the same data!\nJoe turns his laptop to Theo. As Theo looks at the code, he realizes that, once again, Joe\niscorrect.\nListing6.13 Two different strings that serialize the same data\nvar stringA = \"{\\\"title\\\":\\\"Watchmen\\\",\\\"publicationYear\\\":1987}\";\nvar stringB = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nTIP Avoid using a string comparison in unit tests for functions that deal with data.\nTheo I see.... Well, what can I do instead?\nJoe Instead of comparing the output of Library.searchBooksByTitleJSON with\na string, you could deserialize the output and compare it to the expected data.\nTheo What do you mean by deserialize a string?\nJoe Deserializing a string s, for example, means to generate a piece of data whose\nserialization is s.\nTheo Is there a Lodash function for string deserialization?\nJoe Actually, there is a native JavaScript function for string deserialization; it’s\ncalled JSON.parse.\nJoe retrieves his laptop and shows Theo an example of string deserialization. The code\nillustrates a common usage of JSON.parse.\nListing6.14 Example of string deserialization\nvar myString = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nvar myData = JSON.parse(myString);\n--- Page 151 ---\n6.3 Unit tests for queries 123\n_.get(myData, \"title\");\n// → \"Watchmen\"\nTheo Cool! Let me try writing a unit test for Library.searchBooksByTitleJSON\nusing JSON.parse.\nIt doesn’t take Theo too much time to come up with a piece of code. Using his laptop, he\ninputs the unit test.\nListing6.15 Unit test for Library.searchBooksByTitleJSON\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Watchmen\")),\n[bookInfo]);\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Batman\")),\n[]);\nJoe Well done! I think you’re ready to move on to the last piece of the puzzle and\nwrite the unit test for Catalog.searchBooksByTitle.",
        "sections_found": []
      },
      "accurate_page_range": "126-151"
    },
    {
      "text": "- 5.3 Reducing collections",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "5 Basic concurrency control",
      "raw_line": "- 5.3 Reducing collections (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 41,
      "chapter_info": {
        "page": 126,
        "title": "Basic concurrency control",
        "pattern_matched": "Chapter 5",
        "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
      },
      "chapter_sections": {
        "start_page": 126,
        "end_page": 151,
        "content": "\n--- Page 126 ---\n98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. It means that the first call to f will be f(0, 1). Then,\nwe’ll have f(f(0, 1), 2) and, finally, f(f(f(0, 1), 2), 3).\nJoe I like your manual expansion, Theo! Let’s make it visual.\nNow Theo goes to the whiteboard and draws a diagram. Figure 5.5 shows what that looks like.\nf\nf a\n2\nf a\n1\na 0 initVal Figure 5.5 Visualization\nof _.reduce\nTheo It’s much clearer now. I think that by implementing my custom version of\n_.reduce, it will make things 100% clear.\nIt takes Theo much less time than he expected to implement reduce(). In no time at all,\nhe shows Joe the code.\nListing5.2 Custom implementation of _.reduce\nfunction reduce(coll, f, initVal) {\nvar currentRes = initVal;\nfor (var i = 0; i < coll.length; i++) {\nWe could use\ncurrentRes = f(currentRes, coll[i])\nforEach instead\n}\nof a for loop.\nreturn currentRes;\n}\nAfter checking that Theo’s code works as expected (see listing 5.3), Joe is proud of Theo.\nHe seems to be catching on better than he anticipated.\nListing5.3 Testing the custom implementation of reduce()\nreduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nJoe Well done!\n--- Page 127 ---\n5.4 Structural difference 99\n5.4 Structural difference\n NOTE This section deals with the implementation of a structural diff algorithm. Feel\nfree to skip this section if you don’t want to challenge your mind right now with the\ndetails of a sophisticated use of recursion. It won’t prevent you from enjoying the rest\nof the book. You can come back to this section later.\nTheo How do you calculate the diff between various versions of the system state?\nJoe That’s the most challenging part of the reconciliation algorithm. We need to\nimplement a structural diff algorithm for hash maps.\nTheo In what sense is the diff structural?\nJoe The structural diff algorithm looks at the structure of the hash maps and\nignores the order of the fields.\nTheo Could you give me an example?\nJoe Let’s start with maps without nested fields. Basically, there are three kinds of\ndiffs: field replacement, field addition, and field deletion. In order to make\nthings not too complicated, for now, we’ll deal only with replacement and\naddition.\nJoe once again goes to the whiteboard and draws table 5.3, representing the three kinds of\ndiffs. Theo is thinking the whiteboard is really starting to fill up today.\nTable 5.3 Kinds of structural differences between maps without nested fields\nKind First map Second map Diff\nReplacement {\"a\": 1} {\"a\": 2} {\"a\": 2}\nAddition {\"a\": 1} {\"a\": 1, \"b\": 2} {\"b\": 2}\nDeletion {\"a\": 1, \"b\": 2} {\"a\": 1} Not supported\nTheo I notice that the order of the maps matters a lot. What about nested fields?\nJoe It’s the same idea, but the nesting makes it a bit more difficult to grasp.\nJoe changes several of the columns in table 5.3. When he’s through, he shows Theo the\nnested fields in table 5.4.\nTable 5.4 Kinds of structural differences between maps with nested fields\nKind First map Second map Diff\nReplacement { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 2 \"x\": 2\n} } }\n} } }\n--- Page 128 ---\n100 CHAPTER 5 Basic concurrency control\nTable 5.4 Kinds of structural differences between maps with nested fields (continued)\nKind First map Second map Diff\nAddition { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 1, \"y\": 2\n} \"y\": 2, }\n} } }\n}\nDeletion { { Not supported\n\"a\": { \"a\": {\n\"x\": 1, \"y\": 2\n\"y\": 2, }\n} }\n}\n NOTE The version of the structural diff algorithm illustrated in this chapter does\nnot deal with deletions. Dealing with deletions is definitely possible, but it requires a\nmore complicated algorithm.\nTheo As you said, it’s harder to grasp. What about arrays?\nJoe We compare the elements of the arrays in order: if they are equal, the diff is\nnull; if they differ, the diff has the value of the second array.\nJoe summarizes the various kinds of diffs in another table on the whiteboard. Theo looks\nat the result in table 5.5.\nTable 5.5 Kinds of structural differences between arrays without nested elements\nKind First array Second array Diff\nReplacement [1] [2] [2]\nAddition [1] [1, 2] [null, 2]\nDeletion [1, 2] [1] Not supported\nTheo This usage of null is a bit weird but OK. Is it complicated to implement the\nstructural diff algorithm?\nJoe Definitely! It took a good dose of mental gymnastics to come up with these 30\nlines of code.\nJoe downloads the code from one his personal repositories. Theo, with thumb and forefin-\ngers touching his chin and his forehead slightly tilted, studies the code.\nListing5.4 The implementation of a structural diff\nfunction diffObjects(data1, data2) {\n_.isArray checks whether\nvar emptyObject = _.isArray(data1) ? [] : {};\nits argument is an array.\nif(data1 == data2) {\n--- Page 129 ---\n5.4 Structural difference 101\nreturn emptyObject;\n_.union creates an\n} array of unique\nvar keys = _.union(_.keys(data1), _.keys(data2)); values from two\nreturn _.reduce(keys, arrays (like union of\nfunction (acc, k) { two sets in Maths).\nvar res = diff(\n_.get(data1, k),\n_.isObject checks\n_.get(data2, k));\nwhether its argument\nif((_.isObject(res) && _.isEmpty(res)) ||\nis a collection (either\na map or an array).\n(res == \"no-diff\")) {\nreturn acc;\n_.isEmpty }\nchecks return _.set(acc, [k], res);\nwhether its },\nargument\nemptyObject);\nis an empty\n} \"no-diff\" is how\ncollection.\nwe mark that\nfunction diff(data1, data2) { two values are\nif(_.isObject(data1) && _.isObject(data2)) { the same.\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"no-diff\";\n}\nTheo Wow! It involves a recursion inside a reduce! I’m sure Dave will love this, but\nI’m too tired to understand this code right now. Let’s focus on what it does\ninstead of how it does it.\nIn order familiarize himself with the structural diff algorithm, Theo runs the algorithm\nwith examples from the table that Joe drew on the whiteboard. While Theo occupies his\nfingers with more and more complicated examples, his mind wanders in the realm of\nperformance.\nListing5.5 An example of usage of a structural diff\nvar data1 = {\n\"a\": {\n\"x\": 1,\n\"y\": [2, 3],\n\"z\": 4\n}\n};\nvar data2 = {\n\"a\": {\n\"x\": 2,\n\"y\": [2, 4],\n\"z\": 4\n}\n}\n--- Page 130 ---\n102 CHAPTER 5 Basic concurrency control\ndiff(data1, data2);\n//{\n// \"a\": {\n// \"x\": 2,\n// \"y\": [\n// undefined,\n// 4\n// ]\n// }\n//}\nTheo What about the performance of the structural diff algorithm? It seems that the\nalgorithm goes over the leaves of both pieces of data?\nJoe In the general case, that’s true. But, in the case of system data that’s manipu-\nlated with structural sharing, the code is much more efficient.\nTheo What do you mean?\nJoe With structural sharing, most of the nested objects are shared between two ver-\nsions of the system state. Therefore, most of the time, when the code enters\ndiffObjects, it will immediately return because data1 and data2 are the same.\nTIP Calculating the diff between two versions of the state is efficient because two\nhash maps created via structural sharing from the same hash map have most of their\nnodes in common.\nTheo Another benefit of immutable data... Let me see how the diff algorithm\nbehaves with concurrent mutations. I think I’ll start with a tiny library with no\nusers and a catalog with a single book, Watchmen.\nListing5.6 The data for a tiny library\nvar library = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\n--- Page 131 ---\n5.4 Structural difference 103\nJoe I suggest that we start with nonconflicting mutations. What do you suggest?\nTheo A mutation that updates the publication year of Watchmen and a mutation that\nupdates both the title of Watchmen and the name of the author of Watchmen.\nOn his laptop, Theo creates three versions of the library. He shows Joe his code, where one\nmutation updates the publication year of Watchmen, and the other one updates the title of\nWatchmen and the author’s name.\nListing5.7 Two nonconflicting mutations\nvar previous = library;\nvar next = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"],\n1986);\nvar libraryWithUpdatedTitle = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"],\n\"The Watchmen\");\nvar current = _.set(\nlibraryWithUpdatedTitle,\n[\"catalog\", \"authorsById\", \"dave-gibbons\", \"name\"],\n\"David Chester Gibbons\");\nTheo I’m curious to see what the diff between previous and current looks like.\nJoe Run the code and you’ll see.\nTheo runs the code snippets for the structural diff between previous and next and for\nthe structural diff between previous and current. His curiosity satisfied, Theo finds it’s\nall beginning to make sense.\nListing5.8 Structural diff between maps with a single difference\ndiff(previous, next);\n//{\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"publicationYear\": 1986\n// }\n// }\n// }\n//}\nListing5.9 Structural diff between maps with two differences\ndiff(previous, current);\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\",\n--- Page 132 ---\n104 CHAPTER 5 Basic concurrency control\n// }\n// },\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\n//\nJoe Can you give me the information path of the single field in the structural diff\nbetween previous and next?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Right. And what are the information paths of the fields in the structural diff\nbetween previous and current?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"] for the book\ntitle and [\"authorsById\", \"dave-gibbons\", \"name\"] for the author’s name.\nJoe Perfect! Now, can you figure out how to detect conflicting mutations by\ninspecting the information paths of the structural diffs?\nTheo We need to check if they have an information path in common or not.\nJoe Exactly! If they have, it means the mutations are conflicting.\nTheo But I have no idea how to write code that retrieves the information paths of a\nnested map.\nJoe Once again, it’s a nontrivial piece of code that involves a recursion inside a\nreduce. Let me download another piece of code from my repository and show\nit to you.\nListing5.10 Calculating the information paths of a (nested) map\nfunction informationPaths (obj, path = []) {\nreturn _.reduce(obj,\nfunction(acc, v, k) {\nif (_.isObject(v)) {\nreturn _.concat(acc,\ninformationPaths(v,\n_.concat(path, k)));\n}\nreturn _.concat(acc, [_.concat(path, k)]);\n},\n[]);\n}\nTheo Let me see if your code works as expected with the structural diffs of the\nmutations.\nTheo tests Joe’s code with two code snippets. The first shows the information paths of the\nstructural diff between previous and next, and the second shows the information paths\nof the structural diff between previous and current.\n--- Page 133 ---\n5.4 Structural difference 105\nListing5.11 Fields that differ between previous and next\ninformationPaths(diff(previous, next));\n// → [\"catalog.booksByIsbn.978-1779501127.publicationYear\"]\nListing5.12 Fields that differ between previous and current\ninformationPaths(diff(previous, current));\n// [\n// [\n// \"catalog\",\n// \"booksByIsbn\",\n// \"978-1779501127\",\n// \"title\"\n// ],\n// [\n// \"authorsById\",\n// \"dave-gibbons\",\n// \"name\"\n// ]\n//]\nTheo Nice! I assume that Lodash has a function that checks whether two arrays have\nan element in common.\nJoe Almost. There is _.intersection, which returns an array of the unique values\nthat are in two given arrays. For our purpose, though, we need to check\nwhether the intersection is empty. Here, look at this example.\nListing5.13 Checking whether two diff maps have a common information path\nfunction havePathInCommon(diff1, diff2) {\nreturn !_.isEmpty(_.intersection(informationPaths(diff1),\ninformationPaths(diff2)));\n}\nTheo You told me earlier that in the case of nonconflicting mutations, we can\nsafely patch the changes induced by the transition from previous to next\ninto current. How do you implement that?\nJoe We do a recursive merge between current and the diff between previous and\nnext.\nTheo Does Lodash provide an immutable version of recursive merge?\nJoe Yes, here’s another example. Take a look at this code.\nListing5.14 Applying a patch\n_.merge(current, (diff(previous, next)));\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\"\n// }\n// },\n--- Page 134 ---\n106 CHAPTER 5 Basic concurrency control\n// \"catalog\": {\n// \"authorsById\": {\n// \"alan-moore\": {\n// \"bookIsbns\": [\"978-1779501127\"]\n// \"name\": \"Alan Moore\"\n// },\n// \"dave-gibbons\": {\n// \"bookIsbns\": [\"978-1779501127\"],\n// \"name\": \"Dave Gibbons\"\n// },\n// },\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n// \"isbn\": \"978-1779501127\",\n// \"publicationYear\": 1986,\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\nTheo Could it be as simple as this?\nJoe Indeed.\n5.5 Implementing the reconciliation algorithm\nJoe All the pieces are now in place to implement our reconciliation algorithm.\nTheo What kind of changes are required?\nJoe It only requires changes in the code of SystemState.commit. Here, look at\nthis example on my laptop.\nListing5.15 The SystemState class\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nvar nextSystemData = SystemConsistency.reconcile(\nthis.systemData,\nSystemConsistency class is\nprevious,\nimplemented in listing 5.16.\nnext);\nif(!SystemValidity.validate(previous, nextSystemData)) {\nthrow \"The system data to be committed is not valid!\";\n};\n--- Page 135 ---\n5.5 Implementing the reconciliation algorithm 107\nthis.systemData = nextSystemData;\n}\n}\nTheo How does SystemConsistency do the reconciliation?\nJoe The SystemConsistency class starts the reconciliation process by comparing\nprevious and current. If they are the same, then we fast-forward and return\nnext. Look at this code for SystemConsistency.\nListing5.16 The reconciliation flow in action\nclass SystemConsistency {\nstatic threeWayMerge(current, previous, next) {\nvar previousToCurrent = diff(previous, current);\nvar previousToNext = diff(previous, next);\nif(havePathInCommon(previousToCurrent, previousToNext)) { When the system\nreturn _.merge(current, previousToNext); state is the same\n} as the state used\nthrow \"Conflicting concurrent mutations.\"; by the calculation\n} phase, we fast-\nstatic reconcile(current, previous, next) { forward.\nif(current == previous) {\nreturn next;\n}\nreturn SystemConsistency.threeWayMerge(current,\nprevious,\nnext);\n}\n}\nTheo Wait a minute! Why do you compare previous and current by reference?\nYou should be comparing them by value, right? And, it would be quite expen-\nsive to compare all the leaves of the two nested hash maps!\nJoe That’s another benefit of immutable data. When the data is not mutated, it is\nsafe to compare references. If they are the same, we know for sure that the data\nis the same.\nTIP When data is immutable, it is safe to compare by reference, which is super fast.\nWhen the references are the same, it means that the data is the same.\nTheo What about the implementation of the three-way merge algorithm?\nJoe When previous differs from current, it means that concurrent mutations\nhave run. In order to determine whether there is a conflict, we calculate two\ndiffs: the diff between previous and current and the diff between previous\nand next. If the intersection between the two diffs is empty, it means there is\nno conflict. We can safely patch the changes between previous to next into\ncurrent.\nTheo takes a closer look at the code for the SystemConsistency class in listing 5.16. He\ntries to figure out if the code is thread-safe or not.\n--- Page 136 ---\n108 CHAPTER 5 Basic concurrency control\nTheo I think the code for SystemConsistency class is not thread-safe! If there’s a\ncontext switch between checking whether the system has changed in the\nSystemConsistency class and the updating of the state in SystemData class, a\nmutation might override the changes of a previous mutation.\nJoe You are totally right! The code works fine in a single-threaded environment\nlike JavaScript, where concurrency is handled via an event loop. However, in a\nmulti-threaded environment, the code needs to be refined in order to be\nthread-safe. I’ll show you some day.\n NOTE The SystemConsistency class is not thread-safe. We will make it thread-safe\nin chapter 8.\nTheo I think I understand why you called it optimistic concurrency control. It’s\nbecause we assume that conflicts don’t occur too often. Right?\nJoe Correct! It makes me wonder what your therapist would say about conflicts that\ncannot be resolved. Are there some cases where it’s not possible to reconcile\nthe couple?\nTheo I don’t think she ever mentioned such a possibility.\nJoe She must be a very optimistic person.\nSummary\n Optimistic concurrency control allows mutations to ask forgiveness instead of\npermission.\n Optimistic concurrency control is lock-free.\n Managing concurrent mutations of our system state with optimistic concurrency\ncontrol allows our system to support a high throughput of reads and writes.\n Optimistic concurrency control with immutable data is super efficient.\n Before updating the state, we need to reconcile the conflicts between possible con-\ncurrent mutations.\n We reconcile between concurrent mutations in a way that is similar to how Git han-\ndles a merge between two branches: either a fast-forward or a three-way merge.\n The changes required to let our system manage concurrency are only in the\ncommit phase.\n The calculation phase does its calculation as if it were the only mutation running.\n The commit phase is responsible for trying to reconcile concurrent mutations.\n The reconciliation algorithm is universal in the sense that it can be used in any sys-\ntem where the system data is represented as an immutable hash map.\n The implementation of the reconciliation algorithm is efficient, as it leverages\nthe fact that subsequent versions of the system state are created via structural\nsharing.\n In a user-facing system, conflicting concurrent mutations are fairly rare.\n When we cannot safely reconcile between concurrent mutations, we abort the\nmutation and ask the user to try again.\n--- Page 137 ---\nSummary 109\n Calculating the structural diff between two versions of the state is efficient because\ntwo hash maps created via structural sharing from the same hash map have most\nof their nodes in common.\n When data is immutable, it is safe to compare by reference, which is fast. When\nthe references are the same, it means that the data is the same.\n There are three kinds of structural differences between two nested hash maps:\nreplacement, addition, and deletion.\n Our structural diff algorithm supports replacements and additions but not\ndeletions.\nLodash functions introduced in this chapter\nFunction Description\nconcat(arrA, arrB) Creates an new array, concatenating arrA and arrB\nintersection(arrA, arrB) Creates an array of unique values both in arrA and arrB\nunion(arrA, arrB) Creates an array of unique values from arrA and arrB\nfind(coll, pred) Iterates over elements of coll, returning the first element for\nwhich pred returns true\nisEmpty(coll) Checks if coll is empty\nreduce(coll, f, initVal) Reduces coll to a value that is the accumulated result of running\neach element in coll through f, where each successive invoca-\ntion is supplied the return value of the previous\nisArray(coll) Checks if coll is an array\nisObject(coll) Checks if coll is a collection\n--- Page 138 ---\nUnit tests\nProgramming at a coffee shop\nThis chapter covers\n Generation of the minimal data input for a\ntest case\n Comparison of the output of a function with\nthe expected output\n Guidance about the quality and the quantity\nof the test cases\nIn a data-oriented system, our code deals mainly with data manipulation: most of\nour functions receive data and return data. As a consequence, it’s quite easy to\nwrite unit tests to check whether our code behaves as expected. A unit test is made\nof test cases that generate data input and compare the data output of the function\nwith the expected data output. In this chapter, we write unit tests for the queries\nand mutations that we wrote in the previous chapters.\n6.1 The simplicity of data-oriented test cases\nTheo and Joe are seated around a large wooden table in a corner of “La vie est belle,” a\nnice little French coffee shop, located near the Golden Gate Bridge. Theo orders a café\nau lait with a croissant, and Joe orders a tight espresso with a pain au chocolat. Instead\nof the usual general discussions about programming and life when they’re out of the\n110\n--- Page 139 ---\n6.1 The simplicity of data-oriented test cases 111\noffice, Joe leads the discussion towards a very concrete topic—unit tests. Theo asks Joe for\nan explanation.\nTheo Are unit tests such a simple topic that we can tackle it here in a coffee shop?\nJoe Unit tests in general, no. But unit tests for data-oriented code, yes!\nTheo Why does that make a difference?\nJoe The vast majority of the code base of a data-oriented system deals with data\nmanipulation.\nTheo Yeah. I noticed that almost all the functions we wrote so far receive data and\nreturn data.\nTIP Most of the code in a data-oriented system deals with data manipulation.\nJoe Writing a test case for functions that deal with data is only about generating\ndata input and expected output, and comparing the output of the function\nwith the expected output.\nThe steps of a test case\n1 Generate data input: dataIn\n2 Generate expected output: dataOut\n3 Compare the output of the function with the expected output: f(dataIn) and\ndataOut\nTheo That’s it?\nJoe Yes. As you’ll see in a moment, in DOP, there’s usually no need for mock\nfunctions.\nTheo I understand how to compare primitive values like strings or numbers, but I’m\nnot sure how I would compare data collections like maps.\nJoe You compare field by field.\nTheo Recursively?\nJoe Yes!\nTheo Oh no! I’m not able to write any recursive code in a coffee shop. I need the\ncalm of my office for that kind of stuff.\nJoe Don’t worry. In DOP, data is represented in a generic way. There is a generic\nfunction in Lodash called _.isEqual for recursive comparison of data collec-\ntions. It works with both maps and arrays.\nJoe opens his laptop. He is able to convince Theo by executing a few code snippets with\n_.isEqual to compare an equal data collection with a non-equal one.\nListing6.1 Comparing an equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n--- Page 140 ---\n112 CHAPTER 6 Unit tests\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n});\n// → true\nListing6.2 Comparing a non-equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"bad-isbn\"]\n});\n// → false\nTheo Nice!\nJoe Most of the test cases in DOP follow this pattern.\nTheo decides he wants to try this out. He fires up his laptop and types a few lines of\npseudocode.\nListing6.3 The general pattern of a data-oriented test case\nvar dataIn = {\n// input\n};\nvar dataOut = {\n// expected output\n};\n_.isEqual(f(dataIn), dataOut);\nTIP It’s straightforward to write unit tests for code that deals with data manipulation.\nTheo Indeed, this looks like something we can tackle in a coffee shop!\n6.2 Unit tests for data manipulation code\nA waiter in an elegant bow tie brings Theo his croissant and Joe his pain au chocolat. The\ntwo friends momentarily interrupt their discussion to savor their French pastries. When\nthey’re done, they ask the waiter to bring them their drinks. Meanwhile, they resume the\ndiscussion.\nJoe Do you remember the code flow of the implementation of the search query?\nTheo Let me look again at the code that implements the search query.\nTheo brings up the implementation of the search query on his laptop. Noticing that Joe is\nchewing on his nails again, he quickly checks out the code.\n--- Page 141 ---\n6.2 Unit tests for data manipulation code 113\nListing6.4 The code involved in the implementation of the search query\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\n}\n6.2.1 The tree of function calls\nThe waiter brings Theo his café au lait and Joe his tight espresso. They continue their dis-\ncussion while enjoying their coffees.\nJoe Before writing a unit test for a code flow, I find it useful to visualize the tree of\nfunction calls of the code flow.\nTheo What do you mean by a tree of function calls?\nJoe Here, I’ll draw the tree of function calls for the Library.searchBooksBy-\nTitleJSON code flow.\nJoe puts down his espresso and takes a napkin from the dispenser. He carefully places it\nflat on the table and starts to draw. When he is done, he shows the illustration to Theo (see\nfigure 6.1).\n--- Page 142 ---\n114 CHAPTER 6 Unit tests\nLibrary.searchBooksByTitleJSON\n_.get JSON.stringify Catalog.searchBooksByTitle\n_.get _.map _.filter Catalog.bookInfo\n_.get Catalog.authorNames\n_.get _.map\nFigure 6.1 The tree of function calls for the search query code flow\nTheo Nice! Can you teach me how to draw a tree of function calls like that?\nJoe Sure. The root of the tree is the name of the function for which you draw the\ntree, in our case, Library.searchBooksByTitleJSON. The children of a\nnode in the tree are the names of the functions called by the function. For exam-\nple, if you look again at the code for Library.searchBooksByTitleJSON (list-\ning 6.4), you’ll see that it calls Catalog.searchBooksByTitle, _.get, and\nJSON.stringify.\nTheo How long would I continue to recursively expand the tree?\nJoe You continue until you reach a function that doesn’t belong to the code base\nof your application. Those nodes are the leaves of our tree; for example, the\nfunctions from Lodash: _.get, _.map, and so forth.\nTheo What if the code of a function doesn’t call any other functions?\nJoe A function that doesn’t call any other function would be a leaf in the tree.\nTheo What about functions that are called inside anonymous functions like Catalog\n.bookInfo?\nJoe Catalog.bookInfo appears in the code of Catalog.searchBooksByTitle.\nTherefore, it is considered to be a child node of Catalog.searchBooksBy-\nTitle. The fact that it is nested inside an anonymous function is not relevant\nin the context of the tree of function calls.\n NOTE A tree of function calls for a function f is a tree where the root is f, and the\nchildren of a node g in the tree are the functions called by g. The leaves of the tree are\nfunctions that are not part of the code base of the application. These are functions\nthat don’t call any other functions.\nTheo It’s very cool to visualize my code as a tree, but I don’t see how it relates to\nunittests.\n--- Page 143 ---\n6.2 Unit tests for data manipulation code 115\nJoe The tree of function calls guides us about the quality and the quantity of test\ncases we should write.\nTheo How?\nJoe You’ll see in a moment.\n6.2.2 Unit tests for functions down the tree\nJoe Let’s start from the function that appears in the deepest node in our tree:\nCatalog.authorNames. Take a look at the code for Catalog.authorNames\nand tell me what are the input and the output of Catalog.authorNames.\nJoe turns his laptop so Theo can a closer look at the code. Theo takes a sip of his café au\nlait as he looks over what’s on Joe’s laptop.\nListing6.5 The code of Catalog.authorNames\nCatalog.authorNames = function (catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n};\nTheo The input of Catalog.authorNames is catalogData and authorIds. The\noutput is authorNames.\nJoe Would you do me a favor and express it visually?\nTheo Sure.\nIt’s Theo’s turn to grab a napkin. He draws a small rectangle with two inward arrows and\none outward arrow as in figure 6.2.\ncatalogData authorIds\nCatalog.authorNames()\nFigure 6.2 Visualization of the input\nauthorNames and output of Catalog.authorNames\nJoe Excellent! Now, how many combinations of input would you include in the\nunit test for Catalog.authorNames?\nTheo Let me see.\nTheo reaches for another napkin. This time he creates a table to gather his thoughts\n(table 6.1).\n--- Page 144 ---\n116 CHAPTER 6 Unit tests\nTable 6.1 The table of test cases for Catalog.authorNames\ncatalogData authorIds authorNames\nCatalog with two authors Empty array Empty array\nCatalog with two authors Array with one author ID Array with one author name\nCatalog with two authors Array with two author IDs Array with two author names\nTheo To begin with, I would have a catalogData with two author IDs and call\nCatalog.authorNames with three arguments: an empty array, an array with a\nsingle author ID, and an array with two author IDs.\nJoe How would you generate the catalogData?\nTheo Exactly as we generated it before.\nTurning to his laptop, Theo writes the code for catalogData. He shows it to Joe.\nListing6.6 A complete catalogData map\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\n--- Page 145 ---\n6.2 Unit tests for data manipulation code 117\nJoe You could use your big catalogData map for the unit test, but you could also\nuse a smaller map in the context of Catalog.authorNames. You can get rid of\nthe booksByIsbn field of the catalogData and the bookIsbns fields of the\nauthors.\nJoe deletes a few lines from catalogData and gets a much smaller map. He shows the revi-\nsion to Theo.\nListing6.7 A minimal version of catalogData\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nTheo Wait a minute! This catalogData is not valid.\nJoe In DOP, data validity depends on the context. In the context of Library\n.searchBooksByTitleJSON and Catalog.searchBooksByTitle, the mini-\nmal version of catalogData is indeed not valid. However, in the context of\nCatalog.bookInfo and Catalog.authorNames, it is perfectly valid. The reason\nis that those two functions access only the authorsById field of catalogData.\nTIP The validity of the data depends on the context.\nTheo Why is it better to use a minimal version of the data in a test case?\nJoe For a very simple reason—the smaller the data, the easier it is to manipulate.\nTIP The smaller the data, the easier it is to manipulate.\nTheo I’ll appreciate that when I write the unit tests!\nJoe Definitely! One last thing before we start coding: how would you check that the\noutput of Catalog.authorNames is as expected?\nTheo I would check that the value returned by Catalog.authorNames is an array\nwith the expected author names.\nJoe How would you handle the array comparison?\nTheo Let me think. I want to compare by value, not by reference. I guess I’ll have to\ncheck that the array is of the expected size and then check member by mem-\nber, recursively.\nJoe That’s too much of a mental burden when you’re in a coffee shop. As I showed\nyou earlier (see listing 6.1), we can recursively compare two data collections by\nvalue with _.isEqual from Lodash.\n--- Page 146 ---\n118 CHAPTER 6 Unit tests\nTIP We can compare the output and the expected output of our functions with\n_.isEqual.\nTheo Sounds good! Let me write the test cases.\nTheo starts typing on his laptop. After a few minutes, he has some test cases for Catalog\n.authorNames, each made from a function call to Catalog.authorNames wrapped in\n_.isEqual.\nListing6.8 Unit test for Catalog.authorNames\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(\ncatalogData,\n[\"alan-moore\"]),\n[\"Alan Moore\"]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\", \"dave-gibbons\"]),\n[\"Alan Moore\", \"Dave Gibbons\"]);\nJoe Well done! Can you think of more test cases?\nTheo Yes. There are test cases where the author ID doesn’t appear in the catalog\ndata, and test cases with empty catalog data. With minimal catalog data and\n_.isEqual, it’s really easy to write lots of test cases!\nTheo really enjoys this challenge. He creates a few more test cases to present to Joe.\nListing6.9 More test cases for Catalog.authorNames\n_.isEqual(Catalog.authorNames({}, []), []);\n_.isEqual(Catalog.authorNames({}, [\"alan-moore\"]), [undefined]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\",\n\"albert-einstein\"]), [\"Alan Moore\", undefined]);\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(catalogData, [\"albert-einstein\"]),\n[undefined]);\nTheo How do I run these unit tests?\nJoe You use your preferred test framework.\n--- Page 147 ---\n6.2 Unit tests for data manipulation code 119\n NOTE We don’t deal here with test runners and test frameworks. We deal only with\nthe logic of the test cases.\n6.2.3 Unit tests for nodes in the tree\nTheo I’m curious to see what unit tests for an upper node in the tree of function calls\nlook like.\nJoe Sure. Let’s write a unit test for Catalog.bookInfo. How many test cases would\nyou have for Catalog.bookInfo?\nListing6.10 The code of Catalog.bookInfo\nCatalog.bookInfo = function (catalogData, book) {\nreturn {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\n};\nTheo takes another look at the code for Catalog.bookInfo on his laptop. Then, reaching\nfor another napkin, he draws a diagram of its input and output (see figure 6.3).\ncatalogData book\nCatalog.bookInfo()\nFigure 6.3 Visualization of the input\nbookInfo and output of Catalog.bookInfo\nTheo I would have a similar number of test cases for Catalog.authorNames: a book\nwith a single author, with two authors, with existing authors, with non-existent\nauthors, with...\nJoe Whoa! That’s not necessary. Given that we have already written unit tests for\nCatalog.authorNames, we don’t need to check all the cases again. We simply\nneed to write a minimal test case to confirm that the code works.\nTIP When we write a unit test for a function, we assume that the functions called by\nthis function are covered by unit tests and work as expected. It significantly reduces\nthe quantity of test cases in our unit tests.\nTheo That makes sense.\nJoe How would you write a minimal test case for Catalog.bookInfo?\nTheo once again takes a look at the code for Catalog.bookInfo (see listing 6.10). Now he\ncan answer Joe’s question.\n--- Page 148 ---\n120 CHAPTER 6 Unit tests\nTheo I would use the same catalog data as for Catalog.authorNames and a book\nrecord. I’d test that the function behaves as expected by comparing its return\nvalue with a book info record using _.isEqual. Here, let me show you.\nIt takes Theo a bit more time to write the unit test. The reason is that the input and the\noutput of Catalog.authorNames are both records. Dealing with a record is more complex\nthan dealing with an array of strings (as it was the case for Catalog.authorNames). Theo\nappreciates the fact that _.isEqual saves him from writing code that compares the two\nmaps property by property. When he’s through, he shows the result to Joe and takes a nap-\nkin to wipe his forehead.\nListing6.11 Unit test for Catalog.bookInfo\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nvar book = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n};\nvar expectedResult = {\n\"authorNames\": [\"Alan Moore\", \"Dave Gibbons\"],\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n};\nvar result = Catalog.bookInfo(catalogData, book);\n_.isEqual(result, expectedResult);\nJoe Perfect! Now, how would you compare the kind of unit tests for Catalog\n.bookInfo with the unit tests for Catalog.authorNames?\nTheo On one hand, there is only a single test case in the unit test for Catalog.book-\nInfo. On the other hand, the data involved in the test case is more complex\nthan the data involved in the test cases for Catalog.authorNames.\nJoe Exactly! Functions that appear in a deep node in the tree of function calls tend\nto require more test cases, but the data involved in the test cases is less complex.\nTIP Functions that appear in a lower level in the tree of function calls tend to\ninvolve less complex data than functions that appear in a higher level in the tree\n(see table 6.2).\n--- Page 149 ---\n6.3 Unit tests for queries 121\nTable 6.2 The correlation between the depth of a function in the tree of function calls and the\nquality and quantity of the test cases\nDepth in the tree Complexity of the data Number of test cases\nLower Higher Lower\nHigher Lower Higher\n6.3 Unit tests for queries\nIn the previous section, we saw how to write unit tests for utility functions like Catalog\n.bookInfo and Catalog.authorNames. Now, we are going to see how to write unit tests\nfor the nodes of a query tree of function calls that are close to the root of the tree.\nJoe Theo, how would you write a unit test for the code of the entry point of the\nsearch query?\nTo recall the particulars, Theo checks the code for Library.searchBooksByTitleJSON.\nAlthough Joe was right about today’s topic being easy enough to enjoy the ambience of a\ncoffee shop, he has been doing quite a lot of coding this morning.\nListing6.12 The code of Library.searchBooksByTitleJSON\nLibrary.searchBooksByTitleJSON = function (libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n};\nHe then takes a moment to think about how he’d write a unit test for that code. After\nanother Aha! moment, now he’s got it.\nTheo The inputs of Library.searchBooksByTitleJSON are library data and a\nquery string, and the output is a JSON string (see figure 6.4). So, I would cre-\nate a library data record with a single book and write tests with query strings\nthat match the name of the book and ones that don’t match.\nlibraryData query\nLibrary.searchBooksByTitleJSON()\nFigure 6.4 The input and output of\nresultsJSON Library.searchBooksByTitleJSON\nJoe What about the expected results of the test cases?\n--- Page 150 ---\n122 CHAPTER 6 Unit tests\nTheo In cases where the query string matches, the expected result is a JSON string\nwith the book info. In cases where the query string doesn’t match, the\nexpected result is a JSON string with an empty array.\nJoe Hmm...\nTheo What?\nJoe I don’t like your answer.\nTheo Why?\nJoe Because your test case relies on a string comparison instead of a data comparison.\nTheo What difference does it make? After all, the strings I’m comparing come from\nthe serialization of data.\nJoe It’s inherently much more complex to compare JSON strings than it is to com-\npare data. For example, two different strings might be the serialization of the\nsame piece of data.\nTheo Really? How?\nJoe Take a look at these two strings. They are the serialization of the same data.\nThey’re different strings because the fields appear in a different order, but in\nfact, they serialize the same data!\nJoe turns his laptop to Theo. As Theo looks at the code, he realizes that, once again, Joe\niscorrect.\nListing6.13 Two different strings that serialize the same data\nvar stringA = \"{\\\"title\\\":\\\"Watchmen\\\",\\\"publicationYear\\\":1987}\";\nvar stringB = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nTIP Avoid using a string comparison in unit tests for functions that deal with data.\nTheo I see.... Well, what can I do instead?\nJoe Instead of comparing the output of Library.searchBooksByTitleJSON with\na string, you could deserialize the output and compare it to the expected data.\nTheo What do you mean by deserialize a string?\nJoe Deserializing a string s, for example, means to generate a piece of data whose\nserialization is s.\nTheo Is there a Lodash function for string deserialization?\nJoe Actually, there is a native JavaScript function for string deserialization; it’s\ncalled JSON.parse.\nJoe retrieves his laptop and shows Theo an example of string deserialization. The code\nillustrates a common usage of JSON.parse.\nListing6.14 Example of string deserialization\nvar myString = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nvar myData = JSON.parse(myString);\n--- Page 151 ---\n6.3 Unit tests for queries 123\n_.get(myData, \"title\");\n// → \"Watchmen\"\nTheo Cool! Let me try writing a unit test for Library.searchBooksByTitleJSON\nusing JSON.parse.\nIt doesn’t take Theo too much time to come up with a piece of code. Using his laptop, he\ninputs the unit test.\nListing6.15 Unit test for Library.searchBooksByTitleJSON\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Watchmen\")),\n[bookInfo]);\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Batman\")),\n[]);\nJoe Well done! I think you’re ready to move on to the last piece of the puzzle and\nwrite the unit test for Catalog.searchBooksByTitle.",
        "sections_found": []
      },
      "accurate_page_range": "126-151"
    },
    {
      "text": "- 5.4 Structural difference",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "5 Basic concurrency control",
      "raw_line": "- 5.4 Structural difference (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 42,
      "chapter_info": {
        "page": 126,
        "title": "Basic concurrency control",
        "pattern_matched": "Chapter 5",
        "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
      },
      "chapter_sections": {
        "start_page": 126,
        "end_page": 151,
        "content": "\n--- Page 126 ---\n98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. It means that the first call to f will be f(0, 1). Then,\nwe’ll have f(f(0, 1), 2) and, finally, f(f(f(0, 1), 2), 3).\nJoe I like your manual expansion, Theo! Let’s make it visual.\nNow Theo goes to the whiteboard and draws a diagram. Figure 5.5 shows what that looks like.\nf\nf a\n2\nf a\n1\na 0 initVal Figure 5.5 Visualization\nof _.reduce\nTheo It’s much clearer now. I think that by implementing my custom version of\n_.reduce, it will make things 100% clear.\nIt takes Theo much less time than he expected to implement reduce(). In no time at all,\nhe shows Joe the code.\nListing5.2 Custom implementation of _.reduce\nfunction reduce(coll, f, initVal) {\nvar currentRes = initVal;\nfor (var i = 0; i < coll.length; i++) {\nWe could use\ncurrentRes = f(currentRes, coll[i])\nforEach instead\n}\nof a for loop.\nreturn currentRes;\n}\nAfter checking that Theo’s code works as expected (see listing 5.3), Joe is proud of Theo.\nHe seems to be catching on better than he anticipated.\nListing5.3 Testing the custom implementation of reduce()\nreduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nJoe Well done!\n--- Page 127 ---\n5.4 Structural difference 99\n5.4 Structural difference\n NOTE This section deals with the implementation of a structural diff algorithm. Feel\nfree to skip this section if you don’t want to challenge your mind right now with the\ndetails of a sophisticated use of recursion. It won’t prevent you from enjoying the rest\nof the book. You can come back to this section later.\nTheo How do you calculate the diff between various versions of the system state?\nJoe That’s the most challenging part of the reconciliation algorithm. We need to\nimplement a structural diff algorithm for hash maps.\nTheo In what sense is the diff structural?\nJoe The structural diff algorithm looks at the structure of the hash maps and\nignores the order of the fields.\nTheo Could you give me an example?\nJoe Let’s start with maps without nested fields. Basically, there are three kinds of\ndiffs: field replacement, field addition, and field deletion. In order to make\nthings not too complicated, for now, we’ll deal only with replacement and\naddition.\nJoe once again goes to the whiteboard and draws table 5.3, representing the three kinds of\ndiffs. Theo is thinking the whiteboard is really starting to fill up today.\nTable 5.3 Kinds of structural differences between maps without nested fields\nKind First map Second map Diff\nReplacement {\"a\": 1} {\"a\": 2} {\"a\": 2}\nAddition {\"a\": 1} {\"a\": 1, \"b\": 2} {\"b\": 2}\nDeletion {\"a\": 1, \"b\": 2} {\"a\": 1} Not supported\nTheo I notice that the order of the maps matters a lot. What about nested fields?\nJoe It’s the same idea, but the nesting makes it a bit more difficult to grasp.\nJoe changes several of the columns in table 5.3. When he’s through, he shows Theo the\nnested fields in table 5.4.\nTable 5.4 Kinds of structural differences between maps with nested fields\nKind First map Second map Diff\nReplacement { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 2 \"x\": 2\n} } }\n} } }\n--- Page 128 ---\n100 CHAPTER 5 Basic concurrency control\nTable 5.4 Kinds of structural differences between maps with nested fields (continued)\nKind First map Second map Diff\nAddition { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 1, \"y\": 2\n} \"y\": 2, }\n} } }\n}\nDeletion { { Not supported\n\"a\": { \"a\": {\n\"x\": 1, \"y\": 2\n\"y\": 2, }\n} }\n}\n NOTE The version of the structural diff algorithm illustrated in this chapter does\nnot deal with deletions. Dealing with deletions is definitely possible, but it requires a\nmore complicated algorithm.\nTheo As you said, it’s harder to grasp. What about arrays?\nJoe We compare the elements of the arrays in order: if they are equal, the diff is\nnull; if they differ, the diff has the value of the second array.\nJoe summarizes the various kinds of diffs in another table on the whiteboard. Theo looks\nat the result in table 5.5.\nTable 5.5 Kinds of structural differences between arrays without nested elements\nKind First array Second array Diff\nReplacement [1] [2] [2]\nAddition [1] [1, 2] [null, 2]\nDeletion [1, 2] [1] Not supported\nTheo This usage of null is a bit weird but OK. Is it complicated to implement the\nstructural diff algorithm?\nJoe Definitely! It took a good dose of mental gymnastics to come up with these 30\nlines of code.\nJoe downloads the code from one his personal repositories. Theo, with thumb and forefin-\ngers touching his chin and his forehead slightly tilted, studies the code.\nListing5.4 The implementation of a structural diff\nfunction diffObjects(data1, data2) {\n_.isArray checks whether\nvar emptyObject = _.isArray(data1) ? [] : {};\nits argument is an array.\nif(data1 == data2) {\n--- Page 129 ---\n5.4 Structural difference 101\nreturn emptyObject;\n_.union creates an\n} array of unique\nvar keys = _.union(_.keys(data1), _.keys(data2)); values from two\nreturn _.reduce(keys, arrays (like union of\nfunction (acc, k) { two sets in Maths).\nvar res = diff(\n_.get(data1, k),\n_.isObject checks\n_.get(data2, k));\nwhether its argument\nif((_.isObject(res) && _.isEmpty(res)) ||\nis a collection (either\na map or an array).\n(res == \"no-diff\")) {\nreturn acc;\n_.isEmpty }\nchecks return _.set(acc, [k], res);\nwhether its },\nargument\nemptyObject);\nis an empty\n} \"no-diff\" is how\ncollection.\nwe mark that\nfunction diff(data1, data2) { two values are\nif(_.isObject(data1) && _.isObject(data2)) { the same.\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"no-diff\";\n}\nTheo Wow! It involves a recursion inside a reduce! I’m sure Dave will love this, but\nI’m too tired to understand this code right now. Let’s focus on what it does\ninstead of how it does it.\nIn order familiarize himself with the structural diff algorithm, Theo runs the algorithm\nwith examples from the table that Joe drew on the whiteboard. While Theo occupies his\nfingers with more and more complicated examples, his mind wanders in the realm of\nperformance.\nListing5.5 An example of usage of a structural diff\nvar data1 = {\n\"a\": {\n\"x\": 1,\n\"y\": [2, 3],\n\"z\": 4\n}\n};\nvar data2 = {\n\"a\": {\n\"x\": 2,\n\"y\": [2, 4],\n\"z\": 4\n}\n}\n--- Page 130 ---\n102 CHAPTER 5 Basic concurrency control\ndiff(data1, data2);\n//{\n// \"a\": {\n// \"x\": 2,\n// \"y\": [\n// undefined,\n// 4\n// ]\n// }\n//}\nTheo What about the performance of the structural diff algorithm? It seems that the\nalgorithm goes over the leaves of both pieces of data?\nJoe In the general case, that’s true. But, in the case of system data that’s manipu-\nlated with structural sharing, the code is much more efficient.\nTheo What do you mean?\nJoe With structural sharing, most of the nested objects are shared between two ver-\nsions of the system state. Therefore, most of the time, when the code enters\ndiffObjects, it will immediately return because data1 and data2 are the same.\nTIP Calculating the diff between two versions of the state is efficient because two\nhash maps created via structural sharing from the same hash map have most of their\nnodes in common.\nTheo Another benefit of immutable data... Let me see how the diff algorithm\nbehaves with concurrent mutations. I think I’ll start with a tiny library with no\nusers and a catalog with a single book, Watchmen.\nListing5.6 The data for a tiny library\nvar library = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\n--- Page 131 ---\n5.4 Structural difference 103\nJoe I suggest that we start with nonconflicting mutations. What do you suggest?\nTheo A mutation that updates the publication year of Watchmen and a mutation that\nupdates both the title of Watchmen and the name of the author of Watchmen.\nOn his laptop, Theo creates three versions of the library. He shows Joe his code, where one\nmutation updates the publication year of Watchmen, and the other one updates the title of\nWatchmen and the author’s name.\nListing5.7 Two nonconflicting mutations\nvar previous = library;\nvar next = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"],\n1986);\nvar libraryWithUpdatedTitle = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"],\n\"The Watchmen\");\nvar current = _.set(\nlibraryWithUpdatedTitle,\n[\"catalog\", \"authorsById\", \"dave-gibbons\", \"name\"],\n\"David Chester Gibbons\");\nTheo I’m curious to see what the diff between previous and current looks like.\nJoe Run the code and you’ll see.\nTheo runs the code snippets for the structural diff between previous and next and for\nthe structural diff between previous and current. His curiosity satisfied, Theo finds it’s\nall beginning to make sense.\nListing5.8 Structural diff between maps with a single difference\ndiff(previous, next);\n//{\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"publicationYear\": 1986\n// }\n// }\n// }\n//}\nListing5.9 Structural diff between maps with two differences\ndiff(previous, current);\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\",\n--- Page 132 ---\n104 CHAPTER 5 Basic concurrency control\n// }\n// },\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\n//\nJoe Can you give me the information path of the single field in the structural diff\nbetween previous and next?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Right. And what are the information paths of the fields in the structural diff\nbetween previous and current?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"] for the book\ntitle and [\"authorsById\", \"dave-gibbons\", \"name\"] for the author’s name.\nJoe Perfect! Now, can you figure out how to detect conflicting mutations by\ninspecting the information paths of the structural diffs?\nTheo We need to check if they have an information path in common or not.\nJoe Exactly! If they have, it means the mutations are conflicting.\nTheo But I have no idea how to write code that retrieves the information paths of a\nnested map.\nJoe Once again, it’s a nontrivial piece of code that involves a recursion inside a\nreduce. Let me download another piece of code from my repository and show\nit to you.\nListing5.10 Calculating the information paths of a (nested) map\nfunction informationPaths (obj, path = []) {\nreturn _.reduce(obj,\nfunction(acc, v, k) {\nif (_.isObject(v)) {\nreturn _.concat(acc,\ninformationPaths(v,\n_.concat(path, k)));\n}\nreturn _.concat(acc, [_.concat(path, k)]);\n},\n[]);\n}\nTheo Let me see if your code works as expected with the structural diffs of the\nmutations.\nTheo tests Joe’s code with two code snippets. The first shows the information paths of the\nstructural diff between previous and next, and the second shows the information paths\nof the structural diff between previous and current.\n--- Page 133 ---\n5.4 Structural difference 105\nListing5.11 Fields that differ between previous and next\ninformationPaths(diff(previous, next));\n// → [\"catalog.booksByIsbn.978-1779501127.publicationYear\"]\nListing5.12 Fields that differ between previous and current\ninformationPaths(diff(previous, current));\n// [\n// [\n// \"catalog\",\n// \"booksByIsbn\",\n// \"978-1779501127\",\n// \"title\"\n// ],\n// [\n// \"authorsById\",\n// \"dave-gibbons\",\n// \"name\"\n// ]\n//]\nTheo Nice! I assume that Lodash has a function that checks whether two arrays have\nan element in common.\nJoe Almost. There is _.intersection, which returns an array of the unique values\nthat are in two given arrays. For our purpose, though, we need to check\nwhether the intersection is empty. Here, look at this example.\nListing5.13 Checking whether two diff maps have a common information path\nfunction havePathInCommon(diff1, diff2) {\nreturn !_.isEmpty(_.intersection(informationPaths(diff1),\ninformationPaths(diff2)));\n}\nTheo You told me earlier that in the case of nonconflicting mutations, we can\nsafely patch the changes induced by the transition from previous to next\ninto current. How do you implement that?\nJoe We do a recursive merge between current and the diff between previous and\nnext.\nTheo Does Lodash provide an immutable version of recursive merge?\nJoe Yes, here’s another example. Take a look at this code.\nListing5.14 Applying a patch\n_.merge(current, (diff(previous, next)));\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\"\n// }\n// },\n--- Page 134 ---\n106 CHAPTER 5 Basic concurrency control\n// \"catalog\": {\n// \"authorsById\": {\n// \"alan-moore\": {\n// \"bookIsbns\": [\"978-1779501127\"]\n// \"name\": \"Alan Moore\"\n// },\n// \"dave-gibbons\": {\n// \"bookIsbns\": [\"978-1779501127\"],\n// \"name\": \"Dave Gibbons\"\n// },\n// },\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n// \"isbn\": \"978-1779501127\",\n// \"publicationYear\": 1986,\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\nTheo Could it be as simple as this?\nJoe Indeed.\n5.5 Implementing the reconciliation algorithm\nJoe All the pieces are now in place to implement our reconciliation algorithm.\nTheo What kind of changes are required?\nJoe It only requires changes in the code of SystemState.commit. Here, look at\nthis example on my laptop.\nListing5.15 The SystemState class\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nvar nextSystemData = SystemConsistency.reconcile(\nthis.systemData,\nSystemConsistency class is\nprevious,\nimplemented in listing 5.16.\nnext);\nif(!SystemValidity.validate(previous, nextSystemData)) {\nthrow \"The system data to be committed is not valid!\";\n};\n--- Page 135 ---\n5.5 Implementing the reconciliation algorithm 107\nthis.systemData = nextSystemData;\n}\n}\nTheo How does SystemConsistency do the reconciliation?\nJoe The SystemConsistency class starts the reconciliation process by comparing\nprevious and current. If they are the same, then we fast-forward and return\nnext. Look at this code for SystemConsistency.\nListing5.16 The reconciliation flow in action\nclass SystemConsistency {\nstatic threeWayMerge(current, previous, next) {\nvar previousToCurrent = diff(previous, current);\nvar previousToNext = diff(previous, next);\nif(havePathInCommon(previousToCurrent, previousToNext)) { When the system\nreturn _.merge(current, previousToNext); state is the same\n} as the state used\nthrow \"Conflicting concurrent mutations.\"; by the calculation\n} phase, we fast-\nstatic reconcile(current, previous, next) { forward.\nif(current == previous) {\nreturn next;\n}\nreturn SystemConsistency.threeWayMerge(current,\nprevious,\nnext);\n}\n}\nTheo Wait a minute! Why do you compare previous and current by reference?\nYou should be comparing them by value, right? And, it would be quite expen-\nsive to compare all the leaves of the two nested hash maps!\nJoe That’s another benefit of immutable data. When the data is not mutated, it is\nsafe to compare references. If they are the same, we know for sure that the data\nis the same.\nTIP When data is immutable, it is safe to compare by reference, which is super fast.\nWhen the references are the same, it means that the data is the same.\nTheo What about the implementation of the three-way merge algorithm?\nJoe When previous differs from current, it means that concurrent mutations\nhave run. In order to determine whether there is a conflict, we calculate two\ndiffs: the diff between previous and current and the diff between previous\nand next. If the intersection between the two diffs is empty, it means there is\nno conflict. We can safely patch the changes between previous to next into\ncurrent.\nTheo takes a closer look at the code for the SystemConsistency class in listing 5.16. He\ntries to figure out if the code is thread-safe or not.\n--- Page 136 ---\n108 CHAPTER 5 Basic concurrency control\nTheo I think the code for SystemConsistency class is not thread-safe! If there’s a\ncontext switch between checking whether the system has changed in the\nSystemConsistency class and the updating of the state in SystemData class, a\nmutation might override the changes of a previous mutation.\nJoe You are totally right! The code works fine in a single-threaded environment\nlike JavaScript, where concurrency is handled via an event loop. However, in a\nmulti-threaded environment, the code needs to be refined in order to be\nthread-safe. I’ll show you some day.\n NOTE The SystemConsistency class is not thread-safe. We will make it thread-safe\nin chapter 8.\nTheo I think I understand why you called it optimistic concurrency control. It’s\nbecause we assume that conflicts don’t occur too often. Right?\nJoe Correct! It makes me wonder what your therapist would say about conflicts that\ncannot be resolved. Are there some cases where it’s not possible to reconcile\nthe couple?\nTheo I don’t think she ever mentioned such a possibility.\nJoe She must be a very optimistic person.\nSummary\n Optimistic concurrency control allows mutations to ask forgiveness instead of\npermission.\n Optimistic concurrency control is lock-free.\n Managing concurrent mutations of our system state with optimistic concurrency\ncontrol allows our system to support a high throughput of reads and writes.\n Optimistic concurrency control with immutable data is super efficient.\n Before updating the state, we need to reconcile the conflicts between possible con-\ncurrent mutations.\n We reconcile between concurrent mutations in a way that is similar to how Git han-\ndles a merge between two branches: either a fast-forward or a three-way merge.\n The changes required to let our system manage concurrency are only in the\ncommit phase.\n The calculation phase does its calculation as if it were the only mutation running.\n The commit phase is responsible for trying to reconcile concurrent mutations.\n The reconciliation algorithm is universal in the sense that it can be used in any sys-\ntem where the system data is represented as an immutable hash map.\n The implementation of the reconciliation algorithm is efficient, as it leverages\nthe fact that subsequent versions of the system state are created via structural\nsharing.\n In a user-facing system, conflicting concurrent mutations are fairly rare.\n When we cannot safely reconcile between concurrent mutations, we abort the\nmutation and ask the user to try again.\n--- Page 137 ---\nSummary 109\n Calculating the structural diff between two versions of the state is efficient because\ntwo hash maps created via structural sharing from the same hash map have most\nof their nodes in common.\n When data is immutable, it is safe to compare by reference, which is fast. When\nthe references are the same, it means that the data is the same.\n There are three kinds of structural differences between two nested hash maps:\nreplacement, addition, and deletion.\n Our structural diff algorithm supports replacements and additions but not\ndeletions.\nLodash functions introduced in this chapter\nFunction Description\nconcat(arrA, arrB) Creates an new array, concatenating arrA and arrB\nintersection(arrA, arrB) Creates an array of unique values both in arrA and arrB\nunion(arrA, arrB) Creates an array of unique values from arrA and arrB\nfind(coll, pred) Iterates over elements of coll, returning the first element for\nwhich pred returns true\nisEmpty(coll) Checks if coll is empty\nreduce(coll, f, initVal) Reduces coll to a value that is the accumulated result of running\neach element in coll through f, where each successive invoca-\ntion is supplied the return value of the previous\nisArray(coll) Checks if coll is an array\nisObject(coll) Checks if coll is a collection\n--- Page 138 ---\nUnit tests\nProgramming at a coffee shop\nThis chapter covers\n Generation of the minimal data input for a\ntest case\n Comparison of the output of a function with\nthe expected output\n Guidance about the quality and the quantity\nof the test cases\nIn a data-oriented system, our code deals mainly with data manipulation: most of\nour functions receive data and return data. As a consequence, it’s quite easy to\nwrite unit tests to check whether our code behaves as expected. A unit test is made\nof test cases that generate data input and compare the data output of the function\nwith the expected data output. In this chapter, we write unit tests for the queries\nand mutations that we wrote in the previous chapters.\n6.1 The simplicity of data-oriented test cases\nTheo and Joe are seated around a large wooden table in a corner of “La vie est belle,” a\nnice little French coffee shop, located near the Golden Gate Bridge. Theo orders a café\nau lait with a croissant, and Joe orders a tight espresso with a pain au chocolat. Instead\nof the usual general discussions about programming and life when they’re out of the\n110\n--- Page 139 ---\n6.1 The simplicity of data-oriented test cases 111\noffice, Joe leads the discussion towards a very concrete topic—unit tests. Theo asks Joe for\nan explanation.\nTheo Are unit tests such a simple topic that we can tackle it here in a coffee shop?\nJoe Unit tests in general, no. But unit tests for data-oriented code, yes!\nTheo Why does that make a difference?\nJoe The vast majority of the code base of a data-oriented system deals with data\nmanipulation.\nTheo Yeah. I noticed that almost all the functions we wrote so far receive data and\nreturn data.\nTIP Most of the code in a data-oriented system deals with data manipulation.\nJoe Writing a test case for functions that deal with data is only about generating\ndata input and expected output, and comparing the output of the function\nwith the expected output.\nThe steps of a test case\n1 Generate data input: dataIn\n2 Generate expected output: dataOut\n3 Compare the output of the function with the expected output: f(dataIn) and\ndataOut\nTheo That’s it?\nJoe Yes. As you’ll see in a moment, in DOP, there’s usually no need for mock\nfunctions.\nTheo I understand how to compare primitive values like strings or numbers, but I’m\nnot sure how I would compare data collections like maps.\nJoe You compare field by field.\nTheo Recursively?\nJoe Yes!\nTheo Oh no! I’m not able to write any recursive code in a coffee shop. I need the\ncalm of my office for that kind of stuff.\nJoe Don’t worry. In DOP, data is represented in a generic way. There is a generic\nfunction in Lodash called _.isEqual for recursive comparison of data collec-\ntions. It works with both maps and arrays.\nJoe opens his laptop. He is able to convince Theo by executing a few code snippets with\n_.isEqual to compare an equal data collection with a non-equal one.\nListing6.1 Comparing an equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n--- Page 140 ---\n112 CHAPTER 6 Unit tests\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n});\n// → true\nListing6.2 Comparing a non-equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"bad-isbn\"]\n});\n// → false\nTheo Nice!\nJoe Most of the test cases in DOP follow this pattern.\nTheo decides he wants to try this out. He fires up his laptop and types a few lines of\npseudocode.\nListing6.3 The general pattern of a data-oriented test case\nvar dataIn = {\n// input\n};\nvar dataOut = {\n// expected output\n};\n_.isEqual(f(dataIn), dataOut);\nTIP It’s straightforward to write unit tests for code that deals with data manipulation.\nTheo Indeed, this looks like something we can tackle in a coffee shop!\n6.2 Unit tests for data manipulation code\nA waiter in an elegant bow tie brings Theo his croissant and Joe his pain au chocolat. The\ntwo friends momentarily interrupt their discussion to savor their French pastries. When\nthey’re done, they ask the waiter to bring them their drinks. Meanwhile, they resume the\ndiscussion.\nJoe Do you remember the code flow of the implementation of the search query?\nTheo Let me look again at the code that implements the search query.\nTheo brings up the implementation of the search query on his laptop. Noticing that Joe is\nchewing on his nails again, he quickly checks out the code.\n--- Page 141 ---\n6.2 Unit tests for data manipulation code 113\nListing6.4 The code involved in the implementation of the search query\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\n}\n6.2.1 The tree of function calls\nThe waiter brings Theo his café au lait and Joe his tight espresso. They continue their dis-\ncussion while enjoying their coffees.\nJoe Before writing a unit test for a code flow, I find it useful to visualize the tree of\nfunction calls of the code flow.\nTheo What do you mean by a tree of function calls?\nJoe Here, I’ll draw the tree of function calls for the Library.searchBooksBy-\nTitleJSON code flow.\nJoe puts down his espresso and takes a napkin from the dispenser. He carefully places it\nflat on the table and starts to draw. When he is done, he shows the illustration to Theo (see\nfigure 6.1).\n--- Page 142 ---\n114 CHAPTER 6 Unit tests\nLibrary.searchBooksByTitleJSON\n_.get JSON.stringify Catalog.searchBooksByTitle\n_.get _.map _.filter Catalog.bookInfo\n_.get Catalog.authorNames\n_.get _.map\nFigure 6.1 The tree of function calls for the search query code flow\nTheo Nice! Can you teach me how to draw a tree of function calls like that?\nJoe Sure. The root of the tree is the name of the function for which you draw the\ntree, in our case, Library.searchBooksByTitleJSON. The children of a\nnode in the tree are the names of the functions called by the function. For exam-\nple, if you look again at the code for Library.searchBooksByTitleJSON (list-\ning 6.4), you’ll see that it calls Catalog.searchBooksByTitle, _.get, and\nJSON.stringify.\nTheo How long would I continue to recursively expand the tree?\nJoe You continue until you reach a function that doesn’t belong to the code base\nof your application. Those nodes are the leaves of our tree; for example, the\nfunctions from Lodash: _.get, _.map, and so forth.\nTheo What if the code of a function doesn’t call any other functions?\nJoe A function that doesn’t call any other function would be a leaf in the tree.\nTheo What about functions that are called inside anonymous functions like Catalog\n.bookInfo?\nJoe Catalog.bookInfo appears in the code of Catalog.searchBooksByTitle.\nTherefore, it is considered to be a child node of Catalog.searchBooksBy-\nTitle. The fact that it is nested inside an anonymous function is not relevant\nin the context of the tree of function calls.\n NOTE A tree of function calls for a function f is a tree where the root is f, and the\nchildren of a node g in the tree are the functions called by g. The leaves of the tree are\nfunctions that are not part of the code base of the application. These are functions\nthat don’t call any other functions.\nTheo It’s very cool to visualize my code as a tree, but I don’t see how it relates to\nunittests.\n--- Page 143 ---\n6.2 Unit tests for data manipulation code 115\nJoe The tree of function calls guides us about the quality and the quantity of test\ncases we should write.\nTheo How?\nJoe You’ll see in a moment.\n6.2.2 Unit tests for functions down the tree\nJoe Let’s start from the function that appears in the deepest node in our tree:\nCatalog.authorNames. Take a look at the code for Catalog.authorNames\nand tell me what are the input and the output of Catalog.authorNames.\nJoe turns his laptop so Theo can a closer look at the code. Theo takes a sip of his café au\nlait as he looks over what’s on Joe’s laptop.\nListing6.5 The code of Catalog.authorNames\nCatalog.authorNames = function (catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n};\nTheo The input of Catalog.authorNames is catalogData and authorIds. The\noutput is authorNames.\nJoe Would you do me a favor and express it visually?\nTheo Sure.\nIt’s Theo’s turn to grab a napkin. He draws a small rectangle with two inward arrows and\none outward arrow as in figure 6.2.\ncatalogData authorIds\nCatalog.authorNames()\nFigure 6.2 Visualization of the input\nauthorNames and output of Catalog.authorNames\nJoe Excellent! Now, how many combinations of input would you include in the\nunit test for Catalog.authorNames?\nTheo Let me see.\nTheo reaches for another napkin. This time he creates a table to gather his thoughts\n(table 6.1).\n--- Page 144 ---\n116 CHAPTER 6 Unit tests\nTable 6.1 The table of test cases for Catalog.authorNames\ncatalogData authorIds authorNames\nCatalog with two authors Empty array Empty array\nCatalog with two authors Array with one author ID Array with one author name\nCatalog with two authors Array with two author IDs Array with two author names\nTheo To begin with, I would have a catalogData with two author IDs and call\nCatalog.authorNames with three arguments: an empty array, an array with a\nsingle author ID, and an array with two author IDs.\nJoe How would you generate the catalogData?\nTheo Exactly as we generated it before.\nTurning to his laptop, Theo writes the code for catalogData. He shows it to Joe.\nListing6.6 A complete catalogData map\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\n--- Page 145 ---\n6.2 Unit tests for data manipulation code 117\nJoe You could use your big catalogData map for the unit test, but you could also\nuse a smaller map in the context of Catalog.authorNames. You can get rid of\nthe booksByIsbn field of the catalogData and the bookIsbns fields of the\nauthors.\nJoe deletes a few lines from catalogData and gets a much smaller map. He shows the revi-\nsion to Theo.\nListing6.7 A minimal version of catalogData\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nTheo Wait a minute! This catalogData is not valid.\nJoe In DOP, data validity depends on the context. In the context of Library\n.searchBooksByTitleJSON and Catalog.searchBooksByTitle, the mini-\nmal version of catalogData is indeed not valid. However, in the context of\nCatalog.bookInfo and Catalog.authorNames, it is perfectly valid. The reason\nis that those two functions access only the authorsById field of catalogData.\nTIP The validity of the data depends on the context.\nTheo Why is it better to use a minimal version of the data in a test case?\nJoe For a very simple reason—the smaller the data, the easier it is to manipulate.\nTIP The smaller the data, the easier it is to manipulate.\nTheo I’ll appreciate that when I write the unit tests!\nJoe Definitely! One last thing before we start coding: how would you check that the\noutput of Catalog.authorNames is as expected?\nTheo I would check that the value returned by Catalog.authorNames is an array\nwith the expected author names.\nJoe How would you handle the array comparison?\nTheo Let me think. I want to compare by value, not by reference. I guess I’ll have to\ncheck that the array is of the expected size and then check member by mem-\nber, recursively.\nJoe That’s too much of a mental burden when you’re in a coffee shop. As I showed\nyou earlier (see listing 6.1), we can recursively compare two data collections by\nvalue with _.isEqual from Lodash.\n--- Page 146 ---\n118 CHAPTER 6 Unit tests\nTIP We can compare the output and the expected output of our functions with\n_.isEqual.\nTheo Sounds good! Let me write the test cases.\nTheo starts typing on his laptop. After a few minutes, he has some test cases for Catalog\n.authorNames, each made from a function call to Catalog.authorNames wrapped in\n_.isEqual.\nListing6.8 Unit test for Catalog.authorNames\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(\ncatalogData,\n[\"alan-moore\"]),\n[\"Alan Moore\"]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\", \"dave-gibbons\"]),\n[\"Alan Moore\", \"Dave Gibbons\"]);\nJoe Well done! Can you think of more test cases?\nTheo Yes. There are test cases where the author ID doesn’t appear in the catalog\ndata, and test cases with empty catalog data. With minimal catalog data and\n_.isEqual, it’s really easy to write lots of test cases!\nTheo really enjoys this challenge. He creates a few more test cases to present to Joe.\nListing6.9 More test cases for Catalog.authorNames\n_.isEqual(Catalog.authorNames({}, []), []);\n_.isEqual(Catalog.authorNames({}, [\"alan-moore\"]), [undefined]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\",\n\"albert-einstein\"]), [\"Alan Moore\", undefined]);\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(catalogData, [\"albert-einstein\"]),\n[undefined]);\nTheo How do I run these unit tests?\nJoe You use your preferred test framework.\n--- Page 147 ---\n6.2 Unit tests for data manipulation code 119\n NOTE We don’t deal here with test runners and test frameworks. We deal only with\nthe logic of the test cases.\n6.2.3 Unit tests for nodes in the tree\nTheo I’m curious to see what unit tests for an upper node in the tree of function calls\nlook like.\nJoe Sure. Let’s write a unit test for Catalog.bookInfo. How many test cases would\nyou have for Catalog.bookInfo?\nListing6.10 The code of Catalog.bookInfo\nCatalog.bookInfo = function (catalogData, book) {\nreturn {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\n};\nTheo takes another look at the code for Catalog.bookInfo on his laptop. Then, reaching\nfor another napkin, he draws a diagram of its input and output (see figure 6.3).\ncatalogData book\nCatalog.bookInfo()\nFigure 6.3 Visualization of the input\nbookInfo and output of Catalog.bookInfo\nTheo I would have a similar number of test cases for Catalog.authorNames: a book\nwith a single author, with two authors, with existing authors, with non-existent\nauthors, with...\nJoe Whoa! That’s not necessary. Given that we have already written unit tests for\nCatalog.authorNames, we don’t need to check all the cases again. We simply\nneed to write a minimal test case to confirm that the code works.\nTIP When we write a unit test for a function, we assume that the functions called by\nthis function are covered by unit tests and work as expected. It significantly reduces\nthe quantity of test cases in our unit tests.\nTheo That makes sense.\nJoe How would you write a minimal test case for Catalog.bookInfo?\nTheo once again takes a look at the code for Catalog.bookInfo (see listing 6.10). Now he\ncan answer Joe’s question.\n--- Page 148 ---\n120 CHAPTER 6 Unit tests\nTheo I would use the same catalog data as for Catalog.authorNames and a book\nrecord. I’d test that the function behaves as expected by comparing its return\nvalue with a book info record using _.isEqual. Here, let me show you.\nIt takes Theo a bit more time to write the unit test. The reason is that the input and the\noutput of Catalog.authorNames are both records. Dealing with a record is more complex\nthan dealing with an array of strings (as it was the case for Catalog.authorNames). Theo\nappreciates the fact that _.isEqual saves him from writing code that compares the two\nmaps property by property. When he’s through, he shows the result to Joe and takes a nap-\nkin to wipe his forehead.\nListing6.11 Unit test for Catalog.bookInfo\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nvar book = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n};\nvar expectedResult = {\n\"authorNames\": [\"Alan Moore\", \"Dave Gibbons\"],\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n};\nvar result = Catalog.bookInfo(catalogData, book);\n_.isEqual(result, expectedResult);\nJoe Perfect! Now, how would you compare the kind of unit tests for Catalog\n.bookInfo with the unit tests for Catalog.authorNames?\nTheo On one hand, there is only a single test case in the unit test for Catalog.book-\nInfo. On the other hand, the data involved in the test case is more complex\nthan the data involved in the test cases for Catalog.authorNames.\nJoe Exactly! Functions that appear in a deep node in the tree of function calls tend\nto require more test cases, but the data involved in the test cases is less complex.\nTIP Functions that appear in a lower level in the tree of function calls tend to\ninvolve less complex data than functions that appear in a higher level in the tree\n(see table 6.2).\n--- Page 149 ---\n6.3 Unit tests for queries 121\nTable 6.2 The correlation between the depth of a function in the tree of function calls and the\nquality and quantity of the test cases\nDepth in the tree Complexity of the data Number of test cases\nLower Higher Lower\nHigher Lower Higher\n6.3 Unit tests for queries\nIn the previous section, we saw how to write unit tests for utility functions like Catalog\n.bookInfo and Catalog.authorNames. Now, we are going to see how to write unit tests\nfor the nodes of a query tree of function calls that are close to the root of the tree.\nJoe Theo, how would you write a unit test for the code of the entry point of the\nsearch query?\nTo recall the particulars, Theo checks the code for Library.searchBooksByTitleJSON.\nAlthough Joe was right about today’s topic being easy enough to enjoy the ambience of a\ncoffee shop, he has been doing quite a lot of coding this morning.\nListing6.12 The code of Library.searchBooksByTitleJSON\nLibrary.searchBooksByTitleJSON = function (libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n};\nHe then takes a moment to think about how he’d write a unit test for that code. After\nanother Aha! moment, now he’s got it.\nTheo The inputs of Library.searchBooksByTitleJSON are library data and a\nquery string, and the output is a JSON string (see figure 6.4). So, I would cre-\nate a library data record with a single book and write tests with query strings\nthat match the name of the book and ones that don’t match.\nlibraryData query\nLibrary.searchBooksByTitleJSON()\nFigure 6.4 The input and output of\nresultsJSON Library.searchBooksByTitleJSON\nJoe What about the expected results of the test cases?\n--- Page 150 ---\n122 CHAPTER 6 Unit tests\nTheo In cases where the query string matches, the expected result is a JSON string\nwith the book info. In cases where the query string doesn’t match, the\nexpected result is a JSON string with an empty array.\nJoe Hmm...\nTheo What?\nJoe I don’t like your answer.\nTheo Why?\nJoe Because your test case relies on a string comparison instead of a data comparison.\nTheo What difference does it make? After all, the strings I’m comparing come from\nthe serialization of data.\nJoe It’s inherently much more complex to compare JSON strings than it is to com-\npare data. For example, two different strings might be the serialization of the\nsame piece of data.\nTheo Really? How?\nJoe Take a look at these two strings. They are the serialization of the same data.\nThey’re different strings because the fields appear in a different order, but in\nfact, they serialize the same data!\nJoe turns his laptop to Theo. As Theo looks at the code, he realizes that, once again, Joe\niscorrect.\nListing6.13 Two different strings that serialize the same data\nvar stringA = \"{\\\"title\\\":\\\"Watchmen\\\",\\\"publicationYear\\\":1987}\";\nvar stringB = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nTIP Avoid using a string comparison in unit tests for functions that deal with data.\nTheo I see.... Well, what can I do instead?\nJoe Instead of comparing the output of Library.searchBooksByTitleJSON with\na string, you could deserialize the output and compare it to the expected data.\nTheo What do you mean by deserialize a string?\nJoe Deserializing a string s, for example, means to generate a piece of data whose\nserialization is s.\nTheo Is there a Lodash function for string deserialization?\nJoe Actually, there is a native JavaScript function for string deserialization; it’s\ncalled JSON.parse.\nJoe retrieves his laptop and shows Theo an example of string deserialization. The code\nillustrates a common usage of JSON.parse.\nListing6.14 Example of string deserialization\nvar myString = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nvar myData = JSON.parse(myString);\n--- Page 151 ---\n6.3 Unit tests for queries 123\n_.get(myData, \"title\");\n// → \"Watchmen\"\nTheo Cool! Let me try writing a unit test for Library.searchBooksByTitleJSON\nusing JSON.parse.\nIt doesn’t take Theo too much time to come up with a piece of code. Using his laptop, he\ninputs the unit test.\nListing6.15 Unit test for Library.searchBooksByTitleJSON\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Watchmen\")),\n[bookInfo]);\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Batman\")),\n[]);\nJoe Well done! I think you’re ready to move on to the last piece of the puzzle and\nwrite the unit test for Catalog.searchBooksByTitle.",
        "sections_found": []
      },
      "accurate_page_range": "126-151"
    },
    {
      "text": "- 5.5 Implementing the reconciliation algorithm",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "5 Basic concurrency control",
      "raw_line": "- 5.5 Implementing the reconciliation algorithm (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 43,
      "chapter_info": {
        "page": 126,
        "title": "Basic concurrency control",
        "pattern_matched": "Chapter 5",
        "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
      },
      "chapter_sections": {
        "start_page": 126,
        "end_page": 151,
        "content": "\n--- Page 126 ---\n98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. It means that the first call to f will be f(0, 1). Then,\nwe’ll have f(f(0, 1), 2) and, finally, f(f(f(0, 1), 2), 3).\nJoe I like your manual expansion, Theo! Let’s make it visual.\nNow Theo goes to the whiteboard and draws a diagram. Figure 5.5 shows what that looks like.\nf\nf a\n2\nf a\n1\na 0 initVal Figure 5.5 Visualization\nof _.reduce\nTheo It’s much clearer now. I think that by implementing my custom version of\n_.reduce, it will make things 100% clear.\nIt takes Theo much less time than he expected to implement reduce(). In no time at all,\nhe shows Joe the code.\nListing5.2 Custom implementation of _.reduce\nfunction reduce(coll, f, initVal) {\nvar currentRes = initVal;\nfor (var i = 0; i < coll.length; i++) {\nWe could use\ncurrentRes = f(currentRes, coll[i])\nforEach instead\n}\nof a for loop.\nreturn currentRes;\n}\nAfter checking that Theo’s code works as expected (see listing 5.3), Joe is proud of Theo.\nHe seems to be catching on better than he anticipated.\nListing5.3 Testing the custom implementation of reduce()\nreduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nJoe Well done!\n--- Page 127 ---\n5.4 Structural difference 99\n5.4 Structural difference\n NOTE This section deals with the implementation of a structural diff algorithm. Feel\nfree to skip this section if you don’t want to challenge your mind right now with the\ndetails of a sophisticated use of recursion. It won’t prevent you from enjoying the rest\nof the book. You can come back to this section later.\nTheo How do you calculate the diff between various versions of the system state?\nJoe That’s the most challenging part of the reconciliation algorithm. We need to\nimplement a structural diff algorithm for hash maps.\nTheo In what sense is the diff structural?\nJoe The structural diff algorithm looks at the structure of the hash maps and\nignores the order of the fields.\nTheo Could you give me an example?\nJoe Let’s start with maps without nested fields. Basically, there are three kinds of\ndiffs: field replacement, field addition, and field deletion. In order to make\nthings not too complicated, for now, we’ll deal only with replacement and\naddition.\nJoe once again goes to the whiteboard and draws table 5.3, representing the three kinds of\ndiffs. Theo is thinking the whiteboard is really starting to fill up today.\nTable 5.3 Kinds of structural differences between maps without nested fields\nKind First map Second map Diff\nReplacement {\"a\": 1} {\"a\": 2} {\"a\": 2}\nAddition {\"a\": 1} {\"a\": 1, \"b\": 2} {\"b\": 2}\nDeletion {\"a\": 1, \"b\": 2} {\"a\": 1} Not supported\nTheo I notice that the order of the maps matters a lot. What about nested fields?\nJoe It’s the same idea, but the nesting makes it a bit more difficult to grasp.\nJoe changes several of the columns in table 5.3. When he’s through, he shows Theo the\nnested fields in table 5.4.\nTable 5.4 Kinds of structural differences between maps with nested fields\nKind First map Second map Diff\nReplacement { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 2 \"x\": 2\n} } }\n} } }\n--- Page 128 ---\n100 CHAPTER 5 Basic concurrency control\nTable 5.4 Kinds of structural differences between maps with nested fields (continued)\nKind First map Second map Diff\nAddition { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 1, \"y\": 2\n} \"y\": 2, }\n} } }\n}\nDeletion { { Not supported\n\"a\": { \"a\": {\n\"x\": 1, \"y\": 2\n\"y\": 2, }\n} }\n}\n NOTE The version of the structural diff algorithm illustrated in this chapter does\nnot deal with deletions. Dealing with deletions is definitely possible, but it requires a\nmore complicated algorithm.\nTheo As you said, it’s harder to grasp. What about arrays?\nJoe We compare the elements of the arrays in order: if they are equal, the diff is\nnull; if they differ, the diff has the value of the second array.\nJoe summarizes the various kinds of diffs in another table on the whiteboard. Theo looks\nat the result in table 5.5.\nTable 5.5 Kinds of structural differences between arrays without nested elements\nKind First array Second array Diff\nReplacement [1] [2] [2]\nAddition [1] [1, 2] [null, 2]\nDeletion [1, 2] [1] Not supported\nTheo This usage of null is a bit weird but OK. Is it complicated to implement the\nstructural diff algorithm?\nJoe Definitely! It took a good dose of mental gymnastics to come up with these 30\nlines of code.\nJoe downloads the code from one his personal repositories. Theo, with thumb and forefin-\ngers touching his chin and his forehead slightly tilted, studies the code.\nListing5.4 The implementation of a structural diff\nfunction diffObjects(data1, data2) {\n_.isArray checks whether\nvar emptyObject = _.isArray(data1) ? [] : {};\nits argument is an array.\nif(data1 == data2) {\n--- Page 129 ---\n5.4 Structural difference 101\nreturn emptyObject;\n_.union creates an\n} array of unique\nvar keys = _.union(_.keys(data1), _.keys(data2)); values from two\nreturn _.reduce(keys, arrays (like union of\nfunction (acc, k) { two sets in Maths).\nvar res = diff(\n_.get(data1, k),\n_.isObject checks\n_.get(data2, k));\nwhether its argument\nif((_.isObject(res) && _.isEmpty(res)) ||\nis a collection (either\na map or an array).\n(res == \"no-diff\")) {\nreturn acc;\n_.isEmpty }\nchecks return _.set(acc, [k], res);\nwhether its },\nargument\nemptyObject);\nis an empty\n} \"no-diff\" is how\ncollection.\nwe mark that\nfunction diff(data1, data2) { two values are\nif(_.isObject(data1) && _.isObject(data2)) { the same.\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"no-diff\";\n}\nTheo Wow! It involves a recursion inside a reduce! I’m sure Dave will love this, but\nI’m too tired to understand this code right now. Let’s focus on what it does\ninstead of how it does it.\nIn order familiarize himself with the structural diff algorithm, Theo runs the algorithm\nwith examples from the table that Joe drew on the whiteboard. While Theo occupies his\nfingers with more and more complicated examples, his mind wanders in the realm of\nperformance.\nListing5.5 An example of usage of a structural diff\nvar data1 = {\n\"a\": {\n\"x\": 1,\n\"y\": [2, 3],\n\"z\": 4\n}\n};\nvar data2 = {\n\"a\": {\n\"x\": 2,\n\"y\": [2, 4],\n\"z\": 4\n}\n}\n--- Page 130 ---\n102 CHAPTER 5 Basic concurrency control\ndiff(data1, data2);\n//{\n// \"a\": {\n// \"x\": 2,\n// \"y\": [\n// undefined,\n// 4\n// ]\n// }\n//}\nTheo What about the performance of the structural diff algorithm? It seems that the\nalgorithm goes over the leaves of both pieces of data?\nJoe In the general case, that’s true. But, in the case of system data that’s manipu-\nlated with structural sharing, the code is much more efficient.\nTheo What do you mean?\nJoe With structural sharing, most of the nested objects are shared between two ver-\nsions of the system state. Therefore, most of the time, when the code enters\ndiffObjects, it will immediately return because data1 and data2 are the same.\nTIP Calculating the diff between two versions of the state is efficient because two\nhash maps created via structural sharing from the same hash map have most of their\nnodes in common.\nTheo Another benefit of immutable data... Let me see how the diff algorithm\nbehaves with concurrent mutations. I think I’ll start with a tiny library with no\nusers and a catalog with a single book, Watchmen.\nListing5.6 The data for a tiny library\nvar library = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\n--- Page 131 ---\n5.4 Structural difference 103\nJoe I suggest that we start with nonconflicting mutations. What do you suggest?\nTheo A mutation that updates the publication year of Watchmen and a mutation that\nupdates both the title of Watchmen and the name of the author of Watchmen.\nOn his laptop, Theo creates three versions of the library. He shows Joe his code, where one\nmutation updates the publication year of Watchmen, and the other one updates the title of\nWatchmen and the author’s name.\nListing5.7 Two nonconflicting mutations\nvar previous = library;\nvar next = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"],\n1986);\nvar libraryWithUpdatedTitle = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"],\n\"The Watchmen\");\nvar current = _.set(\nlibraryWithUpdatedTitle,\n[\"catalog\", \"authorsById\", \"dave-gibbons\", \"name\"],\n\"David Chester Gibbons\");\nTheo I’m curious to see what the diff between previous and current looks like.\nJoe Run the code and you’ll see.\nTheo runs the code snippets for the structural diff between previous and next and for\nthe structural diff between previous and current. His curiosity satisfied, Theo finds it’s\nall beginning to make sense.\nListing5.8 Structural diff between maps with a single difference\ndiff(previous, next);\n//{\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"publicationYear\": 1986\n// }\n// }\n// }\n//}\nListing5.9 Structural diff between maps with two differences\ndiff(previous, current);\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\",\n--- Page 132 ---\n104 CHAPTER 5 Basic concurrency control\n// }\n// },\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\n//\nJoe Can you give me the information path of the single field in the structural diff\nbetween previous and next?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Right. And what are the information paths of the fields in the structural diff\nbetween previous and current?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"] for the book\ntitle and [\"authorsById\", \"dave-gibbons\", \"name\"] for the author’s name.\nJoe Perfect! Now, can you figure out how to detect conflicting mutations by\ninspecting the information paths of the structural diffs?\nTheo We need to check if they have an information path in common or not.\nJoe Exactly! If they have, it means the mutations are conflicting.\nTheo But I have no idea how to write code that retrieves the information paths of a\nnested map.\nJoe Once again, it’s a nontrivial piece of code that involves a recursion inside a\nreduce. Let me download another piece of code from my repository and show\nit to you.\nListing5.10 Calculating the information paths of a (nested) map\nfunction informationPaths (obj, path = []) {\nreturn _.reduce(obj,\nfunction(acc, v, k) {\nif (_.isObject(v)) {\nreturn _.concat(acc,\ninformationPaths(v,\n_.concat(path, k)));\n}\nreturn _.concat(acc, [_.concat(path, k)]);\n},\n[]);\n}\nTheo Let me see if your code works as expected with the structural diffs of the\nmutations.\nTheo tests Joe’s code with two code snippets. The first shows the information paths of the\nstructural diff between previous and next, and the second shows the information paths\nof the structural diff between previous and current.\n--- Page 133 ---\n5.4 Structural difference 105\nListing5.11 Fields that differ between previous and next\ninformationPaths(diff(previous, next));\n// → [\"catalog.booksByIsbn.978-1779501127.publicationYear\"]\nListing5.12 Fields that differ between previous and current\ninformationPaths(diff(previous, current));\n// [\n// [\n// \"catalog\",\n// \"booksByIsbn\",\n// \"978-1779501127\",\n// \"title\"\n// ],\n// [\n// \"authorsById\",\n// \"dave-gibbons\",\n// \"name\"\n// ]\n//]\nTheo Nice! I assume that Lodash has a function that checks whether two arrays have\nan element in common.\nJoe Almost. There is _.intersection, which returns an array of the unique values\nthat are in two given arrays. For our purpose, though, we need to check\nwhether the intersection is empty. Here, look at this example.\nListing5.13 Checking whether two diff maps have a common information path\nfunction havePathInCommon(diff1, diff2) {\nreturn !_.isEmpty(_.intersection(informationPaths(diff1),\ninformationPaths(diff2)));\n}\nTheo You told me earlier that in the case of nonconflicting mutations, we can\nsafely patch the changes induced by the transition from previous to next\ninto current. How do you implement that?\nJoe We do a recursive merge between current and the diff between previous and\nnext.\nTheo Does Lodash provide an immutable version of recursive merge?\nJoe Yes, here’s another example. Take a look at this code.\nListing5.14 Applying a patch\n_.merge(current, (diff(previous, next)));\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\"\n// }\n// },\n--- Page 134 ---\n106 CHAPTER 5 Basic concurrency control\n// \"catalog\": {\n// \"authorsById\": {\n// \"alan-moore\": {\n// \"bookIsbns\": [\"978-1779501127\"]\n// \"name\": \"Alan Moore\"\n// },\n// \"dave-gibbons\": {\n// \"bookIsbns\": [\"978-1779501127\"],\n// \"name\": \"Dave Gibbons\"\n// },\n// },\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n// \"isbn\": \"978-1779501127\",\n// \"publicationYear\": 1986,\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\nTheo Could it be as simple as this?\nJoe Indeed.\n5.5 Implementing the reconciliation algorithm\nJoe All the pieces are now in place to implement our reconciliation algorithm.\nTheo What kind of changes are required?\nJoe It only requires changes in the code of SystemState.commit. Here, look at\nthis example on my laptop.\nListing5.15 The SystemState class\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nvar nextSystemData = SystemConsistency.reconcile(\nthis.systemData,\nSystemConsistency class is\nprevious,\nimplemented in listing 5.16.\nnext);\nif(!SystemValidity.validate(previous, nextSystemData)) {\nthrow \"The system data to be committed is not valid!\";\n};\n--- Page 135 ---\n5.5 Implementing the reconciliation algorithm 107\nthis.systemData = nextSystemData;\n}\n}\nTheo How does SystemConsistency do the reconciliation?\nJoe The SystemConsistency class starts the reconciliation process by comparing\nprevious and current. If they are the same, then we fast-forward and return\nnext. Look at this code for SystemConsistency.\nListing5.16 The reconciliation flow in action\nclass SystemConsistency {\nstatic threeWayMerge(current, previous, next) {\nvar previousToCurrent = diff(previous, current);\nvar previousToNext = diff(previous, next);\nif(havePathInCommon(previousToCurrent, previousToNext)) { When the system\nreturn _.merge(current, previousToNext); state is the same\n} as the state used\nthrow \"Conflicting concurrent mutations.\"; by the calculation\n} phase, we fast-\nstatic reconcile(current, previous, next) { forward.\nif(current == previous) {\nreturn next;\n}\nreturn SystemConsistency.threeWayMerge(current,\nprevious,\nnext);\n}\n}\nTheo Wait a minute! Why do you compare previous and current by reference?\nYou should be comparing them by value, right? And, it would be quite expen-\nsive to compare all the leaves of the two nested hash maps!\nJoe That’s another benefit of immutable data. When the data is not mutated, it is\nsafe to compare references. If they are the same, we know for sure that the data\nis the same.\nTIP When data is immutable, it is safe to compare by reference, which is super fast.\nWhen the references are the same, it means that the data is the same.\nTheo What about the implementation of the three-way merge algorithm?\nJoe When previous differs from current, it means that concurrent mutations\nhave run. In order to determine whether there is a conflict, we calculate two\ndiffs: the diff between previous and current and the diff between previous\nand next. If the intersection between the two diffs is empty, it means there is\nno conflict. We can safely patch the changes between previous to next into\ncurrent.\nTheo takes a closer look at the code for the SystemConsistency class in listing 5.16. He\ntries to figure out if the code is thread-safe or not.\n--- Page 136 ---\n108 CHAPTER 5 Basic concurrency control\nTheo I think the code for SystemConsistency class is not thread-safe! If there’s a\ncontext switch between checking whether the system has changed in the\nSystemConsistency class and the updating of the state in SystemData class, a\nmutation might override the changes of a previous mutation.\nJoe You are totally right! The code works fine in a single-threaded environment\nlike JavaScript, where concurrency is handled via an event loop. However, in a\nmulti-threaded environment, the code needs to be refined in order to be\nthread-safe. I’ll show you some day.\n NOTE The SystemConsistency class is not thread-safe. We will make it thread-safe\nin chapter 8.\nTheo I think I understand why you called it optimistic concurrency control. It’s\nbecause we assume that conflicts don’t occur too often. Right?\nJoe Correct! It makes me wonder what your therapist would say about conflicts that\ncannot be resolved. Are there some cases where it’s not possible to reconcile\nthe couple?\nTheo I don’t think she ever mentioned such a possibility.\nJoe She must be a very optimistic person.\nSummary\n Optimistic concurrency control allows mutations to ask forgiveness instead of\npermission.\n Optimistic concurrency control is lock-free.\n Managing concurrent mutations of our system state with optimistic concurrency\ncontrol allows our system to support a high throughput of reads and writes.\n Optimistic concurrency control with immutable data is super efficient.\n Before updating the state, we need to reconcile the conflicts between possible con-\ncurrent mutations.\n We reconcile between concurrent mutations in a way that is similar to how Git han-\ndles a merge between two branches: either a fast-forward or a three-way merge.\n The changes required to let our system manage concurrency are only in the\ncommit phase.\n The calculation phase does its calculation as if it were the only mutation running.\n The commit phase is responsible for trying to reconcile concurrent mutations.\n The reconciliation algorithm is universal in the sense that it can be used in any sys-\ntem where the system data is represented as an immutable hash map.\n The implementation of the reconciliation algorithm is efficient, as it leverages\nthe fact that subsequent versions of the system state are created via structural\nsharing.\n In a user-facing system, conflicting concurrent mutations are fairly rare.\n When we cannot safely reconcile between concurrent mutations, we abort the\nmutation and ask the user to try again.\n--- Page 137 ---\nSummary 109\n Calculating the structural diff between two versions of the state is efficient because\ntwo hash maps created via structural sharing from the same hash map have most\nof their nodes in common.\n When data is immutable, it is safe to compare by reference, which is fast. When\nthe references are the same, it means that the data is the same.\n There are three kinds of structural differences between two nested hash maps:\nreplacement, addition, and deletion.\n Our structural diff algorithm supports replacements and additions but not\ndeletions.\nLodash functions introduced in this chapter\nFunction Description\nconcat(arrA, arrB) Creates an new array, concatenating arrA and arrB\nintersection(arrA, arrB) Creates an array of unique values both in arrA and arrB\nunion(arrA, arrB) Creates an array of unique values from arrA and arrB\nfind(coll, pred) Iterates over elements of coll, returning the first element for\nwhich pred returns true\nisEmpty(coll) Checks if coll is empty\nreduce(coll, f, initVal) Reduces coll to a value that is the accumulated result of running\neach element in coll through f, where each successive invoca-\ntion is supplied the return value of the previous\nisArray(coll) Checks if coll is an array\nisObject(coll) Checks if coll is a collection\n--- Page 138 ---\nUnit tests\nProgramming at a coffee shop\nThis chapter covers\n Generation of the minimal data input for a\ntest case\n Comparison of the output of a function with\nthe expected output\n Guidance about the quality and the quantity\nof the test cases\nIn a data-oriented system, our code deals mainly with data manipulation: most of\nour functions receive data and return data. As a consequence, it’s quite easy to\nwrite unit tests to check whether our code behaves as expected. A unit test is made\nof test cases that generate data input and compare the data output of the function\nwith the expected data output. In this chapter, we write unit tests for the queries\nand mutations that we wrote in the previous chapters.\n6.1 The simplicity of data-oriented test cases\nTheo and Joe are seated around a large wooden table in a corner of “La vie est belle,” a\nnice little French coffee shop, located near the Golden Gate Bridge. Theo orders a café\nau lait with a croissant, and Joe orders a tight espresso with a pain au chocolat. Instead\nof the usual general discussions about programming and life when they’re out of the\n110\n--- Page 139 ---\n6.1 The simplicity of data-oriented test cases 111\noffice, Joe leads the discussion towards a very concrete topic—unit tests. Theo asks Joe for\nan explanation.\nTheo Are unit tests such a simple topic that we can tackle it here in a coffee shop?\nJoe Unit tests in general, no. But unit tests for data-oriented code, yes!\nTheo Why does that make a difference?\nJoe The vast majority of the code base of a data-oriented system deals with data\nmanipulation.\nTheo Yeah. I noticed that almost all the functions we wrote so far receive data and\nreturn data.\nTIP Most of the code in a data-oriented system deals with data manipulation.\nJoe Writing a test case for functions that deal with data is only about generating\ndata input and expected output, and comparing the output of the function\nwith the expected output.\nThe steps of a test case\n1 Generate data input: dataIn\n2 Generate expected output: dataOut\n3 Compare the output of the function with the expected output: f(dataIn) and\ndataOut\nTheo That’s it?\nJoe Yes. As you’ll see in a moment, in DOP, there’s usually no need for mock\nfunctions.\nTheo I understand how to compare primitive values like strings or numbers, but I’m\nnot sure how I would compare data collections like maps.\nJoe You compare field by field.\nTheo Recursively?\nJoe Yes!\nTheo Oh no! I’m not able to write any recursive code in a coffee shop. I need the\ncalm of my office for that kind of stuff.\nJoe Don’t worry. In DOP, data is represented in a generic way. There is a generic\nfunction in Lodash called _.isEqual for recursive comparison of data collec-\ntions. It works with both maps and arrays.\nJoe opens his laptop. He is able to convince Theo by executing a few code snippets with\n_.isEqual to compare an equal data collection with a non-equal one.\nListing6.1 Comparing an equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n--- Page 140 ---\n112 CHAPTER 6 Unit tests\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n});\n// → true\nListing6.2 Comparing a non-equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"bad-isbn\"]\n});\n// → false\nTheo Nice!\nJoe Most of the test cases in DOP follow this pattern.\nTheo decides he wants to try this out. He fires up his laptop and types a few lines of\npseudocode.\nListing6.3 The general pattern of a data-oriented test case\nvar dataIn = {\n// input\n};\nvar dataOut = {\n// expected output\n};\n_.isEqual(f(dataIn), dataOut);\nTIP It’s straightforward to write unit tests for code that deals with data manipulation.\nTheo Indeed, this looks like something we can tackle in a coffee shop!\n6.2 Unit tests for data manipulation code\nA waiter in an elegant bow tie brings Theo his croissant and Joe his pain au chocolat. The\ntwo friends momentarily interrupt their discussion to savor their French pastries. When\nthey’re done, they ask the waiter to bring them their drinks. Meanwhile, they resume the\ndiscussion.\nJoe Do you remember the code flow of the implementation of the search query?\nTheo Let me look again at the code that implements the search query.\nTheo brings up the implementation of the search query on his laptop. Noticing that Joe is\nchewing on his nails again, he quickly checks out the code.\n--- Page 141 ---\n6.2 Unit tests for data manipulation code 113\nListing6.4 The code involved in the implementation of the search query\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\n}\n6.2.1 The tree of function calls\nThe waiter brings Theo his café au lait and Joe his tight espresso. They continue their dis-\ncussion while enjoying their coffees.\nJoe Before writing a unit test for a code flow, I find it useful to visualize the tree of\nfunction calls of the code flow.\nTheo What do you mean by a tree of function calls?\nJoe Here, I’ll draw the tree of function calls for the Library.searchBooksBy-\nTitleJSON code flow.\nJoe puts down his espresso and takes a napkin from the dispenser. He carefully places it\nflat on the table and starts to draw. When he is done, he shows the illustration to Theo (see\nfigure 6.1).\n--- Page 142 ---\n114 CHAPTER 6 Unit tests\nLibrary.searchBooksByTitleJSON\n_.get JSON.stringify Catalog.searchBooksByTitle\n_.get _.map _.filter Catalog.bookInfo\n_.get Catalog.authorNames\n_.get _.map\nFigure 6.1 The tree of function calls for the search query code flow\nTheo Nice! Can you teach me how to draw a tree of function calls like that?\nJoe Sure. The root of the tree is the name of the function for which you draw the\ntree, in our case, Library.searchBooksByTitleJSON. The children of a\nnode in the tree are the names of the functions called by the function. For exam-\nple, if you look again at the code for Library.searchBooksByTitleJSON (list-\ning 6.4), you’ll see that it calls Catalog.searchBooksByTitle, _.get, and\nJSON.stringify.\nTheo How long would I continue to recursively expand the tree?\nJoe You continue until you reach a function that doesn’t belong to the code base\nof your application. Those nodes are the leaves of our tree; for example, the\nfunctions from Lodash: _.get, _.map, and so forth.\nTheo What if the code of a function doesn’t call any other functions?\nJoe A function that doesn’t call any other function would be a leaf in the tree.\nTheo What about functions that are called inside anonymous functions like Catalog\n.bookInfo?\nJoe Catalog.bookInfo appears in the code of Catalog.searchBooksByTitle.\nTherefore, it is considered to be a child node of Catalog.searchBooksBy-\nTitle. The fact that it is nested inside an anonymous function is not relevant\nin the context of the tree of function calls.\n NOTE A tree of function calls for a function f is a tree where the root is f, and the\nchildren of a node g in the tree are the functions called by g. The leaves of the tree are\nfunctions that are not part of the code base of the application. These are functions\nthat don’t call any other functions.\nTheo It’s very cool to visualize my code as a tree, but I don’t see how it relates to\nunittests.\n--- Page 143 ---\n6.2 Unit tests for data manipulation code 115\nJoe The tree of function calls guides us about the quality and the quantity of test\ncases we should write.\nTheo How?\nJoe You’ll see in a moment.\n6.2.2 Unit tests for functions down the tree\nJoe Let’s start from the function that appears in the deepest node in our tree:\nCatalog.authorNames. Take a look at the code for Catalog.authorNames\nand tell me what are the input and the output of Catalog.authorNames.\nJoe turns his laptop so Theo can a closer look at the code. Theo takes a sip of his café au\nlait as he looks over what’s on Joe’s laptop.\nListing6.5 The code of Catalog.authorNames\nCatalog.authorNames = function (catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n};\nTheo The input of Catalog.authorNames is catalogData and authorIds. The\noutput is authorNames.\nJoe Would you do me a favor and express it visually?\nTheo Sure.\nIt’s Theo’s turn to grab a napkin. He draws a small rectangle with two inward arrows and\none outward arrow as in figure 6.2.\ncatalogData authorIds\nCatalog.authorNames()\nFigure 6.2 Visualization of the input\nauthorNames and output of Catalog.authorNames\nJoe Excellent! Now, how many combinations of input would you include in the\nunit test for Catalog.authorNames?\nTheo Let me see.\nTheo reaches for another napkin. This time he creates a table to gather his thoughts\n(table 6.1).\n--- Page 144 ---\n116 CHAPTER 6 Unit tests\nTable 6.1 The table of test cases for Catalog.authorNames\ncatalogData authorIds authorNames\nCatalog with two authors Empty array Empty array\nCatalog with two authors Array with one author ID Array with one author name\nCatalog with two authors Array with two author IDs Array with two author names\nTheo To begin with, I would have a catalogData with two author IDs and call\nCatalog.authorNames with three arguments: an empty array, an array with a\nsingle author ID, and an array with two author IDs.\nJoe How would you generate the catalogData?\nTheo Exactly as we generated it before.\nTurning to his laptop, Theo writes the code for catalogData. He shows it to Joe.\nListing6.6 A complete catalogData map\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\n--- Page 145 ---\n6.2 Unit tests for data manipulation code 117\nJoe You could use your big catalogData map for the unit test, but you could also\nuse a smaller map in the context of Catalog.authorNames. You can get rid of\nthe booksByIsbn field of the catalogData and the bookIsbns fields of the\nauthors.\nJoe deletes a few lines from catalogData and gets a much smaller map. He shows the revi-\nsion to Theo.\nListing6.7 A minimal version of catalogData\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nTheo Wait a minute! This catalogData is not valid.\nJoe In DOP, data validity depends on the context. In the context of Library\n.searchBooksByTitleJSON and Catalog.searchBooksByTitle, the mini-\nmal version of catalogData is indeed not valid. However, in the context of\nCatalog.bookInfo and Catalog.authorNames, it is perfectly valid. The reason\nis that those two functions access only the authorsById field of catalogData.\nTIP The validity of the data depends on the context.\nTheo Why is it better to use a minimal version of the data in a test case?\nJoe For a very simple reason—the smaller the data, the easier it is to manipulate.\nTIP The smaller the data, the easier it is to manipulate.\nTheo I’ll appreciate that when I write the unit tests!\nJoe Definitely! One last thing before we start coding: how would you check that the\noutput of Catalog.authorNames is as expected?\nTheo I would check that the value returned by Catalog.authorNames is an array\nwith the expected author names.\nJoe How would you handle the array comparison?\nTheo Let me think. I want to compare by value, not by reference. I guess I’ll have to\ncheck that the array is of the expected size and then check member by mem-\nber, recursively.\nJoe That’s too much of a mental burden when you’re in a coffee shop. As I showed\nyou earlier (see listing 6.1), we can recursively compare two data collections by\nvalue with _.isEqual from Lodash.\n--- Page 146 ---\n118 CHAPTER 6 Unit tests\nTIP We can compare the output and the expected output of our functions with\n_.isEqual.\nTheo Sounds good! Let me write the test cases.\nTheo starts typing on his laptop. After a few minutes, he has some test cases for Catalog\n.authorNames, each made from a function call to Catalog.authorNames wrapped in\n_.isEqual.\nListing6.8 Unit test for Catalog.authorNames\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(\ncatalogData,\n[\"alan-moore\"]),\n[\"Alan Moore\"]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\", \"dave-gibbons\"]),\n[\"Alan Moore\", \"Dave Gibbons\"]);\nJoe Well done! Can you think of more test cases?\nTheo Yes. There are test cases where the author ID doesn’t appear in the catalog\ndata, and test cases with empty catalog data. With minimal catalog data and\n_.isEqual, it’s really easy to write lots of test cases!\nTheo really enjoys this challenge. He creates a few more test cases to present to Joe.\nListing6.9 More test cases for Catalog.authorNames\n_.isEqual(Catalog.authorNames({}, []), []);\n_.isEqual(Catalog.authorNames({}, [\"alan-moore\"]), [undefined]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\",\n\"albert-einstein\"]), [\"Alan Moore\", undefined]);\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(catalogData, [\"albert-einstein\"]),\n[undefined]);\nTheo How do I run these unit tests?\nJoe You use your preferred test framework.\n--- Page 147 ---\n6.2 Unit tests for data manipulation code 119\n NOTE We don’t deal here with test runners and test frameworks. We deal only with\nthe logic of the test cases.\n6.2.3 Unit tests for nodes in the tree\nTheo I’m curious to see what unit tests for an upper node in the tree of function calls\nlook like.\nJoe Sure. Let’s write a unit test for Catalog.bookInfo. How many test cases would\nyou have for Catalog.bookInfo?\nListing6.10 The code of Catalog.bookInfo\nCatalog.bookInfo = function (catalogData, book) {\nreturn {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\n};\nTheo takes another look at the code for Catalog.bookInfo on his laptop. Then, reaching\nfor another napkin, he draws a diagram of its input and output (see figure 6.3).\ncatalogData book\nCatalog.bookInfo()\nFigure 6.3 Visualization of the input\nbookInfo and output of Catalog.bookInfo\nTheo I would have a similar number of test cases for Catalog.authorNames: a book\nwith a single author, with two authors, with existing authors, with non-existent\nauthors, with...\nJoe Whoa! That’s not necessary. Given that we have already written unit tests for\nCatalog.authorNames, we don’t need to check all the cases again. We simply\nneed to write a minimal test case to confirm that the code works.\nTIP When we write a unit test for a function, we assume that the functions called by\nthis function are covered by unit tests and work as expected. It significantly reduces\nthe quantity of test cases in our unit tests.\nTheo That makes sense.\nJoe How would you write a minimal test case for Catalog.bookInfo?\nTheo once again takes a look at the code for Catalog.bookInfo (see listing 6.10). Now he\ncan answer Joe’s question.\n--- Page 148 ---\n120 CHAPTER 6 Unit tests\nTheo I would use the same catalog data as for Catalog.authorNames and a book\nrecord. I’d test that the function behaves as expected by comparing its return\nvalue with a book info record using _.isEqual. Here, let me show you.\nIt takes Theo a bit more time to write the unit test. The reason is that the input and the\noutput of Catalog.authorNames are both records. Dealing with a record is more complex\nthan dealing with an array of strings (as it was the case for Catalog.authorNames). Theo\nappreciates the fact that _.isEqual saves him from writing code that compares the two\nmaps property by property. When he’s through, he shows the result to Joe and takes a nap-\nkin to wipe his forehead.\nListing6.11 Unit test for Catalog.bookInfo\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nvar book = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n};\nvar expectedResult = {\n\"authorNames\": [\"Alan Moore\", \"Dave Gibbons\"],\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n};\nvar result = Catalog.bookInfo(catalogData, book);\n_.isEqual(result, expectedResult);\nJoe Perfect! Now, how would you compare the kind of unit tests for Catalog\n.bookInfo with the unit tests for Catalog.authorNames?\nTheo On one hand, there is only a single test case in the unit test for Catalog.book-\nInfo. On the other hand, the data involved in the test case is more complex\nthan the data involved in the test cases for Catalog.authorNames.\nJoe Exactly! Functions that appear in a deep node in the tree of function calls tend\nto require more test cases, but the data involved in the test cases is less complex.\nTIP Functions that appear in a lower level in the tree of function calls tend to\ninvolve less complex data than functions that appear in a higher level in the tree\n(see table 6.2).\n--- Page 149 ---\n6.3 Unit tests for queries 121\nTable 6.2 The correlation between the depth of a function in the tree of function calls and the\nquality and quantity of the test cases\nDepth in the tree Complexity of the data Number of test cases\nLower Higher Lower\nHigher Lower Higher\n6.3 Unit tests for queries\nIn the previous section, we saw how to write unit tests for utility functions like Catalog\n.bookInfo and Catalog.authorNames. Now, we are going to see how to write unit tests\nfor the nodes of a query tree of function calls that are close to the root of the tree.\nJoe Theo, how would you write a unit test for the code of the entry point of the\nsearch query?\nTo recall the particulars, Theo checks the code for Library.searchBooksByTitleJSON.\nAlthough Joe was right about today’s topic being easy enough to enjoy the ambience of a\ncoffee shop, he has been doing quite a lot of coding this morning.\nListing6.12 The code of Library.searchBooksByTitleJSON\nLibrary.searchBooksByTitleJSON = function (libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n};\nHe then takes a moment to think about how he’d write a unit test for that code. After\nanother Aha! moment, now he’s got it.\nTheo The inputs of Library.searchBooksByTitleJSON are library data and a\nquery string, and the output is a JSON string (see figure 6.4). So, I would cre-\nate a library data record with a single book and write tests with query strings\nthat match the name of the book and ones that don’t match.\nlibraryData query\nLibrary.searchBooksByTitleJSON()\nFigure 6.4 The input and output of\nresultsJSON Library.searchBooksByTitleJSON\nJoe What about the expected results of the test cases?\n--- Page 150 ---\n122 CHAPTER 6 Unit tests\nTheo In cases where the query string matches, the expected result is a JSON string\nwith the book info. In cases where the query string doesn’t match, the\nexpected result is a JSON string with an empty array.\nJoe Hmm...\nTheo What?\nJoe I don’t like your answer.\nTheo Why?\nJoe Because your test case relies on a string comparison instead of a data comparison.\nTheo What difference does it make? After all, the strings I’m comparing come from\nthe serialization of data.\nJoe It’s inherently much more complex to compare JSON strings than it is to com-\npare data. For example, two different strings might be the serialization of the\nsame piece of data.\nTheo Really? How?\nJoe Take a look at these two strings. They are the serialization of the same data.\nThey’re different strings because the fields appear in a different order, but in\nfact, they serialize the same data!\nJoe turns his laptop to Theo. As Theo looks at the code, he realizes that, once again, Joe\niscorrect.\nListing6.13 Two different strings that serialize the same data\nvar stringA = \"{\\\"title\\\":\\\"Watchmen\\\",\\\"publicationYear\\\":1987}\";\nvar stringB = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nTIP Avoid using a string comparison in unit tests for functions that deal with data.\nTheo I see.... Well, what can I do instead?\nJoe Instead of comparing the output of Library.searchBooksByTitleJSON with\na string, you could deserialize the output and compare it to the expected data.\nTheo What do you mean by deserialize a string?\nJoe Deserializing a string s, for example, means to generate a piece of data whose\nserialization is s.\nTheo Is there a Lodash function for string deserialization?\nJoe Actually, there is a native JavaScript function for string deserialization; it’s\ncalled JSON.parse.\nJoe retrieves his laptop and shows Theo an example of string deserialization. The code\nillustrates a common usage of JSON.parse.\nListing6.14 Example of string deserialization\nvar myString = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nvar myData = JSON.parse(myString);\n--- Page 151 ---\n6.3 Unit tests for queries 123\n_.get(myData, \"title\");\n// → \"Watchmen\"\nTheo Cool! Let me try writing a unit test for Library.searchBooksByTitleJSON\nusing JSON.parse.\nIt doesn’t take Theo too much time to come up with a piece of code. Using his laptop, he\ninputs the unit test.\nListing6.15 Unit test for Library.searchBooksByTitleJSON\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Watchmen\")),\n[bookInfo]);\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Batman\")),\n[]);\nJoe Well done! I think you’re ready to move on to the last piece of the puzzle and\nwrite the unit test for Catalog.searchBooksByTitle.",
        "sections_found": []
      },
      "accurate_page_range": "126-151"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "5 Basic concurrency control",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 44,
      "chapter_info": {
        "page": 126,
        "title": "Basic concurrency control",
        "pattern_matched": "Chapter 5",
        "text_preview": "98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. "
      },
      "chapter_sections": {
        "start_page": 126,
        "end_page": 151,
        "content": "\n--- Page 126 ---\n98 CHAPTER 5 Basic concurrency control\nTheo Would you mind if I manually expand the logic flow of that code you just wrote\nfor _.reduce?\nJoe I think it’s a great idea!\nTheo In our case, initVal is 0. It means that the first call to f will be f(0, 1). Then,\nwe’ll have f(f(0, 1), 2) and, finally, f(f(f(0, 1), 2), 3).\nJoe I like your manual expansion, Theo! Let’s make it visual.\nNow Theo goes to the whiteboard and draws a diagram. Figure 5.5 shows what that looks like.\nf\nf a\n2\nf a\n1\na 0 initVal Figure 5.5 Visualization\nof _.reduce\nTheo It’s much clearer now. I think that by implementing my custom version of\n_.reduce, it will make things 100% clear.\nIt takes Theo much less time than he expected to implement reduce(). In no time at all,\nhe shows Joe the code.\nListing5.2 Custom implementation of _.reduce\nfunction reduce(coll, f, initVal) {\nvar currentRes = initVal;\nfor (var i = 0; i < coll.length; i++) {\nWe could use\ncurrentRes = f(currentRes, coll[i])\nforEach instead\n}\nof a for loop.\nreturn currentRes;\n}\nAfter checking that Theo’s code works as expected (see listing 5.3), Joe is proud of Theo.\nHe seems to be catching on better than he anticipated.\nListing5.3 Testing the custom implementation of reduce()\nreduce([1, 2, 3], function(res, elem) {\nreturn res + elem;\n}, 0);\n// → 6\nJoe Well done!\n--- Page 127 ---\n5.4 Structural difference 99\n5.4 Structural difference\n NOTE This section deals with the implementation of a structural diff algorithm. Feel\nfree to skip this section if you don’t want to challenge your mind right now with the\ndetails of a sophisticated use of recursion. It won’t prevent you from enjoying the rest\nof the book. You can come back to this section later.\nTheo How do you calculate the diff between various versions of the system state?\nJoe That’s the most challenging part of the reconciliation algorithm. We need to\nimplement a structural diff algorithm for hash maps.\nTheo In what sense is the diff structural?\nJoe The structural diff algorithm looks at the structure of the hash maps and\nignores the order of the fields.\nTheo Could you give me an example?\nJoe Let’s start with maps without nested fields. Basically, there are three kinds of\ndiffs: field replacement, field addition, and field deletion. In order to make\nthings not too complicated, for now, we’ll deal only with replacement and\naddition.\nJoe once again goes to the whiteboard and draws table 5.3, representing the three kinds of\ndiffs. Theo is thinking the whiteboard is really starting to fill up today.\nTable 5.3 Kinds of structural differences between maps without nested fields\nKind First map Second map Diff\nReplacement {\"a\": 1} {\"a\": 2} {\"a\": 2}\nAddition {\"a\": 1} {\"a\": 1, \"b\": 2} {\"b\": 2}\nDeletion {\"a\": 1, \"b\": 2} {\"a\": 1} Not supported\nTheo I notice that the order of the maps matters a lot. What about nested fields?\nJoe It’s the same idea, but the nesting makes it a bit more difficult to grasp.\nJoe changes several of the columns in table 5.3. When he’s through, he shows Theo the\nnested fields in table 5.4.\nTable 5.4 Kinds of structural differences between maps with nested fields\nKind First map Second map Diff\nReplacement { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 2 \"x\": 2\n} } }\n} } }\n--- Page 128 ---\n100 CHAPTER 5 Basic concurrency control\nTable 5.4 Kinds of structural differences between maps with nested fields (continued)\nKind First map Second map Diff\nAddition { { {\n\"a\": { \"a\": { \"a\": {\n\"x\": 1 \"x\": 1, \"y\": 2\n} \"y\": 2, }\n} } }\n}\nDeletion { { Not supported\n\"a\": { \"a\": {\n\"x\": 1, \"y\": 2\n\"y\": 2, }\n} }\n}\n NOTE The version of the structural diff algorithm illustrated in this chapter does\nnot deal with deletions. Dealing with deletions is definitely possible, but it requires a\nmore complicated algorithm.\nTheo As you said, it’s harder to grasp. What about arrays?\nJoe We compare the elements of the arrays in order: if they are equal, the diff is\nnull; if they differ, the diff has the value of the second array.\nJoe summarizes the various kinds of diffs in another table on the whiteboard. Theo looks\nat the result in table 5.5.\nTable 5.5 Kinds of structural differences between arrays without nested elements\nKind First array Second array Diff\nReplacement [1] [2] [2]\nAddition [1] [1, 2] [null, 2]\nDeletion [1, 2] [1] Not supported\nTheo This usage of null is a bit weird but OK. Is it complicated to implement the\nstructural diff algorithm?\nJoe Definitely! It took a good dose of mental gymnastics to come up with these 30\nlines of code.\nJoe downloads the code from one his personal repositories. Theo, with thumb and forefin-\ngers touching his chin and his forehead slightly tilted, studies the code.\nListing5.4 The implementation of a structural diff\nfunction diffObjects(data1, data2) {\n_.isArray checks whether\nvar emptyObject = _.isArray(data1) ? [] : {};\nits argument is an array.\nif(data1 == data2) {\n--- Page 129 ---\n5.4 Structural difference 101\nreturn emptyObject;\n_.union creates an\n} array of unique\nvar keys = _.union(_.keys(data1), _.keys(data2)); values from two\nreturn _.reduce(keys, arrays (like union of\nfunction (acc, k) { two sets in Maths).\nvar res = diff(\n_.get(data1, k),\n_.isObject checks\n_.get(data2, k));\nwhether its argument\nif((_.isObject(res) && _.isEmpty(res)) ||\nis a collection (either\na map or an array).\n(res == \"no-diff\")) {\nreturn acc;\n_.isEmpty }\nchecks return _.set(acc, [k], res);\nwhether its },\nargument\nemptyObject);\nis an empty\n} \"no-diff\" is how\ncollection.\nwe mark that\nfunction diff(data1, data2) { two values are\nif(_.isObject(data1) && _.isObject(data2)) { the same.\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"no-diff\";\n}\nTheo Wow! It involves a recursion inside a reduce! I’m sure Dave will love this, but\nI’m too tired to understand this code right now. Let’s focus on what it does\ninstead of how it does it.\nIn order familiarize himself with the structural diff algorithm, Theo runs the algorithm\nwith examples from the table that Joe drew on the whiteboard. While Theo occupies his\nfingers with more and more complicated examples, his mind wanders in the realm of\nperformance.\nListing5.5 An example of usage of a structural diff\nvar data1 = {\n\"a\": {\n\"x\": 1,\n\"y\": [2, 3],\n\"z\": 4\n}\n};\nvar data2 = {\n\"a\": {\n\"x\": 2,\n\"y\": [2, 4],\n\"z\": 4\n}\n}\n--- Page 130 ---\n102 CHAPTER 5 Basic concurrency control\ndiff(data1, data2);\n//{\n// \"a\": {\n// \"x\": 2,\n// \"y\": [\n// undefined,\n// 4\n// ]\n// }\n//}\nTheo What about the performance of the structural diff algorithm? It seems that the\nalgorithm goes over the leaves of both pieces of data?\nJoe In the general case, that’s true. But, in the case of system data that’s manipu-\nlated with structural sharing, the code is much more efficient.\nTheo What do you mean?\nJoe With structural sharing, most of the nested objects are shared between two ver-\nsions of the system state. Therefore, most of the time, when the code enters\ndiffObjects, it will immediately return because data1 and data2 are the same.\nTIP Calculating the diff between two versions of the state is efficient because two\nhash maps created via structural sharing from the same hash map have most of their\nnodes in common.\nTheo Another benefit of immutable data... Let me see how the diff algorithm\nbehaves with concurrent mutations. I think I’ll start with a tiny library with no\nusers and a catalog with a single book, Watchmen.\nListing5.6 The data for a tiny library\nvar library = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\n--- Page 131 ---\n5.4 Structural difference 103\nJoe I suggest that we start with nonconflicting mutations. What do you suggest?\nTheo A mutation that updates the publication year of Watchmen and a mutation that\nupdates both the title of Watchmen and the name of the author of Watchmen.\nOn his laptop, Theo creates three versions of the library. He shows Joe his code, where one\nmutation updates the publication year of Watchmen, and the other one updates the title of\nWatchmen and the author’s name.\nListing5.7 Two nonconflicting mutations\nvar previous = library;\nvar next = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"],\n1986);\nvar libraryWithUpdatedTitle = _.set(\nlibrary,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"],\n\"The Watchmen\");\nvar current = _.set(\nlibraryWithUpdatedTitle,\n[\"catalog\", \"authorsById\", \"dave-gibbons\", \"name\"],\n\"David Chester Gibbons\");\nTheo I’m curious to see what the diff between previous and current looks like.\nJoe Run the code and you’ll see.\nTheo runs the code snippets for the structural diff between previous and next and for\nthe structural diff between previous and current. His curiosity satisfied, Theo finds it’s\nall beginning to make sense.\nListing5.8 Structural diff between maps with a single difference\ndiff(previous, next);\n//{\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"publicationYear\": 1986\n// }\n// }\n// }\n//}\nListing5.9 Structural diff between maps with two differences\ndiff(previous, current);\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\",\n--- Page 132 ---\n104 CHAPTER 5 Basic concurrency control\n// }\n// },\n// \"catalog\": {\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\n//\nJoe Can you give me the information path of the single field in the structural diff\nbetween previous and next?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"publicationYear\"].\nJoe Right. And what are the information paths of the fields in the structural diff\nbetween previous and current?\nTheo It’s [\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"] for the book\ntitle and [\"authorsById\", \"dave-gibbons\", \"name\"] for the author’s name.\nJoe Perfect! Now, can you figure out how to detect conflicting mutations by\ninspecting the information paths of the structural diffs?\nTheo We need to check if they have an information path in common or not.\nJoe Exactly! If they have, it means the mutations are conflicting.\nTheo But I have no idea how to write code that retrieves the information paths of a\nnested map.\nJoe Once again, it’s a nontrivial piece of code that involves a recursion inside a\nreduce. Let me download another piece of code from my repository and show\nit to you.\nListing5.10 Calculating the information paths of a (nested) map\nfunction informationPaths (obj, path = []) {\nreturn _.reduce(obj,\nfunction(acc, v, k) {\nif (_.isObject(v)) {\nreturn _.concat(acc,\ninformationPaths(v,\n_.concat(path, k)));\n}\nreturn _.concat(acc, [_.concat(path, k)]);\n},\n[]);\n}\nTheo Let me see if your code works as expected with the structural diffs of the\nmutations.\nTheo tests Joe’s code with two code snippets. The first shows the information paths of the\nstructural diff between previous and next, and the second shows the information paths\nof the structural diff between previous and current.\n--- Page 133 ---\n5.4 Structural difference 105\nListing5.11 Fields that differ between previous and next\ninformationPaths(diff(previous, next));\n// → [\"catalog.booksByIsbn.978-1779501127.publicationYear\"]\nListing5.12 Fields that differ between previous and current\ninformationPaths(diff(previous, current));\n// [\n// [\n// \"catalog\",\n// \"booksByIsbn\",\n// \"978-1779501127\",\n// \"title\"\n// ],\n// [\n// \"authorsById\",\n// \"dave-gibbons\",\n// \"name\"\n// ]\n//]\nTheo Nice! I assume that Lodash has a function that checks whether two arrays have\nan element in common.\nJoe Almost. There is _.intersection, which returns an array of the unique values\nthat are in two given arrays. For our purpose, though, we need to check\nwhether the intersection is empty. Here, look at this example.\nListing5.13 Checking whether two diff maps have a common information path\nfunction havePathInCommon(diff1, diff2) {\nreturn !_.isEmpty(_.intersection(informationPaths(diff1),\ninformationPaths(diff2)));\n}\nTheo You told me earlier that in the case of nonconflicting mutations, we can\nsafely patch the changes induced by the transition from previous to next\ninto current. How do you implement that?\nJoe We do a recursive merge between current and the diff between previous and\nnext.\nTheo Does Lodash provide an immutable version of recursive merge?\nJoe Yes, here’s another example. Take a look at this code.\nListing5.14 Applying a patch\n_.merge(current, (diff(previous, next)));\n//{\n// \"authorsById\": {\n// \"dave-gibbons\": {\n// \"name\": \"David Chester Gibbons\"\n// }\n// },\n--- Page 134 ---\n106 CHAPTER 5 Basic concurrency control\n// \"catalog\": {\n// \"authorsById\": {\n// \"alan-moore\": {\n// \"bookIsbns\": [\"978-1779501127\"]\n// \"name\": \"Alan Moore\"\n// },\n// \"dave-gibbons\": {\n// \"bookIsbns\": [\"978-1779501127\"],\n// \"name\": \"Dave Gibbons\"\n// },\n// },\n// \"booksByIsbn\": {\n// \"978-1779501127\": {\n// \"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n// \"isbn\": \"978-1779501127\",\n// \"publicationYear\": 1986,\n// \"title\": \"The Watchmen\"\n// }\n// }\n// }\n//}\nTheo Could it be as simple as this?\nJoe Indeed.\n5.5 Implementing the reconciliation algorithm\nJoe All the pieces are now in place to implement our reconciliation algorithm.\nTheo What kind of changes are required?\nJoe It only requires changes in the code of SystemState.commit. Here, look at\nthis example on my laptop.\nListing5.15 The SystemState class\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nvar nextSystemData = SystemConsistency.reconcile(\nthis.systemData,\nSystemConsistency class is\nprevious,\nimplemented in listing 5.16.\nnext);\nif(!SystemValidity.validate(previous, nextSystemData)) {\nthrow \"The system data to be committed is not valid!\";\n};\n--- Page 135 ---\n5.5 Implementing the reconciliation algorithm 107\nthis.systemData = nextSystemData;\n}\n}\nTheo How does SystemConsistency do the reconciliation?\nJoe The SystemConsistency class starts the reconciliation process by comparing\nprevious and current. If they are the same, then we fast-forward and return\nnext. Look at this code for SystemConsistency.\nListing5.16 The reconciliation flow in action\nclass SystemConsistency {\nstatic threeWayMerge(current, previous, next) {\nvar previousToCurrent = diff(previous, current);\nvar previousToNext = diff(previous, next);\nif(havePathInCommon(previousToCurrent, previousToNext)) { When the system\nreturn _.merge(current, previousToNext); state is the same\n} as the state used\nthrow \"Conflicting concurrent mutations.\"; by the calculation\n} phase, we fast-\nstatic reconcile(current, previous, next) { forward.\nif(current == previous) {\nreturn next;\n}\nreturn SystemConsistency.threeWayMerge(current,\nprevious,\nnext);\n}\n}\nTheo Wait a minute! Why do you compare previous and current by reference?\nYou should be comparing them by value, right? And, it would be quite expen-\nsive to compare all the leaves of the two nested hash maps!\nJoe That’s another benefit of immutable data. When the data is not mutated, it is\nsafe to compare references. If they are the same, we know for sure that the data\nis the same.\nTIP When data is immutable, it is safe to compare by reference, which is super fast.\nWhen the references are the same, it means that the data is the same.\nTheo What about the implementation of the three-way merge algorithm?\nJoe When previous differs from current, it means that concurrent mutations\nhave run. In order to determine whether there is a conflict, we calculate two\ndiffs: the diff between previous and current and the diff between previous\nand next. If the intersection between the two diffs is empty, it means there is\nno conflict. We can safely patch the changes between previous to next into\ncurrent.\nTheo takes a closer look at the code for the SystemConsistency class in listing 5.16. He\ntries to figure out if the code is thread-safe or not.\n--- Page 136 ---\n108 CHAPTER 5 Basic concurrency control\nTheo I think the code for SystemConsistency class is not thread-safe! If there’s a\ncontext switch between checking whether the system has changed in the\nSystemConsistency class and the updating of the state in SystemData class, a\nmutation might override the changes of a previous mutation.\nJoe You are totally right! The code works fine in a single-threaded environment\nlike JavaScript, where concurrency is handled via an event loop. However, in a\nmulti-threaded environment, the code needs to be refined in order to be\nthread-safe. I’ll show you some day.\n NOTE The SystemConsistency class is not thread-safe. We will make it thread-safe\nin chapter 8.\nTheo I think I understand why you called it optimistic concurrency control. It’s\nbecause we assume that conflicts don’t occur too often. Right?\nJoe Correct! It makes me wonder what your therapist would say about conflicts that\ncannot be resolved. Are there some cases where it’s not possible to reconcile\nthe couple?\nTheo I don’t think she ever mentioned such a possibility.\nJoe She must be a very optimistic person.\nSummary\n Optimistic concurrency control allows mutations to ask forgiveness instead of\npermission.\n Optimistic concurrency control is lock-free.\n Managing concurrent mutations of our system state with optimistic concurrency\ncontrol allows our system to support a high throughput of reads and writes.\n Optimistic concurrency control with immutable data is super efficient.\n Before updating the state, we need to reconcile the conflicts between possible con-\ncurrent mutations.\n We reconcile between concurrent mutations in a way that is similar to how Git han-\ndles a merge between two branches: either a fast-forward or a three-way merge.\n The changes required to let our system manage concurrency are only in the\ncommit phase.\n The calculation phase does its calculation as if it were the only mutation running.\n The commit phase is responsible for trying to reconcile concurrent mutations.\n The reconciliation algorithm is universal in the sense that it can be used in any sys-\ntem where the system data is represented as an immutable hash map.\n The implementation of the reconciliation algorithm is efficient, as it leverages\nthe fact that subsequent versions of the system state are created via structural\nsharing.\n In a user-facing system, conflicting concurrent mutations are fairly rare.\n When we cannot safely reconcile between concurrent mutations, we abort the\nmutation and ask the user to try again.\n--- Page 137 ---\nSummary 109\n Calculating the structural diff between two versions of the state is efficient because\ntwo hash maps created via structural sharing from the same hash map have most\nof their nodes in common.\n When data is immutable, it is safe to compare by reference, which is fast. When\nthe references are the same, it means that the data is the same.\n There are three kinds of structural differences between two nested hash maps:\nreplacement, addition, and deletion.\n Our structural diff algorithm supports replacements and additions but not\ndeletions.\nLodash functions introduced in this chapter\nFunction Description\nconcat(arrA, arrB) Creates an new array, concatenating arrA and arrB\nintersection(arrA, arrB) Creates an array of unique values both in arrA and arrB\nunion(arrA, arrB) Creates an array of unique values from arrA and arrB\nfind(coll, pred) Iterates over elements of coll, returning the first element for\nwhich pred returns true\nisEmpty(coll) Checks if coll is empty\nreduce(coll, f, initVal) Reduces coll to a value that is the accumulated result of running\neach element in coll through f, where each successive invoca-\ntion is supplied the return value of the previous\nisArray(coll) Checks if coll is an array\nisObject(coll) Checks if coll is a collection\n--- Page 138 ---\nUnit tests\nProgramming at a coffee shop\nThis chapter covers\n Generation of the minimal data input for a\ntest case\n Comparison of the output of a function with\nthe expected output\n Guidance about the quality and the quantity\nof the test cases\nIn a data-oriented system, our code deals mainly with data manipulation: most of\nour functions receive data and return data. As a consequence, it’s quite easy to\nwrite unit tests to check whether our code behaves as expected. A unit test is made\nof test cases that generate data input and compare the data output of the function\nwith the expected data output. In this chapter, we write unit tests for the queries\nand mutations that we wrote in the previous chapters.\n6.1 The simplicity of data-oriented test cases\nTheo and Joe are seated around a large wooden table in a corner of “La vie est belle,” a\nnice little French coffee shop, located near the Golden Gate Bridge. Theo orders a café\nau lait with a croissant, and Joe orders a tight espresso with a pain au chocolat. Instead\nof the usual general discussions about programming and life when they’re out of the\n110\n--- Page 139 ---\n6.1 The simplicity of data-oriented test cases 111\noffice, Joe leads the discussion towards a very concrete topic—unit tests. Theo asks Joe for\nan explanation.\nTheo Are unit tests such a simple topic that we can tackle it here in a coffee shop?\nJoe Unit tests in general, no. But unit tests for data-oriented code, yes!\nTheo Why does that make a difference?\nJoe The vast majority of the code base of a data-oriented system deals with data\nmanipulation.\nTheo Yeah. I noticed that almost all the functions we wrote so far receive data and\nreturn data.\nTIP Most of the code in a data-oriented system deals with data manipulation.\nJoe Writing a test case for functions that deal with data is only about generating\ndata input and expected output, and comparing the output of the function\nwith the expected output.\nThe steps of a test case\n1 Generate data input: dataIn\n2 Generate expected output: dataOut\n3 Compare the output of the function with the expected output: f(dataIn) and\ndataOut\nTheo That’s it?\nJoe Yes. As you’ll see in a moment, in DOP, there’s usually no need for mock\nfunctions.\nTheo I understand how to compare primitive values like strings or numbers, but I’m\nnot sure how I would compare data collections like maps.\nJoe You compare field by field.\nTheo Recursively?\nJoe Yes!\nTheo Oh no! I’m not able to write any recursive code in a coffee shop. I need the\ncalm of my office for that kind of stuff.\nJoe Don’t worry. In DOP, data is represented in a generic way. There is a generic\nfunction in Lodash called _.isEqual for recursive comparison of data collec-\ntions. It works with both maps and arrays.\nJoe opens his laptop. He is able to convince Theo by executing a few code snippets with\n_.isEqual to compare an equal data collection with a non-equal one.\nListing6.1 Comparing an equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n--- Page 140 ---\n112 CHAPTER 6 Unit tests\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n});\n// → true\nListing6.2 Comparing a non-equal data collection recursively\n_.isEqual({\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n}, {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"bad-isbn\"]\n});\n// → false\nTheo Nice!\nJoe Most of the test cases in DOP follow this pattern.\nTheo decides he wants to try this out. He fires up his laptop and types a few lines of\npseudocode.\nListing6.3 The general pattern of a data-oriented test case\nvar dataIn = {\n// input\n};\nvar dataOut = {\n// expected output\n};\n_.isEqual(f(dataIn), dataOut);\nTIP It’s straightforward to write unit tests for code that deals with data manipulation.\nTheo Indeed, this looks like something we can tackle in a coffee shop!\n6.2 Unit tests for data manipulation code\nA waiter in an elegant bow tie brings Theo his croissant and Joe his pain au chocolat. The\ntwo friends momentarily interrupt their discussion to savor their French pastries. When\nthey’re done, they ask the waiter to bring them their drinks. Meanwhile, they resume the\ndiscussion.\nJoe Do you remember the code flow of the implementation of the search query?\nTheo Let me look again at the code that implements the search query.\nTheo brings up the implementation of the search query on his laptop. Noticing that Joe is\nchewing on his nails again, he quickly checks out the code.\n--- Page 141 ---\n6.2 Unit tests for data manipulation code 113\nListing6.4 The code involved in the implementation of the search query\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nclass Library {\nstatic searchBooksByTitleJSON(libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n}\n}\n6.2.1 The tree of function calls\nThe waiter brings Theo his café au lait and Joe his tight espresso. They continue their dis-\ncussion while enjoying their coffees.\nJoe Before writing a unit test for a code flow, I find it useful to visualize the tree of\nfunction calls of the code flow.\nTheo What do you mean by a tree of function calls?\nJoe Here, I’ll draw the tree of function calls for the Library.searchBooksBy-\nTitleJSON code flow.\nJoe puts down his espresso and takes a napkin from the dispenser. He carefully places it\nflat on the table and starts to draw. When he is done, he shows the illustration to Theo (see\nfigure 6.1).\n--- Page 142 ---\n114 CHAPTER 6 Unit tests\nLibrary.searchBooksByTitleJSON\n_.get JSON.stringify Catalog.searchBooksByTitle\n_.get _.map _.filter Catalog.bookInfo\n_.get Catalog.authorNames\n_.get _.map\nFigure 6.1 The tree of function calls for the search query code flow\nTheo Nice! Can you teach me how to draw a tree of function calls like that?\nJoe Sure. The root of the tree is the name of the function for which you draw the\ntree, in our case, Library.searchBooksByTitleJSON. The children of a\nnode in the tree are the names of the functions called by the function. For exam-\nple, if you look again at the code for Library.searchBooksByTitleJSON (list-\ning 6.4), you’ll see that it calls Catalog.searchBooksByTitle, _.get, and\nJSON.stringify.\nTheo How long would I continue to recursively expand the tree?\nJoe You continue until you reach a function that doesn’t belong to the code base\nof your application. Those nodes are the leaves of our tree; for example, the\nfunctions from Lodash: _.get, _.map, and so forth.\nTheo What if the code of a function doesn’t call any other functions?\nJoe A function that doesn’t call any other function would be a leaf in the tree.\nTheo What about functions that are called inside anonymous functions like Catalog\n.bookInfo?\nJoe Catalog.bookInfo appears in the code of Catalog.searchBooksByTitle.\nTherefore, it is considered to be a child node of Catalog.searchBooksBy-\nTitle. The fact that it is nested inside an anonymous function is not relevant\nin the context of the tree of function calls.\n NOTE A tree of function calls for a function f is a tree where the root is f, and the\nchildren of a node g in the tree are the functions called by g. The leaves of the tree are\nfunctions that are not part of the code base of the application. These are functions\nthat don’t call any other functions.\nTheo It’s very cool to visualize my code as a tree, but I don’t see how it relates to\nunittests.\n--- Page 143 ---\n6.2 Unit tests for data manipulation code 115\nJoe The tree of function calls guides us about the quality and the quantity of test\ncases we should write.\nTheo How?\nJoe You’ll see in a moment.\n6.2.2 Unit tests for functions down the tree\nJoe Let’s start from the function that appears in the deepest node in our tree:\nCatalog.authorNames. Take a look at the code for Catalog.authorNames\nand tell me what are the input and the output of Catalog.authorNames.\nJoe turns his laptop so Theo can a closer look at the code. Theo takes a sip of his café au\nlait as he looks over what’s on Joe’s laptop.\nListing6.5 The code of Catalog.authorNames\nCatalog.authorNames = function (catalogData, authorIds) {\nreturn _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\n};\nTheo The input of Catalog.authorNames is catalogData and authorIds. The\noutput is authorNames.\nJoe Would you do me a favor and express it visually?\nTheo Sure.\nIt’s Theo’s turn to grab a napkin. He draws a small rectangle with two inward arrows and\none outward arrow as in figure 6.2.\ncatalogData authorIds\nCatalog.authorNames()\nFigure 6.2 Visualization of the input\nauthorNames and output of Catalog.authorNames\nJoe Excellent! Now, how many combinations of input would you include in the\nunit test for Catalog.authorNames?\nTheo Let me see.\nTheo reaches for another napkin. This time he creates a table to gather his thoughts\n(table 6.1).\n--- Page 144 ---\n116 CHAPTER 6 Unit tests\nTable 6.1 The table of test cases for Catalog.authorNames\ncatalogData authorIds authorNames\nCatalog with two authors Empty array Empty array\nCatalog with two authors Array with one author ID Array with one author name\nCatalog with two authors Array with two author IDs Array with two author names\nTheo To begin with, I would have a catalogData with two author IDs and call\nCatalog.authorNames with three arguments: an empty array, an array with a\nsingle author ID, and an array with two author IDs.\nJoe How would you generate the catalogData?\nTheo Exactly as we generated it before.\nTurning to his laptop, Theo writes the code for catalogData. He shows it to Joe.\nListing6.6 A complete catalogData map\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"],\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-2\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\n--- Page 145 ---\n6.2 Unit tests for data manipulation code 117\nJoe You could use your big catalogData map for the unit test, but you could also\nuse a smaller map in the context of Catalog.authorNames. You can get rid of\nthe booksByIsbn field of the catalogData and the bookIsbns fields of the\nauthors.\nJoe deletes a few lines from catalogData and gets a much smaller map. He shows the revi-\nsion to Theo.\nListing6.7 A minimal version of catalogData\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nTheo Wait a minute! This catalogData is not valid.\nJoe In DOP, data validity depends on the context. In the context of Library\n.searchBooksByTitleJSON and Catalog.searchBooksByTitle, the mini-\nmal version of catalogData is indeed not valid. However, in the context of\nCatalog.bookInfo and Catalog.authorNames, it is perfectly valid. The reason\nis that those two functions access only the authorsById field of catalogData.\nTIP The validity of the data depends on the context.\nTheo Why is it better to use a minimal version of the data in a test case?\nJoe For a very simple reason—the smaller the data, the easier it is to manipulate.\nTIP The smaller the data, the easier it is to manipulate.\nTheo I’ll appreciate that when I write the unit tests!\nJoe Definitely! One last thing before we start coding: how would you check that the\noutput of Catalog.authorNames is as expected?\nTheo I would check that the value returned by Catalog.authorNames is an array\nwith the expected author names.\nJoe How would you handle the array comparison?\nTheo Let me think. I want to compare by value, not by reference. I guess I’ll have to\ncheck that the array is of the expected size and then check member by mem-\nber, recursively.\nJoe That’s too much of a mental burden when you’re in a coffee shop. As I showed\nyou earlier (see listing 6.1), we can recursively compare two data collections by\nvalue with _.isEqual from Lodash.\n--- Page 146 ---\n118 CHAPTER 6 Unit tests\nTIP We can compare the output and the expected output of our functions with\n_.isEqual.\nTheo Sounds good! Let me write the test cases.\nTheo starts typing on his laptop. After a few minutes, he has some test cases for Catalog\n.authorNames, each made from a function call to Catalog.authorNames wrapped in\n_.isEqual.\nListing6.8 Unit test for Catalog.authorNames\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(\ncatalogData,\n[\"alan-moore\"]),\n[\"Alan Moore\"]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\", \"dave-gibbons\"]),\n[\"Alan Moore\", \"Dave Gibbons\"]);\nJoe Well done! Can you think of more test cases?\nTheo Yes. There are test cases where the author ID doesn’t appear in the catalog\ndata, and test cases with empty catalog data. With minimal catalog data and\n_.isEqual, it’s really easy to write lots of test cases!\nTheo really enjoys this challenge. He creates a few more test cases to present to Joe.\nListing6.9 More test cases for Catalog.authorNames\n_.isEqual(Catalog.authorNames({}, []), []);\n_.isEqual(Catalog.authorNames({}, [\"alan-moore\"]), [undefined]);\n_.isEqual(Catalog.authorNames(catalogData, [\"alan-moore\",\n\"albert-einstein\"]), [\"Alan Moore\", undefined]);\n_.isEqual(Catalog.authorNames(catalogData, []), []);\n_.isEqual(Catalog.authorNames(catalogData, [\"albert-einstein\"]),\n[undefined]);\nTheo How do I run these unit tests?\nJoe You use your preferred test framework.\n--- Page 147 ---\n6.2 Unit tests for data manipulation code 119\n NOTE We don’t deal here with test runners and test frameworks. We deal only with\nthe logic of the test cases.\n6.2.3 Unit tests for nodes in the tree\nTheo I’m curious to see what unit tests for an upper node in the tree of function calls\nlook like.\nJoe Sure. Let’s write a unit test for Catalog.bookInfo. How many test cases would\nyou have for Catalog.bookInfo?\nListing6.10 The code of Catalog.bookInfo\nCatalog.bookInfo = function (catalogData, book) {\nreturn {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData,\n_.get(book, \"authorIds\"))\n};\n};\nTheo takes another look at the code for Catalog.bookInfo on his laptop. Then, reaching\nfor another napkin, he draws a diagram of its input and output (see figure 6.3).\ncatalogData book\nCatalog.bookInfo()\nFigure 6.3 Visualization of the input\nbookInfo and output of Catalog.bookInfo\nTheo I would have a similar number of test cases for Catalog.authorNames: a book\nwith a single author, with two authors, with existing authors, with non-existent\nauthors, with...\nJoe Whoa! That’s not necessary. Given that we have already written unit tests for\nCatalog.authorNames, we don’t need to check all the cases again. We simply\nneed to write a minimal test case to confirm that the code works.\nTIP When we write a unit test for a function, we assume that the functions called by\nthis function are covered by unit tests and work as expected. It significantly reduces\nthe quantity of test cases in our unit tests.\nTheo That makes sense.\nJoe How would you write a minimal test case for Catalog.bookInfo?\nTheo once again takes a look at the code for Catalog.bookInfo (see listing 6.10). Now he\ncan answer Joe’s question.\n--- Page 148 ---\n120 CHAPTER 6 Unit tests\nTheo I would use the same catalog data as for Catalog.authorNames and a book\nrecord. I’d test that the function behaves as expected by comparing its return\nvalue with a book info record using _.isEqual. Here, let me show you.\nIt takes Theo a bit more time to write the unit test. The reason is that the input and the\noutput of Catalog.authorNames are both records. Dealing with a record is more complex\nthan dealing with an array of strings (as it was the case for Catalog.authorNames). Theo\nappreciates the fact that _.isEqual saves him from writing code that compares the two\nmaps property by property. When he’s through, he shows the result to Joe and takes a nap-\nkin to wipe his forehead.\nListing6.11 Unit test for Catalog.bookInfo\nvar catalogData = {\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\"\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\"\n}\n}\n};\nvar book = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\", \"dave-gibbons\"]\n};\nvar expectedResult = {\n\"authorNames\": [\"Alan Moore\", \"Dave Gibbons\"],\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n};\nvar result = Catalog.bookInfo(catalogData, book);\n_.isEqual(result, expectedResult);\nJoe Perfect! Now, how would you compare the kind of unit tests for Catalog\n.bookInfo with the unit tests for Catalog.authorNames?\nTheo On one hand, there is only a single test case in the unit test for Catalog.book-\nInfo. On the other hand, the data involved in the test case is more complex\nthan the data involved in the test cases for Catalog.authorNames.\nJoe Exactly! Functions that appear in a deep node in the tree of function calls tend\nto require more test cases, but the data involved in the test cases is less complex.\nTIP Functions that appear in a lower level in the tree of function calls tend to\ninvolve less complex data than functions that appear in a higher level in the tree\n(see table 6.2).\n--- Page 149 ---\n6.3 Unit tests for queries 121\nTable 6.2 The correlation between the depth of a function in the tree of function calls and the\nquality and quantity of the test cases\nDepth in the tree Complexity of the data Number of test cases\nLower Higher Lower\nHigher Lower Higher\n6.3 Unit tests for queries\nIn the previous section, we saw how to write unit tests for utility functions like Catalog\n.bookInfo and Catalog.authorNames. Now, we are going to see how to write unit tests\nfor the nodes of a query tree of function calls that are close to the root of the tree.\nJoe Theo, how would you write a unit test for the code of the entry point of the\nsearch query?\nTo recall the particulars, Theo checks the code for Library.searchBooksByTitleJSON.\nAlthough Joe was right about today’s topic being easy enough to enjoy the ambience of a\ncoffee shop, he has been doing quite a lot of coding this morning.\nListing6.12 The code of Library.searchBooksByTitleJSON\nLibrary.searchBooksByTitleJSON = function (libraryData, query) {\nvar catalogData = _.get(libraryData, \"catalog\");\nvar results = Catalog.searchBooksByTitle(catalogData, query);\nvar resultsJSON = JSON.stringify(results);\nreturn resultsJSON;\n};\nHe then takes a moment to think about how he’d write a unit test for that code. After\nanother Aha! moment, now he’s got it.\nTheo The inputs of Library.searchBooksByTitleJSON are library data and a\nquery string, and the output is a JSON string (see figure 6.4). So, I would cre-\nate a library data record with a single book and write tests with query strings\nthat match the name of the book and ones that don’t match.\nlibraryData query\nLibrary.searchBooksByTitleJSON()\nFigure 6.4 The input and output of\nresultsJSON Library.searchBooksByTitleJSON\nJoe What about the expected results of the test cases?\n--- Page 150 ---\n122 CHAPTER 6 Unit tests\nTheo In cases where the query string matches, the expected result is a JSON string\nwith the book info. In cases where the query string doesn’t match, the\nexpected result is a JSON string with an empty array.\nJoe Hmm...\nTheo What?\nJoe I don’t like your answer.\nTheo Why?\nJoe Because your test case relies on a string comparison instead of a data comparison.\nTheo What difference does it make? After all, the strings I’m comparing come from\nthe serialization of data.\nJoe It’s inherently much more complex to compare JSON strings than it is to com-\npare data. For example, two different strings might be the serialization of the\nsame piece of data.\nTheo Really? How?\nJoe Take a look at these two strings. They are the serialization of the same data.\nThey’re different strings because the fields appear in a different order, but in\nfact, they serialize the same data!\nJoe turns his laptop to Theo. As Theo looks at the code, he realizes that, once again, Joe\niscorrect.\nListing6.13 Two different strings that serialize the same data\nvar stringA = \"{\\\"title\\\":\\\"Watchmen\\\",\\\"publicationYear\\\":1987}\";\nvar stringB = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nTIP Avoid using a string comparison in unit tests for functions that deal with data.\nTheo I see.... Well, what can I do instead?\nJoe Instead of comparing the output of Library.searchBooksByTitleJSON with\na string, you could deserialize the output and compare it to the expected data.\nTheo What do you mean by deserialize a string?\nJoe Deserializing a string s, for example, means to generate a piece of data whose\nserialization is s.\nTheo Is there a Lodash function for string deserialization?\nJoe Actually, there is a native JavaScript function for string deserialization; it’s\ncalled JSON.parse.\nJoe retrieves his laptop and shows Theo an example of string deserialization. The code\nillustrates a common usage of JSON.parse.\nListing6.14 Example of string deserialization\nvar myString = \"{\\\"publicationYear\\\":1987,\\\"title\\\":\\\"Watchmen\\\"}\";\nvar myData = JSON.parse(myString);\n--- Page 151 ---\n6.3 Unit tests for queries 123\n_.get(myData, \"title\");\n// → \"Watchmen\"\nTheo Cool! Let me try writing a unit test for Library.searchBooksByTitleJSON\nusing JSON.parse.\nIt doesn’t take Theo too much time to come up with a piece of code. Using his laptop, he\ninputs the unit test.\nListing6.15 Unit test for Library.searchBooksByTitleJSON\nvar libraryData = {\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Watchmen\")),\n[bookInfo]);\n_.isEqual(JSON.parse(Library.searchBooksByTitleJSON(libraryData,\n\"Batman\")),\n[]);\nJoe Well done! I think you’re ready to move on to the last piece of the puzzle and\nwrite the unit test for Catalog.searchBooksByTitle.",
        "sections_found": []
      },
      "accurate_page_range": "126-151"
    },
    {
      "text": "- 6.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 45,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- 6.1 The simplicity of data-oriented test cases",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.1 The simplicity of data-oriented test cases (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 46,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- 6.2.0 Introduction (사용자 추가)",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.2.0 Introduction (사용자 추가) (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 47,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- 6.2.1 The tree of function calls",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.2.1 The tree of function calls (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 48,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- 6.2.2 Unit tests for functions down the tree",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.2.2 Unit tests for functions down the tree (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 49,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- 6.2.3 Unit tests for nodes in the tree",
      "node_level": 4,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.2.3 Unit tests for nodes in the tree (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 50,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- 6.3 Unit tests for queries",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.3 Unit tests for queries (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 51,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- 6.4 Unit tests for mutations",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- 6.4 Unit tests for mutations (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 52,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- Moving forward",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- Moving forward (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 53,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "6 Unit tests",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 54,
      "chapter_info": {
        "page": 152,
        "title": "Unit tests",
        "pattern_matched": "Chapter 6",
        "text_preview": "124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again "
      },
      "chapter_sections": {
        "start_page": 152,
        "end_page": 175,
        "content": "\n--- Page 152 ---\n124 CHAPTER 6 Unit tests\nBecause Theo and Joe have been discussing unit tests for quite some time, he asks Joe if he\nwould like another espresso. They call the waiter and order, then Theo looks again at the\ncode for Catalog.searchBooksByTitle.\nListing6.16 The code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nWriting the unit test for Catalog.searchBooksByTitle is a more pleasant experience for\nTheo than writing the unit test for Library.searchBooksByTitleJSON. He appreciates\nthis for two reasons:\n It’s not necessary to deserialize the output because the function returns data.\n It’s not necessary to wrap the catalog data in a library data map.\nListing6.17 Unit test for Catalog.searchBooksByTitle\nvar catalogData = {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n};\nvar bookInfo = {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n};\n--- Page 153 ---\n6.3 Unit tests for queries 125\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Watchmen\"), [bookInfo]);\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"Batman\"), []);\nJoe That’s a good start!\nTheo I thought I was done. What did I miss?\nJoe You forgot to test cases where the query string is all lowercase.\nTheo You’re right! Let me quickly add one more test case.\nIn less than a minute, Theo creates an additional test case and shows it to Joe. What a dis-\nappointment when Theo discovers that the test case with \"watchmen\" in lowercase fails!\nListing6.18 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe Don’t be too upset, my friend. After all, the purpose of unit tests is to find bugs\nin the code so that you can fix them. Can you fix the code of Catalog-\nData.searchBooksByTitle?\nTheo Sure. All I need to do is to lowercase both the query string and the book title\nbefore comparing them. I’d probably do something like this.\nListing6.19 Fixed code of Catalog.searchBooksByTitle\nCatalog.searchBooksByTitle = function(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nConverts the query\nvar matchingBooks = _.filter(allBooks, function(book) {\nto lowercase\nreturn _.get(book, \"title\")\n.toLowerCase()\nConverts the book\n.includes(queryLowerCased);\ntitle to lowercase\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nAfter fixing the code of Catalog.searchBooksByTitle, Theo runs all the test cases\nagain. This time, all of them pass—what a relief!\nListing6.20 Additional test case for Catalog.searchBooksByTitle\n_.isEqual(Catalog.searchBooksByTitle(catalogData, \"watchmen\"),\n[bookInfo]);\nJoe It’s such good feeling when all the test cases pass.\nTheo Sure is.\nJoe I think we’ve written unit tests for all the search query code, so now we’re ready\nto write unit tests for mutations. Thank goodness the waiter just brought our\ncoffee orders.\n--- Page 154 ---\n126 CHAPTER 6 Unit tests\n6.4 Unit tests for mutations\nJoe Before writing unit tests for the add member mutation, let’s draw the tree of\nfunction calls for System.addMember.\nTheo I can do that.\nTheo takes a look at the code for the functions involved in the add member mutation. He\nnotices the code is spread over three classes: System, Library, and UserManagement.\nListing6.21 The functions involved in the add member mutation\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nLibrary.addMember = function(library, member) {\nvar currentUserManagement = _.get(library, \"userManagement\");\nvar nextUserManagement = UserManagement.addMember(\ncurrentUserManagement, member);\nvar nextLibrary = _.set(library, \"userManagement\", nextUserManagement);\nreturn nextLibrary;\n};\nUserManagement.addMember = function(userManagement, member) {\nvar email = _.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(_.has(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = _.set(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo grabs another napkin. Drawing the tree of function calls for System.addMember is\nnow quite easy (see figure 6.5).\nSystem.addMember\nSystemState.get SystemState.commit Library.addMember\n_.get _.set UserManagement.addMember\n_.has _.set\nFigure 6.5 The tree of function calls for System.addMember\n--- Page 155 ---\n6.4 Unit tests for mutations 127\nJoe Excellent! So which functions of the tree should be unit tested for the add\nmember mutation?\nTheo I think the functions we need to test are System.addMember, SystemState\n.get, SystemState.commit, Library.addMember, and UserManagement\n.addMember. That right?\nJoe You’re totally right. Let’s defer writing unit tests for functions that belong to\nSystemState until later. Those are generic functions that should be tested\noutside the context of a specific mutation. Let’s assume for now that we’ve\nalready written unit tests for the SystemState class. We’re left with three func-\ntions: System.addMember, Library.addMember, and UserManagement.add-\nMember.\nTheo In what order should we write the unit tests, bottom up or top down?\nJoe Let’s start where the real meat is—in UserManagement.addMember. The two\nother functions are just wrappers.\nTheo OK.\nJoe Writing a unit test for the main function of a mutation requires more effort\nthan writing the test for a query. The reason is that a query returns a response\nbased on the system data, whereas a mutation computes a new state of the system\nbased on the current state of the system and some arguments (see figure 6.6).\nSystemData Argument Argument SystemData\nMutation Query\nNextSystemData ResponseData\nFigure 6.6 The output of a mutation is more complex than\nthe output of a query.\nTIP Writing a unit test for the main function of a mutation requires more effort than\nfor a query.\nTheo It means that in the test cases of UserManagement.addMember, both the input\nand the expected output are maps that describe the state of the system.\nJoe Exactly. Let’s start with the simplest case, where the initial state of the system\nis empty.\nTheo You mean that userManagementData passed to UserManagement.addMember\nis an empty map?\nJoe Yes.\nOnce again, Theo places his hands over his laptop keyboard, thinks for a moment, and\nbegins typing. He reminds himself that the code needs to add a member to an empty user\n--- Page 156 ---\n128 CHAPTER 6 Unit tests\nmanagement map and to check that the resulting map is as expected. When he’s finished,\nhe shows his code to Joe.\nListing6.22 Test case for Catalog.addMember without members\nvar member = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, member);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Very nice! Keep going and write a test case when the initial state is not empty.\nTheo knows this requires a few more lines of code but nothing complicated. When he fin-\nishes, he once again shows the code to Joe.\nListing6.23 Test case for Catalog.addMember with existing members\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar expectedUserManagementStateAfter = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n--- Page 157 ---\n6.4 Unit tests for mutations 129\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n};\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\n_.isEqual(result, expectedUserManagementStateAfter);\nJoe Awesome! Can you think of other test cases for UserManagement.addMember?\nTheo No.\nJoe What about cases where the mutation fails?\nTheo Right! I always forget to think about negative test cases. I assume that relates to\nthe fact that I’m an optimistic person.\nTIP Don’t forget to include negative test cases in your unit tests.\nJoe Me too. The more I meditate, the more I’m able to focus on the positive side of\nlife. Anyway, how would you write a test case where the mutation fails?\nTheo I would pass to UserManagement.addMember a member that already exists in\nuserManagementStateBefore.\nJoe And how would you check that the code behaves as expected in case of a failure?\nTheo Let me see. When a member already exists, UserManagement.addMember\nthrows an exception. Therefore, what I need to do in my test case is to wrap the\ncode in a try/catch block.\nJoe Sounds good to me.\nOnce again, it doesn’t require too much of an effort for Theo to create a new test case.\nWhen he’s finished, he eagerly turns his laptop to Joe.\nListing6.24 Test case for UserManagement.addMember if it’s expected to fail\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar userManagementStateBefore = {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n}\n}\n};\n--- Page 158 ---\n130 CHAPTER 6 Unit tests\nvar expectedException = \"Member already exists.\";\nvar exceptionInMutation;\ntry {\nUserManagement.addMember(userManagementStateBefore, jessie);\n} catch (e) {\nexceptionInMutation = e;\n}\n_.isEqual(exceptionInMutation, expectedException);\nTheo Now, I think I’m ready to move forward and write unit tests for Library.add-\nMember and System.addMember.\nJoe I agree with you. Please start with Library.addMember.\nTheo Library.addMember is quite similar to UserManagement.addMember. So I\nguess I’ll write similar test cases.\nJoe In fact, that won’t be required. As I told you when we wrote unit tests for a\nquery, when you write a unit test for a function, you can assume that the func-\ntions down the tree work as expected.\nTheo Right. So I’ll just write the test case for existing members.\nJoe Go for it!\nTheo starts with a copy-and-paste of the code from the UserManagement.addMember test\ncase with the existing members in listing 6.23. After a few modifications, the unit test for\nLibrary.addMember is ready.\nListing6.25 Unit test for Library.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 159 ---\n6.4 Unit tests for mutations 131\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar result = Library.addMember(libraryStateBefore, jessie);\n_.isEqual(result, expectedLibraryStateAfter);\nJoe Beautiful! Now, we’re ready for the last piece. Write a unit test for System\n.addMember. Before you start, could you please describe the input and the out-\nput of System.addMember?\nTheo takes another look at the code for System.addMember and hesitates; he’s a bit con-\nfused. The function doesn’t seem to return anything!\nListing6.26 The code of System.addMember\nSystem.addMember = function(systemState, member) {\nvar previous = systemState.get();\nvar next = Library.addMember(previous, member);\nsystemState.commit(previous, next);\n};\nTheo The input of System.addMember is a system state instance and a member. But,\nI’m not sure what the output of System.addMember is.\nJoe In fact, System.addMember doesn’t have any output. It belongs to this stateful\npart of our code that doesn’t deal with data manipulation. Although DOP\nallows us to reduce the size of the stateful part of our code, it still exists. Here is\nhow I visualize it.\nJoe calls the waiter to see if he can get more napkins. With that problem resolved, he draws\nthe diagram in figure 6.7.\nSystemData Member\nMutation Change system state\nFigure 6.7 System.addMember\ndoesn’t return data—it changes the\nNothing system state!\n--- Page 160 ---\n132 CHAPTER 6 Unit tests\nTheo Then how do we validate that the code works as expected?\nJoe We’ll retrieve the system state after the code is executed and compare it to the\nexpected value of the state.\nTheo OK. I’ll try to write the unit test.\nJoe Writing unit tests for stateful code is more complicated than for data manipula-\ntion code. It requires the calm of the office.\nTheo Then let’s go back to the office. Waiter! Check, please.\nTheo picks up the tab, and he and Joe take the cable car back to Albatross. When they’re\nback at the office, Theo starts coding the unit test for Library.addMember.\nTheo Can we use _.isEqual with system state?\nJoe Definitely. The system state is a map like any other map.\nTIP The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state using\n_.isEqual\nTheo copies and pastes the code for Library.addMember (listing 6.21), which initializes\nthe data for the test. Then, he passes a SystemState object that is initialized with\nlibraryStateBefore to System.addMember. Finally, to complete the test, he compares\nthe system state after the mutation is executed with the expected value of the state.\nclass SystemState {\nsystemState;\nget() {\nreturn this.systemState;\n}\ncommit(previous, next) {\nthis.systemState = next;\n}\n}\nwindow.SystemState = SystemState;\nListing6.27 Unit test for System.addMember\nvar jessie = {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n};\nvar franck = {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n};\nvar libraryStateBefore = {\n\"userManagement\": {\n\"membersByEmail\": {\n--- Page 161 ---\n6.4 Unit tests for mutations 133\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n}\n};\nvar expectedLibraryStateAfter = {\n\"userManagement\": {\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\nCreates an empty\n}\nSystemState object\n}\n(see chapter 4)\n}\n};\nInitializes the system\nstate with the library\ndata before the\nvar systemState = new SystemState();\nmutation\nsystemState.commit(null, libraryStateBefore);\nSystem.addMember(systemState, jessie);\nExecutes the\nmutation on the\n_.isEqual(systemState.get(),\nSystemState object\nexpectedLibraryStateAfter);\nValidates the state after the\nmutation is executed\nJoe Wow, I’m impressed; you did it! Congratulations!\nTheo Thank you. I’m so glad that in DOP most of our code deals with data manipu-\nlation. It’s definitely more pleasant to write unit tests for stateless code that\nonly deals with data manipulation.\nJoe Now that you know the basics of DOP, would you like to refactor the code of\nyour Klafim prototype according to DOP principles?\nTheo Definitely. Nancy told me yesterday that Klafim is getting nice market traction.\nI’m supposed to have a meeting with her in a week or so about the next steps.\nHopefully, she’ll be willing to work with Albatross for the long term.\nJoe Exciting! Do you know what might influence Nancy’s decision?\nTheo Our cost estimate, certainly, but I know she’s in touch with other software com-\npanies. If we come up with a competitive proposal, I think we’ll get the deal.\nJoe I’m quite sure that after refactoring to DOP, features will take much less time\nto implement. That means you should be able to quote Nancy a lower total cost\nthan the competition, right?\nTheo I’ll keep my fingers crossed!\n--- Page 162 ---\n134 CHAPTER 6 Unit tests\nMoving forward\nThe meeting with Nancy went well. Albatross got the deal, Monica (Theo’s boss) is\npleased, and it’s going to be a long-term project with a nice budget. They’ll need to hire a\nteam of developers in order to meet the tough deadlines. While driving back to the office,\nTheo gets a phone call from Joe.\nJoe How was your meeting with Nancy?\nTheo We got the deal!\nJoe Awesome! I told you that with DOP the cost estimation would be lower.\nTheo In fact, we are not going to use DOP for this project.\nJoe Why?\nTheo After refactoring the Library Management System prototype to DOP, I did a\ndeep analysis with my engineers. We came to the conclusion that DOP might\nbe a good fit for the prototype phase, but it won’t work well at scale.\nJoe Could you share the details of your analysis?\nTheo I can’t right now. I’m driving.\nJoe Could we meet in your office later today?\nTheo I’m quite busy with the new project and the tough deadlines.\nJoe Let’s meet at least in order to have a proper farewell.\nTheo OK. Let’s meet at 4 PM, then.\n NOTE The story continues in the opener of part 2.\nSummary\n Most of the code in a data-oriented system deals with data manipulation.\n It’s straightforward to write unit tests for code that deals with data manipulation.\n Test cases follow the same simple general pattern:\na Generate data input\nb Generate expected data output\nc Compare the output of the function with the expected data output\n In order to compare the output of a function with the expected data output, we\nneed to recursively compare the two pieces of data.\n The recursive comparison of two pieces of data is implemented via a generic\nfunction.\n When a function returns a JSON string, we parse the string back to data so that\nwe deal with data comparison instead of string comparison.\n A tree of function calls for a function f is a tree where the root is f, and the chil-\ndren of a node g in the tree are the functions called by g.\n The leaves of the tree are functions that are not part of the code base of the\napplication and are functions that don’t call any other functions.\n The tree of function calls visualization guides us regarding the quality and\nquantity of the test cases in a unit test.\n--- Page 163 ---\nSummary 135\n Functions that appear in a lower level in the tree of function calls tend to involve\nless complex data than functions that appear in a higher level in the tree.\n Functions that appear in a lower level in the tree of function calls usually need\nto be covered with more test cases than functions that appear in a higher level\nin the tree.\n Unit tests for mutations focus on the calculation phase of the mutation.\n The validity of the data depends on the context.\n The smaller the data, the easier it is to manipulate.\n We compare the output and the expected output of our functions with a generic\nfunction that recursively compares two pieces of data (e.g., _.isEqual).\n When we write a unit test for a function, we assume that the functions called by\nthis function are covered by the unit tests and work as expected. This signifi-\ncantly reduces the quantity of test cases in our unit tests.\n We avoid using string comparison in unit tests for functions that deal with data.\n Writing a unit test for the main function of a mutation requires more effort\nthan for a query.\n Remember to include negative test cases in your unit tests.\n The system state is a map. Therefore, in the context of a test case, we can com-\npare the system state after a mutation is executed to the expected system state\nusing a generic function like _.isEqual.\n--- Page 164 ---\n\n--- Page 165 ---\nPart 2\nScalability\nT\nheo feels a bit uncomfortable about the meeting with Joe. He was so enthusias-\ntic about DOP, and he was very good at teaching it. Every meeting with him was an\nopportunity to learn new things. Theo feels lot of gratitude for the time Joe spent\nwith him. He doesn’t want to hurt him in any fashion. Surprisingly, Joe enters the\noffice with the same relaxed attitude as usual, and he is even smiling.\nJoe I’m really glad that you got the deal with Nancy.\nTheo Yeah. There’s lot of excitement about it here in the office, and a bit of\nstress too.\nJoe What kind of stress?\nTheo You know.... We need to hire a team of developers, and the deadlines\nare quite tight.\nJoe But you told me that you won’t use DOP. I assume that you gave regular\ndeadlines?\nTheo No, my boss Monica really wanted to close the deal. She feels that success\nwith this project is strategically important for Albatross, so it’s worthwhile\nto accept some risk by giving what she calls an “optimistic” time estima-\ntion. I told her that it was really an unrealistic time estimation, but Mon-\nica insists that if we make smart decisions and bring in more developers,\nwe can do it.\nJoe I see. Now I understand why you told me over the phone that you were\nvery busy. Anyway, would you please share the reasons that made you\nthink DOP wouldn’t be a good fit at scale?\n--- Page 166 ---\n138 PART 2 Scalability\nTheo First of all, let me tell you that I feel lot of gratitude for all the teaching you\nshared with me. Reimplementing the Klafim prototype with DOP was really\nfun and productive due to the flexibility this paradigm offers.\nJoe I’m happy that you found it valuable.\nTheo But, as I told you over the phone, now we’re scaling up into a long-term project\nwith several developers working on a large code base. We came to the conclu-\nsion that DOP will not be a good fit at scale.\nJoe Could you share the reasons behind your conclusion?\nTheo There are many of them. First of all, as DOP deals only with generic data struc-\ntures, it’s hard to know what kind of data we have in hand, while in OOP, we\nknow the type of every piece of data. For the prototype, it was kind of OK. But\nas the code base grows and more developers are involved in the project, it\nwould be too painful.\nJoe I hear you. What else, my friend?\nTheo Our system is going to run on a multi-threaded environment. I reviewed the\nconcurrency control strategy that you presented, and it’s not thread-safe.\nJoe I hear you. What else, my friend?\nTheo I have been doing a bit of research about implementing immutable data struc-\ntures with structural sharing. I discovered that when the size of the data\nstructures grows, there is a significant performance hit.\nJoe I hear you. What else?\nTheo As our system grows, we will use a database to store the application data and\nexternal services to enrich book information, and in what you have showed me\nso far, data lives in memory.\nJoe I hear you. What else, my friend?\nTheo Don’t you think I have shared enough reasons to abandon DOP?\nJoe I think that your concerns about DOP at scale totally make sense. However, it\ndoesn’t mean that you should abandon DOP.\nTheo What do you mean?\nJoe With the help of meditation, I learned not be attached to the objections that\nflow in my mind while I’m practicing. Sometimes all that is needed to quiet our\nminds is to keep breathing; sometimes, a deeper level of practice is needed.\nTheo I don’t see how breathing would convince me to give DOP a second chance.\nJoe Breathing might not be enough in this case, but a deeper knowledge of DOP\ncould be helpful. Until now, I have shared with you only the material that was\nneeded in order to refactor your prototype. In order to use DOP in a big proj-\nect, a few more lessons are necessary.\nTheo But I don’t have time for more lessons. I need to work.\nJoe Have you heard the story about the young woodcutter and the old man?\nTheo No.\nJoe It goes like this.\n--- Page 167 ---\nPART 2 Scalability 139\nThe young woodcutter and the old man\nA young woodcutter strained to saw down a tree. An old man who was watching near-\nby asked, “What are you doing?”\n“Are you blind?” the woodcutter replied. “I’m cutting down this tree.”\nThe old man replied, “You look exhausted! Take a break. Sharpen your saw.”\nThe young woodcutter explained to the old man that he had been sawing for hours\nand did not have time to take a break.\nThe old man pushed back, “If you sharpen the saw, you would cut down the tree much\nfaster.”\nThe woodcutter said, “I don’t have time to sharpen the saw. Don’t you see, I’m too\nbusy!”\nTheo takes a moment to meditate on the story. He wonders if he needs to take the time to\nsharpen his saw and commit to a deeper level of practice.\nTheo Do you really think that with DOP, it will take much less time to deliver the\nproject?\nJoe I know so!\nTheo But if we miss the deadline, I will probably get fired. I’m the one that needs to\ntake the risk, not you.\nJoe Let’s make a deal. If you miss the deadline and get fired, I will hire you at my\ncompany for double the salary you make at Albatross.\nTheo And what if we meet the deadline?\nJoe If you meet the deadline, you will probably get promoted. In that case, I will\nask you to buy a gift for my son Neriah and my daughter Aurelia.\nTheo Deal! When will I get my first lesson about going deeper into DOP?\nJoe Why not start right now?\nTheo Let me reschedule my meetings.\n--- Page 168 ---\n\n--- Page 169 ---\nBasic data validation\nA solemn gift\nThis chapter covers\n The importance of validating data at system\nboundaries\n Validating data using the JSON Schema language\n Integrating data validation into an existing code\nbase\n Getting detailed information about data validation\nfailures\nAt first glance, it may seem that embracing DOP means accessing data without validat-\ning it and engaging in wishful thinking, where data is always valid. In fact, data valida-\ntion is not only possible but recommended when we follow data-oriented principles.\nThis chapter illustrates how to validate data when data is represented with\ngeneric data structures. It focuses on data validation occurring at the boundaries of\nthe system, while in part 3, we will deal with validating data as it flows through the\nsystem. This chapter is a deep dive into the fourth principle of DOP.\nPRINCIPLE #4 Separate data schema from data representation.\n141\n--- Page 170 ---\n142 CHAPTER 7 Basic data validation\n7.1 Data validation in DOP\nTheo has rescheduled his meetings. With such an imposing deadline, he’s still not sure if\nhe’s made a big mistake giving DOP a second chance.\n NOTE The reason why Theo rescheduled his meetings is explained in the opener\nfor part 2. Take a moment to read the opener if you missed it.\nJoe What aspect of OOP do you think you will miss the most in your big project?\nTheo Data validation.\nJoe Can you elaborate a bit?\nTheo In OOP, I have this strong guarantee that when a class is instantiated, its mem-\nber fields have the proper names and proper types. But with DOP, it’s so easy\nto have small mistakes in field names and field types.\nJoe Well, I have good news for you! There is a way to validate data in DOP.\nTheo How does it work? I thought DOP and data validation were two contradictory\nconcepts!\nJoe Not at all. It’s true that DOP doesn’t force you to validate data, but it doesn’t\nprevent you from doing so. In DOP, the data schema is separate from the data\nrepresentation.\nTheo I don’t get how that would eliminate data consistency issues.\nJoe According to DOP, the most important data to validate is data that crosses the\nboundaries of the system.\nTheo Which boundaries are you referring to?\nJoe In the case of a web server, it would be the areas where the web server commu-\nnicates with its clients and with its data sources.\nTheo A diagram might help me see it better.\nJoe goes to the whiteboard and picks up the pen. He then draws a diagram like the one in\nfigure 7.1.\nClient (e.g., web browser)\nData\nWeb server\nData Data\nWeb service Database Figure 7.1 High-level architecture of\na modern web server\n--- Page 171 ---\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n--- Page 172 ---\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n--- Page 173 ---\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n--- Page 174 ---\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n--- Page 175 ---\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer",
        "sections_found": []
      },
      "accurate_page_range": "152-175"
    },
    {
      "text": "- Part2 Introduction content",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "6 Unit tests",
      "raw_line": "- Part2 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 55,
      "accurate_page_range": "171-175",
      "extracted_content": "\n=== Page 171 ===\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n\n=== Page 172 ===\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n\n=== Page 173 ===\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n\n=== Page 174 ===\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\n=== Page 175 ===\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer"
    },
    {
      "text": "- Part2 Introduction content",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "Part2 Introduction (사용자 추가)",
      "raw_line": "- Part2 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 56,
      "accurate_page_range": "171-175",
      "extracted_content": "\n=== Page 171 ===\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n\n=== Page 172 ===\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n\n=== Page 173 ===\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n\n=== Page 174 ===\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\n=== Page 175 ===\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer"
    },
    {
      "text": "- 7.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "7 Basic data validation",
      "raw_line": "- 7.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 57,
      "chapter_info": {
        "page": 176,
        "title": "Basic data validation",
        "pattern_matched": "Chapter 7",
        "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
      },
      "chapter_sections": {
        "start_page": 176,
        "end_page": 201,
        "content": "\n--- Page 176 ---\n148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema from listing 7.6.\nListing7.7 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe Give it a try, and you’ll see.\nIndeed! When Theo executes the code to validate the search request, it returns true.\nListing7.8 Validating the search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksRequest = {\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nvalidate(searchBooksRequestSchema, searchBooksRequest);\n// → true\nJoe Now, please try an invalid request.\nTheo Let me think about what kind of invalidity to try. I know, I’ll make a typo in the\ntitle field and call it tilte with the l before the t.\nAs expected, the code with the type returns false. Theo is not surprised, and Joe is smil-\ning from ear to ear.\nListing7.9 Validating an invalid search request\nvar invalidSearchBooksRequest = {\n\"tilte\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\n--- Page 177 ---\n7.3 Schema flexibility and strictness 149\nvalidate(searchBooksRequestSchema, invalidSearchBooksRequest);\n// → false\nTheo The syntax of JSON Schema is much more verbose than the syntax for declar-\ning the members in a class. Why is that so?\nJoe For two reasons. First, because JSON Schema is language independent, it can\nbe used in any programming language. As I told you, there are JSON Schema\nvalidators available in most programming languages.\nTheo I see.\nJoe Second, JSON Schema allows you to express validation conditions that are much\nharder, if not impossible, to express when data is represented with classes.\nTIP The expressive power of JSON Schema is high!\nTheo Now you have triggered my curiosity. Can you give me some examples?\nJoe In a moment, we’ll talk about schema composition. Someday I’ll show you\nsome examples of advanced validation.\n NOTE Advanced validation is covered in chapter 12.\nTheo What kind of advanced validation?\nJoe What I mean by advanced validation is, for instance, validating that a number\nfalls within a given range or validating that a string matches a regular expression.\nTheo Is there a way to get details about why the request is invalid?\nJoe Absolutely! I’ll show you later. For now, let me show you how to make sure the\nresponse the server sends back to the client is valid.\nTheo It sounds much more complicated than a search book request!\nJoe Why?\nTheo Because a search response is made of multiple book results, and in each book\nresult, some of the fields are optional!\n7.3 Schema flexibility and strictness\nJoe Can you give me an example of what a book search response would look like?\nTheo Take a look at this example. It’s a search response with information about two\nbooks: 7 Habits of Highly Effective People and The Power of Habit.\nListing7.10 An example of a search response\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432\n},\n--- Page 178 ---\n150 CHAPTER 7 Basic data validation\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn_13\": \"978-1982137274\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n]\n}\n]\nJoe It’s funny that you mention The Power of Habit. I’m reading this book in order\nto get rid of my habit of biting my nails. Anyway, what fields are required and\nwhat fields are optional in a book search response?\nTheo In book information, the title and available fields are required. The other\nfields are optional.\nJoe As I told you when we built the schema for the book search request, fields in a\nmap are optional by default. In order to make a field mandatory, we have to\ninclude it in the required array. I’d probably implement it with something\nlike this.\nListing7.11 Schema of a search response\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, map fields are optional by default.\nTheo I must admit that specifying a list of required fields is much simpler than hav-\ning to specify that a member in a class in nullable!\nJoe Agreed!\nTheo On the other hand, I find the nesting of the book information schema in the\nsearch response schema a bit hard to read.\n--- Page 179 ---\n7.3 Schema flexibility and strictness 151\nJoe Nothing prevents you from separating the book information schema from the\nsearch response schema.\nTheo How?\nJoe It’s just JSON, my friend. It means, you are free to manipulate the schema as\nany other map in your program. For instance, you could have the book infor-\nmation schema in a variable named bookInfoSchema and use it in the search\nbooks response schema. Let me refactor the schema to show you what I mean.\nListing7.12 Schema of a search response refactored\nvar bookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n};\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": bookInfoSchema\n};\nTheo Once again, I have to admit that JSON Schemas are more composable than\nclass definitions.\nTIP JSON Schemas are just maps. We are free to compose and manipulate them like\nany other map.\nJoe Let’s move on to validating data received from external data sources.\nTheo Is that different?\nJoe Not really, but I’ll take it as an opportunity to show you some other features of\nJSON Schema.\nTheo I’m curious to learn how data validation is used when we access data from the\ndatabase.\nJoe Each time we access data from the outside, it’s a good practice to validate it.\nCan you show me an example of how a database response for a search query\nwould look?\nTIP It’s a good practice to validate data that comes from an external data source.\n--- Page 180 ---\n152 CHAPTER 7 Basic data validation\nTheo When we query books from the database, we expect to receive an array of\nbooks with three fields: title, isbn, and available. The first two values should\nbe strings, and the third one should be a Boolean.\nJoe Are those fields optional or required?\nTheo What do you mean?\nJoe Could there be books for which some of the fields are not defined?\nTheo No.\nJoe In that case, the schema is quite simple. Would you like to try writing the\nschema for the database response?\nTheo Let me see. It’s an array of objects where each object has three properties, so\nsomething like this?\nListing7.13 Schema of a database response\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n}\nJoe Well done, my friend! Now, I want to tell you about the additionalProperties\nfield in JSON Schema.\nTheo What’s that?\nJoe Take a look at this array.\nListing7.14 A book array with an additional property\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"dummy_property\": 42\n},\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn\": \"978-1982137274\",\n\"dummy_property\": 45\n}\n]\n--- Page 181 ---\n7.3 Schema flexibility and strictness 153\nJoe Is it a valid database response?\nTheo No. A database response should not have a dummy_property field. It should\nhave only the three required fields specified in the schema.\nJoe It might be surprising but, by default, fields not specified in the schema of an\nobject are allowed in JSON Schema. In order to disallow them, one has to set\nadditionalProperties to false like this.\nListing7.15 Disallowing properties not mentioned in the schema\nvar booksFromDBSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, by default, fields not specified in the schema of a map are\nallowed.\nTheo Why is that?\nJoe The reason is that usually having additional fields in a map doesn’t cause\ntrouble. If your code doesn’t care about a field, it simply ignores it. But some-\ntimes we want to be as strict as possible, and we set additionalProperties\nto false.\nTheo What about the search request and response schema from the previous discus-\nsions? Should we set additionalProperties to false?\nJoe That’s an excellent question. I’d say it’s a matter of taste. Personally, I like to\nallow additional fields in requests and disallow them in responses.\nTheo What’s the advantage?\nJoe Well, the web server is responsible for the responses it sends to its clients. It\nmakes sense then to be as strict as possible. However, the requests are created\nby the clients, and I prefer to do my best to serve my clients even when they are\nnot as strict as they should be.\nTheo Naturally. “The client is always right.”\nJoe Actually, I prefer the way Jon Postel formulated his robustness principle: “Be\nconservative in what you send, be liberal in what you accept.”\nTIP It’s a good practice to be strict with the data that you send and to be flexible with\nthe data that you receive.\n--- Page 182 ---\n154 CHAPTER 7 Basic data validation\n7.4 Schema composition\nTheo What about validating data that comes from an external web service?\nJoe Can you give me an example?\nTheo In the near future, we’ll have to integrate with a service called Open Library\nBooks API that provides detailed information about books.\n NOTE For information on the Open Library Books API, see https://openlibrary\n.org/dev/docs/api/books.\nJoe Can you show me, for instance, the service response for Watchmen?\nTheo Sure. Here you go.\nTheo taps a few keys on his keyboard and brings up the response. Joe looks at the JSON for\na long time.\nListing7.16 An Open Library Books API response example\n{\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n}\nTheo asks himself, “What could be so special in this JSON?” While Joe is meditating about\nthis piece of JSON, Theo writes the JSON Schema for the Books API response. It doesn’t\nseem to be more complicated than any of the previous schemas. When Theo is done, he\nasks Joe to take a look at the schema.\nListing7.17 Schema of the Open Library Books API response\n{\n\"type\": \"object\",\n\"required\": [\"title\"],\n--- Page 183 ---\n7.4 Schema composition 155\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n}\nJoe Good job!\nTheo That wasn’t so hard. I really don’t see why you looked at this JSON response for\nsuch a long time.\nJoe Well, it has to do with the isbn_10 and isbn_13 fields. I assume that they’re\nnot both mandatory.\nTheo Right! That’s why I didn’t include them in the required field of my schema.\nJoe But one of them should always be there. Right?\nTheo Sometimes one of them and sometimes both of them, like for Watchmen. It\ndepends on the publication year of the book. Books published before 2007\nhave isbn_10, and books published after 2007 have isbn_13.\nJoe Oh, I see. And Watchmen has both because it was originally published in 1986\nbut published again after 2007.\nTheo Correct.\nJoe Then, you need your schema to indicate that one of the isbn fields is man-\ndatory. That’s a good opportunity for me to tell you about JSON Schema\ncomposition.\nTheo What’s that?\nJoe It’s a way to combine schemas, similarly to how we combine logical conditions\nwith AND, OR, and NOT.\nTheo I’d like to see that.\nJoe Sure. How would you express the schema for the Books API response as a\ncomposition of three schemas: basicBookInfoSchema, the schema that you\nwrote where only title is required; mandatoryIsbn13, a schema where only\n--- Page 184 ---\n156 CHAPTER 7 Basic data validation\nisbn_13 is required; and mandatoryIsb10, a schema where only isbn_10 is\nrequired?\nTheo I think it should be basicBookInfoSchema AND (mandatoryIsbn13 OR\nmandatoryIsbn10).\nJoe Exactly! The only thing is that in JSON Schema, we use allOf instead of AND,\nand anyOf instead of OR.\nJoe shows Theo the result in listing 7.18 and an example of its usage in listing 7.19.\nListing7.18 Schema of an external API response\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n--- Page 185 ---\n7.4 Schema composition 157\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing7.19 Validating an external API response\nvar bookInfo = {\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n};\nvalidate(bookInfoSchema, bookInfo);\n// → true\nTheo I see why they call it allOf and anyOf. The first one means that data must con-\nform to all the schemas, and the second one means that data must conform to\nany of the schemas.\nJoe Yup.\n NOTE JSON Schema also supports oneOf for cases where data must be valid against\nexactly one schema.\nTheo Nice. With schema composition, JSON Schema seems to have more expressive\npower than what I was used to when representing data with classes.\nJoe That’s only the beginning. I’ll show you more data validation conditions that\ncan’t be expressed when data is represented with classes some other time.\n NOTE Advanced data validation is covered in chapter 12.\nTheo Something still bothers me, though. When data isn’t valid, you don’t know what\nwent wrong.\n--- Page 186 ---\n158 CHAPTER 7 Basic data validation\n7.5 Details about data validation failures\nJoe So far, we’ve treated JSON Schema validation as though it were binary: either a\npiece of data is valid or it isn’t.\nTheo Right...\nJoe But, in fact, when a piece of data is not valid, we can get details about the\nreason of the invalidity.\nTheo Like when a required field is missing, can we get the name of the missing field?\nJoe Yes. When a piece of data is not of the expected type, we can get information\nabout that also.\nTheo That sounds very useful!\nJoe Indeed. Let me show you how it works. Until now, we used a generic validate\nfunction, but when we deal with validation failures, we need to be more specific.\nTheo Why?\nJoe Because each data validator library has its own way of exposing the details of\nadata validation failure. For instance, in JavaScript Ajv, the errors from the\nlast data validation are stored as an array inside the validator instance.\nTheo Why an array?\nJoe Because there could be several failures. But let’s start with the case of a single\nfailure. Imagine we encounter a search book request where the title field is\nnamed myTitle instead of title. Take a look at this example. As you can see,\nwe first instantiate a validator instance.\nListing7.20 Accessing validation errors in Ajv\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nInstantiates a\nvar ajv = new Ajv(); validator instance\najv.validate(searchBooksRequestSchema, invalidSearchBooksRequest);\najv.errors\nDisplays the\nvalidation errors\n--- Page 187 ---\n7.5 Details about data validation failures 159\nTheo And what does the information inside the errors array look like?\nJoe Execute the code snippet. You’ll see.\nWhen Theo executes the code snippets from listing 7.20, he can hardly believe his eyes. He\nlooks at the details, finding the results hard to digest.\nListing7.21 Details for a single data validation failure in an array format\n[\n{\n\"instancePath\": \"\",\n\"schemaPath\": \"#/required\",\n\"keyword\": \"required\",\n\"params\": {\n\"missingProperty\":\"title\"\n},\n\"message\": \"must have required property 'title'\"\n}\n]\nTheo I find the contents of the errors array a bit hard to understand.\nJoe Me too. Fortunately, Ajv provides a errorsText utility function to convert the\nerrors array in a human readable format. See, for instance, what is returned\nwhen you call errorsText.\nListing7.22 Displaying the errors in human readable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title'\"\nTheo Let me see what happens when there are more than one validation failure in\nthe data.\nJoe By default, Ajv catches only one validation error.\nTIP By default, Ajv catches only the first validation failure.\nTheo I guess that’s for performance reasons. Once the validator encounters an\nerror, it doesn’t continue the data parsing.\nJoe Probably. Anyway, in order to catch more than one validation failure, you need\nto pass the allErrors options to the Ajv constructor. Check out this code.\nListing7.23 Catching multiple validation failures\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n--- Page 188 ---\n160 CHAPTER 7 Basic data validation\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nA request with\nthree failures\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [1, 2]\n}; Instantiates the Ajv constructor\nwith allErrors: true in order to\ncatch more than one failure\nvar ajv = new Ajv({allErrors: true});\najv.validate(searchBooksRequestSchema,\ninvalidSearchBooksRequest); Converts the\nerrors to a human\nreadable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title',\n// → data/fields/0 must be string,\n// → data/fields/1 must be string\"\nJoe We validate a search request with myTitle instead of title and numbers\ninstead of strings in the fields array. As you can see in the output of the code\nsnippet, three errors are returned.\nTheo Great! I think I have all that I need in order to add data validation to the\nboundaries of my system when Nancy asks me to make the Library Manage-\nment System into a web server.\nJoe Would you allow me to give you a small gift as a token of our friendship?\nTheo I’d be honored.\nJoe takes a small package out of his bag, wrapped in a light-green ribbon. He hands Theo\nthe package with a solemn gesture.\nWhen Theo undoes the ribbon, he discovers an elegant piece of paper decorated with\npretty little designs. In the center of the paper, Theo manages to read the inscription\n“JSON Schema cheat sheet.” He smiles while browsing the cheat sheet. It’s exactly what he\nneeds.\nListing7.24 JSON Schema cheat sheet\n{ At the root level,\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the\narray is a map.\n\"type\": \"object\",\nmyNumber \"properties\": {\nThe properties of\nis a number. \"myNumber\": {\"type\": \"number\"},\neach field in the map\n\"myString\": {\"type\": \"string\"},\nmyString is\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\na string. myEnum is a\n\"myBool\": {\"type\": \"boolean\"}\nenumeration\nmyBool is a }, value with two\nboolean. \"required\": [\"myNumber\", \"myString\"], possibilities:\nThe mandatory fields in the map \"myVal\" and\nare myNumber and myString; \"yourVal\".\nother fields are optional.\n--- Page 189 ---\nSummary 161\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nThen, Theo turns the paper over to find that the back is also filled with drawings. In the\ncenter of the paper, he reads the inscription, “An example of valid data.”\nListing7.25 An example of valid data\n[\n{\nThis map is valid\n\"myNumber\": 42,\nbecause all its\n\"myString\": \"Hello\",\nfields are valid.\n\"myEnum\": \"myVal\",\n\"myBool\": true\n},\n{\nThis map is valid\n\"myNumber\": 54,\nbecause it contains all\n\"myString\": \"Happy\"\nthe required fields.\n}\n]\nSummary\n DOP Principle #4 is to separate data schema and data representation.\n The boundaries of a system are defined to be the areas where the system\nexchanges data.\n Some examples of data validation at the boundaries of the system are validation\nof client requests and responses, and validation of data that comes from exter-\nnal sources.\n Data validation in DOP means checking whether a piece of data conforms to a\nschema.\n When a piece of data is not valid, we get information about the validation fail-\nures and send this information back to the client in a human readable format.\n When data at system boundaries is valid, it’s not critical to validate data again\ninside the system.\n JSON Schema is a language that allows us to separate data validation from data\nrepresentation.\n JSON Schema syntax is a bit verbose.\n The expressive power of JSON Schema is high.\n JSON Schemas are just maps and, as so, we are free to manipulate them like any\nother maps in our programs.\n We can store a schema definition in a variable and use this variable in another\nschema.\n In JSON Schema, map fields are optional by default.\n It’s good practice to validate data that comes from an external data source.\n--- Page 190 ---\n162 CHAPTER 7 Basic data validation\n It’s good practice to be strict regarding data that you send and to be flexible\nregarding data that you receive.\n Ajv is a JSON Schema library in JavaScript.\n By default, Ajv catches only the first validation failure.\n Advanced validation is covered in chapter 12.\n--- Page 191 ---\nAdvanced\nconcurrency control\nNo more deadlocks!\nThis chapter covers\n Atoms as an alternative to locks\n Managing a thread-safe counter and a thread-safe\nin-memory cache with atoms\n Managing the whole system state in a thread-safe\nway with atoms\nThe traditional way to manage concurrency in a multi-threaded environment\ninvolves lock mechanisms like mutexes. Lock mechanisms tend to increase the com-\nplexity of the system because it’s not trivial to make sure the system is free of dead-\nlocks. In DOP, we leverage the fact that data is immutable, and we use a lock-free\nmechanism, called an atom, to manage concurrency. Atoms are simpler to manage\nthan locks because they are lock-free. As a consequence, the usual complexity of\nlocks that are required to avoid deadlocks don’t apply to atoms.\n NOTE This chapter is mostly relevant to multi-threaded environments like Java,\nC#, Python, and Ruby. It is less relevant to single-threaded environments like Java-\nScript. The JavaScript code snippets in this chapter are written as though JavaScript\nwere multi-threaded.\n163\n--- Page 192 ---\n164 CHAPTER 8 Advanced concurrency control\n8.1 The complexity of locks\nThis Sunday afternoon, while riding his bike across the Golden Gate Bridge, Theo thinks\nabout the Klafim project with concern, not yet sure that betting on DOP was a good\nchoice. Suddenly, Theo realizes that he hasn’t yet scheduled the next session with Joe. He\ngets off his bike to call Joe. Bad luck, the line is busy.\nWhen Theo gets home, he tries to call Joe again, but once again the phone is busy. After\ndinner, Theo tries to call Joe one more time, with the same result—a busy signal. “Obvi-\nously, Joe is very busy today,” Theo tells himself. Exhausted by his 50-mile bike ride at an\naverage of 17 miles per hour, he falls asleep on the sofa. When Theo wakes up, he’s elated\nto see a text message from Joe, “See you Monday morning at 11 AM?” Theo answers with a\nthumbs up and prepares for another week of work.\nWhen Joe arrives at the office, Theo asks him why his phone was constantly busy the day\nbefore. Joe answers that he was about to ask Theo the same question. They look at each\nother, puzzled, and then simultaneously break into laughter as they realize what hap-\npened: in an amazing coincidence, they’d tried to phone each other at exactly the same\ntimes. They both say at once:\n“A deadlock!”\nThey both head for Theo’s office. When they get to Theo’s desk, Joe tells him that today’s\nsession is going to be about concurrency management in multi-threaded environments.\nJoe How do you usually manage concurrency in a multi-threaded environment?\nTheo I protect access to critical sections with a lock mechanism, a mutex, for instance.\nJoe When you say access, do you mean write access or also read access?\nTheo Both!\nJoe Why do you need to protect read access with a lock?\nTheo Because, without a lock protection, in the middle of a read, a write could hap-\npen in another thread. It would make my read logically inconsistent.\nJoe Another option would be to clone the data before processing it in a read.\nTheo Sometimes I would clone the data; but in many cases, when it’s large, it’s too\nexpensive to clone.\nTIP Cloning data to avoid read locks doesn’t scale.\nJoe In DOP, we don’t need to clone or to protect read access.\nTheo Because data is immutable?\nJoe Right. When data is immutable, even if a write happens in another thread\nduring a read, it won’t make the read inconsistent because the write never\nmutates the data that is read.\nTheo In a sense, a read always works on a data snapshot.\nJoe Exactly!\nTIP When data is immutable, a read is always safe.\nTheo But what about write access? Don’t you need to protect that with locks?\nJoe Nope.\n--- Page 193 ---\n8.2 Thread-safe counter with atoms 165\nTheo Why not?\nJoe We have a simpler mechanism—it’s called an atom.\nTheo I am glad to hear there is a something simpler than locks. I really struggle each\ntime I have to integrate locks into a multi-threaded system.\nJoe Me too! I remember a bug we had in production 10 years ago. We forgot to\nrelease a lock when an exception was thrown in a critical section. It caused a\nterrible deadlock.\nTheo Deadlocks are really hard to avoid. Last year, we had a deadlock issue when two\nlocks were not released in the proper order.\nJoe I have great news for you. With atoms, deadlocks never happen!\nTIP With atoms, deadlocks never happen.\nTheo That sounds great. Tell me more!\nTIP Atoms provide a way to manage concurrency without locks.\n8.2 Thread-safe counter with atoms\nJoe Let’s start with a simple case: a counter shared between threads.\nTheo What do you mean by a counter?\nJoe Imagine that we’d like to count the number of database accesses and write the\ntotal number of accesses to a log every minute.\nTheo OK.\nJoe Could you write JavaScript code for this multi-threaded counter using locks?\nTheo But JavaScript is single-threaded!\nJoe I know, but it’s just for the sake of illustration. Imagine that JavaScript were\nmulti-threaded and that it provided a Mutex object that you could lock and\nunlock.\nTheo It’s a bit awkward. I guess it would look like this.\nTheo goes to the whiteboard. He writes what he imagines to be JavaScript code for a multi-\nthreaded counter with locks.\nListing8.1 A thread-safe counter protected by a mutex\nvar mutex = new Mutex();\nvar counter = 0;\nfunction dbAccess() {\nmutex.lock();\ncounter = counter + 1;\nmutex.unlock();\n// access the database\n}\nfunction logCounter() {\nmutex.lock();\n--- Page 194 ---\n166 CHAPTER 8 Advanced concurrency control\nconsole.log('Number of database accesses: ' + counter);\nmutex.unlock();\n}\nJoe Excellent. Now, I am going to show you how to write the same code with atoms.\nAn atom provides three methods:\n get returns the current value of the atom.\n set overwrites the current value of the atom.\n swap receives a function and updates the value of the atom with the result\nof the function called on the current value of the atom.\nJoe unzips a pocket in his laptop case and takes out a piece of paper. He hands it to\nTheo. Theo is pleasantly surprised as the sheet of paper succinctly describes the methods\n(table 8.1).\nTable 8.1 The three methods of an atom\nMethod Description\nget Returns the current value\nset Overwrites the current value\nswap Updates the current value with a function\nTheo How would it look like to implement a thread-safe counter with an atom?\nJoe It’s quite simple, actually.\nJoe pulls out his laptop, fires it up, and begins to type. When he’s done, he turns the laptop\naround so that Theo can see the code to implement a thread-safe counter in an atom.\nListing8.2 A thread-safe counter stored in an atom\nvar counter = new Atom();\ncounter.set(0);\nfunction dbAccess() {\ncounter.swap(function(x) {\nThe argument x is the\nreturn x + 1;\ncurrent value of the atom,\n});\nsame as counter.get().\n// access the database\n}\nfunction logCounter() {\nconsole.log('Number of database accesses: ' + counter.get());\n}\nTheo Could you tell me what’s going on here?\nJoe Sure! First, we create an empty atom. Then, we initialize the value of the atom\nwith counter.set(0). In the logger thread, we read the current value of the\natom with counter.get().\nTheo And how do you increment the counter in the threads that access the database?\n--- Page 195 ---\n8.2 Thread-safe counter with atoms 167\nJoe We call swap with a function that receives x and returns x + 1.\nTheo I don’t understand how swap could be thread-safe without using any locks.\nJoe quickly goes to the whiteboard. He sketches the diagram in figure 8.1.\nTake snapshot\nCompute next state\nYes\nState changed?\nNo\nUpdate state\nFigure 8.1 High-level flow of swap\nJoe You see, swap computes the next value of the atom, and before modifying the\ncurrent value of the atom, it checks whether the value of the atom has changed\nduring the computation. If so, swap tries again, until no changes occur during\nthe computation.\nTheo Is swap easy to implement?\nJoe Let me show you the implementation of the Atom class and you’ll see.\nListing8.3 Implementation of the Atom class\nclass Atom {\nstate;\nconstructor() {}\nget() {\nreturn this.state;\n}\nset(state) {\nthis.state = state;\n}\nswap(f) {\nwhile(true) {\nvar stateSnapshot = this.state;\nvar nextState = f(stateSnapshot);\nif (!atomicCompareAndSet(this.state,\n--- Page 196 ---\n168 CHAPTER 8 Advanced concurrency control\nstateSnapshot,\nnextState)) {\nUses a special thread-safe comparison operation\ncontinue;\nas this.state might have changed in another\n}\nthread during execution of the function f.\nreturn nextState;\n}\n}\n}\nTheo comes closer to the whiteboard. He modifies Joe’s diagram a bit to make the flow of\nthe swap operation more detailed. The resulting diagram is in figure 8.2. Theo still has a\nfew questions, though.\nTake snapshot\nsnapshot = state\nCompute next state\nnextState = f(snapshot)\nCheck if state has changed\nstate == snapshot\nYes\nState changed?\nNo\nUpdate state\nstate = nextState\nFigure 8.2 Detailed flow of swap\nTheo What is atomicCompareAndSet?\nJoe It’s the core operation of an atom. atomicCompareAndSet atomically sets the\nstate to a new value if, and only if, the state equals the provided old value. It\nreturns true upon success and false upon failure.\nTheo How could it be atomic without using locks?\nJoe That’s a great question! In fact, atomicCompareAndSet is a compare-and-swap\noperation, provided by the language that relies on a functionality of the CPU\nitself. For example, in Java the java.util.concurrent.atomic package has\nan AtomicReference generic class that provides a compareAndSet() method.\n NOTE See http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html\nfor general information about compare-and-swap operations. Implementations for\nmulti-threaded languages appear in table 8.2.\n--- Page 197 ---\n8.2 Thread-safe counter with atoms 169\nTable 8.2 Implementation of an atomic compare and set in various languages\nLanguage Link\nJava http://mng.bz/mx0W\nJavaScript Not relevant (single-threaded language)\nRuby http://mng.bz/5KG8\nPython https://github.com/maxcountryman/atomos\nC# http://mng.bz/6Zzp\nTheo Apropos Java, how would the implementation of an atom look?\nJoe It’s quite the same, besides the fact that Atom has to use generics, and the inner\nstate has to be stored in an AtomicReference.\nJoe brings up a Java implementation of Atom on his laptop. Theo looks over the code.\nListing8.4 Implementation of the Atom class in Java\nclass Atom<ValueType> {\nprivate AtomicReference<ValueType> state;\npublic Atom() {}\nValueType get() {\nreturn this.state.get();\n}\nthis.state might have\nchanged in another thread\nvoid set(ValueType state) {\nduring the execution of f.\nthis.state.set(state);\n}\nValueType swap(UnaryOPerator<ValueType> f) {\nwhile(true) {\nValueType stateSnapshot = this.state.get();\nValueType nextState = f(stateSnapshot);\nif (!this.state.compareAndSet(stateSnapshot,\nnextState)) {\ncontinue;\n}\n}\nreturn nextState;\n}\n}\nTheo What about using an atom in Java?\nJoe Here, take a look. It’s quite simple.\n--- Page 198 ---\n170 CHAPTER 8 Advanced concurrency control\nListing8.5 Using an Atom in Java\nAtom<Integer> counter = new Atom<Integer>();\ncounter.set(0);\ncounter.swap(x -> x + 1);\ncounter.get();\nTheo takes a couple of minutes to meditate about this atom stuff and to digest what he’s\njust learned. Then, he asks Joe:\nTheo What if swap never succeeds? I mean, could the while loop inside the code of\nswap turn out to be an infinite loop?\nJoe No! By definition, when atomicCompareAndSet fails on a thread, it means that\nthe same atom was changed on another thread during the execution of swap.\nIn this race between threads, there is always a winner.\nTheo But isn’t it possible that some thread never succeeds because it always loses the\nrace against other threads?\nJoe In theory, yes, but I’ve never encountered such a situation. If you have thou-\nsands of threads that do nothing besides swapping an atom, it could happen I\nsuppose. But, in practice, once the atom is swapped, the threads do some real\nwork, for example, database access or I/O. This gives other threads the oppor-\ntunity to swap the atom successfully.\n NOTE In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing beside swapping an atom. In practice, once an atom is swapped, the\nthreads do some real work (e.g., database access), which creates an opportunity for\nother threads to swap the atom successfully.\nTheo Interesting.... Indeed, atoms look much easier to manage than locks.\nJoe Now let me show you how to use atoms with composite data.\nTheo Why would that be different?\nJoe Usually, dealing with composite data is more difficult than dealing with primi-\ntive types.\nTheo When you sold me on DOP, you told me that we are able to manage data with\nthe same simplicity as we manage numbers.\nTIP In DOP, data is managed with the same simplicity as numbers.\nJoe That’s exactly what I am about to show you.\n8.3 Thread-safe cache with atoms\nJoe Are you familiar with the notion of in-memory cache?\nTheo You mean memoization?\n--- Page 199 ---\n8.3 Thread-safe cache with atoms 171\nJoe Kind of. Imagine that database queries don’t vary too much in your applica-\ntion. It makes sense in that case to store the results of previous queries in mem-\nory in order to improve the response time.\nTheo Yes, of course!\nJoe What data structure would you use to store the in-memory cache?\nTheo Probably a string map, where the keys are the queries, and the values are the\nresults from the database.\nTIP It’s quite common to represent an in-memory cache as a string map.\nJoe Excellent! Now can you write the code to cache database queries in a thread-\nsafe way using a lock?\nTheo Let me see: I’m going to use an immutable string map. Therefore, I don’t\nneed to protect read access with a lock. Only the cache update needs to be\nprotected.\nJoe You’re getting the hang of this!\nTheo The code should be something like this.\nListing8.6 Thread-safe cache with locks\nvar mutex = new Mutex();\nvar cache = {};\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache, query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\nmutex.lock();\ncache = _.set(cache, query, result);\nmutex.unlock();\nreturn result;\n}\nJoe Nice! Now, let me show you how to write the same code using an atom instead\nof a lock. Take a look at this code and let me know if it’s clear to you.\nListing8.7 Thread-safe cache with atoms\nvar cache = new Atom();\ncache.set({});\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache.get(), query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\ncache.swap(function(oldCache) {\n--- Page 200 ---\n172 CHAPTER 8 Advanced concurrency control\nreturn _.set(oldCache, query, result);\n});\nreturn result;\n}\nTheo I don’t understand the function you’re passing to the swap method.\nJoe The function passed to swap receives the current value of the cache, which is a\nstring map, and returns a new version of the string map with an additional key-\nvalue pair.\nTheo I see. But something bothers me with the performance of the swap method in\nthe case of a string map. How does the comparison work? I mean, comparing\ntwo string maps might take some time.\nJoe Not if you compare them by reference. As we discussed in the past, when data\nis immutable, it is safe to compare by reference, and it’s super fast.\nTIP When data is immutable, it is safe (and fast) to compare it by reference.\nTheo Cool. So atoms play well with immutable data.\nJoe Exactly!\n8.4 State management with atoms\nJoe Do you remember a couple of weeks ago when I showed you how we resolve\npotential conflicts between mutations? You told me that the code was not\nthread-safe.\nTheo Let me look again at the code.\nTheo takes a look at the code for the SystemData class that he wrote some time ago\n(repeated in listing 8.8). Without the validation logic, it makes the code easier to grasp.\nListing8.8 SystemData class from part 1\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nthis.systemData = SystemConsistency.reconcile(this.systemData,\nprevious,\nnext);\n}\n}\n--- Page 201 ---\n8.4 State management with atoms 173\nIt takes him a few minutes to remember how the commit method works. Suddenly, he has\nan Aha! moment.\nTheo This code is not thread-safe because the SystemConsistency.reconcile\ncode inside the commit method is not protected. Nothing prevents the two\nthreads from executing this code concurrently.\nJoe Right! Now, can you tell me how to make it thread-safe?\nTheo With locks?\nJoe Come on...\nTheo I was kidding, of course. We make the code thread-safe not with a lock but with\nan atom.\nJoe Nice joke!\nTheo Let me see. I’d need to store the system data inside an atom. The get and set\nmethod of SystemData would simply call the get and set methods of the\natom. How does this look?\nListing8.9 SystemData class with atom (without the commit method)\nclass SystemState {\nsystemData;\nconstructor() {\nthis.systemData = new Atom();\n}\nget() {\nreturn this.systemData.get();\n}\ncommit(prev, next) {\nthis.systemData.set(next);\n}\n}\nJoe Excellent. Now for the fun part. Implement the commit method by calling the\nswap method of the atom.\nTheo Instead of calling SystemConsistency.reconcile() directly, I need to wrap\nit into a call to swap. So, something like this?\nListing8.10 Implementation of SystemData.commit with atom\nSystemData.commit = function(previous, next) {\nthis.systemData.swap(function(current) {\nreturn SystemConsistency.reconcile(current,\nprevious,\nnext);\n});\n};",
        "sections_found": []
      },
      "accurate_page_range": "176-201"
    },
    {
      "text": "- 7.1 Data validation in DOP",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "7 Basic data validation",
      "raw_line": "- 7.1 Data validation in DOP (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 58,
      "chapter_info": {
        "page": 176,
        "title": "Basic data validation",
        "pattern_matched": "Chapter 7",
        "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
      },
      "chapter_sections": {
        "start_page": 176,
        "end_page": 201,
        "content": "\n--- Page 176 ---\n148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema from listing 7.6.\nListing7.7 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe Give it a try, and you’ll see.\nIndeed! When Theo executes the code to validate the search request, it returns true.\nListing7.8 Validating the search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksRequest = {\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nvalidate(searchBooksRequestSchema, searchBooksRequest);\n// → true\nJoe Now, please try an invalid request.\nTheo Let me think about what kind of invalidity to try. I know, I’ll make a typo in the\ntitle field and call it tilte with the l before the t.\nAs expected, the code with the type returns false. Theo is not surprised, and Joe is smil-\ning from ear to ear.\nListing7.9 Validating an invalid search request\nvar invalidSearchBooksRequest = {\n\"tilte\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\n--- Page 177 ---\n7.3 Schema flexibility and strictness 149\nvalidate(searchBooksRequestSchema, invalidSearchBooksRequest);\n// → false\nTheo The syntax of JSON Schema is much more verbose than the syntax for declar-\ning the members in a class. Why is that so?\nJoe For two reasons. First, because JSON Schema is language independent, it can\nbe used in any programming language. As I told you, there are JSON Schema\nvalidators available in most programming languages.\nTheo I see.\nJoe Second, JSON Schema allows you to express validation conditions that are much\nharder, if not impossible, to express when data is represented with classes.\nTIP The expressive power of JSON Schema is high!\nTheo Now you have triggered my curiosity. Can you give me some examples?\nJoe In a moment, we’ll talk about schema composition. Someday I’ll show you\nsome examples of advanced validation.\n NOTE Advanced validation is covered in chapter 12.\nTheo What kind of advanced validation?\nJoe What I mean by advanced validation is, for instance, validating that a number\nfalls within a given range or validating that a string matches a regular expression.\nTheo Is there a way to get details about why the request is invalid?\nJoe Absolutely! I’ll show you later. For now, let me show you how to make sure the\nresponse the server sends back to the client is valid.\nTheo It sounds much more complicated than a search book request!\nJoe Why?\nTheo Because a search response is made of multiple book results, and in each book\nresult, some of the fields are optional!\n7.3 Schema flexibility and strictness\nJoe Can you give me an example of what a book search response would look like?\nTheo Take a look at this example. It’s a search response with information about two\nbooks: 7 Habits of Highly Effective People and The Power of Habit.\nListing7.10 An example of a search response\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432\n},\n--- Page 178 ---\n150 CHAPTER 7 Basic data validation\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn_13\": \"978-1982137274\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n]\n}\n]\nJoe It’s funny that you mention The Power of Habit. I’m reading this book in order\nto get rid of my habit of biting my nails. Anyway, what fields are required and\nwhat fields are optional in a book search response?\nTheo In book information, the title and available fields are required. The other\nfields are optional.\nJoe As I told you when we built the schema for the book search request, fields in a\nmap are optional by default. In order to make a field mandatory, we have to\ninclude it in the required array. I’d probably implement it with something\nlike this.\nListing7.11 Schema of a search response\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, map fields are optional by default.\nTheo I must admit that specifying a list of required fields is much simpler than hav-\ning to specify that a member in a class in nullable!\nJoe Agreed!\nTheo On the other hand, I find the nesting of the book information schema in the\nsearch response schema a bit hard to read.\n--- Page 179 ---\n7.3 Schema flexibility and strictness 151\nJoe Nothing prevents you from separating the book information schema from the\nsearch response schema.\nTheo How?\nJoe It’s just JSON, my friend. It means, you are free to manipulate the schema as\nany other map in your program. For instance, you could have the book infor-\nmation schema in a variable named bookInfoSchema and use it in the search\nbooks response schema. Let me refactor the schema to show you what I mean.\nListing7.12 Schema of a search response refactored\nvar bookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n};\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": bookInfoSchema\n};\nTheo Once again, I have to admit that JSON Schemas are more composable than\nclass definitions.\nTIP JSON Schemas are just maps. We are free to compose and manipulate them like\nany other map.\nJoe Let’s move on to validating data received from external data sources.\nTheo Is that different?\nJoe Not really, but I’ll take it as an opportunity to show you some other features of\nJSON Schema.\nTheo I’m curious to learn how data validation is used when we access data from the\ndatabase.\nJoe Each time we access data from the outside, it’s a good practice to validate it.\nCan you show me an example of how a database response for a search query\nwould look?\nTIP It’s a good practice to validate data that comes from an external data source.\n--- Page 180 ---\n152 CHAPTER 7 Basic data validation\nTheo When we query books from the database, we expect to receive an array of\nbooks with three fields: title, isbn, and available. The first two values should\nbe strings, and the third one should be a Boolean.\nJoe Are those fields optional or required?\nTheo What do you mean?\nJoe Could there be books for which some of the fields are not defined?\nTheo No.\nJoe In that case, the schema is quite simple. Would you like to try writing the\nschema for the database response?\nTheo Let me see. It’s an array of objects where each object has three properties, so\nsomething like this?\nListing7.13 Schema of a database response\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n}\nJoe Well done, my friend! Now, I want to tell you about the additionalProperties\nfield in JSON Schema.\nTheo What’s that?\nJoe Take a look at this array.\nListing7.14 A book array with an additional property\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"dummy_property\": 42\n},\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn\": \"978-1982137274\",\n\"dummy_property\": 45\n}\n]\n--- Page 181 ---\n7.3 Schema flexibility and strictness 153\nJoe Is it a valid database response?\nTheo No. A database response should not have a dummy_property field. It should\nhave only the three required fields specified in the schema.\nJoe It might be surprising but, by default, fields not specified in the schema of an\nobject are allowed in JSON Schema. In order to disallow them, one has to set\nadditionalProperties to false like this.\nListing7.15 Disallowing properties not mentioned in the schema\nvar booksFromDBSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, by default, fields not specified in the schema of a map are\nallowed.\nTheo Why is that?\nJoe The reason is that usually having additional fields in a map doesn’t cause\ntrouble. If your code doesn’t care about a field, it simply ignores it. But some-\ntimes we want to be as strict as possible, and we set additionalProperties\nto false.\nTheo What about the search request and response schema from the previous discus-\nsions? Should we set additionalProperties to false?\nJoe That’s an excellent question. I’d say it’s a matter of taste. Personally, I like to\nallow additional fields in requests and disallow them in responses.\nTheo What’s the advantage?\nJoe Well, the web server is responsible for the responses it sends to its clients. It\nmakes sense then to be as strict as possible. However, the requests are created\nby the clients, and I prefer to do my best to serve my clients even when they are\nnot as strict as they should be.\nTheo Naturally. “The client is always right.”\nJoe Actually, I prefer the way Jon Postel formulated his robustness principle: “Be\nconservative in what you send, be liberal in what you accept.”\nTIP It’s a good practice to be strict with the data that you send and to be flexible with\nthe data that you receive.\n--- Page 182 ---\n154 CHAPTER 7 Basic data validation\n7.4 Schema composition\nTheo What about validating data that comes from an external web service?\nJoe Can you give me an example?\nTheo In the near future, we’ll have to integrate with a service called Open Library\nBooks API that provides detailed information about books.\n NOTE For information on the Open Library Books API, see https://openlibrary\n.org/dev/docs/api/books.\nJoe Can you show me, for instance, the service response for Watchmen?\nTheo Sure. Here you go.\nTheo taps a few keys on his keyboard and brings up the response. Joe looks at the JSON for\na long time.\nListing7.16 An Open Library Books API response example\n{\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n}\nTheo asks himself, “What could be so special in this JSON?” While Joe is meditating about\nthis piece of JSON, Theo writes the JSON Schema for the Books API response. It doesn’t\nseem to be more complicated than any of the previous schemas. When Theo is done, he\nasks Joe to take a look at the schema.\nListing7.17 Schema of the Open Library Books API response\n{\n\"type\": \"object\",\n\"required\": [\"title\"],\n--- Page 183 ---\n7.4 Schema composition 155\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n}\nJoe Good job!\nTheo That wasn’t so hard. I really don’t see why you looked at this JSON response for\nsuch a long time.\nJoe Well, it has to do with the isbn_10 and isbn_13 fields. I assume that they’re\nnot both mandatory.\nTheo Right! That’s why I didn’t include them in the required field of my schema.\nJoe But one of them should always be there. Right?\nTheo Sometimes one of them and sometimes both of them, like for Watchmen. It\ndepends on the publication year of the book. Books published before 2007\nhave isbn_10, and books published after 2007 have isbn_13.\nJoe Oh, I see. And Watchmen has both because it was originally published in 1986\nbut published again after 2007.\nTheo Correct.\nJoe Then, you need your schema to indicate that one of the isbn fields is man-\ndatory. That’s a good opportunity for me to tell you about JSON Schema\ncomposition.\nTheo What’s that?\nJoe It’s a way to combine schemas, similarly to how we combine logical conditions\nwith AND, OR, and NOT.\nTheo I’d like to see that.\nJoe Sure. How would you express the schema for the Books API response as a\ncomposition of three schemas: basicBookInfoSchema, the schema that you\nwrote where only title is required; mandatoryIsbn13, a schema where only\n--- Page 184 ---\n156 CHAPTER 7 Basic data validation\nisbn_13 is required; and mandatoryIsb10, a schema where only isbn_10 is\nrequired?\nTheo I think it should be basicBookInfoSchema AND (mandatoryIsbn13 OR\nmandatoryIsbn10).\nJoe Exactly! The only thing is that in JSON Schema, we use allOf instead of AND,\nand anyOf instead of OR.\nJoe shows Theo the result in listing 7.18 and an example of its usage in listing 7.19.\nListing7.18 Schema of an external API response\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n--- Page 185 ---\n7.4 Schema composition 157\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing7.19 Validating an external API response\nvar bookInfo = {\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n};\nvalidate(bookInfoSchema, bookInfo);\n// → true\nTheo I see why they call it allOf and anyOf. The first one means that data must con-\nform to all the schemas, and the second one means that data must conform to\nany of the schemas.\nJoe Yup.\n NOTE JSON Schema also supports oneOf for cases where data must be valid against\nexactly one schema.\nTheo Nice. With schema composition, JSON Schema seems to have more expressive\npower than what I was used to when representing data with classes.\nJoe That’s only the beginning. I’ll show you more data validation conditions that\ncan’t be expressed when data is represented with classes some other time.\n NOTE Advanced data validation is covered in chapter 12.\nTheo Something still bothers me, though. When data isn’t valid, you don’t know what\nwent wrong.\n--- Page 186 ---\n158 CHAPTER 7 Basic data validation\n7.5 Details about data validation failures\nJoe So far, we’ve treated JSON Schema validation as though it were binary: either a\npiece of data is valid or it isn’t.\nTheo Right...\nJoe But, in fact, when a piece of data is not valid, we can get details about the\nreason of the invalidity.\nTheo Like when a required field is missing, can we get the name of the missing field?\nJoe Yes. When a piece of data is not of the expected type, we can get information\nabout that also.\nTheo That sounds very useful!\nJoe Indeed. Let me show you how it works. Until now, we used a generic validate\nfunction, but when we deal with validation failures, we need to be more specific.\nTheo Why?\nJoe Because each data validator library has its own way of exposing the details of\nadata validation failure. For instance, in JavaScript Ajv, the errors from the\nlast data validation are stored as an array inside the validator instance.\nTheo Why an array?\nJoe Because there could be several failures. But let’s start with the case of a single\nfailure. Imagine we encounter a search book request where the title field is\nnamed myTitle instead of title. Take a look at this example. As you can see,\nwe first instantiate a validator instance.\nListing7.20 Accessing validation errors in Ajv\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nInstantiates a\nvar ajv = new Ajv(); validator instance\najv.validate(searchBooksRequestSchema, invalidSearchBooksRequest);\najv.errors\nDisplays the\nvalidation errors\n--- Page 187 ---\n7.5 Details about data validation failures 159\nTheo And what does the information inside the errors array look like?\nJoe Execute the code snippet. You’ll see.\nWhen Theo executes the code snippets from listing 7.20, he can hardly believe his eyes. He\nlooks at the details, finding the results hard to digest.\nListing7.21 Details for a single data validation failure in an array format\n[\n{\n\"instancePath\": \"\",\n\"schemaPath\": \"#/required\",\n\"keyword\": \"required\",\n\"params\": {\n\"missingProperty\":\"title\"\n},\n\"message\": \"must have required property 'title'\"\n}\n]\nTheo I find the contents of the errors array a bit hard to understand.\nJoe Me too. Fortunately, Ajv provides a errorsText utility function to convert the\nerrors array in a human readable format. See, for instance, what is returned\nwhen you call errorsText.\nListing7.22 Displaying the errors in human readable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title'\"\nTheo Let me see what happens when there are more than one validation failure in\nthe data.\nJoe By default, Ajv catches only one validation error.\nTIP By default, Ajv catches only the first validation failure.\nTheo I guess that’s for performance reasons. Once the validator encounters an\nerror, it doesn’t continue the data parsing.\nJoe Probably. Anyway, in order to catch more than one validation failure, you need\nto pass the allErrors options to the Ajv constructor. Check out this code.\nListing7.23 Catching multiple validation failures\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n--- Page 188 ---\n160 CHAPTER 7 Basic data validation\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nA request with\nthree failures\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [1, 2]\n}; Instantiates the Ajv constructor\nwith allErrors: true in order to\ncatch more than one failure\nvar ajv = new Ajv({allErrors: true});\najv.validate(searchBooksRequestSchema,\ninvalidSearchBooksRequest); Converts the\nerrors to a human\nreadable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title',\n// → data/fields/0 must be string,\n// → data/fields/1 must be string\"\nJoe We validate a search request with myTitle instead of title and numbers\ninstead of strings in the fields array. As you can see in the output of the code\nsnippet, three errors are returned.\nTheo Great! I think I have all that I need in order to add data validation to the\nboundaries of my system when Nancy asks me to make the Library Manage-\nment System into a web server.\nJoe Would you allow me to give you a small gift as a token of our friendship?\nTheo I’d be honored.\nJoe takes a small package out of his bag, wrapped in a light-green ribbon. He hands Theo\nthe package with a solemn gesture.\nWhen Theo undoes the ribbon, he discovers an elegant piece of paper decorated with\npretty little designs. In the center of the paper, Theo manages to read the inscription\n“JSON Schema cheat sheet.” He smiles while browsing the cheat sheet. It’s exactly what he\nneeds.\nListing7.24 JSON Schema cheat sheet\n{ At the root level,\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the\narray is a map.\n\"type\": \"object\",\nmyNumber \"properties\": {\nThe properties of\nis a number. \"myNumber\": {\"type\": \"number\"},\neach field in the map\n\"myString\": {\"type\": \"string\"},\nmyString is\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\na string. myEnum is a\n\"myBool\": {\"type\": \"boolean\"}\nenumeration\nmyBool is a }, value with two\nboolean. \"required\": [\"myNumber\", \"myString\"], possibilities:\nThe mandatory fields in the map \"myVal\" and\nare myNumber and myString; \"yourVal\".\nother fields are optional.\n--- Page 189 ---\nSummary 161\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nThen, Theo turns the paper over to find that the back is also filled with drawings. In the\ncenter of the paper, he reads the inscription, “An example of valid data.”\nListing7.25 An example of valid data\n[\n{\nThis map is valid\n\"myNumber\": 42,\nbecause all its\n\"myString\": \"Hello\",\nfields are valid.\n\"myEnum\": \"myVal\",\n\"myBool\": true\n},\n{\nThis map is valid\n\"myNumber\": 54,\nbecause it contains all\n\"myString\": \"Happy\"\nthe required fields.\n}\n]\nSummary\n DOP Principle #4 is to separate data schema and data representation.\n The boundaries of a system are defined to be the areas where the system\nexchanges data.\n Some examples of data validation at the boundaries of the system are validation\nof client requests and responses, and validation of data that comes from exter-\nnal sources.\n Data validation in DOP means checking whether a piece of data conforms to a\nschema.\n When a piece of data is not valid, we get information about the validation fail-\nures and send this information back to the client in a human readable format.\n When data at system boundaries is valid, it’s not critical to validate data again\ninside the system.\n JSON Schema is a language that allows us to separate data validation from data\nrepresentation.\n JSON Schema syntax is a bit verbose.\n The expressive power of JSON Schema is high.\n JSON Schemas are just maps and, as so, we are free to manipulate them like any\nother maps in our programs.\n We can store a schema definition in a variable and use this variable in another\nschema.\n In JSON Schema, map fields are optional by default.\n It’s good practice to validate data that comes from an external data source.\n--- Page 190 ---\n162 CHAPTER 7 Basic data validation\n It’s good practice to be strict regarding data that you send and to be flexible\nregarding data that you receive.\n Ajv is a JSON Schema library in JavaScript.\n By default, Ajv catches only the first validation failure.\n Advanced validation is covered in chapter 12.\n--- Page 191 ---\nAdvanced\nconcurrency control\nNo more deadlocks!\nThis chapter covers\n Atoms as an alternative to locks\n Managing a thread-safe counter and a thread-safe\nin-memory cache with atoms\n Managing the whole system state in a thread-safe\nway with atoms\nThe traditional way to manage concurrency in a multi-threaded environment\ninvolves lock mechanisms like mutexes. Lock mechanisms tend to increase the com-\nplexity of the system because it’s not trivial to make sure the system is free of dead-\nlocks. In DOP, we leverage the fact that data is immutable, and we use a lock-free\nmechanism, called an atom, to manage concurrency. Atoms are simpler to manage\nthan locks because they are lock-free. As a consequence, the usual complexity of\nlocks that are required to avoid deadlocks don’t apply to atoms.\n NOTE This chapter is mostly relevant to multi-threaded environments like Java,\nC#, Python, and Ruby. It is less relevant to single-threaded environments like Java-\nScript. The JavaScript code snippets in this chapter are written as though JavaScript\nwere multi-threaded.\n163\n--- Page 192 ---\n164 CHAPTER 8 Advanced concurrency control\n8.1 The complexity of locks\nThis Sunday afternoon, while riding his bike across the Golden Gate Bridge, Theo thinks\nabout the Klafim project with concern, not yet sure that betting on DOP was a good\nchoice. Suddenly, Theo realizes that he hasn’t yet scheduled the next session with Joe. He\ngets off his bike to call Joe. Bad luck, the line is busy.\nWhen Theo gets home, he tries to call Joe again, but once again the phone is busy. After\ndinner, Theo tries to call Joe one more time, with the same result—a busy signal. “Obvi-\nously, Joe is very busy today,” Theo tells himself. Exhausted by his 50-mile bike ride at an\naverage of 17 miles per hour, he falls asleep on the sofa. When Theo wakes up, he’s elated\nto see a text message from Joe, “See you Monday morning at 11 AM?” Theo answers with a\nthumbs up and prepares for another week of work.\nWhen Joe arrives at the office, Theo asks him why his phone was constantly busy the day\nbefore. Joe answers that he was about to ask Theo the same question. They look at each\nother, puzzled, and then simultaneously break into laughter as they realize what hap-\npened: in an amazing coincidence, they’d tried to phone each other at exactly the same\ntimes. They both say at once:\n“A deadlock!”\nThey both head for Theo’s office. When they get to Theo’s desk, Joe tells him that today’s\nsession is going to be about concurrency management in multi-threaded environments.\nJoe How do you usually manage concurrency in a multi-threaded environment?\nTheo I protect access to critical sections with a lock mechanism, a mutex, for instance.\nJoe When you say access, do you mean write access or also read access?\nTheo Both!\nJoe Why do you need to protect read access with a lock?\nTheo Because, without a lock protection, in the middle of a read, a write could hap-\npen in another thread. It would make my read logically inconsistent.\nJoe Another option would be to clone the data before processing it in a read.\nTheo Sometimes I would clone the data; but in many cases, when it’s large, it’s too\nexpensive to clone.\nTIP Cloning data to avoid read locks doesn’t scale.\nJoe In DOP, we don’t need to clone or to protect read access.\nTheo Because data is immutable?\nJoe Right. When data is immutable, even if a write happens in another thread\nduring a read, it won’t make the read inconsistent because the write never\nmutates the data that is read.\nTheo In a sense, a read always works on a data snapshot.\nJoe Exactly!\nTIP When data is immutable, a read is always safe.\nTheo But what about write access? Don’t you need to protect that with locks?\nJoe Nope.\n--- Page 193 ---\n8.2 Thread-safe counter with atoms 165\nTheo Why not?\nJoe We have a simpler mechanism—it’s called an atom.\nTheo I am glad to hear there is a something simpler than locks. I really struggle each\ntime I have to integrate locks into a multi-threaded system.\nJoe Me too! I remember a bug we had in production 10 years ago. We forgot to\nrelease a lock when an exception was thrown in a critical section. It caused a\nterrible deadlock.\nTheo Deadlocks are really hard to avoid. Last year, we had a deadlock issue when two\nlocks were not released in the proper order.\nJoe I have great news for you. With atoms, deadlocks never happen!\nTIP With atoms, deadlocks never happen.\nTheo That sounds great. Tell me more!\nTIP Atoms provide a way to manage concurrency without locks.\n8.2 Thread-safe counter with atoms\nJoe Let’s start with a simple case: a counter shared between threads.\nTheo What do you mean by a counter?\nJoe Imagine that we’d like to count the number of database accesses and write the\ntotal number of accesses to a log every minute.\nTheo OK.\nJoe Could you write JavaScript code for this multi-threaded counter using locks?\nTheo But JavaScript is single-threaded!\nJoe I know, but it’s just for the sake of illustration. Imagine that JavaScript were\nmulti-threaded and that it provided a Mutex object that you could lock and\nunlock.\nTheo It’s a bit awkward. I guess it would look like this.\nTheo goes to the whiteboard. He writes what he imagines to be JavaScript code for a multi-\nthreaded counter with locks.\nListing8.1 A thread-safe counter protected by a mutex\nvar mutex = new Mutex();\nvar counter = 0;\nfunction dbAccess() {\nmutex.lock();\ncounter = counter + 1;\nmutex.unlock();\n// access the database\n}\nfunction logCounter() {\nmutex.lock();\n--- Page 194 ---\n166 CHAPTER 8 Advanced concurrency control\nconsole.log('Number of database accesses: ' + counter);\nmutex.unlock();\n}\nJoe Excellent. Now, I am going to show you how to write the same code with atoms.\nAn atom provides three methods:\n get returns the current value of the atom.\n set overwrites the current value of the atom.\n swap receives a function and updates the value of the atom with the result\nof the function called on the current value of the atom.\nJoe unzips a pocket in his laptop case and takes out a piece of paper. He hands it to\nTheo. Theo is pleasantly surprised as the sheet of paper succinctly describes the methods\n(table 8.1).\nTable 8.1 The three methods of an atom\nMethod Description\nget Returns the current value\nset Overwrites the current value\nswap Updates the current value with a function\nTheo How would it look like to implement a thread-safe counter with an atom?\nJoe It’s quite simple, actually.\nJoe pulls out his laptop, fires it up, and begins to type. When he’s done, he turns the laptop\naround so that Theo can see the code to implement a thread-safe counter in an atom.\nListing8.2 A thread-safe counter stored in an atom\nvar counter = new Atom();\ncounter.set(0);\nfunction dbAccess() {\ncounter.swap(function(x) {\nThe argument x is the\nreturn x + 1;\ncurrent value of the atom,\n});\nsame as counter.get().\n// access the database\n}\nfunction logCounter() {\nconsole.log('Number of database accesses: ' + counter.get());\n}\nTheo Could you tell me what’s going on here?\nJoe Sure! First, we create an empty atom. Then, we initialize the value of the atom\nwith counter.set(0). In the logger thread, we read the current value of the\natom with counter.get().\nTheo And how do you increment the counter in the threads that access the database?\n--- Page 195 ---\n8.2 Thread-safe counter with atoms 167\nJoe We call swap with a function that receives x and returns x + 1.\nTheo I don’t understand how swap could be thread-safe without using any locks.\nJoe quickly goes to the whiteboard. He sketches the diagram in figure 8.1.\nTake snapshot\nCompute next state\nYes\nState changed?\nNo\nUpdate state\nFigure 8.1 High-level flow of swap\nJoe You see, swap computes the next value of the atom, and before modifying the\ncurrent value of the atom, it checks whether the value of the atom has changed\nduring the computation. If so, swap tries again, until no changes occur during\nthe computation.\nTheo Is swap easy to implement?\nJoe Let me show you the implementation of the Atom class and you’ll see.\nListing8.3 Implementation of the Atom class\nclass Atom {\nstate;\nconstructor() {}\nget() {\nreturn this.state;\n}\nset(state) {\nthis.state = state;\n}\nswap(f) {\nwhile(true) {\nvar stateSnapshot = this.state;\nvar nextState = f(stateSnapshot);\nif (!atomicCompareAndSet(this.state,\n--- Page 196 ---\n168 CHAPTER 8 Advanced concurrency control\nstateSnapshot,\nnextState)) {\nUses a special thread-safe comparison operation\ncontinue;\nas this.state might have changed in another\n}\nthread during execution of the function f.\nreturn nextState;\n}\n}\n}\nTheo comes closer to the whiteboard. He modifies Joe’s diagram a bit to make the flow of\nthe swap operation more detailed. The resulting diagram is in figure 8.2. Theo still has a\nfew questions, though.\nTake snapshot\nsnapshot = state\nCompute next state\nnextState = f(snapshot)\nCheck if state has changed\nstate == snapshot\nYes\nState changed?\nNo\nUpdate state\nstate = nextState\nFigure 8.2 Detailed flow of swap\nTheo What is atomicCompareAndSet?\nJoe It’s the core operation of an atom. atomicCompareAndSet atomically sets the\nstate to a new value if, and only if, the state equals the provided old value. It\nreturns true upon success and false upon failure.\nTheo How could it be atomic without using locks?\nJoe That’s a great question! In fact, atomicCompareAndSet is a compare-and-swap\noperation, provided by the language that relies on a functionality of the CPU\nitself. For example, in Java the java.util.concurrent.atomic package has\nan AtomicReference generic class that provides a compareAndSet() method.\n NOTE See http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html\nfor general information about compare-and-swap operations. Implementations for\nmulti-threaded languages appear in table 8.2.\n--- Page 197 ---\n8.2 Thread-safe counter with atoms 169\nTable 8.2 Implementation of an atomic compare and set in various languages\nLanguage Link\nJava http://mng.bz/mx0W\nJavaScript Not relevant (single-threaded language)\nRuby http://mng.bz/5KG8\nPython https://github.com/maxcountryman/atomos\nC# http://mng.bz/6Zzp\nTheo Apropos Java, how would the implementation of an atom look?\nJoe It’s quite the same, besides the fact that Atom has to use generics, and the inner\nstate has to be stored in an AtomicReference.\nJoe brings up a Java implementation of Atom on his laptop. Theo looks over the code.\nListing8.4 Implementation of the Atom class in Java\nclass Atom<ValueType> {\nprivate AtomicReference<ValueType> state;\npublic Atom() {}\nValueType get() {\nreturn this.state.get();\n}\nthis.state might have\nchanged in another thread\nvoid set(ValueType state) {\nduring the execution of f.\nthis.state.set(state);\n}\nValueType swap(UnaryOPerator<ValueType> f) {\nwhile(true) {\nValueType stateSnapshot = this.state.get();\nValueType nextState = f(stateSnapshot);\nif (!this.state.compareAndSet(stateSnapshot,\nnextState)) {\ncontinue;\n}\n}\nreturn nextState;\n}\n}\nTheo What about using an atom in Java?\nJoe Here, take a look. It’s quite simple.\n--- Page 198 ---\n170 CHAPTER 8 Advanced concurrency control\nListing8.5 Using an Atom in Java\nAtom<Integer> counter = new Atom<Integer>();\ncounter.set(0);\ncounter.swap(x -> x + 1);\ncounter.get();\nTheo takes a couple of minutes to meditate about this atom stuff and to digest what he’s\njust learned. Then, he asks Joe:\nTheo What if swap never succeeds? I mean, could the while loop inside the code of\nswap turn out to be an infinite loop?\nJoe No! By definition, when atomicCompareAndSet fails on a thread, it means that\nthe same atom was changed on another thread during the execution of swap.\nIn this race between threads, there is always a winner.\nTheo But isn’t it possible that some thread never succeeds because it always loses the\nrace against other threads?\nJoe In theory, yes, but I’ve never encountered such a situation. If you have thou-\nsands of threads that do nothing besides swapping an atom, it could happen I\nsuppose. But, in practice, once the atom is swapped, the threads do some real\nwork, for example, database access or I/O. This gives other threads the oppor-\ntunity to swap the atom successfully.\n NOTE In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing beside swapping an atom. In practice, once an atom is swapped, the\nthreads do some real work (e.g., database access), which creates an opportunity for\nother threads to swap the atom successfully.\nTheo Interesting.... Indeed, atoms look much easier to manage than locks.\nJoe Now let me show you how to use atoms with composite data.\nTheo Why would that be different?\nJoe Usually, dealing with composite data is more difficult than dealing with primi-\ntive types.\nTheo When you sold me on DOP, you told me that we are able to manage data with\nthe same simplicity as we manage numbers.\nTIP In DOP, data is managed with the same simplicity as numbers.\nJoe That’s exactly what I am about to show you.\n8.3 Thread-safe cache with atoms\nJoe Are you familiar with the notion of in-memory cache?\nTheo You mean memoization?\n--- Page 199 ---\n8.3 Thread-safe cache with atoms 171\nJoe Kind of. Imagine that database queries don’t vary too much in your applica-\ntion. It makes sense in that case to store the results of previous queries in mem-\nory in order to improve the response time.\nTheo Yes, of course!\nJoe What data structure would you use to store the in-memory cache?\nTheo Probably a string map, where the keys are the queries, and the values are the\nresults from the database.\nTIP It’s quite common to represent an in-memory cache as a string map.\nJoe Excellent! Now can you write the code to cache database queries in a thread-\nsafe way using a lock?\nTheo Let me see: I’m going to use an immutable string map. Therefore, I don’t\nneed to protect read access with a lock. Only the cache update needs to be\nprotected.\nJoe You’re getting the hang of this!\nTheo The code should be something like this.\nListing8.6 Thread-safe cache with locks\nvar mutex = new Mutex();\nvar cache = {};\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache, query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\nmutex.lock();\ncache = _.set(cache, query, result);\nmutex.unlock();\nreturn result;\n}\nJoe Nice! Now, let me show you how to write the same code using an atom instead\nof a lock. Take a look at this code and let me know if it’s clear to you.\nListing8.7 Thread-safe cache with atoms\nvar cache = new Atom();\ncache.set({});\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache.get(), query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\ncache.swap(function(oldCache) {\n--- Page 200 ---\n172 CHAPTER 8 Advanced concurrency control\nreturn _.set(oldCache, query, result);\n});\nreturn result;\n}\nTheo I don’t understand the function you’re passing to the swap method.\nJoe The function passed to swap receives the current value of the cache, which is a\nstring map, and returns a new version of the string map with an additional key-\nvalue pair.\nTheo I see. But something bothers me with the performance of the swap method in\nthe case of a string map. How does the comparison work? I mean, comparing\ntwo string maps might take some time.\nJoe Not if you compare them by reference. As we discussed in the past, when data\nis immutable, it is safe to compare by reference, and it’s super fast.\nTIP When data is immutable, it is safe (and fast) to compare it by reference.\nTheo Cool. So atoms play well with immutable data.\nJoe Exactly!\n8.4 State management with atoms\nJoe Do you remember a couple of weeks ago when I showed you how we resolve\npotential conflicts between mutations? You told me that the code was not\nthread-safe.\nTheo Let me look again at the code.\nTheo takes a look at the code for the SystemData class that he wrote some time ago\n(repeated in listing 8.8). Without the validation logic, it makes the code easier to grasp.\nListing8.8 SystemData class from part 1\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nthis.systemData = SystemConsistency.reconcile(this.systemData,\nprevious,\nnext);\n}\n}\n--- Page 201 ---\n8.4 State management with atoms 173\nIt takes him a few minutes to remember how the commit method works. Suddenly, he has\nan Aha! moment.\nTheo This code is not thread-safe because the SystemConsistency.reconcile\ncode inside the commit method is not protected. Nothing prevents the two\nthreads from executing this code concurrently.\nJoe Right! Now, can you tell me how to make it thread-safe?\nTheo With locks?\nJoe Come on...\nTheo I was kidding, of course. We make the code thread-safe not with a lock but with\nan atom.\nJoe Nice joke!\nTheo Let me see. I’d need to store the system data inside an atom. The get and set\nmethod of SystemData would simply call the get and set methods of the\natom. How does this look?\nListing8.9 SystemData class with atom (without the commit method)\nclass SystemState {\nsystemData;\nconstructor() {\nthis.systemData = new Atom();\n}\nget() {\nreturn this.systemData.get();\n}\ncommit(prev, next) {\nthis.systemData.set(next);\n}\n}\nJoe Excellent. Now for the fun part. Implement the commit method by calling the\nswap method of the atom.\nTheo Instead of calling SystemConsistency.reconcile() directly, I need to wrap\nit into a call to swap. So, something like this?\nListing8.10 Implementation of SystemData.commit with atom\nSystemData.commit = function(previous, next) {\nthis.systemData.swap(function(current) {\nreturn SystemConsistency.reconcile(current,\nprevious,\nnext);\n});\n};",
        "sections_found": []
      },
      "accurate_page_range": "176-201"
    },
    {
      "text": "- 7.2 JSON Schema in a nutshell",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "7 Basic data validation",
      "raw_line": "- 7.2 JSON Schema in a nutshell (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 59,
      "chapter_info": {
        "page": 176,
        "title": "Basic data validation",
        "pattern_matched": "Chapter 7",
        "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
      },
      "chapter_sections": {
        "start_page": 176,
        "end_page": 201,
        "content": "\n--- Page 176 ---\n148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema from listing 7.6.\nListing7.7 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe Give it a try, and you’ll see.\nIndeed! When Theo executes the code to validate the search request, it returns true.\nListing7.8 Validating the search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksRequest = {\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nvalidate(searchBooksRequestSchema, searchBooksRequest);\n// → true\nJoe Now, please try an invalid request.\nTheo Let me think about what kind of invalidity to try. I know, I’ll make a typo in the\ntitle field and call it tilte with the l before the t.\nAs expected, the code with the type returns false. Theo is not surprised, and Joe is smil-\ning from ear to ear.\nListing7.9 Validating an invalid search request\nvar invalidSearchBooksRequest = {\n\"tilte\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\n--- Page 177 ---\n7.3 Schema flexibility and strictness 149\nvalidate(searchBooksRequestSchema, invalidSearchBooksRequest);\n// → false\nTheo The syntax of JSON Schema is much more verbose than the syntax for declar-\ning the members in a class. Why is that so?\nJoe For two reasons. First, because JSON Schema is language independent, it can\nbe used in any programming language. As I told you, there are JSON Schema\nvalidators available in most programming languages.\nTheo I see.\nJoe Second, JSON Schema allows you to express validation conditions that are much\nharder, if not impossible, to express when data is represented with classes.\nTIP The expressive power of JSON Schema is high!\nTheo Now you have triggered my curiosity. Can you give me some examples?\nJoe In a moment, we’ll talk about schema composition. Someday I’ll show you\nsome examples of advanced validation.\n NOTE Advanced validation is covered in chapter 12.\nTheo What kind of advanced validation?\nJoe What I mean by advanced validation is, for instance, validating that a number\nfalls within a given range or validating that a string matches a regular expression.\nTheo Is there a way to get details about why the request is invalid?\nJoe Absolutely! I’ll show you later. For now, let me show you how to make sure the\nresponse the server sends back to the client is valid.\nTheo It sounds much more complicated than a search book request!\nJoe Why?\nTheo Because a search response is made of multiple book results, and in each book\nresult, some of the fields are optional!\n7.3 Schema flexibility and strictness\nJoe Can you give me an example of what a book search response would look like?\nTheo Take a look at this example. It’s a search response with information about two\nbooks: 7 Habits of Highly Effective People and The Power of Habit.\nListing7.10 An example of a search response\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432\n},\n--- Page 178 ---\n150 CHAPTER 7 Basic data validation\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn_13\": \"978-1982137274\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n]\n}\n]\nJoe It’s funny that you mention The Power of Habit. I’m reading this book in order\nto get rid of my habit of biting my nails. Anyway, what fields are required and\nwhat fields are optional in a book search response?\nTheo In book information, the title and available fields are required. The other\nfields are optional.\nJoe As I told you when we built the schema for the book search request, fields in a\nmap are optional by default. In order to make a field mandatory, we have to\ninclude it in the required array. I’d probably implement it with something\nlike this.\nListing7.11 Schema of a search response\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, map fields are optional by default.\nTheo I must admit that specifying a list of required fields is much simpler than hav-\ning to specify that a member in a class in nullable!\nJoe Agreed!\nTheo On the other hand, I find the nesting of the book information schema in the\nsearch response schema a bit hard to read.\n--- Page 179 ---\n7.3 Schema flexibility and strictness 151\nJoe Nothing prevents you from separating the book information schema from the\nsearch response schema.\nTheo How?\nJoe It’s just JSON, my friend. It means, you are free to manipulate the schema as\nany other map in your program. For instance, you could have the book infor-\nmation schema in a variable named bookInfoSchema and use it in the search\nbooks response schema. Let me refactor the schema to show you what I mean.\nListing7.12 Schema of a search response refactored\nvar bookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n};\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": bookInfoSchema\n};\nTheo Once again, I have to admit that JSON Schemas are more composable than\nclass definitions.\nTIP JSON Schemas are just maps. We are free to compose and manipulate them like\nany other map.\nJoe Let’s move on to validating data received from external data sources.\nTheo Is that different?\nJoe Not really, but I’ll take it as an opportunity to show you some other features of\nJSON Schema.\nTheo I’m curious to learn how data validation is used when we access data from the\ndatabase.\nJoe Each time we access data from the outside, it’s a good practice to validate it.\nCan you show me an example of how a database response for a search query\nwould look?\nTIP It’s a good practice to validate data that comes from an external data source.\n--- Page 180 ---\n152 CHAPTER 7 Basic data validation\nTheo When we query books from the database, we expect to receive an array of\nbooks with three fields: title, isbn, and available. The first two values should\nbe strings, and the third one should be a Boolean.\nJoe Are those fields optional or required?\nTheo What do you mean?\nJoe Could there be books for which some of the fields are not defined?\nTheo No.\nJoe In that case, the schema is quite simple. Would you like to try writing the\nschema for the database response?\nTheo Let me see. It’s an array of objects where each object has three properties, so\nsomething like this?\nListing7.13 Schema of a database response\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n}\nJoe Well done, my friend! Now, I want to tell you about the additionalProperties\nfield in JSON Schema.\nTheo What’s that?\nJoe Take a look at this array.\nListing7.14 A book array with an additional property\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"dummy_property\": 42\n},\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn\": \"978-1982137274\",\n\"dummy_property\": 45\n}\n]\n--- Page 181 ---\n7.3 Schema flexibility and strictness 153\nJoe Is it a valid database response?\nTheo No. A database response should not have a dummy_property field. It should\nhave only the three required fields specified in the schema.\nJoe It might be surprising but, by default, fields not specified in the schema of an\nobject are allowed in JSON Schema. In order to disallow them, one has to set\nadditionalProperties to false like this.\nListing7.15 Disallowing properties not mentioned in the schema\nvar booksFromDBSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, by default, fields not specified in the schema of a map are\nallowed.\nTheo Why is that?\nJoe The reason is that usually having additional fields in a map doesn’t cause\ntrouble. If your code doesn’t care about a field, it simply ignores it. But some-\ntimes we want to be as strict as possible, and we set additionalProperties\nto false.\nTheo What about the search request and response schema from the previous discus-\nsions? Should we set additionalProperties to false?\nJoe That’s an excellent question. I’d say it’s a matter of taste. Personally, I like to\nallow additional fields in requests and disallow them in responses.\nTheo What’s the advantage?\nJoe Well, the web server is responsible for the responses it sends to its clients. It\nmakes sense then to be as strict as possible. However, the requests are created\nby the clients, and I prefer to do my best to serve my clients even when they are\nnot as strict as they should be.\nTheo Naturally. “The client is always right.”\nJoe Actually, I prefer the way Jon Postel formulated his robustness principle: “Be\nconservative in what you send, be liberal in what you accept.”\nTIP It’s a good practice to be strict with the data that you send and to be flexible with\nthe data that you receive.\n--- Page 182 ---\n154 CHAPTER 7 Basic data validation\n7.4 Schema composition\nTheo What about validating data that comes from an external web service?\nJoe Can you give me an example?\nTheo In the near future, we’ll have to integrate with a service called Open Library\nBooks API that provides detailed information about books.\n NOTE For information on the Open Library Books API, see https://openlibrary\n.org/dev/docs/api/books.\nJoe Can you show me, for instance, the service response for Watchmen?\nTheo Sure. Here you go.\nTheo taps a few keys on his keyboard and brings up the response. Joe looks at the JSON for\na long time.\nListing7.16 An Open Library Books API response example\n{\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n}\nTheo asks himself, “What could be so special in this JSON?” While Joe is meditating about\nthis piece of JSON, Theo writes the JSON Schema for the Books API response. It doesn’t\nseem to be more complicated than any of the previous schemas. When Theo is done, he\nasks Joe to take a look at the schema.\nListing7.17 Schema of the Open Library Books API response\n{\n\"type\": \"object\",\n\"required\": [\"title\"],\n--- Page 183 ---\n7.4 Schema composition 155\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n}\nJoe Good job!\nTheo That wasn’t so hard. I really don’t see why you looked at this JSON response for\nsuch a long time.\nJoe Well, it has to do with the isbn_10 and isbn_13 fields. I assume that they’re\nnot both mandatory.\nTheo Right! That’s why I didn’t include them in the required field of my schema.\nJoe But one of them should always be there. Right?\nTheo Sometimes one of them and sometimes both of them, like for Watchmen. It\ndepends on the publication year of the book. Books published before 2007\nhave isbn_10, and books published after 2007 have isbn_13.\nJoe Oh, I see. And Watchmen has both because it was originally published in 1986\nbut published again after 2007.\nTheo Correct.\nJoe Then, you need your schema to indicate that one of the isbn fields is man-\ndatory. That’s a good opportunity for me to tell you about JSON Schema\ncomposition.\nTheo What’s that?\nJoe It’s a way to combine schemas, similarly to how we combine logical conditions\nwith AND, OR, and NOT.\nTheo I’d like to see that.\nJoe Sure. How would you express the schema for the Books API response as a\ncomposition of three schemas: basicBookInfoSchema, the schema that you\nwrote where only title is required; mandatoryIsbn13, a schema where only\n--- Page 184 ---\n156 CHAPTER 7 Basic data validation\nisbn_13 is required; and mandatoryIsb10, a schema where only isbn_10 is\nrequired?\nTheo I think it should be basicBookInfoSchema AND (mandatoryIsbn13 OR\nmandatoryIsbn10).\nJoe Exactly! The only thing is that in JSON Schema, we use allOf instead of AND,\nand anyOf instead of OR.\nJoe shows Theo the result in listing 7.18 and an example of its usage in listing 7.19.\nListing7.18 Schema of an external API response\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n--- Page 185 ---\n7.4 Schema composition 157\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing7.19 Validating an external API response\nvar bookInfo = {\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n};\nvalidate(bookInfoSchema, bookInfo);\n// → true\nTheo I see why they call it allOf and anyOf. The first one means that data must con-\nform to all the schemas, and the second one means that data must conform to\nany of the schemas.\nJoe Yup.\n NOTE JSON Schema also supports oneOf for cases where data must be valid against\nexactly one schema.\nTheo Nice. With schema composition, JSON Schema seems to have more expressive\npower than what I was used to when representing data with classes.\nJoe That’s only the beginning. I’ll show you more data validation conditions that\ncan’t be expressed when data is represented with classes some other time.\n NOTE Advanced data validation is covered in chapter 12.\nTheo Something still bothers me, though. When data isn’t valid, you don’t know what\nwent wrong.\n--- Page 186 ---\n158 CHAPTER 7 Basic data validation\n7.5 Details about data validation failures\nJoe So far, we’ve treated JSON Schema validation as though it were binary: either a\npiece of data is valid or it isn’t.\nTheo Right...\nJoe But, in fact, when a piece of data is not valid, we can get details about the\nreason of the invalidity.\nTheo Like when a required field is missing, can we get the name of the missing field?\nJoe Yes. When a piece of data is not of the expected type, we can get information\nabout that also.\nTheo That sounds very useful!\nJoe Indeed. Let me show you how it works. Until now, we used a generic validate\nfunction, but when we deal with validation failures, we need to be more specific.\nTheo Why?\nJoe Because each data validator library has its own way of exposing the details of\nadata validation failure. For instance, in JavaScript Ajv, the errors from the\nlast data validation are stored as an array inside the validator instance.\nTheo Why an array?\nJoe Because there could be several failures. But let’s start with the case of a single\nfailure. Imagine we encounter a search book request where the title field is\nnamed myTitle instead of title. Take a look at this example. As you can see,\nwe first instantiate a validator instance.\nListing7.20 Accessing validation errors in Ajv\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nInstantiates a\nvar ajv = new Ajv(); validator instance\najv.validate(searchBooksRequestSchema, invalidSearchBooksRequest);\najv.errors\nDisplays the\nvalidation errors\n--- Page 187 ---\n7.5 Details about data validation failures 159\nTheo And what does the information inside the errors array look like?\nJoe Execute the code snippet. You’ll see.\nWhen Theo executes the code snippets from listing 7.20, he can hardly believe his eyes. He\nlooks at the details, finding the results hard to digest.\nListing7.21 Details for a single data validation failure in an array format\n[\n{\n\"instancePath\": \"\",\n\"schemaPath\": \"#/required\",\n\"keyword\": \"required\",\n\"params\": {\n\"missingProperty\":\"title\"\n},\n\"message\": \"must have required property 'title'\"\n}\n]\nTheo I find the contents of the errors array a bit hard to understand.\nJoe Me too. Fortunately, Ajv provides a errorsText utility function to convert the\nerrors array in a human readable format. See, for instance, what is returned\nwhen you call errorsText.\nListing7.22 Displaying the errors in human readable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title'\"\nTheo Let me see what happens when there are more than one validation failure in\nthe data.\nJoe By default, Ajv catches only one validation error.\nTIP By default, Ajv catches only the first validation failure.\nTheo I guess that’s for performance reasons. Once the validator encounters an\nerror, it doesn’t continue the data parsing.\nJoe Probably. Anyway, in order to catch more than one validation failure, you need\nto pass the allErrors options to the Ajv constructor. Check out this code.\nListing7.23 Catching multiple validation failures\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n--- Page 188 ---\n160 CHAPTER 7 Basic data validation\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nA request with\nthree failures\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [1, 2]\n}; Instantiates the Ajv constructor\nwith allErrors: true in order to\ncatch more than one failure\nvar ajv = new Ajv({allErrors: true});\najv.validate(searchBooksRequestSchema,\ninvalidSearchBooksRequest); Converts the\nerrors to a human\nreadable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title',\n// → data/fields/0 must be string,\n// → data/fields/1 must be string\"\nJoe We validate a search request with myTitle instead of title and numbers\ninstead of strings in the fields array. As you can see in the output of the code\nsnippet, three errors are returned.\nTheo Great! I think I have all that I need in order to add data validation to the\nboundaries of my system when Nancy asks me to make the Library Manage-\nment System into a web server.\nJoe Would you allow me to give you a small gift as a token of our friendship?\nTheo I’d be honored.\nJoe takes a small package out of his bag, wrapped in a light-green ribbon. He hands Theo\nthe package with a solemn gesture.\nWhen Theo undoes the ribbon, he discovers an elegant piece of paper decorated with\npretty little designs. In the center of the paper, Theo manages to read the inscription\n“JSON Schema cheat sheet.” He smiles while browsing the cheat sheet. It’s exactly what he\nneeds.\nListing7.24 JSON Schema cheat sheet\n{ At the root level,\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the\narray is a map.\n\"type\": \"object\",\nmyNumber \"properties\": {\nThe properties of\nis a number. \"myNumber\": {\"type\": \"number\"},\neach field in the map\n\"myString\": {\"type\": \"string\"},\nmyString is\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\na string. myEnum is a\n\"myBool\": {\"type\": \"boolean\"}\nenumeration\nmyBool is a }, value with two\nboolean. \"required\": [\"myNumber\", \"myString\"], possibilities:\nThe mandatory fields in the map \"myVal\" and\nare myNumber and myString; \"yourVal\".\nother fields are optional.\n--- Page 189 ---\nSummary 161\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nThen, Theo turns the paper over to find that the back is also filled with drawings. In the\ncenter of the paper, he reads the inscription, “An example of valid data.”\nListing7.25 An example of valid data\n[\n{\nThis map is valid\n\"myNumber\": 42,\nbecause all its\n\"myString\": \"Hello\",\nfields are valid.\n\"myEnum\": \"myVal\",\n\"myBool\": true\n},\n{\nThis map is valid\n\"myNumber\": 54,\nbecause it contains all\n\"myString\": \"Happy\"\nthe required fields.\n}\n]\nSummary\n DOP Principle #4 is to separate data schema and data representation.\n The boundaries of a system are defined to be the areas where the system\nexchanges data.\n Some examples of data validation at the boundaries of the system are validation\nof client requests and responses, and validation of data that comes from exter-\nnal sources.\n Data validation in DOP means checking whether a piece of data conforms to a\nschema.\n When a piece of data is not valid, we get information about the validation fail-\nures and send this information back to the client in a human readable format.\n When data at system boundaries is valid, it’s not critical to validate data again\ninside the system.\n JSON Schema is a language that allows us to separate data validation from data\nrepresentation.\n JSON Schema syntax is a bit verbose.\n The expressive power of JSON Schema is high.\n JSON Schemas are just maps and, as so, we are free to manipulate them like any\nother maps in our programs.\n We can store a schema definition in a variable and use this variable in another\nschema.\n In JSON Schema, map fields are optional by default.\n It’s good practice to validate data that comes from an external data source.\n--- Page 190 ---\n162 CHAPTER 7 Basic data validation\n It’s good practice to be strict regarding data that you send and to be flexible\nregarding data that you receive.\n Ajv is a JSON Schema library in JavaScript.\n By default, Ajv catches only the first validation failure.\n Advanced validation is covered in chapter 12.\n--- Page 191 ---\nAdvanced\nconcurrency control\nNo more deadlocks!\nThis chapter covers\n Atoms as an alternative to locks\n Managing a thread-safe counter and a thread-safe\nin-memory cache with atoms\n Managing the whole system state in a thread-safe\nway with atoms\nThe traditional way to manage concurrency in a multi-threaded environment\ninvolves lock mechanisms like mutexes. Lock mechanisms tend to increase the com-\nplexity of the system because it’s not trivial to make sure the system is free of dead-\nlocks. In DOP, we leverage the fact that data is immutable, and we use a lock-free\nmechanism, called an atom, to manage concurrency. Atoms are simpler to manage\nthan locks because they are lock-free. As a consequence, the usual complexity of\nlocks that are required to avoid deadlocks don’t apply to atoms.\n NOTE This chapter is mostly relevant to multi-threaded environments like Java,\nC#, Python, and Ruby. It is less relevant to single-threaded environments like Java-\nScript. The JavaScript code snippets in this chapter are written as though JavaScript\nwere multi-threaded.\n163\n--- Page 192 ---\n164 CHAPTER 8 Advanced concurrency control\n8.1 The complexity of locks\nThis Sunday afternoon, while riding his bike across the Golden Gate Bridge, Theo thinks\nabout the Klafim project with concern, not yet sure that betting on DOP was a good\nchoice. Suddenly, Theo realizes that he hasn’t yet scheduled the next session with Joe. He\ngets off his bike to call Joe. Bad luck, the line is busy.\nWhen Theo gets home, he tries to call Joe again, but once again the phone is busy. After\ndinner, Theo tries to call Joe one more time, with the same result—a busy signal. “Obvi-\nously, Joe is very busy today,” Theo tells himself. Exhausted by his 50-mile bike ride at an\naverage of 17 miles per hour, he falls asleep on the sofa. When Theo wakes up, he’s elated\nto see a text message from Joe, “See you Monday morning at 11 AM?” Theo answers with a\nthumbs up and prepares for another week of work.\nWhen Joe arrives at the office, Theo asks him why his phone was constantly busy the day\nbefore. Joe answers that he was about to ask Theo the same question. They look at each\nother, puzzled, and then simultaneously break into laughter as they realize what hap-\npened: in an amazing coincidence, they’d tried to phone each other at exactly the same\ntimes. They both say at once:\n“A deadlock!”\nThey both head for Theo’s office. When they get to Theo’s desk, Joe tells him that today’s\nsession is going to be about concurrency management in multi-threaded environments.\nJoe How do you usually manage concurrency in a multi-threaded environment?\nTheo I protect access to critical sections with a lock mechanism, a mutex, for instance.\nJoe When you say access, do you mean write access or also read access?\nTheo Both!\nJoe Why do you need to protect read access with a lock?\nTheo Because, without a lock protection, in the middle of a read, a write could hap-\npen in another thread. It would make my read logically inconsistent.\nJoe Another option would be to clone the data before processing it in a read.\nTheo Sometimes I would clone the data; but in many cases, when it’s large, it’s too\nexpensive to clone.\nTIP Cloning data to avoid read locks doesn’t scale.\nJoe In DOP, we don’t need to clone or to protect read access.\nTheo Because data is immutable?\nJoe Right. When data is immutable, even if a write happens in another thread\nduring a read, it won’t make the read inconsistent because the write never\nmutates the data that is read.\nTheo In a sense, a read always works on a data snapshot.\nJoe Exactly!\nTIP When data is immutable, a read is always safe.\nTheo But what about write access? Don’t you need to protect that with locks?\nJoe Nope.\n--- Page 193 ---\n8.2 Thread-safe counter with atoms 165\nTheo Why not?\nJoe We have a simpler mechanism—it’s called an atom.\nTheo I am glad to hear there is a something simpler than locks. I really struggle each\ntime I have to integrate locks into a multi-threaded system.\nJoe Me too! I remember a bug we had in production 10 years ago. We forgot to\nrelease a lock when an exception was thrown in a critical section. It caused a\nterrible deadlock.\nTheo Deadlocks are really hard to avoid. Last year, we had a deadlock issue when two\nlocks were not released in the proper order.\nJoe I have great news for you. With atoms, deadlocks never happen!\nTIP With atoms, deadlocks never happen.\nTheo That sounds great. Tell me more!\nTIP Atoms provide a way to manage concurrency without locks.\n8.2 Thread-safe counter with atoms\nJoe Let’s start with a simple case: a counter shared between threads.\nTheo What do you mean by a counter?\nJoe Imagine that we’d like to count the number of database accesses and write the\ntotal number of accesses to a log every minute.\nTheo OK.\nJoe Could you write JavaScript code for this multi-threaded counter using locks?\nTheo But JavaScript is single-threaded!\nJoe I know, but it’s just for the sake of illustration. Imagine that JavaScript were\nmulti-threaded and that it provided a Mutex object that you could lock and\nunlock.\nTheo It’s a bit awkward. I guess it would look like this.\nTheo goes to the whiteboard. He writes what he imagines to be JavaScript code for a multi-\nthreaded counter with locks.\nListing8.1 A thread-safe counter protected by a mutex\nvar mutex = new Mutex();\nvar counter = 0;\nfunction dbAccess() {\nmutex.lock();\ncounter = counter + 1;\nmutex.unlock();\n// access the database\n}\nfunction logCounter() {\nmutex.lock();\n--- Page 194 ---\n166 CHAPTER 8 Advanced concurrency control\nconsole.log('Number of database accesses: ' + counter);\nmutex.unlock();\n}\nJoe Excellent. Now, I am going to show you how to write the same code with atoms.\nAn atom provides three methods:\n get returns the current value of the atom.\n set overwrites the current value of the atom.\n swap receives a function and updates the value of the atom with the result\nof the function called on the current value of the atom.\nJoe unzips a pocket in his laptop case and takes out a piece of paper. He hands it to\nTheo. Theo is pleasantly surprised as the sheet of paper succinctly describes the methods\n(table 8.1).\nTable 8.1 The three methods of an atom\nMethod Description\nget Returns the current value\nset Overwrites the current value\nswap Updates the current value with a function\nTheo How would it look like to implement a thread-safe counter with an atom?\nJoe It’s quite simple, actually.\nJoe pulls out his laptop, fires it up, and begins to type. When he’s done, he turns the laptop\naround so that Theo can see the code to implement a thread-safe counter in an atom.\nListing8.2 A thread-safe counter stored in an atom\nvar counter = new Atom();\ncounter.set(0);\nfunction dbAccess() {\ncounter.swap(function(x) {\nThe argument x is the\nreturn x + 1;\ncurrent value of the atom,\n});\nsame as counter.get().\n// access the database\n}\nfunction logCounter() {\nconsole.log('Number of database accesses: ' + counter.get());\n}\nTheo Could you tell me what’s going on here?\nJoe Sure! First, we create an empty atom. Then, we initialize the value of the atom\nwith counter.set(0). In the logger thread, we read the current value of the\natom with counter.get().\nTheo And how do you increment the counter in the threads that access the database?\n--- Page 195 ---\n8.2 Thread-safe counter with atoms 167\nJoe We call swap with a function that receives x and returns x + 1.\nTheo I don’t understand how swap could be thread-safe without using any locks.\nJoe quickly goes to the whiteboard. He sketches the diagram in figure 8.1.\nTake snapshot\nCompute next state\nYes\nState changed?\nNo\nUpdate state\nFigure 8.1 High-level flow of swap\nJoe You see, swap computes the next value of the atom, and before modifying the\ncurrent value of the atom, it checks whether the value of the atom has changed\nduring the computation. If so, swap tries again, until no changes occur during\nthe computation.\nTheo Is swap easy to implement?\nJoe Let me show you the implementation of the Atom class and you’ll see.\nListing8.3 Implementation of the Atom class\nclass Atom {\nstate;\nconstructor() {}\nget() {\nreturn this.state;\n}\nset(state) {\nthis.state = state;\n}\nswap(f) {\nwhile(true) {\nvar stateSnapshot = this.state;\nvar nextState = f(stateSnapshot);\nif (!atomicCompareAndSet(this.state,\n--- Page 196 ---\n168 CHAPTER 8 Advanced concurrency control\nstateSnapshot,\nnextState)) {\nUses a special thread-safe comparison operation\ncontinue;\nas this.state might have changed in another\n}\nthread during execution of the function f.\nreturn nextState;\n}\n}\n}\nTheo comes closer to the whiteboard. He modifies Joe’s diagram a bit to make the flow of\nthe swap operation more detailed. The resulting diagram is in figure 8.2. Theo still has a\nfew questions, though.\nTake snapshot\nsnapshot = state\nCompute next state\nnextState = f(snapshot)\nCheck if state has changed\nstate == snapshot\nYes\nState changed?\nNo\nUpdate state\nstate = nextState\nFigure 8.2 Detailed flow of swap\nTheo What is atomicCompareAndSet?\nJoe It’s the core operation of an atom. atomicCompareAndSet atomically sets the\nstate to a new value if, and only if, the state equals the provided old value. It\nreturns true upon success and false upon failure.\nTheo How could it be atomic without using locks?\nJoe That’s a great question! In fact, atomicCompareAndSet is a compare-and-swap\noperation, provided by the language that relies on a functionality of the CPU\nitself. For example, in Java the java.util.concurrent.atomic package has\nan AtomicReference generic class that provides a compareAndSet() method.\n NOTE See http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html\nfor general information about compare-and-swap operations. Implementations for\nmulti-threaded languages appear in table 8.2.\n--- Page 197 ---\n8.2 Thread-safe counter with atoms 169\nTable 8.2 Implementation of an atomic compare and set in various languages\nLanguage Link\nJava http://mng.bz/mx0W\nJavaScript Not relevant (single-threaded language)\nRuby http://mng.bz/5KG8\nPython https://github.com/maxcountryman/atomos\nC# http://mng.bz/6Zzp\nTheo Apropos Java, how would the implementation of an atom look?\nJoe It’s quite the same, besides the fact that Atom has to use generics, and the inner\nstate has to be stored in an AtomicReference.\nJoe brings up a Java implementation of Atom on his laptop. Theo looks over the code.\nListing8.4 Implementation of the Atom class in Java\nclass Atom<ValueType> {\nprivate AtomicReference<ValueType> state;\npublic Atom() {}\nValueType get() {\nreturn this.state.get();\n}\nthis.state might have\nchanged in another thread\nvoid set(ValueType state) {\nduring the execution of f.\nthis.state.set(state);\n}\nValueType swap(UnaryOPerator<ValueType> f) {\nwhile(true) {\nValueType stateSnapshot = this.state.get();\nValueType nextState = f(stateSnapshot);\nif (!this.state.compareAndSet(stateSnapshot,\nnextState)) {\ncontinue;\n}\n}\nreturn nextState;\n}\n}\nTheo What about using an atom in Java?\nJoe Here, take a look. It’s quite simple.\n--- Page 198 ---\n170 CHAPTER 8 Advanced concurrency control\nListing8.5 Using an Atom in Java\nAtom<Integer> counter = new Atom<Integer>();\ncounter.set(0);\ncounter.swap(x -> x + 1);\ncounter.get();\nTheo takes a couple of minutes to meditate about this atom stuff and to digest what he’s\njust learned. Then, he asks Joe:\nTheo What if swap never succeeds? I mean, could the while loop inside the code of\nswap turn out to be an infinite loop?\nJoe No! By definition, when atomicCompareAndSet fails on a thread, it means that\nthe same atom was changed on another thread during the execution of swap.\nIn this race between threads, there is always a winner.\nTheo But isn’t it possible that some thread never succeeds because it always loses the\nrace against other threads?\nJoe In theory, yes, but I’ve never encountered such a situation. If you have thou-\nsands of threads that do nothing besides swapping an atom, it could happen I\nsuppose. But, in practice, once the atom is swapped, the threads do some real\nwork, for example, database access or I/O. This gives other threads the oppor-\ntunity to swap the atom successfully.\n NOTE In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing beside swapping an atom. In practice, once an atom is swapped, the\nthreads do some real work (e.g., database access), which creates an opportunity for\nother threads to swap the atom successfully.\nTheo Interesting.... Indeed, atoms look much easier to manage than locks.\nJoe Now let me show you how to use atoms with composite data.\nTheo Why would that be different?\nJoe Usually, dealing with composite data is more difficult than dealing with primi-\ntive types.\nTheo When you sold me on DOP, you told me that we are able to manage data with\nthe same simplicity as we manage numbers.\nTIP In DOP, data is managed with the same simplicity as numbers.\nJoe That’s exactly what I am about to show you.\n8.3 Thread-safe cache with atoms\nJoe Are you familiar with the notion of in-memory cache?\nTheo You mean memoization?\n--- Page 199 ---\n8.3 Thread-safe cache with atoms 171\nJoe Kind of. Imagine that database queries don’t vary too much in your applica-\ntion. It makes sense in that case to store the results of previous queries in mem-\nory in order to improve the response time.\nTheo Yes, of course!\nJoe What data structure would you use to store the in-memory cache?\nTheo Probably a string map, where the keys are the queries, and the values are the\nresults from the database.\nTIP It’s quite common to represent an in-memory cache as a string map.\nJoe Excellent! Now can you write the code to cache database queries in a thread-\nsafe way using a lock?\nTheo Let me see: I’m going to use an immutable string map. Therefore, I don’t\nneed to protect read access with a lock. Only the cache update needs to be\nprotected.\nJoe You’re getting the hang of this!\nTheo The code should be something like this.\nListing8.6 Thread-safe cache with locks\nvar mutex = new Mutex();\nvar cache = {};\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache, query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\nmutex.lock();\ncache = _.set(cache, query, result);\nmutex.unlock();\nreturn result;\n}\nJoe Nice! Now, let me show you how to write the same code using an atom instead\nof a lock. Take a look at this code and let me know if it’s clear to you.\nListing8.7 Thread-safe cache with atoms\nvar cache = new Atom();\ncache.set({});\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache.get(), query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\ncache.swap(function(oldCache) {\n--- Page 200 ---\n172 CHAPTER 8 Advanced concurrency control\nreturn _.set(oldCache, query, result);\n});\nreturn result;\n}\nTheo I don’t understand the function you’re passing to the swap method.\nJoe The function passed to swap receives the current value of the cache, which is a\nstring map, and returns a new version of the string map with an additional key-\nvalue pair.\nTheo I see. But something bothers me with the performance of the swap method in\nthe case of a string map. How does the comparison work? I mean, comparing\ntwo string maps might take some time.\nJoe Not if you compare them by reference. As we discussed in the past, when data\nis immutable, it is safe to compare by reference, and it’s super fast.\nTIP When data is immutable, it is safe (and fast) to compare it by reference.\nTheo Cool. So atoms play well with immutable data.\nJoe Exactly!\n8.4 State management with atoms\nJoe Do you remember a couple of weeks ago when I showed you how we resolve\npotential conflicts between mutations? You told me that the code was not\nthread-safe.\nTheo Let me look again at the code.\nTheo takes a look at the code for the SystemData class that he wrote some time ago\n(repeated in listing 8.8). Without the validation logic, it makes the code easier to grasp.\nListing8.8 SystemData class from part 1\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nthis.systemData = SystemConsistency.reconcile(this.systemData,\nprevious,\nnext);\n}\n}\n--- Page 201 ---\n8.4 State management with atoms 173\nIt takes him a few minutes to remember how the commit method works. Suddenly, he has\nan Aha! moment.\nTheo This code is not thread-safe because the SystemConsistency.reconcile\ncode inside the commit method is not protected. Nothing prevents the two\nthreads from executing this code concurrently.\nJoe Right! Now, can you tell me how to make it thread-safe?\nTheo With locks?\nJoe Come on...\nTheo I was kidding, of course. We make the code thread-safe not with a lock but with\nan atom.\nJoe Nice joke!\nTheo Let me see. I’d need to store the system data inside an atom. The get and set\nmethod of SystemData would simply call the get and set methods of the\natom. How does this look?\nListing8.9 SystemData class with atom (without the commit method)\nclass SystemState {\nsystemData;\nconstructor() {\nthis.systemData = new Atom();\n}\nget() {\nreturn this.systemData.get();\n}\ncommit(prev, next) {\nthis.systemData.set(next);\n}\n}\nJoe Excellent. Now for the fun part. Implement the commit method by calling the\nswap method of the atom.\nTheo Instead of calling SystemConsistency.reconcile() directly, I need to wrap\nit into a call to swap. So, something like this?\nListing8.10 Implementation of SystemData.commit with atom\nSystemData.commit = function(previous, next) {\nthis.systemData.swap(function(current) {\nreturn SystemConsistency.reconcile(current,\nprevious,\nnext);\n});\n};",
        "sections_found": []
      },
      "accurate_page_range": "176-201"
    },
    {
      "text": "- 7.3 Schema flexibility and strictness",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "7 Basic data validation",
      "raw_line": "- 7.3 Schema flexibility and strictness (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 60,
      "chapter_info": {
        "page": 176,
        "title": "Basic data validation",
        "pattern_matched": "Chapter 7",
        "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
      },
      "chapter_sections": {
        "start_page": 176,
        "end_page": 201,
        "content": "\n--- Page 176 ---\n148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema from listing 7.6.\nListing7.7 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe Give it a try, and you’ll see.\nIndeed! When Theo executes the code to validate the search request, it returns true.\nListing7.8 Validating the search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksRequest = {\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nvalidate(searchBooksRequestSchema, searchBooksRequest);\n// → true\nJoe Now, please try an invalid request.\nTheo Let me think about what kind of invalidity to try. I know, I’ll make a typo in the\ntitle field and call it tilte with the l before the t.\nAs expected, the code with the type returns false. Theo is not surprised, and Joe is smil-\ning from ear to ear.\nListing7.9 Validating an invalid search request\nvar invalidSearchBooksRequest = {\n\"tilte\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\n--- Page 177 ---\n7.3 Schema flexibility and strictness 149\nvalidate(searchBooksRequestSchema, invalidSearchBooksRequest);\n// → false\nTheo The syntax of JSON Schema is much more verbose than the syntax for declar-\ning the members in a class. Why is that so?\nJoe For two reasons. First, because JSON Schema is language independent, it can\nbe used in any programming language. As I told you, there are JSON Schema\nvalidators available in most programming languages.\nTheo I see.\nJoe Second, JSON Schema allows you to express validation conditions that are much\nharder, if not impossible, to express when data is represented with classes.\nTIP The expressive power of JSON Schema is high!\nTheo Now you have triggered my curiosity. Can you give me some examples?\nJoe In a moment, we’ll talk about schema composition. Someday I’ll show you\nsome examples of advanced validation.\n NOTE Advanced validation is covered in chapter 12.\nTheo What kind of advanced validation?\nJoe What I mean by advanced validation is, for instance, validating that a number\nfalls within a given range or validating that a string matches a regular expression.\nTheo Is there a way to get details about why the request is invalid?\nJoe Absolutely! I’ll show you later. For now, let me show you how to make sure the\nresponse the server sends back to the client is valid.\nTheo It sounds much more complicated than a search book request!\nJoe Why?\nTheo Because a search response is made of multiple book results, and in each book\nresult, some of the fields are optional!\n7.3 Schema flexibility and strictness\nJoe Can you give me an example of what a book search response would look like?\nTheo Take a look at this example. It’s a search response with information about two\nbooks: 7 Habits of Highly Effective People and The Power of Habit.\nListing7.10 An example of a search response\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432\n},\n--- Page 178 ---\n150 CHAPTER 7 Basic data validation\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn_13\": \"978-1982137274\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n]\n}\n]\nJoe It’s funny that you mention The Power of Habit. I’m reading this book in order\nto get rid of my habit of biting my nails. Anyway, what fields are required and\nwhat fields are optional in a book search response?\nTheo In book information, the title and available fields are required. The other\nfields are optional.\nJoe As I told you when we built the schema for the book search request, fields in a\nmap are optional by default. In order to make a field mandatory, we have to\ninclude it in the required array. I’d probably implement it with something\nlike this.\nListing7.11 Schema of a search response\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, map fields are optional by default.\nTheo I must admit that specifying a list of required fields is much simpler than hav-\ning to specify that a member in a class in nullable!\nJoe Agreed!\nTheo On the other hand, I find the nesting of the book information schema in the\nsearch response schema a bit hard to read.\n--- Page 179 ---\n7.3 Schema flexibility and strictness 151\nJoe Nothing prevents you from separating the book information schema from the\nsearch response schema.\nTheo How?\nJoe It’s just JSON, my friend. It means, you are free to manipulate the schema as\nany other map in your program. For instance, you could have the book infor-\nmation schema in a variable named bookInfoSchema and use it in the search\nbooks response schema. Let me refactor the schema to show you what I mean.\nListing7.12 Schema of a search response refactored\nvar bookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n};\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": bookInfoSchema\n};\nTheo Once again, I have to admit that JSON Schemas are more composable than\nclass definitions.\nTIP JSON Schemas are just maps. We are free to compose and manipulate them like\nany other map.\nJoe Let’s move on to validating data received from external data sources.\nTheo Is that different?\nJoe Not really, but I’ll take it as an opportunity to show you some other features of\nJSON Schema.\nTheo I’m curious to learn how data validation is used when we access data from the\ndatabase.\nJoe Each time we access data from the outside, it’s a good practice to validate it.\nCan you show me an example of how a database response for a search query\nwould look?\nTIP It’s a good practice to validate data that comes from an external data source.\n--- Page 180 ---\n152 CHAPTER 7 Basic data validation\nTheo When we query books from the database, we expect to receive an array of\nbooks with three fields: title, isbn, and available. The first two values should\nbe strings, and the third one should be a Boolean.\nJoe Are those fields optional or required?\nTheo What do you mean?\nJoe Could there be books for which some of the fields are not defined?\nTheo No.\nJoe In that case, the schema is quite simple. Would you like to try writing the\nschema for the database response?\nTheo Let me see. It’s an array of objects where each object has three properties, so\nsomething like this?\nListing7.13 Schema of a database response\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n}\nJoe Well done, my friend! Now, I want to tell you about the additionalProperties\nfield in JSON Schema.\nTheo What’s that?\nJoe Take a look at this array.\nListing7.14 A book array with an additional property\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"dummy_property\": 42\n},\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn\": \"978-1982137274\",\n\"dummy_property\": 45\n}\n]\n--- Page 181 ---\n7.3 Schema flexibility and strictness 153\nJoe Is it a valid database response?\nTheo No. A database response should not have a dummy_property field. It should\nhave only the three required fields specified in the schema.\nJoe It might be surprising but, by default, fields not specified in the schema of an\nobject are allowed in JSON Schema. In order to disallow them, one has to set\nadditionalProperties to false like this.\nListing7.15 Disallowing properties not mentioned in the schema\nvar booksFromDBSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, by default, fields not specified in the schema of a map are\nallowed.\nTheo Why is that?\nJoe The reason is that usually having additional fields in a map doesn’t cause\ntrouble. If your code doesn’t care about a field, it simply ignores it. But some-\ntimes we want to be as strict as possible, and we set additionalProperties\nto false.\nTheo What about the search request and response schema from the previous discus-\nsions? Should we set additionalProperties to false?\nJoe That’s an excellent question. I’d say it’s a matter of taste. Personally, I like to\nallow additional fields in requests and disallow them in responses.\nTheo What’s the advantage?\nJoe Well, the web server is responsible for the responses it sends to its clients. It\nmakes sense then to be as strict as possible. However, the requests are created\nby the clients, and I prefer to do my best to serve my clients even when they are\nnot as strict as they should be.\nTheo Naturally. “The client is always right.”\nJoe Actually, I prefer the way Jon Postel formulated his robustness principle: “Be\nconservative in what you send, be liberal in what you accept.”\nTIP It’s a good practice to be strict with the data that you send and to be flexible with\nthe data that you receive.\n--- Page 182 ---\n154 CHAPTER 7 Basic data validation\n7.4 Schema composition\nTheo What about validating data that comes from an external web service?\nJoe Can you give me an example?\nTheo In the near future, we’ll have to integrate with a service called Open Library\nBooks API that provides detailed information about books.\n NOTE For information on the Open Library Books API, see https://openlibrary\n.org/dev/docs/api/books.\nJoe Can you show me, for instance, the service response for Watchmen?\nTheo Sure. Here you go.\nTheo taps a few keys on his keyboard and brings up the response. Joe looks at the JSON for\na long time.\nListing7.16 An Open Library Books API response example\n{\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n}\nTheo asks himself, “What could be so special in this JSON?” While Joe is meditating about\nthis piece of JSON, Theo writes the JSON Schema for the Books API response. It doesn’t\nseem to be more complicated than any of the previous schemas. When Theo is done, he\nasks Joe to take a look at the schema.\nListing7.17 Schema of the Open Library Books API response\n{\n\"type\": \"object\",\n\"required\": [\"title\"],\n--- Page 183 ---\n7.4 Schema composition 155\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n}\nJoe Good job!\nTheo That wasn’t so hard. I really don’t see why you looked at this JSON response for\nsuch a long time.\nJoe Well, it has to do with the isbn_10 and isbn_13 fields. I assume that they’re\nnot both mandatory.\nTheo Right! That’s why I didn’t include them in the required field of my schema.\nJoe But one of them should always be there. Right?\nTheo Sometimes one of them and sometimes both of them, like for Watchmen. It\ndepends on the publication year of the book. Books published before 2007\nhave isbn_10, and books published after 2007 have isbn_13.\nJoe Oh, I see. And Watchmen has both because it was originally published in 1986\nbut published again after 2007.\nTheo Correct.\nJoe Then, you need your schema to indicate that one of the isbn fields is man-\ndatory. That’s a good opportunity for me to tell you about JSON Schema\ncomposition.\nTheo What’s that?\nJoe It’s a way to combine schemas, similarly to how we combine logical conditions\nwith AND, OR, and NOT.\nTheo I’d like to see that.\nJoe Sure. How would you express the schema for the Books API response as a\ncomposition of three schemas: basicBookInfoSchema, the schema that you\nwrote where only title is required; mandatoryIsbn13, a schema where only\n--- Page 184 ---\n156 CHAPTER 7 Basic data validation\nisbn_13 is required; and mandatoryIsb10, a schema where only isbn_10 is\nrequired?\nTheo I think it should be basicBookInfoSchema AND (mandatoryIsbn13 OR\nmandatoryIsbn10).\nJoe Exactly! The only thing is that in JSON Schema, we use allOf instead of AND,\nand anyOf instead of OR.\nJoe shows Theo the result in listing 7.18 and an example of its usage in listing 7.19.\nListing7.18 Schema of an external API response\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n--- Page 185 ---\n7.4 Schema composition 157\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing7.19 Validating an external API response\nvar bookInfo = {\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n};\nvalidate(bookInfoSchema, bookInfo);\n// → true\nTheo I see why they call it allOf and anyOf. The first one means that data must con-\nform to all the schemas, and the second one means that data must conform to\nany of the schemas.\nJoe Yup.\n NOTE JSON Schema also supports oneOf for cases where data must be valid against\nexactly one schema.\nTheo Nice. With schema composition, JSON Schema seems to have more expressive\npower than what I was used to when representing data with classes.\nJoe That’s only the beginning. I’ll show you more data validation conditions that\ncan’t be expressed when data is represented with classes some other time.\n NOTE Advanced data validation is covered in chapter 12.\nTheo Something still bothers me, though. When data isn’t valid, you don’t know what\nwent wrong.\n--- Page 186 ---\n158 CHAPTER 7 Basic data validation\n7.5 Details about data validation failures\nJoe So far, we’ve treated JSON Schema validation as though it were binary: either a\npiece of data is valid or it isn’t.\nTheo Right...\nJoe But, in fact, when a piece of data is not valid, we can get details about the\nreason of the invalidity.\nTheo Like when a required field is missing, can we get the name of the missing field?\nJoe Yes. When a piece of data is not of the expected type, we can get information\nabout that also.\nTheo That sounds very useful!\nJoe Indeed. Let me show you how it works. Until now, we used a generic validate\nfunction, but when we deal with validation failures, we need to be more specific.\nTheo Why?\nJoe Because each data validator library has its own way of exposing the details of\nadata validation failure. For instance, in JavaScript Ajv, the errors from the\nlast data validation are stored as an array inside the validator instance.\nTheo Why an array?\nJoe Because there could be several failures. But let’s start with the case of a single\nfailure. Imagine we encounter a search book request where the title field is\nnamed myTitle instead of title. Take a look at this example. As you can see,\nwe first instantiate a validator instance.\nListing7.20 Accessing validation errors in Ajv\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nInstantiates a\nvar ajv = new Ajv(); validator instance\najv.validate(searchBooksRequestSchema, invalidSearchBooksRequest);\najv.errors\nDisplays the\nvalidation errors\n--- Page 187 ---\n7.5 Details about data validation failures 159\nTheo And what does the information inside the errors array look like?\nJoe Execute the code snippet. You’ll see.\nWhen Theo executes the code snippets from listing 7.20, he can hardly believe his eyes. He\nlooks at the details, finding the results hard to digest.\nListing7.21 Details for a single data validation failure in an array format\n[\n{\n\"instancePath\": \"\",\n\"schemaPath\": \"#/required\",\n\"keyword\": \"required\",\n\"params\": {\n\"missingProperty\":\"title\"\n},\n\"message\": \"must have required property 'title'\"\n}\n]\nTheo I find the contents of the errors array a bit hard to understand.\nJoe Me too. Fortunately, Ajv provides a errorsText utility function to convert the\nerrors array in a human readable format. See, for instance, what is returned\nwhen you call errorsText.\nListing7.22 Displaying the errors in human readable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title'\"\nTheo Let me see what happens when there are more than one validation failure in\nthe data.\nJoe By default, Ajv catches only one validation error.\nTIP By default, Ajv catches only the first validation failure.\nTheo I guess that’s for performance reasons. Once the validator encounters an\nerror, it doesn’t continue the data parsing.\nJoe Probably. Anyway, in order to catch more than one validation failure, you need\nto pass the allErrors options to the Ajv constructor. Check out this code.\nListing7.23 Catching multiple validation failures\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n--- Page 188 ---\n160 CHAPTER 7 Basic data validation\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nA request with\nthree failures\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [1, 2]\n}; Instantiates the Ajv constructor\nwith allErrors: true in order to\ncatch more than one failure\nvar ajv = new Ajv({allErrors: true});\najv.validate(searchBooksRequestSchema,\ninvalidSearchBooksRequest); Converts the\nerrors to a human\nreadable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title',\n// → data/fields/0 must be string,\n// → data/fields/1 must be string\"\nJoe We validate a search request with myTitle instead of title and numbers\ninstead of strings in the fields array. As you can see in the output of the code\nsnippet, three errors are returned.\nTheo Great! I think I have all that I need in order to add data validation to the\nboundaries of my system when Nancy asks me to make the Library Manage-\nment System into a web server.\nJoe Would you allow me to give you a small gift as a token of our friendship?\nTheo I’d be honored.\nJoe takes a small package out of his bag, wrapped in a light-green ribbon. He hands Theo\nthe package with a solemn gesture.\nWhen Theo undoes the ribbon, he discovers an elegant piece of paper decorated with\npretty little designs. In the center of the paper, Theo manages to read the inscription\n“JSON Schema cheat sheet.” He smiles while browsing the cheat sheet. It’s exactly what he\nneeds.\nListing7.24 JSON Schema cheat sheet\n{ At the root level,\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the\narray is a map.\n\"type\": \"object\",\nmyNumber \"properties\": {\nThe properties of\nis a number. \"myNumber\": {\"type\": \"number\"},\neach field in the map\n\"myString\": {\"type\": \"string\"},\nmyString is\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\na string. myEnum is a\n\"myBool\": {\"type\": \"boolean\"}\nenumeration\nmyBool is a }, value with two\nboolean. \"required\": [\"myNumber\", \"myString\"], possibilities:\nThe mandatory fields in the map \"myVal\" and\nare myNumber and myString; \"yourVal\".\nother fields are optional.\n--- Page 189 ---\nSummary 161\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nThen, Theo turns the paper over to find that the back is also filled with drawings. In the\ncenter of the paper, he reads the inscription, “An example of valid data.”\nListing7.25 An example of valid data\n[\n{\nThis map is valid\n\"myNumber\": 42,\nbecause all its\n\"myString\": \"Hello\",\nfields are valid.\n\"myEnum\": \"myVal\",\n\"myBool\": true\n},\n{\nThis map is valid\n\"myNumber\": 54,\nbecause it contains all\n\"myString\": \"Happy\"\nthe required fields.\n}\n]\nSummary\n DOP Principle #4 is to separate data schema and data representation.\n The boundaries of a system are defined to be the areas where the system\nexchanges data.\n Some examples of data validation at the boundaries of the system are validation\nof client requests and responses, and validation of data that comes from exter-\nnal sources.\n Data validation in DOP means checking whether a piece of data conforms to a\nschema.\n When a piece of data is not valid, we get information about the validation fail-\nures and send this information back to the client in a human readable format.\n When data at system boundaries is valid, it’s not critical to validate data again\ninside the system.\n JSON Schema is a language that allows us to separate data validation from data\nrepresentation.\n JSON Schema syntax is a bit verbose.\n The expressive power of JSON Schema is high.\n JSON Schemas are just maps and, as so, we are free to manipulate them like any\nother maps in our programs.\n We can store a schema definition in a variable and use this variable in another\nschema.\n In JSON Schema, map fields are optional by default.\n It’s good practice to validate data that comes from an external data source.\n--- Page 190 ---\n162 CHAPTER 7 Basic data validation\n It’s good practice to be strict regarding data that you send and to be flexible\nregarding data that you receive.\n Ajv is a JSON Schema library in JavaScript.\n By default, Ajv catches only the first validation failure.\n Advanced validation is covered in chapter 12.\n--- Page 191 ---\nAdvanced\nconcurrency control\nNo more deadlocks!\nThis chapter covers\n Atoms as an alternative to locks\n Managing a thread-safe counter and a thread-safe\nin-memory cache with atoms\n Managing the whole system state in a thread-safe\nway with atoms\nThe traditional way to manage concurrency in a multi-threaded environment\ninvolves lock mechanisms like mutexes. Lock mechanisms tend to increase the com-\nplexity of the system because it’s not trivial to make sure the system is free of dead-\nlocks. In DOP, we leverage the fact that data is immutable, and we use a lock-free\nmechanism, called an atom, to manage concurrency. Atoms are simpler to manage\nthan locks because they are lock-free. As a consequence, the usual complexity of\nlocks that are required to avoid deadlocks don’t apply to atoms.\n NOTE This chapter is mostly relevant to multi-threaded environments like Java,\nC#, Python, and Ruby. It is less relevant to single-threaded environments like Java-\nScript. The JavaScript code snippets in this chapter are written as though JavaScript\nwere multi-threaded.\n163\n--- Page 192 ---\n164 CHAPTER 8 Advanced concurrency control\n8.1 The complexity of locks\nThis Sunday afternoon, while riding his bike across the Golden Gate Bridge, Theo thinks\nabout the Klafim project with concern, not yet sure that betting on DOP was a good\nchoice. Suddenly, Theo realizes that he hasn’t yet scheduled the next session with Joe. He\ngets off his bike to call Joe. Bad luck, the line is busy.\nWhen Theo gets home, he tries to call Joe again, but once again the phone is busy. After\ndinner, Theo tries to call Joe one more time, with the same result—a busy signal. “Obvi-\nously, Joe is very busy today,” Theo tells himself. Exhausted by his 50-mile bike ride at an\naverage of 17 miles per hour, he falls asleep on the sofa. When Theo wakes up, he’s elated\nto see a text message from Joe, “See you Monday morning at 11 AM?” Theo answers with a\nthumbs up and prepares for another week of work.\nWhen Joe arrives at the office, Theo asks him why his phone was constantly busy the day\nbefore. Joe answers that he was about to ask Theo the same question. They look at each\nother, puzzled, and then simultaneously break into laughter as they realize what hap-\npened: in an amazing coincidence, they’d tried to phone each other at exactly the same\ntimes. They both say at once:\n“A deadlock!”\nThey both head for Theo’s office. When they get to Theo’s desk, Joe tells him that today’s\nsession is going to be about concurrency management in multi-threaded environments.\nJoe How do you usually manage concurrency in a multi-threaded environment?\nTheo I protect access to critical sections with a lock mechanism, a mutex, for instance.\nJoe When you say access, do you mean write access or also read access?\nTheo Both!\nJoe Why do you need to protect read access with a lock?\nTheo Because, without a lock protection, in the middle of a read, a write could hap-\npen in another thread. It would make my read logically inconsistent.\nJoe Another option would be to clone the data before processing it in a read.\nTheo Sometimes I would clone the data; but in many cases, when it’s large, it’s too\nexpensive to clone.\nTIP Cloning data to avoid read locks doesn’t scale.\nJoe In DOP, we don’t need to clone or to protect read access.\nTheo Because data is immutable?\nJoe Right. When data is immutable, even if a write happens in another thread\nduring a read, it won’t make the read inconsistent because the write never\nmutates the data that is read.\nTheo In a sense, a read always works on a data snapshot.\nJoe Exactly!\nTIP When data is immutable, a read is always safe.\nTheo But what about write access? Don’t you need to protect that with locks?\nJoe Nope.\n--- Page 193 ---\n8.2 Thread-safe counter with atoms 165\nTheo Why not?\nJoe We have a simpler mechanism—it’s called an atom.\nTheo I am glad to hear there is a something simpler than locks. I really struggle each\ntime I have to integrate locks into a multi-threaded system.\nJoe Me too! I remember a bug we had in production 10 years ago. We forgot to\nrelease a lock when an exception was thrown in a critical section. It caused a\nterrible deadlock.\nTheo Deadlocks are really hard to avoid. Last year, we had a deadlock issue when two\nlocks were not released in the proper order.\nJoe I have great news for you. With atoms, deadlocks never happen!\nTIP With atoms, deadlocks never happen.\nTheo That sounds great. Tell me more!\nTIP Atoms provide a way to manage concurrency without locks.\n8.2 Thread-safe counter with atoms\nJoe Let’s start with a simple case: a counter shared between threads.\nTheo What do you mean by a counter?\nJoe Imagine that we’d like to count the number of database accesses and write the\ntotal number of accesses to a log every minute.\nTheo OK.\nJoe Could you write JavaScript code for this multi-threaded counter using locks?\nTheo But JavaScript is single-threaded!\nJoe I know, but it’s just for the sake of illustration. Imagine that JavaScript were\nmulti-threaded and that it provided a Mutex object that you could lock and\nunlock.\nTheo It’s a bit awkward. I guess it would look like this.\nTheo goes to the whiteboard. He writes what he imagines to be JavaScript code for a multi-\nthreaded counter with locks.\nListing8.1 A thread-safe counter protected by a mutex\nvar mutex = new Mutex();\nvar counter = 0;\nfunction dbAccess() {\nmutex.lock();\ncounter = counter + 1;\nmutex.unlock();\n// access the database\n}\nfunction logCounter() {\nmutex.lock();\n--- Page 194 ---\n166 CHAPTER 8 Advanced concurrency control\nconsole.log('Number of database accesses: ' + counter);\nmutex.unlock();\n}\nJoe Excellent. Now, I am going to show you how to write the same code with atoms.\nAn atom provides three methods:\n get returns the current value of the atom.\n set overwrites the current value of the atom.\n swap receives a function and updates the value of the atom with the result\nof the function called on the current value of the atom.\nJoe unzips a pocket in his laptop case and takes out a piece of paper. He hands it to\nTheo. Theo is pleasantly surprised as the sheet of paper succinctly describes the methods\n(table 8.1).\nTable 8.1 The three methods of an atom\nMethod Description\nget Returns the current value\nset Overwrites the current value\nswap Updates the current value with a function\nTheo How would it look like to implement a thread-safe counter with an atom?\nJoe It’s quite simple, actually.\nJoe pulls out his laptop, fires it up, and begins to type. When he’s done, he turns the laptop\naround so that Theo can see the code to implement a thread-safe counter in an atom.\nListing8.2 A thread-safe counter stored in an atom\nvar counter = new Atom();\ncounter.set(0);\nfunction dbAccess() {\ncounter.swap(function(x) {\nThe argument x is the\nreturn x + 1;\ncurrent value of the atom,\n});\nsame as counter.get().\n// access the database\n}\nfunction logCounter() {\nconsole.log('Number of database accesses: ' + counter.get());\n}\nTheo Could you tell me what’s going on here?\nJoe Sure! First, we create an empty atom. Then, we initialize the value of the atom\nwith counter.set(0). In the logger thread, we read the current value of the\natom with counter.get().\nTheo And how do you increment the counter in the threads that access the database?\n--- Page 195 ---\n8.2 Thread-safe counter with atoms 167\nJoe We call swap with a function that receives x and returns x + 1.\nTheo I don’t understand how swap could be thread-safe without using any locks.\nJoe quickly goes to the whiteboard. He sketches the diagram in figure 8.1.\nTake snapshot\nCompute next state\nYes\nState changed?\nNo\nUpdate state\nFigure 8.1 High-level flow of swap\nJoe You see, swap computes the next value of the atom, and before modifying the\ncurrent value of the atom, it checks whether the value of the atom has changed\nduring the computation. If so, swap tries again, until no changes occur during\nthe computation.\nTheo Is swap easy to implement?\nJoe Let me show you the implementation of the Atom class and you’ll see.\nListing8.3 Implementation of the Atom class\nclass Atom {\nstate;\nconstructor() {}\nget() {\nreturn this.state;\n}\nset(state) {\nthis.state = state;\n}\nswap(f) {\nwhile(true) {\nvar stateSnapshot = this.state;\nvar nextState = f(stateSnapshot);\nif (!atomicCompareAndSet(this.state,\n--- Page 196 ---\n168 CHAPTER 8 Advanced concurrency control\nstateSnapshot,\nnextState)) {\nUses a special thread-safe comparison operation\ncontinue;\nas this.state might have changed in another\n}\nthread during execution of the function f.\nreturn nextState;\n}\n}\n}\nTheo comes closer to the whiteboard. He modifies Joe’s diagram a bit to make the flow of\nthe swap operation more detailed. The resulting diagram is in figure 8.2. Theo still has a\nfew questions, though.\nTake snapshot\nsnapshot = state\nCompute next state\nnextState = f(snapshot)\nCheck if state has changed\nstate == snapshot\nYes\nState changed?\nNo\nUpdate state\nstate = nextState\nFigure 8.2 Detailed flow of swap\nTheo What is atomicCompareAndSet?\nJoe It’s the core operation of an atom. atomicCompareAndSet atomically sets the\nstate to a new value if, and only if, the state equals the provided old value. It\nreturns true upon success and false upon failure.\nTheo How could it be atomic without using locks?\nJoe That’s a great question! In fact, atomicCompareAndSet is a compare-and-swap\noperation, provided by the language that relies on a functionality of the CPU\nitself. For example, in Java the java.util.concurrent.atomic package has\nan AtomicReference generic class that provides a compareAndSet() method.\n NOTE See http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html\nfor general information about compare-and-swap operations. Implementations for\nmulti-threaded languages appear in table 8.2.\n--- Page 197 ---\n8.2 Thread-safe counter with atoms 169\nTable 8.2 Implementation of an atomic compare and set in various languages\nLanguage Link\nJava http://mng.bz/mx0W\nJavaScript Not relevant (single-threaded language)\nRuby http://mng.bz/5KG8\nPython https://github.com/maxcountryman/atomos\nC# http://mng.bz/6Zzp\nTheo Apropos Java, how would the implementation of an atom look?\nJoe It’s quite the same, besides the fact that Atom has to use generics, and the inner\nstate has to be stored in an AtomicReference.\nJoe brings up a Java implementation of Atom on his laptop. Theo looks over the code.\nListing8.4 Implementation of the Atom class in Java\nclass Atom<ValueType> {\nprivate AtomicReference<ValueType> state;\npublic Atom() {}\nValueType get() {\nreturn this.state.get();\n}\nthis.state might have\nchanged in another thread\nvoid set(ValueType state) {\nduring the execution of f.\nthis.state.set(state);\n}\nValueType swap(UnaryOPerator<ValueType> f) {\nwhile(true) {\nValueType stateSnapshot = this.state.get();\nValueType nextState = f(stateSnapshot);\nif (!this.state.compareAndSet(stateSnapshot,\nnextState)) {\ncontinue;\n}\n}\nreturn nextState;\n}\n}\nTheo What about using an atom in Java?\nJoe Here, take a look. It’s quite simple.\n--- Page 198 ---\n170 CHAPTER 8 Advanced concurrency control\nListing8.5 Using an Atom in Java\nAtom<Integer> counter = new Atom<Integer>();\ncounter.set(0);\ncounter.swap(x -> x + 1);\ncounter.get();\nTheo takes a couple of minutes to meditate about this atom stuff and to digest what he’s\njust learned. Then, he asks Joe:\nTheo What if swap never succeeds? I mean, could the while loop inside the code of\nswap turn out to be an infinite loop?\nJoe No! By definition, when atomicCompareAndSet fails on a thread, it means that\nthe same atom was changed on another thread during the execution of swap.\nIn this race between threads, there is always a winner.\nTheo But isn’t it possible that some thread never succeeds because it always loses the\nrace against other threads?\nJoe In theory, yes, but I’ve never encountered such a situation. If you have thou-\nsands of threads that do nothing besides swapping an atom, it could happen I\nsuppose. But, in practice, once the atom is swapped, the threads do some real\nwork, for example, database access or I/O. This gives other threads the oppor-\ntunity to swap the atom successfully.\n NOTE In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing beside swapping an atom. In practice, once an atom is swapped, the\nthreads do some real work (e.g., database access), which creates an opportunity for\nother threads to swap the atom successfully.\nTheo Interesting.... Indeed, atoms look much easier to manage than locks.\nJoe Now let me show you how to use atoms with composite data.\nTheo Why would that be different?\nJoe Usually, dealing with composite data is more difficult than dealing with primi-\ntive types.\nTheo When you sold me on DOP, you told me that we are able to manage data with\nthe same simplicity as we manage numbers.\nTIP In DOP, data is managed with the same simplicity as numbers.\nJoe That’s exactly what I am about to show you.\n8.3 Thread-safe cache with atoms\nJoe Are you familiar with the notion of in-memory cache?\nTheo You mean memoization?\n--- Page 199 ---\n8.3 Thread-safe cache with atoms 171\nJoe Kind of. Imagine that database queries don’t vary too much in your applica-\ntion. It makes sense in that case to store the results of previous queries in mem-\nory in order to improve the response time.\nTheo Yes, of course!\nJoe What data structure would you use to store the in-memory cache?\nTheo Probably a string map, where the keys are the queries, and the values are the\nresults from the database.\nTIP It’s quite common to represent an in-memory cache as a string map.\nJoe Excellent! Now can you write the code to cache database queries in a thread-\nsafe way using a lock?\nTheo Let me see: I’m going to use an immutable string map. Therefore, I don’t\nneed to protect read access with a lock. Only the cache update needs to be\nprotected.\nJoe You’re getting the hang of this!\nTheo The code should be something like this.\nListing8.6 Thread-safe cache with locks\nvar mutex = new Mutex();\nvar cache = {};\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache, query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\nmutex.lock();\ncache = _.set(cache, query, result);\nmutex.unlock();\nreturn result;\n}\nJoe Nice! Now, let me show you how to write the same code using an atom instead\nof a lock. Take a look at this code and let me know if it’s clear to you.\nListing8.7 Thread-safe cache with atoms\nvar cache = new Atom();\ncache.set({});\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache.get(), query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\ncache.swap(function(oldCache) {\n--- Page 200 ---\n172 CHAPTER 8 Advanced concurrency control\nreturn _.set(oldCache, query, result);\n});\nreturn result;\n}\nTheo I don’t understand the function you’re passing to the swap method.\nJoe The function passed to swap receives the current value of the cache, which is a\nstring map, and returns a new version of the string map with an additional key-\nvalue pair.\nTheo I see. But something bothers me with the performance of the swap method in\nthe case of a string map. How does the comparison work? I mean, comparing\ntwo string maps might take some time.\nJoe Not if you compare them by reference. As we discussed in the past, when data\nis immutable, it is safe to compare by reference, and it’s super fast.\nTIP When data is immutable, it is safe (and fast) to compare it by reference.\nTheo Cool. So atoms play well with immutable data.\nJoe Exactly!\n8.4 State management with atoms\nJoe Do you remember a couple of weeks ago when I showed you how we resolve\npotential conflicts between mutations? You told me that the code was not\nthread-safe.\nTheo Let me look again at the code.\nTheo takes a look at the code for the SystemData class that he wrote some time ago\n(repeated in listing 8.8). Without the validation logic, it makes the code easier to grasp.\nListing8.8 SystemData class from part 1\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nthis.systemData = SystemConsistency.reconcile(this.systemData,\nprevious,\nnext);\n}\n}\n--- Page 201 ---\n8.4 State management with atoms 173\nIt takes him a few minutes to remember how the commit method works. Suddenly, he has\nan Aha! moment.\nTheo This code is not thread-safe because the SystemConsistency.reconcile\ncode inside the commit method is not protected. Nothing prevents the two\nthreads from executing this code concurrently.\nJoe Right! Now, can you tell me how to make it thread-safe?\nTheo With locks?\nJoe Come on...\nTheo I was kidding, of course. We make the code thread-safe not with a lock but with\nan atom.\nJoe Nice joke!\nTheo Let me see. I’d need to store the system data inside an atom. The get and set\nmethod of SystemData would simply call the get and set methods of the\natom. How does this look?\nListing8.9 SystemData class with atom (without the commit method)\nclass SystemState {\nsystemData;\nconstructor() {\nthis.systemData = new Atom();\n}\nget() {\nreturn this.systemData.get();\n}\ncommit(prev, next) {\nthis.systemData.set(next);\n}\n}\nJoe Excellent. Now for the fun part. Implement the commit method by calling the\nswap method of the atom.\nTheo Instead of calling SystemConsistency.reconcile() directly, I need to wrap\nit into a call to swap. So, something like this?\nListing8.10 Implementation of SystemData.commit with atom\nSystemData.commit = function(previous, next) {\nthis.systemData.swap(function(current) {\nreturn SystemConsistency.reconcile(current,\nprevious,\nnext);\n});\n};",
        "sections_found": []
      },
      "accurate_page_range": "176-201"
    },
    {
      "text": "- 7.4 Schema composition",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "7 Basic data validation",
      "raw_line": "- 7.4 Schema composition (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 61,
      "chapter_info": {
        "page": 176,
        "title": "Basic data validation",
        "pattern_matched": "Chapter 7",
        "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
      },
      "chapter_sections": {
        "start_page": 176,
        "end_page": 201,
        "content": "\n--- Page 176 ---\n148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema from listing 7.6.\nListing7.7 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe Give it a try, and you’ll see.\nIndeed! When Theo executes the code to validate the search request, it returns true.\nListing7.8 Validating the search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksRequest = {\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nvalidate(searchBooksRequestSchema, searchBooksRequest);\n// → true\nJoe Now, please try an invalid request.\nTheo Let me think about what kind of invalidity to try. I know, I’ll make a typo in the\ntitle field and call it tilte with the l before the t.\nAs expected, the code with the type returns false. Theo is not surprised, and Joe is smil-\ning from ear to ear.\nListing7.9 Validating an invalid search request\nvar invalidSearchBooksRequest = {\n\"tilte\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\n--- Page 177 ---\n7.3 Schema flexibility and strictness 149\nvalidate(searchBooksRequestSchema, invalidSearchBooksRequest);\n// → false\nTheo The syntax of JSON Schema is much more verbose than the syntax for declar-\ning the members in a class. Why is that so?\nJoe For two reasons. First, because JSON Schema is language independent, it can\nbe used in any programming language. As I told you, there are JSON Schema\nvalidators available in most programming languages.\nTheo I see.\nJoe Second, JSON Schema allows you to express validation conditions that are much\nharder, if not impossible, to express when data is represented with classes.\nTIP The expressive power of JSON Schema is high!\nTheo Now you have triggered my curiosity. Can you give me some examples?\nJoe In a moment, we’ll talk about schema composition. Someday I’ll show you\nsome examples of advanced validation.\n NOTE Advanced validation is covered in chapter 12.\nTheo What kind of advanced validation?\nJoe What I mean by advanced validation is, for instance, validating that a number\nfalls within a given range or validating that a string matches a regular expression.\nTheo Is there a way to get details about why the request is invalid?\nJoe Absolutely! I’ll show you later. For now, let me show you how to make sure the\nresponse the server sends back to the client is valid.\nTheo It sounds much more complicated than a search book request!\nJoe Why?\nTheo Because a search response is made of multiple book results, and in each book\nresult, some of the fields are optional!\n7.3 Schema flexibility and strictness\nJoe Can you give me an example of what a book search response would look like?\nTheo Take a look at this example. It’s a search response with information about two\nbooks: 7 Habits of Highly Effective People and The Power of Habit.\nListing7.10 An example of a search response\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432\n},\n--- Page 178 ---\n150 CHAPTER 7 Basic data validation\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn_13\": \"978-1982137274\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n]\n}\n]\nJoe It’s funny that you mention The Power of Habit. I’m reading this book in order\nto get rid of my habit of biting my nails. Anyway, what fields are required and\nwhat fields are optional in a book search response?\nTheo In book information, the title and available fields are required. The other\nfields are optional.\nJoe As I told you when we built the schema for the book search request, fields in a\nmap are optional by default. In order to make a field mandatory, we have to\ninclude it in the required array. I’d probably implement it with something\nlike this.\nListing7.11 Schema of a search response\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, map fields are optional by default.\nTheo I must admit that specifying a list of required fields is much simpler than hav-\ning to specify that a member in a class in nullable!\nJoe Agreed!\nTheo On the other hand, I find the nesting of the book information schema in the\nsearch response schema a bit hard to read.\n--- Page 179 ---\n7.3 Schema flexibility and strictness 151\nJoe Nothing prevents you from separating the book information schema from the\nsearch response schema.\nTheo How?\nJoe It’s just JSON, my friend. It means, you are free to manipulate the schema as\nany other map in your program. For instance, you could have the book infor-\nmation schema in a variable named bookInfoSchema and use it in the search\nbooks response schema. Let me refactor the schema to show you what I mean.\nListing7.12 Schema of a search response refactored\nvar bookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n};\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": bookInfoSchema\n};\nTheo Once again, I have to admit that JSON Schemas are more composable than\nclass definitions.\nTIP JSON Schemas are just maps. We are free to compose and manipulate them like\nany other map.\nJoe Let’s move on to validating data received from external data sources.\nTheo Is that different?\nJoe Not really, but I’ll take it as an opportunity to show you some other features of\nJSON Schema.\nTheo I’m curious to learn how data validation is used when we access data from the\ndatabase.\nJoe Each time we access data from the outside, it’s a good practice to validate it.\nCan you show me an example of how a database response for a search query\nwould look?\nTIP It’s a good practice to validate data that comes from an external data source.\n--- Page 180 ---\n152 CHAPTER 7 Basic data validation\nTheo When we query books from the database, we expect to receive an array of\nbooks with three fields: title, isbn, and available. The first two values should\nbe strings, and the third one should be a Boolean.\nJoe Are those fields optional or required?\nTheo What do you mean?\nJoe Could there be books for which some of the fields are not defined?\nTheo No.\nJoe In that case, the schema is quite simple. Would you like to try writing the\nschema for the database response?\nTheo Let me see. It’s an array of objects where each object has three properties, so\nsomething like this?\nListing7.13 Schema of a database response\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n}\nJoe Well done, my friend! Now, I want to tell you about the additionalProperties\nfield in JSON Schema.\nTheo What’s that?\nJoe Take a look at this array.\nListing7.14 A book array with an additional property\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"dummy_property\": 42\n},\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn\": \"978-1982137274\",\n\"dummy_property\": 45\n}\n]\n--- Page 181 ---\n7.3 Schema flexibility and strictness 153\nJoe Is it a valid database response?\nTheo No. A database response should not have a dummy_property field. It should\nhave only the three required fields specified in the schema.\nJoe It might be surprising but, by default, fields not specified in the schema of an\nobject are allowed in JSON Schema. In order to disallow them, one has to set\nadditionalProperties to false like this.\nListing7.15 Disallowing properties not mentioned in the schema\nvar booksFromDBSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, by default, fields not specified in the schema of a map are\nallowed.\nTheo Why is that?\nJoe The reason is that usually having additional fields in a map doesn’t cause\ntrouble. If your code doesn’t care about a field, it simply ignores it. But some-\ntimes we want to be as strict as possible, and we set additionalProperties\nto false.\nTheo What about the search request and response schema from the previous discus-\nsions? Should we set additionalProperties to false?\nJoe That’s an excellent question. I’d say it’s a matter of taste. Personally, I like to\nallow additional fields in requests and disallow them in responses.\nTheo What’s the advantage?\nJoe Well, the web server is responsible for the responses it sends to its clients. It\nmakes sense then to be as strict as possible. However, the requests are created\nby the clients, and I prefer to do my best to serve my clients even when they are\nnot as strict as they should be.\nTheo Naturally. “The client is always right.”\nJoe Actually, I prefer the way Jon Postel formulated his robustness principle: “Be\nconservative in what you send, be liberal in what you accept.”\nTIP It’s a good practice to be strict with the data that you send and to be flexible with\nthe data that you receive.\n--- Page 182 ---\n154 CHAPTER 7 Basic data validation\n7.4 Schema composition\nTheo What about validating data that comes from an external web service?\nJoe Can you give me an example?\nTheo In the near future, we’ll have to integrate with a service called Open Library\nBooks API that provides detailed information about books.\n NOTE For information on the Open Library Books API, see https://openlibrary\n.org/dev/docs/api/books.\nJoe Can you show me, for instance, the service response for Watchmen?\nTheo Sure. Here you go.\nTheo taps a few keys on his keyboard and brings up the response. Joe looks at the JSON for\na long time.\nListing7.16 An Open Library Books API response example\n{\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n}\nTheo asks himself, “What could be so special in this JSON?” While Joe is meditating about\nthis piece of JSON, Theo writes the JSON Schema for the Books API response. It doesn’t\nseem to be more complicated than any of the previous schemas. When Theo is done, he\nasks Joe to take a look at the schema.\nListing7.17 Schema of the Open Library Books API response\n{\n\"type\": \"object\",\n\"required\": [\"title\"],\n--- Page 183 ---\n7.4 Schema composition 155\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n}\nJoe Good job!\nTheo That wasn’t so hard. I really don’t see why you looked at this JSON response for\nsuch a long time.\nJoe Well, it has to do with the isbn_10 and isbn_13 fields. I assume that they’re\nnot both mandatory.\nTheo Right! That’s why I didn’t include them in the required field of my schema.\nJoe But one of them should always be there. Right?\nTheo Sometimes one of them and sometimes both of them, like for Watchmen. It\ndepends on the publication year of the book. Books published before 2007\nhave isbn_10, and books published after 2007 have isbn_13.\nJoe Oh, I see. And Watchmen has both because it was originally published in 1986\nbut published again after 2007.\nTheo Correct.\nJoe Then, you need your schema to indicate that one of the isbn fields is man-\ndatory. That’s a good opportunity for me to tell you about JSON Schema\ncomposition.\nTheo What’s that?\nJoe It’s a way to combine schemas, similarly to how we combine logical conditions\nwith AND, OR, and NOT.\nTheo I’d like to see that.\nJoe Sure. How would you express the schema for the Books API response as a\ncomposition of three schemas: basicBookInfoSchema, the schema that you\nwrote where only title is required; mandatoryIsbn13, a schema where only\n--- Page 184 ---\n156 CHAPTER 7 Basic data validation\nisbn_13 is required; and mandatoryIsb10, a schema where only isbn_10 is\nrequired?\nTheo I think it should be basicBookInfoSchema AND (mandatoryIsbn13 OR\nmandatoryIsbn10).\nJoe Exactly! The only thing is that in JSON Schema, we use allOf instead of AND,\nand anyOf instead of OR.\nJoe shows Theo the result in listing 7.18 and an example of its usage in listing 7.19.\nListing7.18 Schema of an external API response\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n--- Page 185 ---\n7.4 Schema composition 157\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing7.19 Validating an external API response\nvar bookInfo = {\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n};\nvalidate(bookInfoSchema, bookInfo);\n// → true\nTheo I see why they call it allOf and anyOf. The first one means that data must con-\nform to all the schemas, and the second one means that data must conform to\nany of the schemas.\nJoe Yup.\n NOTE JSON Schema also supports oneOf for cases where data must be valid against\nexactly one schema.\nTheo Nice. With schema composition, JSON Schema seems to have more expressive\npower than what I was used to when representing data with classes.\nJoe That’s only the beginning. I’ll show you more data validation conditions that\ncan’t be expressed when data is represented with classes some other time.\n NOTE Advanced data validation is covered in chapter 12.\nTheo Something still bothers me, though. When data isn’t valid, you don’t know what\nwent wrong.\n--- Page 186 ---\n158 CHAPTER 7 Basic data validation\n7.5 Details about data validation failures\nJoe So far, we’ve treated JSON Schema validation as though it were binary: either a\npiece of data is valid or it isn’t.\nTheo Right...\nJoe But, in fact, when a piece of data is not valid, we can get details about the\nreason of the invalidity.\nTheo Like when a required field is missing, can we get the name of the missing field?\nJoe Yes. When a piece of data is not of the expected type, we can get information\nabout that also.\nTheo That sounds very useful!\nJoe Indeed. Let me show you how it works. Until now, we used a generic validate\nfunction, but when we deal with validation failures, we need to be more specific.\nTheo Why?\nJoe Because each data validator library has its own way of exposing the details of\nadata validation failure. For instance, in JavaScript Ajv, the errors from the\nlast data validation are stored as an array inside the validator instance.\nTheo Why an array?\nJoe Because there could be several failures. But let’s start with the case of a single\nfailure. Imagine we encounter a search book request where the title field is\nnamed myTitle instead of title. Take a look at this example. As you can see,\nwe first instantiate a validator instance.\nListing7.20 Accessing validation errors in Ajv\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nInstantiates a\nvar ajv = new Ajv(); validator instance\najv.validate(searchBooksRequestSchema, invalidSearchBooksRequest);\najv.errors\nDisplays the\nvalidation errors\n--- Page 187 ---\n7.5 Details about data validation failures 159\nTheo And what does the information inside the errors array look like?\nJoe Execute the code snippet. You’ll see.\nWhen Theo executes the code snippets from listing 7.20, he can hardly believe his eyes. He\nlooks at the details, finding the results hard to digest.\nListing7.21 Details for a single data validation failure in an array format\n[\n{\n\"instancePath\": \"\",\n\"schemaPath\": \"#/required\",\n\"keyword\": \"required\",\n\"params\": {\n\"missingProperty\":\"title\"\n},\n\"message\": \"must have required property 'title'\"\n}\n]\nTheo I find the contents of the errors array a bit hard to understand.\nJoe Me too. Fortunately, Ajv provides a errorsText utility function to convert the\nerrors array in a human readable format. See, for instance, what is returned\nwhen you call errorsText.\nListing7.22 Displaying the errors in human readable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title'\"\nTheo Let me see what happens when there are more than one validation failure in\nthe data.\nJoe By default, Ajv catches only one validation error.\nTIP By default, Ajv catches only the first validation failure.\nTheo I guess that’s for performance reasons. Once the validator encounters an\nerror, it doesn’t continue the data parsing.\nJoe Probably. Anyway, in order to catch more than one validation failure, you need\nto pass the allErrors options to the Ajv constructor. Check out this code.\nListing7.23 Catching multiple validation failures\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n--- Page 188 ---\n160 CHAPTER 7 Basic data validation\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nA request with\nthree failures\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [1, 2]\n}; Instantiates the Ajv constructor\nwith allErrors: true in order to\ncatch more than one failure\nvar ajv = new Ajv({allErrors: true});\najv.validate(searchBooksRequestSchema,\ninvalidSearchBooksRequest); Converts the\nerrors to a human\nreadable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title',\n// → data/fields/0 must be string,\n// → data/fields/1 must be string\"\nJoe We validate a search request with myTitle instead of title and numbers\ninstead of strings in the fields array. As you can see in the output of the code\nsnippet, three errors are returned.\nTheo Great! I think I have all that I need in order to add data validation to the\nboundaries of my system when Nancy asks me to make the Library Manage-\nment System into a web server.\nJoe Would you allow me to give you a small gift as a token of our friendship?\nTheo I’d be honored.\nJoe takes a small package out of his bag, wrapped in a light-green ribbon. He hands Theo\nthe package with a solemn gesture.\nWhen Theo undoes the ribbon, he discovers an elegant piece of paper decorated with\npretty little designs. In the center of the paper, Theo manages to read the inscription\n“JSON Schema cheat sheet.” He smiles while browsing the cheat sheet. It’s exactly what he\nneeds.\nListing7.24 JSON Schema cheat sheet\n{ At the root level,\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the\narray is a map.\n\"type\": \"object\",\nmyNumber \"properties\": {\nThe properties of\nis a number. \"myNumber\": {\"type\": \"number\"},\neach field in the map\n\"myString\": {\"type\": \"string\"},\nmyString is\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\na string. myEnum is a\n\"myBool\": {\"type\": \"boolean\"}\nenumeration\nmyBool is a }, value with two\nboolean. \"required\": [\"myNumber\", \"myString\"], possibilities:\nThe mandatory fields in the map \"myVal\" and\nare myNumber and myString; \"yourVal\".\nother fields are optional.\n--- Page 189 ---\nSummary 161\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nThen, Theo turns the paper over to find that the back is also filled with drawings. In the\ncenter of the paper, he reads the inscription, “An example of valid data.”\nListing7.25 An example of valid data\n[\n{\nThis map is valid\n\"myNumber\": 42,\nbecause all its\n\"myString\": \"Hello\",\nfields are valid.\n\"myEnum\": \"myVal\",\n\"myBool\": true\n},\n{\nThis map is valid\n\"myNumber\": 54,\nbecause it contains all\n\"myString\": \"Happy\"\nthe required fields.\n}\n]\nSummary\n DOP Principle #4 is to separate data schema and data representation.\n The boundaries of a system are defined to be the areas where the system\nexchanges data.\n Some examples of data validation at the boundaries of the system are validation\nof client requests and responses, and validation of data that comes from exter-\nnal sources.\n Data validation in DOP means checking whether a piece of data conforms to a\nschema.\n When a piece of data is not valid, we get information about the validation fail-\nures and send this information back to the client in a human readable format.\n When data at system boundaries is valid, it’s not critical to validate data again\ninside the system.\n JSON Schema is a language that allows us to separate data validation from data\nrepresentation.\n JSON Schema syntax is a bit verbose.\n The expressive power of JSON Schema is high.\n JSON Schemas are just maps and, as so, we are free to manipulate them like any\nother maps in our programs.\n We can store a schema definition in a variable and use this variable in another\nschema.\n In JSON Schema, map fields are optional by default.\n It’s good practice to validate data that comes from an external data source.\n--- Page 190 ---\n162 CHAPTER 7 Basic data validation\n It’s good practice to be strict regarding data that you send and to be flexible\nregarding data that you receive.\n Ajv is a JSON Schema library in JavaScript.\n By default, Ajv catches only the first validation failure.\n Advanced validation is covered in chapter 12.\n--- Page 191 ---\nAdvanced\nconcurrency control\nNo more deadlocks!\nThis chapter covers\n Atoms as an alternative to locks\n Managing a thread-safe counter and a thread-safe\nin-memory cache with atoms\n Managing the whole system state in a thread-safe\nway with atoms\nThe traditional way to manage concurrency in a multi-threaded environment\ninvolves lock mechanisms like mutexes. Lock mechanisms tend to increase the com-\nplexity of the system because it’s not trivial to make sure the system is free of dead-\nlocks. In DOP, we leverage the fact that data is immutable, and we use a lock-free\nmechanism, called an atom, to manage concurrency. Atoms are simpler to manage\nthan locks because they are lock-free. As a consequence, the usual complexity of\nlocks that are required to avoid deadlocks don’t apply to atoms.\n NOTE This chapter is mostly relevant to multi-threaded environments like Java,\nC#, Python, and Ruby. It is less relevant to single-threaded environments like Java-\nScript. The JavaScript code snippets in this chapter are written as though JavaScript\nwere multi-threaded.\n163\n--- Page 192 ---\n164 CHAPTER 8 Advanced concurrency control\n8.1 The complexity of locks\nThis Sunday afternoon, while riding his bike across the Golden Gate Bridge, Theo thinks\nabout the Klafim project with concern, not yet sure that betting on DOP was a good\nchoice. Suddenly, Theo realizes that he hasn’t yet scheduled the next session with Joe. He\ngets off his bike to call Joe. Bad luck, the line is busy.\nWhen Theo gets home, he tries to call Joe again, but once again the phone is busy. After\ndinner, Theo tries to call Joe one more time, with the same result—a busy signal. “Obvi-\nously, Joe is very busy today,” Theo tells himself. Exhausted by his 50-mile bike ride at an\naverage of 17 miles per hour, he falls asleep on the sofa. When Theo wakes up, he’s elated\nto see a text message from Joe, “See you Monday morning at 11 AM?” Theo answers with a\nthumbs up and prepares for another week of work.\nWhen Joe arrives at the office, Theo asks him why his phone was constantly busy the day\nbefore. Joe answers that he was about to ask Theo the same question. They look at each\nother, puzzled, and then simultaneously break into laughter as they realize what hap-\npened: in an amazing coincidence, they’d tried to phone each other at exactly the same\ntimes. They both say at once:\n“A deadlock!”\nThey both head for Theo’s office. When they get to Theo’s desk, Joe tells him that today’s\nsession is going to be about concurrency management in multi-threaded environments.\nJoe How do you usually manage concurrency in a multi-threaded environment?\nTheo I protect access to critical sections with a lock mechanism, a mutex, for instance.\nJoe When you say access, do you mean write access or also read access?\nTheo Both!\nJoe Why do you need to protect read access with a lock?\nTheo Because, without a lock protection, in the middle of a read, a write could hap-\npen in another thread. It would make my read logically inconsistent.\nJoe Another option would be to clone the data before processing it in a read.\nTheo Sometimes I would clone the data; but in many cases, when it’s large, it’s too\nexpensive to clone.\nTIP Cloning data to avoid read locks doesn’t scale.\nJoe In DOP, we don’t need to clone or to protect read access.\nTheo Because data is immutable?\nJoe Right. When data is immutable, even if a write happens in another thread\nduring a read, it won’t make the read inconsistent because the write never\nmutates the data that is read.\nTheo In a sense, a read always works on a data snapshot.\nJoe Exactly!\nTIP When data is immutable, a read is always safe.\nTheo But what about write access? Don’t you need to protect that with locks?\nJoe Nope.\n--- Page 193 ---\n8.2 Thread-safe counter with atoms 165\nTheo Why not?\nJoe We have a simpler mechanism—it’s called an atom.\nTheo I am glad to hear there is a something simpler than locks. I really struggle each\ntime I have to integrate locks into a multi-threaded system.\nJoe Me too! I remember a bug we had in production 10 years ago. We forgot to\nrelease a lock when an exception was thrown in a critical section. It caused a\nterrible deadlock.\nTheo Deadlocks are really hard to avoid. Last year, we had a deadlock issue when two\nlocks were not released in the proper order.\nJoe I have great news for you. With atoms, deadlocks never happen!\nTIP With atoms, deadlocks never happen.\nTheo That sounds great. Tell me more!\nTIP Atoms provide a way to manage concurrency without locks.\n8.2 Thread-safe counter with atoms\nJoe Let’s start with a simple case: a counter shared between threads.\nTheo What do you mean by a counter?\nJoe Imagine that we’d like to count the number of database accesses and write the\ntotal number of accesses to a log every minute.\nTheo OK.\nJoe Could you write JavaScript code for this multi-threaded counter using locks?\nTheo But JavaScript is single-threaded!\nJoe I know, but it’s just for the sake of illustration. Imagine that JavaScript were\nmulti-threaded and that it provided a Mutex object that you could lock and\nunlock.\nTheo It’s a bit awkward. I guess it would look like this.\nTheo goes to the whiteboard. He writes what he imagines to be JavaScript code for a multi-\nthreaded counter with locks.\nListing8.1 A thread-safe counter protected by a mutex\nvar mutex = new Mutex();\nvar counter = 0;\nfunction dbAccess() {\nmutex.lock();\ncounter = counter + 1;\nmutex.unlock();\n// access the database\n}\nfunction logCounter() {\nmutex.lock();\n--- Page 194 ---\n166 CHAPTER 8 Advanced concurrency control\nconsole.log('Number of database accesses: ' + counter);\nmutex.unlock();\n}\nJoe Excellent. Now, I am going to show you how to write the same code with atoms.\nAn atom provides three methods:\n get returns the current value of the atom.\n set overwrites the current value of the atom.\n swap receives a function and updates the value of the atom with the result\nof the function called on the current value of the atom.\nJoe unzips a pocket in his laptop case and takes out a piece of paper. He hands it to\nTheo. Theo is pleasantly surprised as the sheet of paper succinctly describes the methods\n(table 8.1).\nTable 8.1 The three methods of an atom\nMethod Description\nget Returns the current value\nset Overwrites the current value\nswap Updates the current value with a function\nTheo How would it look like to implement a thread-safe counter with an atom?\nJoe It’s quite simple, actually.\nJoe pulls out his laptop, fires it up, and begins to type. When he’s done, he turns the laptop\naround so that Theo can see the code to implement a thread-safe counter in an atom.\nListing8.2 A thread-safe counter stored in an atom\nvar counter = new Atom();\ncounter.set(0);\nfunction dbAccess() {\ncounter.swap(function(x) {\nThe argument x is the\nreturn x + 1;\ncurrent value of the atom,\n});\nsame as counter.get().\n// access the database\n}\nfunction logCounter() {\nconsole.log('Number of database accesses: ' + counter.get());\n}\nTheo Could you tell me what’s going on here?\nJoe Sure! First, we create an empty atom. Then, we initialize the value of the atom\nwith counter.set(0). In the logger thread, we read the current value of the\natom with counter.get().\nTheo And how do you increment the counter in the threads that access the database?\n--- Page 195 ---\n8.2 Thread-safe counter with atoms 167\nJoe We call swap with a function that receives x and returns x + 1.\nTheo I don’t understand how swap could be thread-safe without using any locks.\nJoe quickly goes to the whiteboard. He sketches the diagram in figure 8.1.\nTake snapshot\nCompute next state\nYes\nState changed?\nNo\nUpdate state\nFigure 8.1 High-level flow of swap\nJoe You see, swap computes the next value of the atom, and before modifying the\ncurrent value of the atom, it checks whether the value of the atom has changed\nduring the computation. If so, swap tries again, until no changes occur during\nthe computation.\nTheo Is swap easy to implement?\nJoe Let me show you the implementation of the Atom class and you’ll see.\nListing8.3 Implementation of the Atom class\nclass Atom {\nstate;\nconstructor() {}\nget() {\nreturn this.state;\n}\nset(state) {\nthis.state = state;\n}\nswap(f) {\nwhile(true) {\nvar stateSnapshot = this.state;\nvar nextState = f(stateSnapshot);\nif (!atomicCompareAndSet(this.state,\n--- Page 196 ---\n168 CHAPTER 8 Advanced concurrency control\nstateSnapshot,\nnextState)) {\nUses a special thread-safe comparison operation\ncontinue;\nas this.state might have changed in another\n}\nthread during execution of the function f.\nreturn nextState;\n}\n}\n}\nTheo comes closer to the whiteboard. He modifies Joe’s diagram a bit to make the flow of\nthe swap operation more detailed. The resulting diagram is in figure 8.2. Theo still has a\nfew questions, though.\nTake snapshot\nsnapshot = state\nCompute next state\nnextState = f(snapshot)\nCheck if state has changed\nstate == snapshot\nYes\nState changed?\nNo\nUpdate state\nstate = nextState\nFigure 8.2 Detailed flow of swap\nTheo What is atomicCompareAndSet?\nJoe It’s the core operation of an atom. atomicCompareAndSet atomically sets the\nstate to a new value if, and only if, the state equals the provided old value. It\nreturns true upon success and false upon failure.\nTheo How could it be atomic without using locks?\nJoe That’s a great question! In fact, atomicCompareAndSet is a compare-and-swap\noperation, provided by the language that relies on a functionality of the CPU\nitself. For example, in Java the java.util.concurrent.atomic package has\nan AtomicReference generic class that provides a compareAndSet() method.\n NOTE See http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html\nfor general information about compare-and-swap operations. Implementations for\nmulti-threaded languages appear in table 8.2.\n--- Page 197 ---\n8.2 Thread-safe counter with atoms 169\nTable 8.2 Implementation of an atomic compare and set in various languages\nLanguage Link\nJava http://mng.bz/mx0W\nJavaScript Not relevant (single-threaded language)\nRuby http://mng.bz/5KG8\nPython https://github.com/maxcountryman/atomos\nC# http://mng.bz/6Zzp\nTheo Apropos Java, how would the implementation of an atom look?\nJoe It’s quite the same, besides the fact that Atom has to use generics, and the inner\nstate has to be stored in an AtomicReference.\nJoe brings up a Java implementation of Atom on his laptop. Theo looks over the code.\nListing8.4 Implementation of the Atom class in Java\nclass Atom<ValueType> {\nprivate AtomicReference<ValueType> state;\npublic Atom() {}\nValueType get() {\nreturn this.state.get();\n}\nthis.state might have\nchanged in another thread\nvoid set(ValueType state) {\nduring the execution of f.\nthis.state.set(state);\n}\nValueType swap(UnaryOPerator<ValueType> f) {\nwhile(true) {\nValueType stateSnapshot = this.state.get();\nValueType nextState = f(stateSnapshot);\nif (!this.state.compareAndSet(stateSnapshot,\nnextState)) {\ncontinue;\n}\n}\nreturn nextState;\n}\n}\nTheo What about using an atom in Java?\nJoe Here, take a look. It’s quite simple.\n--- Page 198 ---\n170 CHAPTER 8 Advanced concurrency control\nListing8.5 Using an Atom in Java\nAtom<Integer> counter = new Atom<Integer>();\ncounter.set(0);\ncounter.swap(x -> x + 1);\ncounter.get();\nTheo takes a couple of minutes to meditate about this atom stuff and to digest what he’s\njust learned. Then, he asks Joe:\nTheo What if swap never succeeds? I mean, could the while loop inside the code of\nswap turn out to be an infinite loop?\nJoe No! By definition, when atomicCompareAndSet fails on a thread, it means that\nthe same atom was changed on another thread during the execution of swap.\nIn this race between threads, there is always a winner.\nTheo But isn’t it possible that some thread never succeeds because it always loses the\nrace against other threads?\nJoe In theory, yes, but I’ve never encountered such a situation. If you have thou-\nsands of threads that do nothing besides swapping an atom, it could happen I\nsuppose. But, in practice, once the atom is swapped, the threads do some real\nwork, for example, database access or I/O. This gives other threads the oppor-\ntunity to swap the atom successfully.\n NOTE In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing beside swapping an atom. In practice, once an atom is swapped, the\nthreads do some real work (e.g., database access), which creates an opportunity for\nother threads to swap the atom successfully.\nTheo Interesting.... Indeed, atoms look much easier to manage than locks.\nJoe Now let me show you how to use atoms with composite data.\nTheo Why would that be different?\nJoe Usually, dealing with composite data is more difficult than dealing with primi-\ntive types.\nTheo When you sold me on DOP, you told me that we are able to manage data with\nthe same simplicity as we manage numbers.\nTIP In DOP, data is managed with the same simplicity as numbers.\nJoe That’s exactly what I am about to show you.\n8.3 Thread-safe cache with atoms\nJoe Are you familiar with the notion of in-memory cache?\nTheo You mean memoization?\n--- Page 199 ---\n8.3 Thread-safe cache with atoms 171\nJoe Kind of. Imagine that database queries don’t vary too much in your applica-\ntion. It makes sense in that case to store the results of previous queries in mem-\nory in order to improve the response time.\nTheo Yes, of course!\nJoe What data structure would you use to store the in-memory cache?\nTheo Probably a string map, where the keys are the queries, and the values are the\nresults from the database.\nTIP It’s quite common to represent an in-memory cache as a string map.\nJoe Excellent! Now can you write the code to cache database queries in a thread-\nsafe way using a lock?\nTheo Let me see: I’m going to use an immutable string map. Therefore, I don’t\nneed to protect read access with a lock. Only the cache update needs to be\nprotected.\nJoe You’re getting the hang of this!\nTheo The code should be something like this.\nListing8.6 Thread-safe cache with locks\nvar mutex = new Mutex();\nvar cache = {};\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache, query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\nmutex.lock();\ncache = _.set(cache, query, result);\nmutex.unlock();\nreturn result;\n}\nJoe Nice! Now, let me show you how to write the same code using an atom instead\nof a lock. Take a look at this code and let me know if it’s clear to you.\nListing8.7 Thread-safe cache with atoms\nvar cache = new Atom();\ncache.set({});\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache.get(), query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\ncache.swap(function(oldCache) {\n--- Page 200 ---\n172 CHAPTER 8 Advanced concurrency control\nreturn _.set(oldCache, query, result);\n});\nreturn result;\n}\nTheo I don’t understand the function you’re passing to the swap method.\nJoe The function passed to swap receives the current value of the cache, which is a\nstring map, and returns a new version of the string map with an additional key-\nvalue pair.\nTheo I see. But something bothers me with the performance of the swap method in\nthe case of a string map. How does the comparison work? I mean, comparing\ntwo string maps might take some time.\nJoe Not if you compare them by reference. As we discussed in the past, when data\nis immutable, it is safe to compare by reference, and it’s super fast.\nTIP When data is immutable, it is safe (and fast) to compare it by reference.\nTheo Cool. So atoms play well with immutable data.\nJoe Exactly!\n8.4 State management with atoms\nJoe Do you remember a couple of weeks ago when I showed you how we resolve\npotential conflicts between mutations? You told me that the code was not\nthread-safe.\nTheo Let me look again at the code.\nTheo takes a look at the code for the SystemData class that he wrote some time ago\n(repeated in listing 8.8). Without the validation logic, it makes the code easier to grasp.\nListing8.8 SystemData class from part 1\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nthis.systemData = SystemConsistency.reconcile(this.systemData,\nprevious,\nnext);\n}\n}\n--- Page 201 ---\n8.4 State management with atoms 173\nIt takes him a few minutes to remember how the commit method works. Suddenly, he has\nan Aha! moment.\nTheo This code is not thread-safe because the SystemConsistency.reconcile\ncode inside the commit method is not protected. Nothing prevents the two\nthreads from executing this code concurrently.\nJoe Right! Now, can you tell me how to make it thread-safe?\nTheo With locks?\nJoe Come on...\nTheo I was kidding, of course. We make the code thread-safe not with a lock but with\nan atom.\nJoe Nice joke!\nTheo Let me see. I’d need to store the system data inside an atom. The get and set\nmethod of SystemData would simply call the get and set methods of the\natom. How does this look?\nListing8.9 SystemData class with atom (without the commit method)\nclass SystemState {\nsystemData;\nconstructor() {\nthis.systemData = new Atom();\n}\nget() {\nreturn this.systemData.get();\n}\ncommit(prev, next) {\nthis.systemData.set(next);\n}\n}\nJoe Excellent. Now for the fun part. Implement the commit method by calling the\nswap method of the atom.\nTheo Instead of calling SystemConsistency.reconcile() directly, I need to wrap\nit into a call to swap. So, something like this?\nListing8.10 Implementation of SystemData.commit with atom\nSystemData.commit = function(previous, next) {\nthis.systemData.swap(function(current) {\nreturn SystemConsistency.reconcile(current,\nprevious,\nnext);\n});\n};",
        "sections_found": []
      },
      "accurate_page_range": "176-201"
    },
    {
      "text": "- 7.5 Details about data validation failures",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "7 Basic data validation",
      "raw_line": "- 7.5 Details about data validation failures (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 62,
      "chapter_info": {
        "page": 176,
        "title": "Basic data validation",
        "pattern_matched": "Chapter 7",
        "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
      },
      "chapter_sections": {
        "start_page": 176,
        "end_page": 201,
        "content": "\n--- Page 176 ---\n148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema from listing 7.6.\nListing7.7 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe Give it a try, and you’ll see.\nIndeed! When Theo executes the code to validate the search request, it returns true.\nListing7.8 Validating the search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksRequest = {\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nvalidate(searchBooksRequestSchema, searchBooksRequest);\n// → true\nJoe Now, please try an invalid request.\nTheo Let me think about what kind of invalidity to try. I know, I’ll make a typo in the\ntitle field and call it tilte with the l before the t.\nAs expected, the code with the type returns false. Theo is not surprised, and Joe is smil-\ning from ear to ear.\nListing7.9 Validating an invalid search request\nvar invalidSearchBooksRequest = {\n\"tilte\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\n--- Page 177 ---\n7.3 Schema flexibility and strictness 149\nvalidate(searchBooksRequestSchema, invalidSearchBooksRequest);\n// → false\nTheo The syntax of JSON Schema is much more verbose than the syntax for declar-\ning the members in a class. Why is that so?\nJoe For two reasons. First, because JSON Schema is language independent, it can\nbe used in any programming language. As I told you, there are JSON Schema\nvalidators available in most programming languages.\nTheo I see.\nJoe Second, JSON Schema allows you to express validation conditions that are much\nharder, if not impossible, to express when data is represented with classes.\nTIP The expressive power of JSON Schema is high!\nTheo Now you have triggered my curiosity. Can you give me some examples?\nJoe In a moment, we’ll talk about schema composition. Someday I’ll show you\nsome examples of advanced validation.\n NOTE Advanced validation is covered in chapter 12.\nTheo What kind of advanced validation?\nJoe What I mean by advanced validation is, for instance, validating that a number\nfalls within a given range or validating that a string matches a regular expression.\nTheo Is there a way to get details about why the request is invalid?\nJoe Absolutely! I’ll show you later. For now, let me show you how to make sure the\nresponse the server sends back to the client is valid.\nTheo It sounds much more complicated than a search book request!\nJoe Why?\nTheo Because a search response is made of multiple book results, and in each book\nresult, some of the fields are optional!\n7.3 Schema flexibility and strictness\nJoe Can you give me an example of what a book search response would look like?\nTheo Take a look at this example. It’s a search response with information about two\nbooks: 7 Habits of Highly Effective People and The Power of Habit.\nListing7.10 An example of a search response\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432\n},\n--- Page 178 ---\n150 CHAPTER 7 Basic data validation\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn_13\": \"978-1982137274\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n]\n}\n]\nJoe It’s funny that you mention The Power of Habit. I’m reading this book in order\nto get rid of my habit of biting my nails. Anyway, what fields are required and\nwhat fields are optional in a book search response?\nTheo In book information, the title and available fields are required. The other\nfields are optional.\nJoe As I told you when we built the schema for the book search request, fields in a\nmap are optional by default. In order to make a field mandatory, we have to\ninclude it in the required array. I’d probably implement it with something\nlike this.\nListing7.11 Schema of a search response\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, map fields are optional by default.\nTheo I must admit that specifying a list of required fields is much simpler than hav-\ning to specify that a member in a class in nullable!\nJoe Agreed!\nTheo On the other hand, I find the nesting of the book information schema in the\nsearch response schema a bit hard to read.\n--- Page 179 ---\n7.3 Schema flexibility and strictness 151\nJoe Nothing prevents you from separating the book information schema from the\nsearch response schema.\nTheo How?\nJoe It’s just JSON, my friend. It means, you are free to manipulate the schema as\nany other map in your program. For instance, you could have the book infor-\nmation schema in a variable named bookInfoSchema and use it in the search\nbooks response schema. Let me refactor the schema to show you what I mean.\nListing7.12 Schema of a search response refactored\nvar bookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n};\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": bookInfoSchema\n};\nTheo Once again, I have to admit that JSON Schemas are more composable than\nclass definitions.\nTIP JSON Schemas are just maps. We are free to compose and manipulate them like\nany other map.\nJoe Let’s move on to validating data received from external data sources.\nTheo Is that different?\nJoe Not really, but I’ll take it as an opportunity to show you some other features of\nJSON Schema.\nTheo I’m curious to learn how data validation is used when we access data from the\ndatabase.\nJoe Each time we access data from the outside, it’s a good practice to validate it.\nCan you show me an example of how a database response for a search query\nwould look?\nTIP It’s a good practice to validate data that comes from an external data source.\n--- Page 180 ---\n152 CHAPTER 7 Basic data validation\nTheo When we query books from the database, we expect to receive an array of\nbooks with three fields: title, isbn, and available. The first two values should\nbe strings, and the third one should be a Boolean.\nJoe Are those fields optional or required?\nTheo What do you mean?\nJoe Could there be books for which some of the fields are not defined?\nTheo No.\nJoe In that case, the schema is quite simple. Would you like to try writing the\nschema for the database response?\nTheo Let me see. It’s an array of objects where each object has three properties, so\nsomething like this?\nListing7.13 Schema of a database response\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n}\nJoe Well done, my friend! Now, I want to tell you about the additionalProperties\nfield in JSON Schema.\nTheo What’s that?\nJoe Take a look at this array.\nListing7.14 A book array with an additional property\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"dummy_property\": 42\n},\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn\": \"978-1982137274\",\n\"dummy_property\": 45\n}\n]\n--- Page 181 ---\n7.3 Schema flexibility and strictness 153\nJoe Is it a valid database response?\nTheo No. A database response should not have a dummy_property field. It should\nhave only the three required fields specified in the schema.\nJoe It might be surprising but, by default, fields not specified in the schema of an\nobject are allowed in JSON Schema. In order to disallow them, one has to set\nadditionalProperties to false like this.\nListing7.15 Disallowing properties not mentioned in the schema\nvar booksFromDBSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, by default, fields not specified in the schema of a map are\nallowed.\nTheo Why is that?\nJoe The reason is that usually having additional fields in a map doesn’t cause\ntrouble. If your code doesn’t care about a field, it simply ignores it. But some-\ntimes we want to be as strict as possible, and we set additionalProperties\nto false.\nTheo What about the search request and response schema from the previous discus-\nsions? Should we set additionalProperties to false?\nJoe That’s an excellent question. I’d say it’s a matter of taste. Personally, I like to\nallow additional fields in requests and disallow them in responses.\nTheo What’s the advantage?\nJoe Well, the web server is responsible for the responses it sends to its clients. It\nmakes sense then to be as strict as possible. However, the requests are created\nby the clients, and I prefer to do my best to serve my clients even when they are\nnot as strict as they should be.\nTheo Naturally. “The client is always right.”\nJoe Actually, I prefer the way Jon Postel formulated his robustness principle: “Be\nconservative in what you send, be liberal in what you accept.”\nTIP It’s a good practice to be strict with the data that you send and to be flexible with\nthe data that you receive.\n--- Page 182 ---\n154 CHAPTER 7 Basic data validation\n7.4 Schema composition\nTheo What about validating data that comes from an external web service?\nJoe Can you give me an example?\nTheo In the near future, we’ll have to integrate with a service called Open Library\nBooks API that provides detailed information about books.\n NOTE For information on the Open Library Books API, see https://openlibrary\n.org/dev/docs/api/books.\nJoe Can you show me, for instance, the service response for Watchmen?\nTheo Sure. Here you go.\nTheo taps a few keys on his keyboard and brings up the response. Joe looks at the JSON for\na long time.\nListing7.16 An Open Library Books API response example\n{\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n}\nTheo asks himself, “What could be so special in this JSON?” While Joe is meditating about\nthis piece of JSON, Theo writes the JSON Schema for the Books API response. It doesn’t\nseem to be more complicated than any of the previous schemas. When Theo is done, he\nasks Joe to take a look at the schema.\nListing7.17 Schema of the Open Library Books API response\n{\n\"type\": \"object\",\n\"required\": [\"title\"],\n--- Page 183 ---\n7.4 Schema composition 155\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n}\nJoe Good job!\nTheo That wasn’t so hard. I really don’t see why you looked at this JSON response for\nsuch a long time.\nJoe Well, it has to do with the isbn_10 and isbn_13 fields. I assume that they’re\nnot both mandatory.\nTheo Right! That’s why I didn’t include them in the required field of my schema.\nJoe But one of them should always be there. Right?\nTheo Sometimes one of them and sometimes both of them, like for Watchmen. It\ndepends on the publication year of the book. Books published before 2007\nhave isbn_10, and books published after 2007 have isbn_13.\nJoe Oh, I see. And Watchmen has both because it was originally published in 1986\nbut published again after 2007.\nTheo Correct.\nJoe Then, you need your schema to indicate that one of the isbn fields is man-\ndatory. That’s a good opportunity for me to tell you about JSON Schema\ncomposition.\nTheo What’s that?\nJoe It’s a way to combine schemas, similarly to how we combine logical conditions\nwith AND, OR, and NOT.\nTheo I’d like to see that.\nJoe Sure. How would you express the schema for the Books API response as a\ncomposition of three schemas: basicBookInfoSchema, the schema that you\nwrote where only title is required; mandatoryIsbn13, a schema where only\n--- Page 184 ---\n156 CHAPTER 7 Basic data validation\nisbn_13 is required; and mandatoryIsb10, a schema where only isbn_10 is\nrequired?\nTheo I think it should be basicBookInfoSchema AND (mandatoryIsbn13 OR\nmandatoryIsbn10).\nJoe Exactly! The only thing is that in JSON Schema, we use allOf instead of AND,\nand anyOf instead of OR.\nJoe shows Theo the result in listing 7.18 and an example of its usage in listing 7.19.\nListing7.18 Schema of an external API response\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n--- Page 185 ---\n7.4 Schema composition 157\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing7.19 Validating an external API response\nvar bookInfo = {\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n};\nvalidate(bookInfoSchema, bookInfo);\n// → true\nTheo I see why they call it allOf and anyOf. The first one means that data must con-\nform to all the schemas, and the second one means that data must conform to\nany of the schemas.\nJoe Yup.\n NOTE JSON Schema also supports oneOf for cases where data must be valid against\nexactly one schema.\nTheo Nice. With schema composition, JSON Schema seems to have more expressive\npower than what I was used to when representing data with classes.\nJoe That’s only the beginning. I’ll show you more data validation conditions that\ncan’t be expressed when data is represented with classes some other time.\n NOTE Advanced data validation is covered in chapter 12.\nTheo Something still bothers me, though. When data isn’t valid, you don’t know what\nwent wrong.\n--- Page 186 ---\n158 CHAPTER 7 Basic data validation\n7.5 Details about data validation failures\nJoe So far, we’ve treated JSON Schema validation as though it were binary: either a\npiece of data is valid or it isn’t.\nTheo Right...\nJoe But, in fact, when a piece of data is not valid, we can get details about the\nreason of the invalidity.\nTheo Like when a required field is missing, can we get the name of the missing field?\nJoe Yes. When a piece of data is not of the expected type, we can get information\nabout that also.\nTheo That sounds very useful!\nJoe Indeed. Let me show you how it works. Until now, we used a generic validate\nfunction, but when we deal with validation failures, we need to be more specific.\nTheo Why?\nJoe Because each data validator library has its own way of exposing the details of\nadata validation failure. For instance, in JavaScript Ajv, the errors from the\nlast data validation are stored as an array inside the validator instance.\nTheo Why an array?\nJoe Because there could be several failures. But let’s start with the case of a single\nfailure. Imagine we encounter a search book request where the title field is\nnamed myTitle instead of title. Take a look at this example. As you can see,\nwe first instantiate a validator instance.\nListing7.20 Accessing validation errors in Ajv\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nInstantiates a\nvar ajv = new Ajv(); validator instance\najv.validate(searchBooksRequestSchema, invalidSearchBooksRequest);\najv.errors\nDisplays the\nvalidation errors\n--- Page 187 ---\n7.5 Details about data validation failures 159\nTheo And what does the information inside the errors array look like?\nJoe Execute the code snippet. You’ll see.\nWhen Theo executes the code snippets from listing 7.20, he can hardly believe his eyes. He\nlooks at the details, finding the results hard to digest.\nListing7.21 Details for a single data validation failure in an array format\n[\n{\n\"instancePath\": \"\",\n\"schemaPath\": \"#/required\",\n\"keyword\": \"required\",\n\"params\": {\n\"missingProperty\":\"title\"\n},\n\"message\": \"must have required property 'title'\"\n}\n]\nTheo I find the contents of the errors array a bit hard to understand.\nJoe Me too. Fortunately, Ajv provides a errorsText utility function to convert the\nerrors array in a human readable format. See, for instance, what is returned\nwhen you call errorsText.\nListing7.22 Displaying the errors in human readable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title'\"\nTheo Let me see what happens when there are more than one validation failure in\nthe data.\nJoe By default, Ajv catches only one validation error.\nTIP By default, Ajv catches only the first validation failure.\nTheo I guess that’s for performance reasons. Once the validator encounters an\nerror, it doesn’t continue the data parsing.\nJoe Probably. Anyway, in order to catch more than one validation failure, you need\nto pass the allErrors options to the Ajv constructor. Check out this code.\nListing7.23 Catching multiple validation failures\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n--- Page 188 ---\n160 CHAPTER 7 Basic data validation\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nA request with\nthree failures\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [1, 2]\n}; Instantiates the Ajv constructor\nwith allErrors: true in order to\ncatch more than one failure\nvar ajv = new Ajv({allErrors: true});\najv.validate(searchBooksRequestSchema,\ninvalidSearchBooksRequest); Converts the\nerrors to a human\nreadable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title',\n// → data/fields/0 must be string,\n// → data/fields/1 must be string\"\nJoe We validate a search request with myTitle instead of title and numbers\ninstead of strings in the fields array. As you can see in the output of the code\nsnippet, three errors are returned.\nTheo Great! I think I have all that I need in order to add data validation to the\nboundaries of my system when Nancy asks me to make the Library Manage-\nment System into a web server.\nJoe Would you allow me to give you a small gift as a token of our friendship?\nTheo I’d be honored.\nJoe takes a small package out of his bag, wrapped in a light-green ribbon. He hands Theo\nthe package with a solemn gesture.\nWhen Theo undoes the ribbon, he discovers an elegant piece of paper decorated with\npretty little designs. In the center of the paper, Theo manages to read the inscription\n“JSON Schema cheat sheet.” He smiles while browsing the cheat sheet. It’s exactly what he\nneeds.\nListing7.24 JSON Schema cheat sheet\n{ At the root level,\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the\narray is a map.\n\"type\": \"object\",\nmyNumber \"properties\": {\nThe properties of\nis a number. \"myNumber\": {\"type\": \"number\"},\neach field in the map\n\"myString\": {\"type\": \"string\"},\nmyString is\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\na string. myEnum is a\n\"myBool\": {\"type\": \"boolean\"}\nenumeration\nmyBool is a }, value with two\nboolean. \"required\": [\"myNumber\", \"myString\"], possibilities:\nThe mandatory fields in the map \"myVal\" and\nare myNumber and myString; \"yourVal\".\nother fields are optional.\n--- Page 189 ---\nSummary 161\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nThen, Theo turns the paper over to find that the back is also filled with drawings. In the\ncenter of the paper, he reads the inscription, “An example of valid data.”\nListing7.25 An example of valid data\n[\n{\nThis map is valid\n\"myNumber\": 42,\nbecause all its\n\"myString\": \"Hello\",\nfields are valid.\n\"myEnum\": \"myVal\",\n\"myBool\": true\n},\n{\nThis map is valid\n\"myNumber\": 54,\nbecause it contains all\n\"myString\": \"Happy\"\nthe required fields.\n}\n]\nSummary\n DOP Principle #4 is to separate data schema and data representation.\n The boundaries of a system are defined to be the areas where the system\nexchanges data.\n Some examples of data validation at the boundaries of the system are validation\nof client requests and responses, and validation of data that comes from exter-\nnal sources.\n Data validation in DOP means checking whether a piece of data conforms to a\nschema.\n When a piece of data is not valid, we get information about the validation fail-\nures and send this information back to the client in a human readable format.\n When data at system boundaries is valid, it’s not critical to validate data again\ninside the system.\n JSON Schema is a language that allows us to separate data validation from data\nrepresentation.\n JSON Schema syntax is a bit verbose.\n The expressive power of JSON Schema is high.\n JSON Schemas are just maps and, as so, we are free to manipulate them like any\nother maps in our programs.\n We can store a schema definition in a variable and use this variable in another\nschema.\n In JSON Schema, map fields are optional by default.\n It’s good practice to validate data that comes from an external data source.\n--- Page 190 ---\n162 CHAPTER 7 Basic data validation\n It’s good practice to be strict regarding data that you send and to be flexible\nregarding data that you receive.\n Ajv is a JSON Schema library in JavaScript.\n By default, Ajv catches only the first validation failure.\n Advanced validation is covered in chapter 12.\n--- Page 191 ---\nAdvanced\nconcurrency control\nNo more deadlocks!\nThis chapter covers\n Atoms as an alternative to locks\n Managing a thread-safe counter and a thread-safe\nin-memory cache with atoms\n Managing the whole system state in a thread-safe\nway with atoms\nThe traditional way to manage concurrency in a multi-threaded environment\ninvolves lock mechanisms like mutexes. Lock mechanisms tend to increase the com-\nplexity of the system because it’s not trivial to make sure the system is free of dead-\nlocks. In DOP, we leverage the fact that data is immutable, and we use a lock-free\nmechanism, called an atom, to manage concurrency. Atoms are simpler to manage\nthan locks because they are lock-free. As a consequence, the usual complexity of\nlocks that are required to avoid deadlocks don’t apply to atoms.\n NOTE This chapter is mostly relevant to multi-threaded environments like Java,\nC#, Python, and Ruby. It is less relevant to single-threaded environments like Java-\nScript. The JavaScript code snippets in this chapter are written as though JavaScript\nwere multi-threaded.\n163\n--- Page 192 ---\n164 CHAPTER 8 Advanced concurrency control\n8.1 The complexity of locks\nThis Sunday afternoon, while riding his bike across the Golden Gate Bridge, Theo thinks\nabout the Klafim project with concern, not yet sure that betting on DOP was a good\nchoice. Suddenly, Theo realizes that he hasn’t yet scheduled the next session with Joe. He\ngets off his bike to call Joe. Bad luck, the line is busy.\nWhen Theo gets home, he tries to call Joe again, but once again the phone is busy. After\ndinner, Theo tries to call Joe one more time, with the same result—a busy signal. “Obvi-\nously, Joe is very busy today,” Theo tells himself. Exhausted by his 50-mile bike ride at an\naverage of 17 miles per hour, he falls asleep on the sofa. When Theo wakes up, he’s elated\nto see a text message from Joe, “See you Monday morning at 11 AM?” Theo answers with a\nthumbs up and prepares for another week of work.\nWhen Joe arrives at the office, Theo asks him why his phone was constantly busy the day\nbefore. Joe answers that he was about to ask Theo the same question. They look at each\nother, puzzled, and then simultaneously break into laughter as they realize what hap-\npened: in an amazing coincidence, they’d tried to phone each other at exactly the same\ntimes. They both say at once:\n“A deadlock!”\nThey both head for Theo’s office. When they get to Theo’s desk, Joe tells him that today’s\nsession is going to be about concurrency management in multi-threaded environments.\nJoe How do you usually manage concurrency in a multi-threaded environment?\nTheo I protect access to critical sections with a lock mechanism, a mutex, for instance.\nJoe When you say access, do you mean write access or also read access?\nTheo Both!\nJoe Why do you need to protect read access with a lock?\nTheo Because, without a lock protection, in the middle of a read, a write could hap-\npen in another thread. It would make my read logically inconsistent.\nJoe Another option would be to clone the data before processing it in a read.\nTheo Sometimes I would clone the data; but in many cases, when it’s large, it’s too\nexpensive to clone.\nTIP Cloning data to avoid read locks doesn’t scale.\nJoe In DOP, we don’t need to clone or to protect read access.\nTheo Because data is immutable?\nJoe Right. When data is immutable, even if a write happens in another thread\nduring a read, it won’t make the read inconsistent because the write never\nmutates the data that is read.\nTheo In a sense, a read always works on a data snapshot.\nJoe Exactly!\nTIP When data is immutable, a read is always safe.\nTheo But what about write access? Don’t you need to protect that with locks?\nJoe Nope.\n--- Page 193 ---\n8.2 Thread-safe counter with atoms 165\nTheo Why not?\nJoe We have a simpler mechanism—it’s called an atom.\nTheo I am glad to hear there is a something simpler than locks. I really struggle each\ntime I have to integrate locks into a multi-threaded system.\nJoe Me too! I remember a bug we had in production 10 years ago. We forgot to\nrelease a lock when an exception was thrown in a critical section. It caused a\nterrible deadlock.\nTheo Deadlocks are really hard to avoid. Last year, we had a deadlock issue when two\nlocks were not released in the proper order.\nJoe I have great news for you. With atoms, deadlocks never happen!\nTIP With atoms, deadlocks never happen.\nTheo That sounds great. Tell me more!\nTIP Atoms provide a way to manage concurrency without locks.\n8.2 Thread-safe counter with atoms\nJoe Let’s start with a simple case: a counter shared between threads.\nTheo What do you mean by a counter?\nJoe Imagine that we’d like to count the number of database accesses and write the\ntotal number of accesses to a log every minute.\nTheo OK.\nJoe Could you write JavaScript code for this multi-threaded counter using locks?\nTheo But JavaScript is single-threaded!\nJoe I know, but it’s just for the sake of illustration. Imagine that JavaScript were\nmulti-threaded and that it provided a Mutex object that you could lock and\nunlock.\nTheo It’s a bit awkward. I guess it would look like this.\nTheo goes to the whiteboard. He writes what he imagines to be JavaScript code for a multi-\nthreaded counter with locks.\nListing8.1 A thread-safe counter protected by a mutex\nvar mutex = new Mutex();\nvar counter = 0;\nfunction dbAccess() {\nmutex.lock();\ncounter = counter + 1;\nmutex.unlock();\n// access the database\n}\nfunction logCounter() {\nmutex.lock();\n--- Page 194 ---\n166 CHAPTER 8 Advanced concurrency control\nconsole.log('Number of database accesses: ' + counter);\nmutex.unlock();\n}\nJoe Excellent. Now, I am going to show you how to write the same code with atoms.\nAn atom provides three methods:\n get returns the current value of the atom.\n set overwrites the current value of the atom.\n swap receives a function and updates the value of the atom with the result\nof the function called on the current value of the atom.\nJoe unzips a pocket in his laptop case and takes out a piece of paper. He hands it to\nTheo. Theo is pleasantly surprised as the sheet of paper succinctly describes the methods\n(table 8.1).\nTable 8.1 The three methods of an atom\nMethod Description\nget Returns the current value\nset Overwrites the current value\nswap Updates the current value with a function\nTheo How would it look like to implement a thread-safe counter with an atom?\nJoe It’s quite simple, actually.\nJoe pulls out his laptop, fires it up, and begins to type. When he’s done, he turns the laptop\naround so that Theo can see the code to implement a thread-safe counter in an atom.\nListing8.2 A thread-safe counter stored in an atom\nvar counter = new Atom();\ncounter.set(0);\nfunction dbAccess() {\ncounter.swap(function(x) {\nThe argument x is the\nreturn x + 1;\ncurrent value of the atom,\n});\nsame as counter.get().\n// access the database\n}\nfunction logCounter() {\nconsole.log('Number of database accesses: ' + counter.get());\n}\nTheo Could you tell me what’s going on here?\nJoe Sure! First, we create an empty atom. Then, we initialize the value of the atom\nwith counter.set(0). In the logger thread, we read the current value of the\natom with counter.get().\nTheo And how do you increment the counter in the threads that access the database?\n--- Page 195 ---\n8.2 Thread-safe counter with atoms 167\nJoe We call swap with a function that receives x and returns x + 1.\nTheo I don’t understand how swap could be thread-safe without using any locks.\nJoe quickly goes to the whiteboard. He sketches the diagram in figure 8.1.\nTake snapshot\nCompute next state\nYes\nState changed?\nNo\nUpdate state\nFigure 8.1 High-level flow of swap\nJoe You see, swap computes the next value of the atom, and before modifying the\ncurrent value of the atom, it checks whether the value of the atom has changed\nduring the computation. If so, swap tries again, until no changes occur during\nthe computation.\nTheo Is swap easy to implement?\nJoe Let me show you the implementation of the Atom class and you’ll see.\nListing8.3 Implementation of the Atom class\nclass Atom {\nstate;\nconstructor() {}\nget() {\nreturn this.state;\n}\nset(state) {\nthis.state = state;\n}\nswap(f) {\nwhile(true) {\nvar stateSnapshot = this.state;\nvar nextState = f(stateSnapshot);\nif (!atomicCompareAndSet(this.state,\n--- Page 196 ---\n168 CHAPTER 8 Advanced concurrency control\nstateSnapshot,\nnextState)) {\nUses a special thread-safe comparison operation\ncontinue;\nas this.state might have changed in another\n}\nthread during execution of the function f.\nreturn nextState;\n}\n}\n}\nTheo comes closer to the whiteboard. He modifies Joe’s diagram a bit to make the flow of\nthe swap operation more detailed. The resulting diagram is in figure 8.2. Theo still has a\nfew questions, though.\nTake snapshot\nsnapshot = state\nCompute next state\nnextState = f(snapshot)\nCheck if state has changed\nstate == snapshot\nYes\nState changed?\nNo\nUpdate state\nstate = nextState\nFigure 8.2 Detailed flow of swap\nTheo What is atomicCompareAndSet?\nJoe It’s the core operation of an atom. atomicCompareAndSet atomically sets the\nstate to a new value if, and only if, the state equals the provided old value. It\nreturns true upon success and false upon failure.\nTheo How could it be atomic without using locks?\nJoe That’s a great question! In fact, atomicCompareAndSet is a compare-and-swap\noperation, provided by the language that relies on a functionality of the CPU\nitself. For example, in Java the java.util.concurrent.atomic package has\nan AtomicReference generic class that provides a compareAndSet() method.\n NOTE See http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html\nfor general information about compare-and-swap operations. Implementations for\nmulti-threaded languages appear in table 8.2.\n--- Page 197 ---\n8.2 Thread-safe counter with atoms 169\nTable 8.2 Implementation of an atomic compare and set in various languages\nLanguage Link\nJava http://mng.bz/mx0W\nJavaScript Not relevant (single-threaded language)\nRuby http://mng.bz/5KG8\nPython https://github.com/maxcountryman/atomos\nC# http://mng.bz/6Zzp\nTheo Apropos Java, how would the implementation of an atom look?\nJoe It’s quite the same, besides the fact that Atom has to use generics, and the inner\nstate has to be stored in an AtomicReference.\nJoe brings up a Java implementation of Atom on his laptop. Theo looks over the code.\nListing8.4 Implementation of the Atom class in Java\nclass Atom<ValueType> {\nprivate AtomicReference<ValueType> state;\npublic Atom() {}\nValueType get() {\nreturn this.state.get();\n}\nthis.state might have\nchanged in another thread\nvoid set(ValueType state) {\nduring the execution of f.\nthis.state.set(state);\n}\nValueType swap(UnaryOPerator<ValueType> f) {\nwhile(true) {\nValueType stateSnapshot = this.state.get();\nValueType nextState = f(stateSnapshot);\nif (!this.state.compareAndSet(stateSnapshot,\nnextState)) {\ncontinue;\n}\n}\nreturn nextState;\n}\n}\nTheo What about using an atom in Java?\nJoe Here, take a look. It’s quite simple.\n--- Page 198 ---\n170 CHAPTER 8 Advanced concurrency control\nListing8.5 Using an Atom in Java\nAtom<Integer> counter = new Atom<Integer>();\ncounter.set(0);\ncounter.swap(x -> x + 1);\ncounter.get();\nTheo takes a couple of minutes to meditate about this atom stuff and to digest what he’s\njust learned. Then, he asks Joe:\nTheo What if swap never succeeds? I mean, could the while loop inside the code of\nswap turn out to be an infinite loop?\nJoe No! By definition, when atomicCompareAndSet fails on a thread, it means that\nthe same atom was changed on another thread during the execution of swap.\nIn this race between threads, there is always a winner.\nTheo But isn’t it possible that some thread never succeeds because it always loses the\nrace against other threads?\nJoe In theory, yes, but I’ve never encountered such a situation. If you have thou-\nsands of threads that do nothing besides swapping an atom, it could happen I\nsuppose. But, in practice, once the atom is swapped, the threads do some real\nwork, for example, database access or I/O. This gives other threads the oppor-\ntunity to swap the atom successfully.\n NOTE In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing beside swapping an atom. In practice, once an atom is swapped, the\nthreads do some real work (e.g., database access), which creates an opportunity for\nother threads to swap the atom successfully.\nTheo Interesting.... Indeed, atoms look much easier to manage than locks.\nJoe Now let me show you how to use atoms with composite data.\nTheo Why would that be different?\nJoe Usually, dealing with composite data is more difficult than dealing with primi-\ntive types.\nTheo When you sold me on DOP, you told me that we are able to manage data with\nthe same simplicity as we manage numbers.\nTIP In DOP, data is managed with the same simplicity as numbers.\nJoe That’s exactly what I am about to show you.\n8.3 Thread-safe cache with atoms\nJoe Are you familiar with the notion of in-memory cache?\nTheo You mean memoization?\n--- Page 199 ---\n8.3 Thread-safe cache with atoms 171\nJoe Kind of. Imagine that database queries don’t vary too much in your applica-\ntion. It makes sense in that case to store the results of previous queries in mem-\nory in order to improve the response time.\nTheo Yes, of course!\nJoe What data structure would you use to store the in-memory cache?\nTheo Probably a string map, where the keys are the queries, and the values are the\nresults from the database.\nTIP It’s quite common to represent an in-memory cache as a string map.\nJoe Excellent! Now can you write the code to cache database queries in a thread-\nsafe way using a lock?\nTheo Let me see: I’m going to use an immutable string map. Therefore, I don’t\nneed to protect read access with a lock. Only the cache update needs to be\nprotected.\nJoe You’re getting the hang of this!\nTheo The code should be something like this.\nListing8.6 Thread-safe cache with locks\nvar mutex = new Mutex();\nvar cache = {};\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache, query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\nmutex.lock();\ncache = _.set(cache, query, result);\nmutex.unlock();\nreturn result;\n}\nJoe Nice! Now, let me show you how to write the same code using an atom instead\nof a lock. Take a look at this code and let me know if it’s clear to you.\nListing8.7 Thread-safe cache with atoms\nvar cache = new Atom();\ncache.set({});\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache.get(), query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\ncache.swap(function(oldCache) {\n--- Page 200 ---\n172 CHAPTER 8 Advanced concurrency control\nreturn _.set(oldCache, query, result);\n});\nreturn result;\n}\nTheo I don’t understand the function you’re passing to the swap method.\nJoe The function passed to swap receives the current value of the cache, which is a\nstring map, and returns a new version of the string map with an additional key-\nvalue pair.\nTheo I see. But something bothers me with the performance of the swap method in\nthe case of a string map. How does the comparison work? I mean, comparing\ntwo string maps might take some time.\nJoe Not if you compare them by reference. As we discussed in the past, when data\nis immutable, it is safe to compare by reference, and it’s super fast.\nTIP When data is immutable, it is safe (and fast) to compare it by reference.\nTheo Cool. So atoms play well with immutable data.\nJoe Exactly!\n8.4 State management with atoms\nJoe Do you remember a couple of weeks ago when I showed you how we resolve\npotential conflicts between mutations? You told me that the code was not\nthread-safe.\nTheo Let me look again at the code.\nTheo takes a look at the code for the SystemData class that he wrote some time ago\n(repeated in listing 8.8). Without the validation logic, it makes the code easier to grasp.\nListing8.8 SystemData class from part 1\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nthis.systemData = SystemConsistency.reconcile(this.systemData,\nprevious,\nnext);\n}\n}\n--- Page 201 ---\n8.4 State management with atoms 173\nIt takes him a few minutes to remember how the commit method works. Suddenly, he has\nan Aha! moment.\nTheo This code is not thread-safe because the SystemConsistency.reconcile\ncode inside the commit method is not protected. Nothing prevents the two\nthreads from executing this code concurrently.\nJoe Right! Now, can you tell me how to make it thread-safe?\nTheo With locks?\nJoe Come on...\nTheo I was kidding, of course. We make the code thread-safe not with a lock but with\nan atom.\nJoe Nice joke!\nTheo Let me see. I’d need to store the system data inside an atom. The get and set\nmethod of SystemData would simply call the get and set methods of the\natom. How does this look?\nListing8.9 SystemData class with atom (without the commit method)\nclass SystemState {\nsystemData;\nconstructor() {\nthis.systemData = new Atom();\n}\nget() {\nreturn this.systemData.get();\n}\ncommit(prev, next) {\nthis.systemData.set(next);\n}\n}\nJoe Excellent. Now for the fun part. Implement the commit method by calling the\nswap method of the atom.\nTheo Instead of calling SystemConsistency.reconcile() directly, I need to wrap\nit into a call to swap. So, something like this?\nListing8.10 Implementation of SystemData.commit with atom\nSystemData.commit = function(previous, next) {\nthis.systemData.swap(function(current) {\nreturn SystemConsistency.reconcile(current,\nprevious,\nnext);\n});\n};",
        "sections_found": []
      },
      "accurate_page_range": "176-201"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "7 Basic data validation",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 63,
      "chapter_info": {
        "page": 176,
        "title": "Basic data validation",
        "pattern_matched": "Chapter 7",
        "text_preview": "148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema"
      },
      "chapter_sections": {
        "start_page": 176,
        "end_page": 201,
        "content": "\n--- Page 176 ---\n148 CHAPTER 7 Basic data validation\nTheo So, if I call validate with this search request and that schema, it will return\ntrue?\nTheo indicates the search request example from listing 7.7 and the schema from listing 7.6.\nListing7.7 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe Give it a try, and you’ll see.\nIndeed! When Theo executes the code to validate the search request, it returns true.\nListing7.8 Validating the search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksRequest = {\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nvalidate(searchBooksRequestSchema, searchBooksRequest);\n// → true\nJoe Now, please try an invalid request.\nTheo Let me think about what kind of invalidity to try. I know, I’ll make a typo in the\ntitle field and call it tilte with the l before the t.\nAs expected, the code with the type returns false. Theo is not surprised, and Joe is smil-\ning from ear to ear.\nListing7.9 Validating an invalid search request\nvar invalidSearchBooksRequest = {\n\"tilte\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\n--- Page 177 ---\n7.3 Schema flexibility and strictness 149\nvalidate(searchBooksRequestSchema, invalidSearchBooksRequest);\n// → false\nTheo The syntax of JSON Schema is much more verbose than the syntax for declar-\ning the members in a class. Why is that so?\nJoe For two reasons. First, because JSON Schema is language independent, it can\nbe used in any programming language. As I told you, there are JSON Schema\nvalidators available in most programming languages.\nTheo I see.\nJoe Second, JSON Schema allows you to express validation conditions that are much\nharder, if not impossible, to express when data is represented with classes.\nTIP The expressive power of JSON Schema is high!\nTheo Now you have triggered my curiosity. Can you give me some examples?\nJoe In a moment, we’ll talk about schema composition. Someday I’ll show you\nsome examples of advanced validation.\n NOTE Advanced validation is covered in chapter 12.\nTheo What kind of advanced validation?\nJoe What I mean by advanced validation is, for instance, validating that a number\nfalls within a given range or validating that a string matches a regular expression.\nTheo Is there a way to get details about why the request is invalid?\nJoe Absolutely! I’ll show you later. For now, let me show you how to make sure the\nresponse the server sends back to the client is valid.\nTheo It sounds much more complicated than a search book request!\nJoe Why?\nTheo Because a search response is made of multiple book results, and in each book\nresult, some of the fields are optional!\n7.3 Schema flexibility and strictness\nJoe Can you give me an example of what a book search response would look like?\nTheo Take a look at this example. It’s a search response with information about two\nbooks: 7 Habits of Highly Effective People and The Power of Habit.\nListing7.10 An example of a search response\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432\n},\n--- Page 178 ---\n150 CHAPTER 7 Basic data validation\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn_13\": \"978-1982137274\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n]\n}\n]\nJoe It’s funny that you mention The Power of Habit. I’m reading this book in order\nto get rid of my habit of biting my nails. Anyway, what fields are required and\nwhat fields are optional in a book search response?\nTheo In book information, the title and available fields are required. The other\nfields are optional.\nJoe As I told you when we built the schema for the book search request, fields in a\nmap are optional by default. In order to make a field mandatory, we have to\ninclude it in the required array. I’d probably implement it with something\nlike this.\nListing7.11 Schema of a search response\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, map fields are optional by default.\nTheo I must admit that specifying a list of required fields is much simpler than hav-\ning to specify that a member in a class in nullable!\nJoe Agreed!\nTheo On the other hand, I find the nesting of the book information schema in the\nsearch response schema a bit hard to read.\n--- Page 179 ---\n7.3 Schema flexibility and strictness 151\nJoe Nothing prevents you from separating the book information schema from the\nsearch response schema.\nTheo How?\nJoe It’s just JSON, my friend. It means, you are free to manipulate the schema as\nany other map in your program. For instance, you could have the book infor-\nmation schema in a variable named bookInfoSchema and use it in the search\nbooks response schema. Let me refactor the schema to show you what I mean.\nListing7.12 Schema of a search response refactored\nvar bookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"subtitle\": {\"type\": \"string\"},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"isbn_13\": {\"type\": \"string\"}\n}\n};\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": bookInfoSchema\n};\nTheo Once again, I have to admit that JSON Schemas are more composable than\nclass definitions.\nTIP JSON Schemas are just maps. We are free to compose and manipulate them like\nany other map.\nJoe Let’s move on to validating data received from external data sources.\nTheo Is that different?\nJoe Not really, but I’ll take it as an opportunity to show you some other features of\nJSON Schema.\nTheo I’m curious to learn how data validation is used when we access data from the\ndatabase.\nJoe Each time we access data from the outside, it’s a good practice to validate it.\nCan you show me an example of how a database response for a search query\nwould look?\nTIP It’s a good practice to validate data that comes from an external data source.\n--- Page 180 ---\n152 CHAPTER 7 Basic data validation\nTheo When we query books from the database, we expect to receive an array of\nbooks with three fields: title, isbn, and available. The first two values should\nbe strings, and the third one should be a Boolean.\nJoe Are those fields optional or required?\nTheo What do you mean?\nJoe Could there be books for which some of the fields are not defined?\nTheo No.\nJoe In that case, the schema is quite simple. Would you like to try writing the\nschema for the database response?\nTheo Let me see. It’s an array of objects where each object has three properties, so\nsomething like this?\nListing7.13 Schema of a database response\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n}\nJoe Well done, my friend! Now, I want to tell you about the additionalProperties\nfield in JSON Schema.\nTheo What’s that?\nJoe Take a look at this array.\nListing7.14 A book array with an additional property\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true,\n\"isbn\": \"978-0812981605\",\n\"dummy_property\": 42\n},\n{\n\"title\": \"The Power of Habit\",\n\"available\": false,\n\"isbn\": \"978-1982137274\",\n\"dummy_property\": 45\n}\n]\n--- Page 181 ---\n7.3 Schema flexibility and strictness 153\nJoe Is it a valid database response?\nTheo No. A database response should not have a dummy_property field. It should\nhave only the three required fields specified in the schema.\nJoe It might be surprising but, by default, fields not specified in the schema of an\nobject are allowed in JSON Schema. In order to disallow them, one has to set\nadditionalProperties to false like this.\nListing7.15 Disallowing properties not mentioned in the schema\nvar booksFromDBSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"additionalProperties\": false,\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"isbn\": {\"type\": \"string\"}\n}\n}\n};\nTIP In JSON Schema, by default, fields not specified in the schema of a map are\nallowed.\nTheo Why is that?\nJoe The reason is that usually having additional fields in a map doesn’t cause\ntrouble. If your code doesn’t care about a field, it simply ignores it. But some-\ntimes we want to be as strict as possible, and we set additionalProperties\nto false.\nTheo What about the search request and response schema from the previous discus-\nsions? Should we set additionalProperties to false?\nJoe That’s an excellent question. I’d say it’s a matter of taste. Personally, I like to\nallow additional fields in requests and disallow them in responses.\nTheo What’s the advantage?\nJoe Well, the web server is responsible for the responses it sends to its clients. It\nmakes sense then to be as strict as possible. However, the requests are created\nby the clients, and I prefer to do my best to serve my clients even when they are\nnot as strict as they should be.\nTheo Naturally. “The client is always right.”\nJoe Actually, I prefer the way Jon Postel formulated his robustness principle: “Be\nconservative in what you send, be liberal in what you accept.”\nTIP It’s a good practice to be strict with the data that you send and to be flexible with\nthe data that you receive.\n--- Page 182 ---\n154 CHAPTER 7 Basic data validation\n7.4 Schema composition\nTheo What about validating data that comes from an external web service?\nJoe Can you give me an example?\nTheo In the near future, we’ll have to integrate with a service called Open Library\nBooks API that provides detailed information about books.\n NOTE For information on the Open Library Books API, see https://openlibrary\n.org/dev/docs/api/books.\nJoe Can you show me, for instance, the service response for Watchmen?\nTheo Sure. Here you go.\nTheo taps a few keys on his keyboard and brings up the response. Joe looks at the JSON for\na long time.\nListing7.16 An Open Library Books API response example\n{\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n}\nTheo asks himself, “What could be so special in this JSON?” While Joe is meditating about\nthis piece of JSON, Theo writes the JSON Schema for the Books API response. It doesn’t\nseem to be more complicated than any of the previous schemas. When Theo is done, he\nasks Joe to take a look at the schema.\nListing7.17 Schema of the Open Library Books API response\n{\n\"type\": \"object\",\n\"required\": [\"title\"],\n--- Page 183 ---\n7.4 Schema composition 155\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n}\nJoe Good job!\nTheo That wasn’t so hard. I really don’t see why you looked at this JSON response for\nsuch a long time.\nJoe Well, it has to do with the isbn_10 and isbn_13 fields. I assume that they’re\nnot both mandatory.\nTheo Right! That’s why I didn’t include them in the required field of my schema.\nJoe But one of them should always be there. Right?\nTheo Sometimes one of them and sometimes both of them, like for Watchmen. It\ndepends on the publication year of the book. Books published before 2007\nhave isbn_10, and books published after 2007 have isbn_13.\nJoe Oh, I see. And Watchmen has both because it was originally published in 1986\nbut published again after 2007.\nTheo Correct.\nJoe Then, you need your schema to indicate that one of the isbn fields is man-\ndatory. That’s a good opportunity for me to tell you about JSON Schema\ncomposition.\nTheo What’s that?\nJoe It’s a way to combine schemas, similarly to how we combine logical conditions\nwith AND, OR, and NOT.\nTheo I’d like to see that.\nJoe Sure. How would you express the schema for the Books API response as a\ncomposition of three schemas: basicBookInfoSchema, the schema that you\nwrote where only title is required; mandatoryIsbn13, a schema where only\n--- Page 184 ---\n156 CHAPTER 7 Basic data validation\nisbn_13 is required; and mandatoryIsb10, a schema where only isbn_10 is\nrequired?\nTheo I think it should be basicBookInfoSchema AND (mandatoryIsbn13 OR\nmandatoryIsbn10).\nJoe Exactly! The only thing is that in JSON Schema, we use allOf instead of AND,\nand anyOf instead of OR.\nJoe shows Theo the result in listing 7.18 and an example of its usage in listing 7.19.\nListing7.18 Schema of an external API response\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n--- Page 185 ---\n7.4 Schema composition 157\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing7.19 Validating an external API response\nvar bookInfo = {\n\"publishers\": [\n\"DC Comics\"\n],\n\"number_of_pages\": 334,\n\"weight\": \"1.4 pounds\",\n\"physical_format\": \"Paperback\",\n\"subjects\": [\n\"Graphic Novels\",\n\"Comics & Graphic Novels\",\n\"Fiction\",\n\"Fantastic fiction\"\n],\n\"isbn_13\": [\n\"9780930289232\"\n],\n\"title\": \"Watchmen\",\n\"isbn_10\": [\n\"0930289234\"\n],\n\"publish_date\": \"April 1, 1995\",\n\"physical_dimensions\": \"10.1 x 6.6 x 0.8 inches\"\n};\nvalidate(bookInfoSchema, bookInfo);\n// → true\nTheo I see why they call it allOf and anyOf. The first one means that data must con-\nform to all the schemas, and the second one means that data must conform to\nany of the schemas.\nJoe Yup.\n NOTE JSON Schema also supports oneOf for cases where data must be valid against\nexactly one schema.\nTheo Nice. With schema composition, JSON Schema seems to have more expressive\npower than what I was used to when representing data with classes.\nJoe That’s only the beginning. I’ll show you more data validation conditions that\ncan’t be expressed when data is represented with classes some other time.\n NOTE Advanced data validation is covered in chapter 12.\nTheo Something still bothers me, though. When data isn’t valid, you don’t know what\nwent wrong.\n--- Page 186 ---\n158 CHAPTER 7 Basic data validation\n7.5 Details about data validation failures\nJoe So far, we’ve treated JSON Schema validation as though it were binary: either a\npiece of data is valid or it isn’t.\nTheo Right...\nJoe But, in fact, when a piece of data is not valid, we can get details about the\nreason of the invalidity.\nTheo Like when a required field is missing, can we get the name of the missing field?\nJoe Yes. When a piece of data is not of the expected type, we can get information\nabout that also.\nTheo That sounds very useful!\nJoe Indeed. Let me show you how it works. Until now, we used a generic validate\nfunction, but when we deal with validation failures, we need to be more specific.\nTheo Why?\nJoe Because each data validator library has its own way of exposing the details of\nadata validation failure. For instance, in JavaScript Ajv, the errors from the\nlast data validation are stored as an array inside the validator instance.\nTheo Why an array?\nJoe Because there could be several failures. But let’s start with the case of a single\nfailure. Imagine we encounter a search book request where the title field is\nnamed myTitle instead of title. Take a look at this example. As you can see,\nwe first instantiate a validator instance.\nListing7.20 Accessing validation errors in Ajv\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n};\nInstantiates a\nvar ajv = new Ajv(); validator instance\najv.validate(searchBooksRequestSchema, invalidSearchBooksRequest);\najv.errors\nDisplays the\nvalidation errors\n--- Page 187 ---\n7.5 Details about data validation failures 159\nTheo And what does the information inside the errors array look like?\nJoe Execute the code snippet. You’ll see.\nWhen Theo executes the code snippets from listing 7.20, he can hardly believe his eyes. He\nlooks at the details, finding the results hard to digest.\nListing7.21 Details for a single data validation failure in an array format\n[\n{\n\"instancePath\": \"\",\n\"schemaPath\": \"#/required\",\n\"keyword\": \"required\",\n\"params\": {\n\"missingProperty\":\"title\"\n},\n\"message\": \"must have required property 'title'\"\n}\n]\nTheo I find the contents of the errors array a bit hard to understand.\nJoe Me too. Fortunately, Ajv provides a errorsText utility function to convert the\nerrors array in a human readable format. See, for instance, what is returned\nwhen you call errorsText.\nListing7.22 Displaying the errors in human readable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title'\"\nTheo Let me see what happens when there are more than one validation failure in\nthe data.\nJoe By default, Ajv catches only one validation error.\nTIP By default, Ajv catches only the first validation failure.\nTheo I guess that’s for performance reasons. Once the validator encounters an\nerror, it doesn’t continue the data parsing.\nJoe Probably. Anyway, in order to catch more than one validation failure, you need\nto pass the allErrors options to the Ajv constructor. Check out this code.\nListing7.23 Catching multiple validation failures\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n--- Page 188 ---\n160 CHAPTER 7 Basic data validation\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nA request with\nthree failures\nvar invalidSearchBooksRequest = {\n\"myTitle\": \"habit\",\n\"fields\": [1, 2]\n}; Instantiates the Ajv constructor\nwith allErrors: true in order to\ncatch more than one failure\nvar ajv = new Ajv({allErrors: true});\najv.validate(searchBooksRequestSchema,\ninvalidSearchBooksRequest); Converts the\nerrors to a human\nreadable format\najv.errorsText(ajv.errors);\n// → \"data must have required property 'title',\n// → data/fields/0 must be string,\n// → data/fields/1 must be string\"\nJoe We validate a search request with myTitle instead of title and numbers\ninstead of strings in the fields array. As you can see in the output of the code\nsnippet, three errors are returned.\nTheo Great! I think I have all that I need in order to add data validation to the\nboundaries of my system when Nancy asks me to make the Library Manage-\nment System into a web server.\nJoe Would you allow me to give you a small gift as a token of our friendship?\nTheo I’d be honored.\nJoe takes a small package out of his bag, wrapped in a light-green ribbon. He hands Theo\nthe package with a solemn gesture.\nWhen Theo undoes the ribbon, he discovers an elegant piece of paper decorated with\npretty little designs. In the center of the paper, Theo manages to read the inscription\n“JSON Schema cheat sheet.” He smiles while browsing the cheat sheet. It’s exactly what he\nneeds.\nListing7.24 JSON Schema cheat sheet\n{ At the root level,\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the\narray is a map.\n\"type\": \"object\",\nmyNumber \"properties\": {\nThe properties of\nis a number. \"myNumber\": {\"type\": \"number\"},\neach field in the map\n\"myString\": {\"type\": \"string\"},\nmyString is\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\na string. myEnum is a\n\"myBool\": {\"type\": \"boolean\"}\nenumeration\nmyBool is a }, value with two\nboolean. \"required\": [\"myNumber\", \"myString\"], possibilities:\nThe mandatory fields in the map \"myVal\" and\nare myNumber and myString; \"yourVal\".\nother fields are optional.\n--- Page 189 ---\nSummary 161\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nThen, Theo turns the paper over to find that the back is also filled with drawings. In the\ncenter of the paper, he reads the inscription, “An example of valid data.”\nListing7.25 An example of valid data\n[\n{\nThis map is valid\n\"myNumber\": 42,\nbecause all its\n\"myString\": \"Hello\",\nfields are valid.\n\"myEnum\": \"myVal\",\n\"myBool\": true\n},\n{\nThis map is valid\n\"myNumber\": 54,\nbecause it contains all\n\"myString\": \"Happy\"\nthe required fields.\n}\n]\nSummary\n DOP Principle #4 is to separate data schema and data representation.\n The boundaries of a system are defined to be the areas where the system\nexchanges data.\n Some examples of data validation at the boundaries of the system are validation\nof client requests and responses, and validation of data that comes from exter-\nnal sources.\n Data validation in DOP means checking whether a piece of data conforms to a\nschema.\n When a piece of data is not valid, we get information about the validation fail-\nures and send this information back to the client in a human readable format.\n When data at system boundaries is valid, it’s not critical to validate data again\ninside the system.\n JSON Schema is a language that allows us to separate data validation from data\nrepresentation.\n JSON Schema syntax is a bit verbose.\n The expressive power of JSON Schema is high.\n JSON Schemas are just maps and, as so, we are free to manipulate them like any\nother maps in our programs.\n We can store a schema definition in a variable and use this variable in another\nschema.\n In JSON Schema, map fields are optional by default.\n It’s good practice to validate data that comes from an external data source.\n--- Page 190 ---\n162 CHAPTER 7 Basic data validation\n It’s good practice to be strict regarding data that you send and to be flexible\nregarding data that you receive.\n Ajv is a JSON Schema library in JavaScript.\n By default, Ajv catches only the first validation failure.\n Advanced validation is covered in chapter 12.\n--- Page 191 ---\nAdvanced\nconcurrency control\nNo more deadlocks!\nThis chapter covers\n Atoms as an alternative to locks\n Managing a thread-safe counter and a thread-safe\nin-memory cache with atoms\n Managing the whole system state in a thread-safe\nway with atoms\nThe traditional way to manage concurrency in a multi-threaded environment\ninvolves lock mechanisms like mutexes. Lock mechanisms tend to increase the com-\nplexity of the system because it’s not trivial to make sure the system is free of dead-\nlocks. In DOP, we leverage the fact that data is immutable, and we use a lock-free\nmechanism, called an atom, to manage concurrency. Atoms are simpler to manage\nthan locks because they are lock-free. As a consequence, the usual complexity of\nlocks that are required to avoid deadlocks don’t apply to atoms.\n NOTE This chapter is mostly relevant to multi-threaded environments like Java,\nC#, Python, and Ruby. It is less relevant to single-threaded environments like Java-\nScript. The JavaScript code snippets in this chapter are written as though JavaScript\nwere multi-threaded.\n163\n--- Page 192 ---\n164 CHAPTER 8 Advanced concurrency control\n8.1 The complexity of locks\nThis Sunday afternoon, while riding his bike across the Golden Gate Bridge, Theo thinks\nabout the Klafim project with concern, not yet sure that betting on DOP was a good\nchoice. Suddenly, Theo realizes that he hasn’t yet scheduled the next session with Joe. He\ngets off his bike to call Joe. Bad luck, the line is busy.\nWhen Theo gets home, he tries to call Joe again, but once again the phone is busy. After\ndinner, Theo tries to call Joe one more time, with the same result—a busy signal. “Obvi-\nously, Joe is very busy today,” Theo tells himself. Exhausted by his 50-mile bike ride at an\naverage of 17 miles per hour, he falls asleep on the sofa. When Theo wakes up, he’s elated\nto see a text message from Joe, “See you Monday morning at 11 AM?” Theo answers with a\nthumbs up and prepares for another week of work.\nWhen Joe arrives at the office, Theo asks him why his phone was constantly busy the day\nbefore. Joe answers that he was about to ask Theo the same question. They look at each\nother, puzzled, and then simultaneously break into laughter as they realize what hap-\npened: in an amazing coincidence, they’d tried to phone each other at exactly the same\ntimes. They both say at once:\n“A deadlock!”\nThey both head for Theo’s office. When they get to Theo’s desk, Joe tells him that today’s\nsession is going to be about concurrency management in multi-threaded environments.\nJoe How do you usually manage concurrency in a multi-threaded environment?\nTheo I protect access to critical sections with a lock mechanism, a mutex, for instance.\nJoe When you say access, do you mean write access or also read access?\nTheo Both!\nJoe Why do you need to protect read access with a lock?\nTheo Because, without a lock protection, in the middle of a read, a write could hap-\npen in another thread. It would make my read logically inconsistent.\nJoe Another option would be to clone the data before processing it in a read.\nTheo Sometimes I would clone the data; but in many cases, when it’s large, it’s too\nexpensive to clone.\nTIP Cloning data to avoid read locks doesn’t scale.\nJoe In DOP, we don’t need to clone or to protect read access.\nTheo Because data is immutable?\nJoe Right. When data is immutable, even if a write happens in another thread\nduring a read, it won’t make the read inconsistent because the write never\nmutates the data that is read.\nTheo In a sense, a read always works on a data snapshot.\nJoe Exactly!\nTIP When data is immutable, a read is always safe.\nTheo But what about write access? Don’t you need to protect that with locks?\nJoe Nope.\n--- Page 193 ---\n8.2 Thread-safe counter with atoms 165\nTheo Why not?\nJoe We have a simpler mechanism—it’s called an atom.\nTheo I am glad to hear there is a something simpler than locks. I really struggle each\ntime I have to integrate locks into a multi-threaded system.\nJoe Me too! I remember a bug we had in production 10 years ago. We forgot to\nrelease a lock when an exception was thrown in a critical section. It caused a\nterrible deadlock.\nTheo Deadlocks are really hard to avoid. Last year, we had a deadlock issue when two\nlocks were not released in the proper order.\nJoe I have great news for you. With atoms, deadlocks never happen!\nTIP With atoms, deadlocks never happen.\nTheo That sounds great. Tell me more!\nTIP Atoms provide a way to manage concurrency without locks.\n8.2 Thread-safe counter with atoms\nJoe Let’s start with a simple case: a counter shared between threads.\nTheo What do you mean by a counter?\nJoe Imagine that we’d like to count the number of database accesses and write the\ntotal number of accesses to a log every minute.\nTheo OK.\nJoe Could you write JavaScript code for this multi-threaded counter using locks?\nTheo But JavaScript is single-threaded!\nJoe I know, but it’s just for the sake of illustration. Imagine that JavaScript were\nmulti-threaded and that it provided a Mutex object that you could lock and\nunlock.\nTheo It’s a bit awkward. I guess it would look like this.\nTheo goes to the whiteboard. He writes what he imagines to be JavaScript code for a multi-\nthreaded counter with locks.\nListing8.1 A thread-safe counter protected by a mutex\nvar mutex = new Mutex();\nvar counter = 0;\nfunction dbAccess() {\nmutex.lock();\ncounter = counter + 1;\nmutex.unlock();\n// access the database\n}\nfunction logCounter() {\nmutex.lock();\n--- Page 194 ---\n166 CHAPTER 8 Advanced concurrency control\nconsole.log('Number of database accesses: ' + counter);\nmutex.unlock();\n}\nJoe Excellent. Now, I am going to show you how to write the same code with atoms.\nAn atom provides three methods:\n get returns the current value of the atom.\n set overwrites the current value of the atom.\n swap receives a function and updates the value of the atom with the result\nof the function called on the current value of the atom.\nJoe unzips a pocket in his laptop case and takes out a piece of paper. He hands it to\nTheo. Theo is pleasantly surprised as the sheet of paper succinctly describes the methods\n(table 8.1).\nTable 8.1 The three methods of an atom\nMethod Description\nget Returns the current value\nset Overwrites the current value\nswap Updates the current value with a function\nTheo How would it look like to implement a thread-safe counter with an atom?\nJoe It’s quite simple, actually.\nJoe pulls out his laptop, fires it up, and begins to type. When he’s done, he turns the laptop\naround so that Theo can see the code to implement a thread-safe counter in an atom.\nListing8.2 A thread-safe counter stored in an atom\nvar counter = new Atom();\ncounter.set(0);\nfunction dbAccess() {\ncounter.swap(function(x) {\nThe argument x is the\nreturn x + 1;\ncurrent value of the atom,\n});\nsame as counter.get().\n// access the database\n}\nfunction logCounter() {\nconsole.log('Number of database accesses: ' + counter.get());\n}\nTheo Could you tell me what’s going on here?\nJoe Sure! First, we create an empty atom. Then, we initialize the value of the atom\nwith counter.set(0). In the logger thread, we read the current value of the\natom with counter.get().\nTheo And how do you increment the counter in the threads that access the database?\n--- Page 195 ---\n8.2 Thread-safe counter with atoms 167\nJoe We call swap with a function that receives x and returns x + 1.\nTheo I don’t understand how swap could be thread-safe without using any locks.\nJoe quickly goes to the whiteboard. He sketches the diagram in figure 8.1.\nTake snapshot\nCompute next state\nYes\nState changed?\nNo\nUpdate state\nFigure 8.1 High-level flow of swap\nJoe You see, swap computes the next value of the atom, and before modifying the\ncurrent value of the atom, it checks whether the value of the atom has changed\nduring the computation. If so, swap tries again, until no changes occur during\nthe computation.\nTheo Is swap easy to implement?\nJoe Let me show you the implementation of the Atom class and you’ll see.\nListing8.3 Implementation of the Atom class\nclass Atom {\nstate;\nconstructor() {}\nget() {\nreturn this.state;\n}\nset(state) {\nthis.state = state;\n}\nswap(f) {\nwhile(true) {\nvar stateSnapshot = this.state;\nvar nextState = f(stateSnapshot);\nif (!atomicCompareAndSet(this.state,\n--- Page 196 ---\n168 CHAPTER 8 Advanced concurrency control\nstateSnapshot,\nnextState)) {\nUses a special thread-safe comparison operation\ncontinue;\nas this.state might have changed in another\n}\nthread during execution of the function f.\nreturn nextState;\n}\n}\n}\nTheo comes closer to the whiteboard. He modifies Joe’s diagram a bit to make the flow of\nthe swap operation more detailed. The resulting diagram is in figure 8.2. Theo still has a\nfew questions, though.\nTake snapshot\nsnapshot = state\nCompute next state\nnextState = f(snapshot)\nCheck if state has changed\nstate == snapshot\nYes\nState changed?\nNo\nUpdate state\nstate = nextState\nFigure 8.2 Detailed flow of swap\nTheo What is atomicCompareAndSet?\nJoe It’s the core operation of an atom. atomicCompareAndSet atomically sets the\nstate to a new value if, and only if, the state equals the provided old value. It\nreturns true upon success and false upon failure.\nTheo How could it be atomic without using locks?\nJoe That’s a great question! In fact, atomicCompareAndSet is a compare-and-swap\noperation, provided by the language that relies on a functionality of the CPU\nitself. For example, in Java the java.util.concurrent.atomic package has\nan AtomicReference generic class that provides a compareAndSet() method.\n NOTE See http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html\nfor general information about compare-and-swap operations. Implementations for\nmulti-threaded languages appear in table 8.2.\n--- Page 197 ---\n8.2 Thread-safe counter with atoms 169\nTable 8.2 Implementation of an atomic compare and set in various languages\nLanguage Link\nJava http://mng.bz/mx0W\nJavaScript Not relevant (single-threaded language)\nRuby http://mng.bz/5KG8\nPython https://github.com/maxcountryman/atomos\nC# http://mng.bz/6Zzp\nTheo Apropos Java, how would the implementation of an atom look?\nJoe It’s quite the same, besides the fact that Atom has to use generics, and the inner\nstate has to be stored in an AtomicReference.\nJoe brings up a Java implementation of Atom on his laptop. Theo looks over the code.\nListing8.4 Implementation of the Atom class in Java\nclass Atom<ValueType> {\nprivate AtomicReference<ValueType> state;\npublic Atom() {}\nValueType get() {\nreturn this.state.get();\n}\nthis.state might have\nchanged in another thread\nvoid set(ValueType state) {\nduring the execution of f.\nthis.state.set(state);\n}\nValueType swap(UnaryOPerator<ValueType> f) {\nwhile(true) {\nValueType stateSnapshot = this.state.get();\nValueType nextState = f(stateSnapshot);\nif (!this.state.compareAndSet(stateSnapshot,\nnextState)) {\ncontinue;\n}\n}\nreturn nextState;\n}\n}\nTheo What about using an atom in Java?\nJoe Here, take a look. It’s quite simple.\n--- Page 198 ---\n170 CHAPTER 8 Advanced concurrency control\nListing8.5 Using an Atom in Java\nAtom<Integer> counter = new Atom<Integer>();\ncounter.set(0);\ncounter.swap(x -> x + 1);\ncounter.get();\nTheo takes a couple of minutes to meditate about this atom stuff and to digest what he’s\njust learned. Then, he asks Joe:\nTheo What if swap never succeeds? I mean, could the while loop inside the code of\nswap turn out to be an infinite loop?\nJoe No! By definition, when atomicCompareAndSet fails on a thread, it means that\nthe same atom was changed on another thread during the execution of swap.\nIn this race between threads, there is always a winner.\nTheo But isn’t it possible that some thread never succeeds because it always loses the\nrace against other threads?\nJoe In theory, yes, but I’ve never encountered such a situation. If you have thou-\nsands of threads that do nothing besides swapping an atom, it could happen I\nsuppose. But, in practice, once the atom is swapped, the threads do some real\nwork, for example, database access or I/O. This gives other threads the oppor-\ntunity to swap the atom successfully.\n NOTE In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing beside swapping an atom. In practice, once an atom is swapped, the\nthreads do some real work (e.g., database access), which creates an opportunity for\nother threads to swap the atom successfully.\nTheo Interesting.... Indeed, atoms look much easier to manage than locks.\nJoe Now let me show you how to use atoms with composite data.\nTheo Why would that be different?\nJoe Usually, dealing with composite data is more difficult than dealing with primi-\ntive types.\nTheo When you sold me on DOP, you told me that we are able to manage data with\nthe same simplicity as we manage numbers.\nTIP In DOP, data is managed with the same simplicity as numbers.\nJoe That’s exactly what I am about to show you.\n8.3 Thread-safe cache with atoms\nJoe Are you familiar with the notion of in-memory cache?\nTheo You mean memoization?\n--- Page 199 ---\n8.3 Thread-safe cache with atoms 171\nJoe Kind of. Imagine that database queries don’t vary too much in your applica-\ntion. It makes sense in that case to store the results of previous queries in mem-\nory in order to improve the response time.\nTheo Yes, of course!\nJoe What data structure would you use to store the in-memory cache?\nTheo Probably a string map, where the keys are the queries, and the values are the\nresults from the database.\nTIP It’s quite common to represent an in-memory cache as a string map.\nJoe Excellent! Now can you write the code to cache database queries in a thread-\nsafe way using a lock?\nTheo Let me see: I’m going to use an immutable string map. Therefore, I don’t\nneed to protect read access with a lock. Only the cache update needs to be\nprotected.\nJoe You’re getting the hang of this!\nTheo The code should be something like this.\nListing8.6 Thread-safe cache with locks\nvar mutex = new Mutex();\nvar cache = {};\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache, query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\nmutex.lock();\ncache = _.set(cache, query, result);\nmutex.unlock();\nreturn result;\n}\nJoe Nice! Now, let me show you how to write the same code using an atom instead\nof a lock. Take a look at this code and let me know if it’s clear to you.\nListing8.7 Thread-safe cache with atoms\nvar cache = new Atom();\ncache.set({});\nfunction dbAccessCached(query) {\nvar resultFromCache = _.get(cache.get(), query);\nif (resultFromCache != nil) {\nreturn resultFromCache;\n}\nvar result = dbAccess(query);\ncache.swap(function(oldCache) {\n--- Page 200 ---\n172 CHAPTER 8 Advanced concurrency control\nreturn _.set(oldCache, query, result);\n});\nreturn result;\n}\nTheo I don’t understand the function you’re passing to the swap method.\nJoe The function passed to swap receives the current value of the cache, which is a\nstring map, and returns a new version of the string map with an additional key-\nvalue pair.\nTheo I see. But something bothers me with the performance of the swap method in\nthe case of a string map. How does the comparison work? I mean, comparing\ntwo string maps might take some time.\nJoe Not if you compare them by reference. As we discussed in the past, when data\nis immutable, it is safe to compare by reference, and it’s super fast.\nTIP When data is immutable, it is safe (and fast) to compare it by reference.\nTheo Cool. So atoms play well with immutable data.\nJoe Exactly!\n8.4 State management with atoms\nJoe Do you remember a couple of weeks ago when I showed you how we resolve\npotential conflicts between mutations? You told me that the code was not\nthread-safe.\nTheo Let me look again at the code.\nTheo takes a look at the code for the SystemData class that he wrote some time ago\n(repeated in listing 8.8). Without the validation logic, it makes the code easier to grasp.\nListing8.8 SystemData class from part 1\nclass SystemState {\nsystemData;\nget() {\nreturn this.systemData;\n}\nset(_systemData) {\nthis.systemData = _systemData;\n}\ncommit(previous, next) {\nthis.systemData = SystemConsistency.reconcile(this.systemData,\nprevious,\nnext);\n}\n}\n--- Page 201 ---\n8.4 State management with atoms 173\nIt takes him a few minutes to remember how the commit method works. Suddenly, he has\nan Aha! moment.\nTheo This code is not thread-safe because the SystemConsistency.reconcile\ncode inside the commit method is not protected. Nothing prevents the two\nthreads from executing this code concurrently.\nJoe Right! Now, can you tell me how to make it thread-safe?\nTheo With locks?\nJoe Come on...\nTheo I was kidding, of course. We make the code thread-safe not with a lock but with\nan atom.\nJoe Nice joke!\nTheo Let me see. I’d need to store the system data inside an atom. The get and set\nmethod of SystemData would simply call the get and set methods of the\natom. How does this look?\nListing8.9 SystemData class with atom (without the commit method)\nclass SystemState {\nsystemData;\nconstructor() {\nthis.systemData = new Atom();\n}\nget() {\nreturn this.systemData.get();\n}\ncommit(prev, next) {\nthis.systemData.set(next);\n}\n}\nJoe Excellent. Now for the fun part. Implement the commit method by calling the\nswap method of the atom.\nTheo Instead of calling SystemConsistency.reconcile() directly, I need to wrap\nit into a call to swap. So, something like this?\nListing8.10 Implementation of SystemData.commit with atom\nSystemData.commit = function(previous, next) {\nthis.systemData.swap(function(current) {\nreturn SystemConsistency.reconcile(current,\nprevious,\nnext);\n});\n};",
        "sections_found": []
      },
      "accurate_page_range": "176-201"
    },
    {
      "text": "- 8.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "8 Advanced concurrency control",
      "raw_line": "- 8.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 64,
      "chapter_info": {
        "page": 202,
        "title": "Advanced concurrency control",
        "pattern_matched": "Chapter 8",
        "text_preview": "174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do yo"
      },
      "chapter_sections": {
        "start_page": 202,
        "end_page": 232,
        "content": "\n--- Page 202 ---\n174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do you mean?\nTheo I don’t know, but I am under the impression that mutexes are like phone calls,\nand atoms are like text messages.\nJoe smiles at Theo but doesn’t reveal the meaning of his smile. After the phone deadlock\nyesterday, Theo’s pretty sure that he and Joe are on the same page.\nSummary\n Managing concurrency with atoms is much simpler than managing concur-\nrency with locks because we don’t have to deal with the risk of deadlocks.\n Cloning data to avoid read locks doesn’t scale.\n When data is immutable, reads are always safe.\n Atoms provide a way to manage concurrency without locks.\n With atoms, deadlocks never happen.\n Using atoms for a thread-safe counter is trivial because the state of the counter\nis represented with a primitive type (an integer).\n We can manage composite data in a thread-safe way with atoms.\n We make the highly scalable state management approach from part 1 thread-\nsafe by keeping the whole system state inside an atom.\n It’s quite common to represent an in-memory cache as a string map.\n When data is immutable, it is safe (and fast) to compare by reference.\n In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing besides swapping an atom.\n In practice, once an atom is swapped, the threads do some real work (e.g.,\ndatabase access) to provide an opportunity for other threads to swap the atom\nsuccessfully.\n--- Page 203 ---\nPersistent data structures\nStanding on the shoulders of giants\nThis chapter covers\n The internal details of persistent data\nstructures\n The time and memory efficiency of persistent\ndata structures\n Using persistent data structures in an\napplication\nIn part 1, we illustrated how to manage the state of a system without mutating data,\nwhere immutability is maintained by constraining ourselves to manipulate the state\nonly with immutable functions using structural sharing. In this chapter, we present\na safer and more scalable way to preserve data immutability—representing data\nwith so-called persistent data structures. Efficient implementations of persistent\ndata structures exist for most programming languages via third-party libraries.\n9.1 The need for persistent data structures\nIt’s at the university where Theo meets Joe this time. When Theo asks Joe if today’s topic\nis academic in nature, Joe tells him that the use of persistent data structures only\nbecame possible in programming languages following a discovery in 2001 by a computer\n175\n--- Page 204 ---\n176 CHAPTER 9 Persistent data structures\nresearcher named Phil Bagwell.1 In 2007, Rich Hickey, the creator of Clojure, used this dis-\ncovery as the foundation of persistent data structures in Clojure. Unveiling the secrets of\nthese data structures to Theo in a university classroom is a way for Joe to honor the mem-\nory of Phil Bagwell, who unfortunately passed away in 2012. When they get to the univer-\nsity classroom, Joe starts the conversation with a question.\nJoe Are you getting used to DOP’s prohibition against mutating data in place and\ncreating new versions instead?\nTheo I think so, but two things bother me about the idea of structural sharing that\nyou showed me.\nJoe What bothers you, my friend?\nTheo Safety and performance.\nJoe What do you mean by safety?\nTheo I mean that using immutable functions to manipulate data doesn’t prevent it\nfrom being modified accidentally.\nJoe Right! Would you like me to show you the naive way to handle immutability or\nthe real way?\nTheo What are the pros and cons of each way?\nJoe The naive way is easy but not efficient, although the real way is efficient but\nnot easy.\nTheo Let’s start with the naive way then.\nJoe Each programming language provides its own way to protect data from being\nmutated.\nTheo How would I do that in Java, for instance?\nJoe Java provides immutable collections, and there is a way to convert a list or a\nmap to an immutable list or an immutable map.\n NOTE Immutable collections are not the same as persistent data structures.\nJoe opens his laptop and fires it up. He brings up two code examples, one for immutable\nlists and one for immutable maps.\nListing9.1 Converting a mutable list to an immutable list in Java\nvar myList = new ArrayList<Integer>();\nmyList.add(1);\nmyList.add(2);\nmyList.add(3);\nvar myImmutableList = List.of(myList.toArray());\n1 P. Bagwell, “Ideal hash trees” (No. REP_WORK), 2001. [Online]. Available: https://lampwww.epfl.ch/papers/\nidealhashtrees.pdf.\n--- Page 205 ---\n9.1 The need for persistent data structures 177\nListing9.2 Converting a mutable map to an immutable map in Java\nvar myMap = new HashMap<String, Object>();\nmyMap.put(\"name\", \"Isaac\");\nmyMap.put(\"age\", 42);\nvar myImmutableMap = Collections.unmodifiableMap(myMap);\nTheo What happens when you try to modify an immutable collection?\nJoe Java throws an UnsupportedOperationException.\nTheo And in JavaScript?\nJoe JavaScript provides an Object.freeze() function that prevents data from\nbeing mutated. It works both with JavaScript arrays and objects.\nJoe takes a minute to scroll through his laptop. When he finds what he’s looking for, he\nshows Theo the code.\nListing9.3 Making an object immutable in JavaScript\nvar a = [1, 2, 3];\nObject.freeze(a);\nvar b = {foo: 1};\nObject.freeze(b);\nTheo What happens when you try to modify a frozen object?\nJoe It depends. In JavaScript strict mode, a TypeError exception is thrown, and in\nnonstrict mode, it fails silently.\n NOTE JavaScript’s strict mode is a way to opt in to a restricted variant of JavaScript\nthat changes some silent errors to throw errors.\nTheo In case of a nested collection, are the nested collections also frozen?\nJoe No, but in JavaScript, one can write a deepFreeze() function that freezes an\nobject recursively. Here’s another example.\nListing9.4 Freezing an object recursively in JavaScript\nfunction deepFreeze(object) {\n// Retrieve the property names defined on object\nconst propNames = Object.getOwnPropertyNames(object);\n// Freeze properties before freezing self\nfor (const name of propNames) {\nconst value = object[name];\nif (value && typeof value === \"object\") {\ndeepFreeze(value);\n}\n}\n--- Page 206 ---\n178 CHAPTER 9 Persistent data structures\nreturn Object.freeze(object);\n}\nTheo I see that it’s possible to ensure that data is never mutated, which answers my\nconcerns about safety. Now, let me share my concerns about performance.\nTIP It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\nJoe Sure.\nTheo If I understand correctly, the main idea behind structural sharing is that most\ndata is usually shared between two versions.\nJoe Correct.\nTheo This insight allows us to create new versions of our collections using a shallow\ncopy instead of a deep copy, and you claimed that it was efficient.\nJoe Exactly!\nTheo Now, here is my concern. In the case of a collection with many entries, a shal-\nlow copy might be expensive.\nJoe Could you give me an example of a collection with many entries?\nTheo A catalog with 100,000 books, for instance.\nJoe On my machine, making a shallow copy of a collection with 100,000 entries\ndoesn’t take more than 50 milliseconds.\nTheo Sometimes, even 50 milliseconds per update isn’t acceptable.\nJoe I totally agree with you. When one needs data immutability at scale, naive struc-\ntural sharing is not appropriate.\nTheo Also, shallow copying an array of 100,000 elements on each update would\nincrease the program memory by 100 KB.\nJoe Indeed, at scale, we have a problem both with memory and computation.\nTIP At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\nTheo Is there a better solution?\nJoe Yes! For that, you’ll need to learn the real way to handle immutability. It’s\ncalled persistent data structures.\n9.2 The efficiency of persistent data structures\nTheo In what sense are those data structures persistent?\nJoe Persistent data structures are so named because they always preserve their pre-\nvious versions.\nTIP Persistent data structures always preserve the previous version of themselves\nwhen they are modified.\nJoe Persistent data structures address the two main limitations of naive structural\nsharing: safety and performance.\n--- Page 207 ---\n9.2 The efficiency of persistent data structures 179\nTheo Let’s start with safety. How do persistent data structures prevent data from\nbeing mutated accidentally?\nJoe In a language like Java, they implement the mutation methods of the collec-\ntion interfaces by throwing the run-time exception UnsupportedOperation-\nException.\nTheo And, in a language like JavaScript?\nJoe In JavaScript, persistent data structures provide their own methods to access\ndata, and none of those methods mutate data.\nTheo Does that mean that we can’t use the dot notation to access fields?\nJoe Correct. Fields of persistent data structures are accessed via a specific API.\nTheo What about efficiency? How do persistent data structures make it possible to\ncreate a new version of a huge collection in an efficient way?\nJoe Persistent data structures organize data in such a way that we can use structural\nsharing at the level of the data structure.\nTheo Could you explain?\nJoe Certainly. Let’s start with the simplest data structure: a linked list. Imagine that\nyou have a linked list with 100,000 elements.\nTheo OK.\nJoe What would it take to prepend an element to the head of the list?\nTheo You mean to create a new version of the list with an additional element?\nJoe Exactly!\nTheo Well, we could copy the list and then prepend an element to the list, but it\nwould be quite expensive.\nJoe What if I tell you that the original linked list is guaranteed to be immutable?\nTheo In that case, I could create a new list with a new head that points to the head of\nthe original list.\nTheo goes to the classroom blackboard. He picks up a piece of chalk and draws the dia-\ngram shown in figure 9.1.\nNew list Original list\nFigure 9.1 Structural sharing\n0 1 2 3 4 5 with linked lists\nJoe Would the efficiency of this operation depend on the size of the list?\nTheo No, it would be efficient, no matter the size of the list.\nJoe That’s what I mean by structural sharing at the level of the data structure itself.\nIt relies on a simple but powerful insight—when data is immutable, it is safe to\nshare it.\nTIP When data is immutable, it is safe to share it.\n--- Page 208 ---\n180 CHAPTER 9 Persistent data structures\nTheo I understand how to use structural sharing at the level of the data structure for\nlinked lists and prepend operations, but how would it work with operations\nlike appending or modifying an element in a list?\nJoe For that purpose, we need to be smarter and represent our list as a tree.\nTheo How does that help?\nJoe It helps because when a list is represented as a tree, most of the nodes in the\ntree can be shared between two versions of the list.\nTheo I am totally confused.\nJoe Imagine that you take a list with 100,000 elements and split it into two lists of\n50,000 elements each: elements 0 to 49,999 in list 1, and elements 50,000 to\n99,999 in list 2. How many operations would you need to create a new version\nof the list where a single element—let’s say, element at index 75,100—is\nmodified?\nIt’s hard for Theo to visualize this kind of stuff mentally. He goes back to the blackboard\nand draws a diagram (see figure 9.2). Once Theo looks at the diagram, it’s easy for him to\nanswer Joe’s question.\nList «Next»\nList\nList 1 List 2\n«Next»\n0...49,999 50,000...99,999\nList 2\nFigure 9.2 Structural sharing when\n50,000...99,999\na list of 100,000 elements is split\nTheo List 1 could be shared with one operation. I’d need to create a new version of\nlist 2, where element 75,100 is modified. It would take 50,000 operations, so it’s\none operation of sharing and one operation of copying 50,000 elements. Over-\nall, it’s 50,001 operations.\nJoe Correct. You see that by splitting our original list into two lists, we can create a\nnew version of the list with a number of operations in the order of the size of\nthe list divided by 2.\nTheo I agree, but 50,000 is still a big number.\nJoe Indeed, but nobody prevents us from applying the same trick again, splitting\nlist 1 and list 2 in two lists each.\nTheo How exactly?\nJoe We can make list 1.1 with elements 0 to 24,999, then list 1.2 with elements\n25,000 to 49,999, list 2.1 with elements 50,000 to 74,999, and list 2.2 with ele-\nments 75,000 to 99,999.\nTheo Can you draw that on the blackboard?\nJoe Sure.\n--- Page 209 ---\n9.2 The efficiency of persistent data structures 181\nNow, it’s Joe that goes to the blackboard. He draws the diagram in figure 9.3.\n«Next»\nList\nList\n«Next»\nList 1 List 2 List 2\nList 1.1 List 1.2 List 2.1 List 2.2 «Next»\n0...24,499 25,000...49,999 50,000...74,999 75,000...99,999 List 2.2\n75,000...99,999\nFigure 9.3 Structural sharing when a list of 100,000 elements is split twice\nTheo Let me count the number of operations for updating a single element. It takes\n2 operations of sharing and 1 operation of copying 25,000 elements. Overall, it\ntakes 25,002 operations to create a new version of the list.\nJoe Correct!\nTheo Let’s split the list again then!\nJoe Absolutely. In fact, we can split the list again and again until the size of the\nlists is at most 2. Can you guess what is the complexity of creating a new ver-\nsion then?\nTheo I’d say around log2 N operations.\nJoe I see that you remember well your material from school. Do you have a gut\nfeeling about what is log2 N when N is 100,000?\nTheo Let me see...2 to the power of 10 is around 1,000, and 2 to the power of 7 is\n128. So, it should be a bit less than 17.\nJoe It’s 16.6 to be precise. It means that in order to update an element in a per-\nsistent list of 100,000 elements, we need around 17 operations. The same goes\nfor accessing elements.\nTheo Nice, but 17 is still not negligible.\nJoe I agree. We can easily improve the performance of accessing elements by using\na higher branching factor in our tree.\nTheo What do you mean?\nJoe Instead of splitting by 2 at each level, we could split by 32.\nTheo But the running time of our algorithm would still grow with log N.\nJoe You’re right. From a theoretical perspective, it’s the same. From a practical\nperspective, however, it makes a big difference.\nTheo Why?\nJoe Because log32 N is 5 times lower than log2 N.\n--- Page 210 ---\n182 CHAPTER 9 Persistent data structures\nTheo That’s true: 2 to the power of 5 is 32.\nJoe Back to our list of 100,000 elements, can you tell me how many operations are\nrequired to access an element if the branching factor is 32?\nTheo With a branching factor of 2, it was 16.6. If I divide 16.6 by 5, I get 3.3.\nJoe Correct!\nTIP By using a branching factor of 32, we make elements accessed in persistent lists\nmore efficient.\nTheo Does this trick also improve the performance of updating an element in a list?\nJoe Yes, indeed, it does.\nTheo How? We’d have to copy 32 elements at each level instead of 2 elements. It’s a\n16× performance hit that’s not compensated for by the fact that the tree depth\nis reduced by 5×!\nJoe I see that you are quite sharp with numbers. There is another thing to take\ninto consideration in our practical analysis of the performance: modern CPU\narchitecture.\nTheo Interesting. The more you tell me about persistent data structures, the more I\nunderstand why you wanted to have this session at a university: it’s because\nwe’re dealing with all this academic stuff.\nJoe Yep. So, to continue, modern CPUs read and write data from and to the main\nmemory in units of cache lines, often 32 or 64 bytes long.\nTheo What difference does that make?\nJoe A nice consequence of this data access pattern is that copying an array of size\n32 is much faster than copying 16 arrays of size 2 that belong to different levels\nof the tree.\nTheo Why is that?\nJoe The reason is that copying an array of size 32 can be done in a single pair of\ncache accesses: one for read and one for write. Although for arrays that belong\nto different tree levels, each array requires its own pair of cache accesses, even\nif there are only 2 elements in the array.\nTheo In other words, the performance of updating a persistent list is dominated by\nthe depth of the tree.\nTIP In modern CPU architectures, the performance of updating a persistent list is\ndominated much more by the depth of the tree than by the number of nodes at each\nlevel of the tree.\nJoe That’s correct, up to a certain point. With today’s CPUs, using a branching fac-\ntor of 64 would, in fact, decrease the performance of update operations.\nTheo I see.\nJoe Now, I am going to make another interesting claim that is not accurate from a\ntheoretical perspective but accurate in practice.\nTheo What is it?\n--- Page 211 ---\n9.2 The efficiency of persistent data structures 183\nJoe The number of operations it takes to get or update an element in a persistent\nlist with branching factor 32 is constant.\nTheo How can that be? You just made the point that the number of operations is\nlog32 N.\nJoe Be patient, my friend. What is the highest number of elements that you can\nhave in a list, in practice?\nTheo I don’t know. I never thought about that.\nJoe Let’s assume that it takes 4 bytes to store an element in a list.\nTheo OK.\nJoe Now, can you tell me how much memory it would take to hold a list with 10 bil-\nlion elements?\nTheo You mean 1 with 10 zeros?\nJoe Yes.\nTheo Each element take 4 bytes, so it would be around 40 GB!\nJoe Correct. Do you agree that it doesn’t make sense to hold a list that takes 40 GB\nof memory?\nTheo I agree.\nJoe So let’s take 10 billion as an upper bound to the number of elements in a list.\nWhat is log32 of 10 billion?\nOnce again, Theo uses the blackboard to clarify his thoughts. With that, he quickly finds\nthe answer.\nTheo 1 billion is approximately 2^30. Therefore, 10 billion is around 2^33. That\nmeans that log2 of 10 billion is 33, so log32 of 10 billion should be around\n33/5, which is a bit less than 7.\nJoe I am impressed again by your sharpness with numbers. To be precise, log32 of\n10 billion is 6.64.\nTheo (smiling) I didn’t get that far.\nJoe Did I convince you that, in practice, accessing or updating an element in a per-\nsistent list is essentially constant?\nTheo Yes, and I find it quite amazing!\nTIP Persistent lists can be manipulated in near constant time.\nJoe Me too.\nTheo What about persistent maps?\nJoe It’s quite similar, but I don’t think we have time to discuss it now.\nStartled, Theo looks at his watch. This morning’s session has gone by so quickly. He notices\nthat it’s time to get back to the office and have lunch.\n--- Page 212 ---\n184 CHAPTER 9 Persistent data structures\n9.3 Persistent data structures libraries\nOn their way back to the office, Theo and Joe don’t talk too much. Theo’s thoughts take\nhim back to what he learned in the university classroom. He feels a lot of respect for Phil\nBagwell, who discovered how to manipulate persistent data structures efficiently, and for\nRich Hickey, who created a programming language incorporating that discovery as a core\nfeature and making it available to the world. Immediately after lunch, Theo asks Joe to\nshow him what it looks like to manipulate persistent data structures for real in a program-\nming language.\nTheo Are persistent data structures available in all programming languages?\nJoe A few programming languages like Clojure, Scala, and C# provide them as part\nof the language. In most programming languages, though, you need a third-\nparty library.\nTheo Could you give me a few references?\nJoe Sure.\nUsing Theo’s laptop, Joe bookmarks some sites. He knows exactly which URLs to look for.\nThen, while Theo is looking over the bookmarked sites, Joe goes to the whiteboard and\njots down the specific libraries in table 9.1.\n Immutable.js for JavaScript at https://immutable-js.com/\n Paguro for Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections for C# at http://mng.bz/QW51\n Pyrsistent for Python at https://github.com/tobgu/pyrsistent\n Hamster for Ruby at https://github.com/hamstergem/hamster\nTable 9.1 Persistent data structure libraries\nLanguage Library\nJavaScript Immutable.js\nJava Paguro\nC# Provided by the language\nPython Pyrsistent\nRuby Hamster\nTheo What does it take to integrate persistent data structures provided by a third-\nparty library into your code?\n9.3.1 Persistent data structures in Java\nJoe In an object-oriented language like Java, it’s quite straightforward to integrate\npersistent data structures in a program because persistent data structures\nimplement collection interfaces, besides the parts of the interface that mutate\nin place.\nTheo What do you mean?\n--- Page 213 ---\n9.3 Persistent data structures libraries 185\nJoe Take for instance, Paguro for Java. Paguro persistent maps implement the\nread-only methods of java.util.Map like get() and containsKey(), but not\nmethods like put() and remove(). On the other hand, Paguro vectors imple-\nment the read-only methods of java.util.List like get() and size(), but not\nmethods like set().\nTheo What happens when we call put() or remove() on a Paguro map?\nJoe It throws an UnSupportedOperationException exception.\nTheo What about iterating over the elements of a Paguro collection with a forEach()?\nJoe That works like it would in any Java collection. Here, let me show you an example.\nListing9.5 Iterating over a Paguro vector\nvar myVec = PersistentVector.ofIter(\nList.of(10, 2, 3));\nCreates a Paguro\nvector from a\nfor (Integer i : myVec) {\nJava list\nSystem.out.println(i);\n}\nTheo What about Java streams?\nJoe Paguro collections are Java collections, so they support the Java stream inter-\nface. Take a look at this code.\nListing9.6 Streaming a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvec1.stream().sorted().map(x -> x + 1);\nTIP Paguro collections implement the read-only parts of Java collection interfaces.\nTherefore, they can be passed to any methods that expect to receive a Java collection\nwithout mutating it.\nTheo So far, you told me how do use Paguro collections as Java read-only collections.\nHow do I make modifications to Paguro persistent data structures?\nJoe In a way similar to the _.set() function of Lodash FP that we talked about\nearlier. Instead of mutating in place, you create a new version.\nTheo What methods does Paguro expose for creating new versions of a data structure?\nJoe For vectors, you use replace(), and for maps, you use assoc().\nListing9.7 Creating a modified version of a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvar myNextVec = myVec.replace(0, 42);\n--- Page 214 ---\n186 CHAPTER 9 Persistent data structures\nListing9.8 Creating a modified version of a Paguro map\nvar myMap = PersistentHashMap.of(Map.of(\"aa\", 1, \"bb\", 2)\n.entrySet());\nCreates a Paguro map\nfrom a Java map entry set\nvar myNextMap = myMap.assoc(\"aa\", 42);\nTheo Yes! Now I see how to use persistent data structures in Java, but what about\nJavaScript?\n9.3.2 Persistent data structures in JavaScript\nJoe In a language like JavaScript, it’s a bit more cumbersome to integrate per-\nsistent data structures.\nTheo How so?\nJoe Because JavaScript objects and arrays don’t expose any interface.\nTheo Bummer.\nJoe It’s not as terrible as it sounds because Immutable.js exposes its own set of\nfunctions to manipulate its data structures.\nTheo What do you mean?\nJoe I’ll show you in a moment. But first, let me show you how to initiate Immutable.js\npersistent data structures.\nTheo OK!\nJoe Immutable.js provides a handy function that recursively converts a native data\nobject to an immutable one. It’s called Immutable.fromJS().\nTheo What do you mean by recursively?\nJoe Consider the map that holds library data from our Library Management Sys-\ntem: it has values that are themselves maps. Immutable.fromJS() converts the\nnested maps into immutable maps.\nTheo Could you show me some code?\nJoe Absolutely. Take a look at this JavaScript code for library data.\nListing9.9 Conversion to immutable data\nvar libraryData = Immutable.fromJS({\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n--- Page 215 ---\n9.3 Persistent data structures libraries 187\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n});\nTheo Do you mean that the catalog value in libraryData map is itself an immutable\nmap?\nJoe Yes, and the same for booksByIsbn, authorIds, and so forth.\nTheo Cool! So how do I access a field inside an immutable map?\nJoe As I told you, Immutable.js provides its own API for data access. For instance,\nin order to access a field inside an immutable map, you use Immutable.get()\nor Immutable.getIn() like the following.\nListing9.10 Accessing a field and a nested field in an immutable map\nImmutable.get(libraryData, \"catalog\");\nImmutable.getIn(libraryData,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nTheo How do I make a modification to a map?\nJoe Similar to what we did with Lodash FP, you use an Immutable.set() or\nImmutable.setIn() map to create a new version of the map where a field is\nmodified. Here’s how.\nListing9.11 Creating a new version of a map where a field is modified\nImmutable.setIn(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1988);\nTheo What happens when I try to access a field in the map using JavaScript’s dot or\nbracket notation?\nJoe You access the internal representation of the map instead of accessing a map\nfield.\nTheo Does that mean that we can’t pass data from Immutable.js to Lodash for data\nmanipulation?\nJoe Yes, but it’s quite easy to convert any immutable collection into a native Java-\nScript object back and forth.\nTheo How?\nJoe Immutable.js provides a toJS() method to convert an arbitrary deeply nested\nimmutable collection into a JavaScript object.\n--- Page 216 ---\n188 CHAPTER 9 Persistent data structures\nTheo But if I have a huge collection, it could take lots of time to convert it, right?\nJoe True. We need a better solution. Hopefully, Immutable.js provides its own set\nof data manipulation functions like map(), filter(), and reduce().\nTheo What if I need more data manipulation like Lodash’s _.groupBy()?\nJoe You could write your own data manipulation functions that work with the\nImmutable.js collections or use a library like mudash, which provides a port of\nLodash to Immutable.js.\n NOTE You can access the mudash library at https://github.com/brianneisler/mudash.\nTheo What would you advise?\nJoe A cup of coffee, then I’ll show you how to port functions from Lodash to\nImmutable.js and how to adapt the code from your Library Management System.\nYou can decide on whichever approach works best for your current project.\n9.4 Persistent data structures in action\nJoe Let’s start with our search query. Can you look at the current code and tell me\nthe Lodash functions that we used to implement the search query?\nTheo Including the code for the unit tests?\nJoe Of course!\n NOTE See chapter 6 for the unit test of the search query.\n9.4.1 Writing queries with persistent data structures\nTheo The Lodash functions we used were get, map, filter, and isEqual.\nJoe Here’s the port of those four functions from Lodash to Immutable.js.\nListing9.12 Porting some functions from Lodash to Immutable.js\nImmutable.map = function(coll, f) {\nreturn coll.map(f);\n};\nImmutable.filter = function(coll, f) {\nif(Immutable.isMap(coll)) {\nreturn coll.valueSeq().filter(f);\n}\nreturn coll.filter(f);\n};\nImmutable.isEqual = Immutable.is;\nTheo The code seems quite simple. But can you explain it to me, function by function?\nJoe Sure. Let’s start with get. For accessing a field in a map, Immutable.js provides\ntwo functions: get for direct fields and getIn for nested fields. It’s different\nfrom Lodash, where _.get works both on direct and nested fields.\n--- Page 217 ---\n9.4 Persistent data structures in action 189\nTheo What about map?\nJoe Immutable.js provides its own map function. The only difference is that it is a\nmethod of the collection, but it is something that we can easily adapt.\nTheo What about filter? How would you make it work both for arrays and maps\nlike Lodash’s filter?\nJoe Immutable.js provides a valueSeq method that returns the values of a map.\nTheo Cool. And what about isEqual to compare two collections?\nJoe That’s easy. Immutable.js provides a function named is that works exactly as\nisEqual.\nTheo So far, so good. What do I need to do now to make the code of the search\nquery work with Immutable.js?\nJoe You simply replace each occurrence of an _ with Immutable; _.map becomes\nImmutable.map, _.filter becomes Immutable.filter, and _.isEqual\nbecomes Immutable.isEqual.\nTheo I can’t believe it’s so easy!\nJoe Try it yourself; you’ll see. Sometimes, it’s a bit more cumbersome because\nyou need to convert the JavaScript objects to Immutable.js objects using\nImmutable.fromJS.\nTheo copies and pastes the snippets for the code and the unit tests of the search query.\nThen, he uses his IDE to replace the _ with Immutable. When Theo executes the tests and\nthey pass, he is surprised but satisfied. Joe smiles.\nListing9.13 Implementing book search with persistent data structures\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn Immutable.map(authorIds, function(authorId) {\nreturn Immutable.getIn(\ncatalogData,\n[\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = Immutable.Map({\n\"title\": Immutable.get(book, \"title\"),\n\"isbn\": Immutable.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(\ncatalogData,\nImmutable.get(book, \"authorIds\"))\n});\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = Immutable.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nvar matchingBooks = Immutable.filter(allBooks, function(book) {\n--- Page 218 ---\n190 CHAPTER 9 Persistent data structures\nreturn Immutable.get(book, \"title\").\ntoLowerCase().\nincludes(queryLowerCased);\n});\nvar bookInfos = Immutable.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nListing9.14 Testing book search with persistent data structures\nvar catalogData = Immutable.fromJS({\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n});\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Watchmen\"),\nImmutable.fromJS([bookInfo]));\n// → true\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Batman\"),\nImmutable.fromJS([]));\n// → true\n--- Page 219 ---\n9.4 Persistent data structures in action 191\n9.4.2 Writing mutations with persistent data structures\nTheo Shall we move forward and port the add member mutation?\nJoe Sure. Porting the add member mutation from Lodash to Immutable.js only\nrequires you to again replace the underscore (_) with Immutable. Let’s look at\nsome code.\nListing9.15 Implementing member addition with persistent data structures\nUserManagement.addMember = function(userManagement, member) {\nvar email = Immutable.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(Immutable.hasIn(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = Immutable.setIn(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo So, for the tests, I’d convert the JavaScript objects to Immutable.js objects with\nImmutable.fromJS(). How does this look?\nListing9.16 Testing member addition with persistent data structures\nvar jessie = Immutable.fromJS({\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n});\nvar franck = Immutable.fromJS({\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n});\nvar userManagementStateBefore = Immutable.fromJS({\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n});\nvar expectedUserManagementStateAfter = Immutable.fromJS({\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n--- Page 220 ---\n192 CHAPTER 9 Persistent data structures\n}\n}\n});\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\nImmutable.isEqual(result, expectedUserManagementStateAfter);\n// → true\nJoe Great!\n9.4.3 Serialization and deserialization\nTheo Does Immutable.js also support JSON serialization and deserialization?\nJoe It supports serialization out of the box. As for deserialization, we need to write\nour own function.\nTheo Does Immutable.js provide an Immutable.stringify() function?\nJoe That’s not necessary because the native JSON.stringify() function works\nwith Immutable.js objects. Here’s another example.\nListing9.17 JSON serialization of an Immutable.js collection\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nJSON.stringify(bookInfo);\n// → {\\\"isbn\\\":\\\"978-1779501127\\\",\\\"title\\\":\\\"Watchmen\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}\nTheo How does JSON.stringify() know how to handle an Immutable.js collection?\nJoe As an OOP developer, you shouldn’t be surprised by that.\nTheo Hmm...let me think a minute. OK, here’s my guess. Is that because JSON\n.stringify() calls some method on its argument?\nJoe Exactly! If the object passed to JSON.stringify() has a .toJSON() method,\nit’s called by JSON.stringify().\nTheo Nice. What about JSON deserialization?\nJoe That needs to be done in two steps. You first convert the JSON string to a Java-\nScript object and then to an immutable collection.\nTheo Something like this piece of code?\nListing9.18 Converting a JSON string into an immutable collection\nImmutable.parseJSON = function(jsonString) {\nreturn Immutable.fromJS(JSON.parse(jsonString));\n};\nJoe Exactly.\n--- Page 221 ---\n9.4 Persistent data structures in action 193\n9.4.4 Structural diff\nTheo So far, we have ported pieces of code that dealt with simple data manipula-\ntions. I’m curious to see how it goes with complex data manipulations such as\nthe code that computes the structural diff between two maps.\n NOTE Chapter 5 introduces structural diff.\nJoe That also works smoothly, but we need to port another eight functions.\nListing9.19 Porting Lodash functions involved in structural diff computation\nImmutable.reduce = function(coll, reducer, initialReduction) {\nreturn coll.reduce(reducer, initialReduction);\n};\nImmutable.isEmpty = function(coll) {\nreturn coll.isEmpty();\n};\nImmutable.keys = function(coll) {\nreturn coll.keySeq();\n};\nImmutable.isObject = function(coll) {\nreturn Immutable.Map.isMap(coll);\n};\nImmutable.isArray = Immutable.isIndexed;\nImmutable.union = function() {\nreturn Immutable.Set.union(arguments);\n};\nTheo Everything looks trivial with one exception: the use of arguments in Immutable\n.union.\nJoe In JavaScript, arguments is an implicit array-like object that contains the values\nof the function arguments.\nTheo I see. It’s one of those pieces of JavaScript magic!\nJoe Yep. We need to use arguments because Lodash and Immutable.js differ slightly\nin the signature of the union function. Immutable.Set.union receives an array\nof lists, whereas a Lodash _.union receives several arrays.\nTheo Makes sense. Let me give it a try.\nBlowing on his fingers like a seasoned safecracker, first one hand and then the next, Theo\nbegins typing. Once again, Theo is surprised to discover that after replacing the _ with\nImmutable in listing 9.20, the tests pass with the code in listing 9.21.\nListing9.20 Implementing structural diff with persistent data structures\nfunction diffObjects(data1, data2) {\nvar emptyObject = Immutable.isArray(data1) ?\nImmutable.fromJS([]) :\n--- Page 222 ---\n194 CHAPTER 9 Persistent data structures\nImmutable.fromJS({});\nif(data1 == data2) {\nreturn emptyObject;\n}\nvar keys = Immutable.union(Immutable.keys(data1), Immutable.keys(data2));\nreturn Immutable.reduce(keys,\nfunction (acc, k) {\nvar res = diff(Immutable.get(data1, k),\nImmutable.get(data2, k));\nif((Immutable.isObject(res) && Immutable.isEmpty(res)) ||\n(res == \"data-diff:no-diff\")) {\nreturn acc;\n}\nreturn Immutable.set(acc, k, res);\n},\nemptyObject);\n}\nfunction diff(data1, data2) {\nif(Immutable.isObject(data1) && Immutable.isObject(data2)) {\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"data-diff:no-diff\";\n}\nListing9.21 Testing structural diff with persistent data structures\nvar data1 = Immutable.fromJS({\ng: {\nc: 3\n},\nx: 2,\ny: {\nz: 1\n},\nw: [5]\n});\nvar data2 = Immutable.fromJS({\ng: {\nc:3\n},\nx: 2,\ny: {\nz: 2\n},\nw: [4]\n});\nImmutable.isEqual(diff(data1, data2),\nImmutable.fromJS({\n--- Page 223 ---\nSummary 195\n\"w\": [\n4\n],\n\"y\": {\n\"z\": 2\n}\n}));\nJoe What do you think of all this, my friend?\nTheo I think that using persistent data collections with a library like Immutable.js is\nmuch easier than understanding the internals of persistent data structures. But\nI’m also glad that I know how it works under the hood.\nAfter accompanying Joe to the office door, Theo meets Dave. Dave had been peering\nthrough the window in Theo’s office, looking at the whiteboard, anxious to catch a glimpse\nof today’s topic on DOP.\nDave What did Joe teach you today?\nTheo He took me to the university and taught me the foundations of persistent data\nstructures for dealing with immutability at scale.\nDave What’s wrong with the structural sharing that I implemented a couple of\nmonths ago?\nTheo When the number of elements in the collection is big enough, naive structural\nsharing has performance issues.\nDave I see. Could you tell me more about that?\nTheo I’d love to, but my brain isn’t functioning properly after this interesting but\nexhausting day. We’ll do it soon, promise.\nDave No worries. Have a nice evening, Theo.\nTheo You too, Dave.\nSummary\n It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\n At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\n Naive structural sharing doesn’t prevent data structures from being accidentally\nmutated.\n Immutable collections are not the same as persistent data structures.\n Immutable collections don’t provide an efficient way to create new versions of\nthe collections.\n Persistent data structures protect data from mutation.\n Persistent data structures provide an efficient way to create new versions of the\ncollections.\n Persistent data structures always preserve the previous version of themselves when\nthey are modified.\n--- Page 224 ---\n196 CHAPTER 9 Persistent data structures\n Persistent data structures represent data internally in such a way that structural\nsharing scales well, both in terms of memory and computation.\n When data is immutable, it is safe to share it.\n Internally, persistence uses a branching factor of 32.\n In practice, manipulation of persistent data structures is efficient even for col-\nlections with 10 billion entries!\n Due to modern architecture considerations, the performance of updating a\npersistent list is dominated much more by the depth of the tree than by the\nnumber of nodes at each level of the tree.\n Persistent lists can be manipulated in near constant time.\n In most languages, third-party libraries provide an implementation of persistent\ndata structures.\n Paguro collections implement the read-only parts of Java collection interfaces.\n Paguro collections can be passed to any methods that expect to receive a Java\ncollection without mutating them.\n--- Page 225 ---\nDatabase operations\nA cloud is a cloud\nThis chapter covers\n Fetching data from the database\n Storing data in the database\n Manipulating data fetched from the database\nTraditionally in OOP, we use design patterns and complex layers of objects to struc-\nture access to the database. In DOP, we prefer to represent data fetched from the\ndatabase with generic data collections, namely, lists of maps, where fields in the\nmaps correspond to database column values. As we’ll see throughout the chapter,\nthe fact that fields inside a map are accessible dynamically via their names allows us\nto use the same generic code for different data entities.\nTIP The best way to manipulate data is to represent data as data.\nIn this chapter, we’ll illustrate the application of data-oriented principles when\naccessing data from a relational database. Basic knowledge of relational database\nand SQL query syntax (like SELECT, AS, WHERE, and INNER JOIN) is assumed. This\napproach can be easily adapted to NoSQL databases.\n197\n--- Page 226 ---\n198 CHAPTER 10 Database operations\nApplications that run on the server usually store data in a database. In DOP, we\nrepresent data retrieved from the database the same way we represent any other data\nin our application—with generic data collections. This leads to\n Reduced system complexity.\n Increased genericity.\n10.1 Fetching data from the database\nTheo and Joe go for a walk in a park near the office. They sit on a bench close to a beau-\ntiful lake and gaze at the clouds in the sky. After a couple of minutes of meditative\nsilence, Joe asks Theo, “What do you see?” Theo tells him that this cloud looks to him\nlike a horse, and that one looks like a car. On their way back to the office, Theo asks Joe\nfor an explanation about the clouds. Joe answers with a mysterious smile on his lips, “A\ncloud is a cloud.”\nTheo So far you’ve shown me how DOP represents data that lives in the memory of\nthe application. What about data that comes from the outside?\nJoe What do you mean by outside?\nTheo Data that comes from the database.\nJoe I’ll return the question to you. How do you think that we should represent data\nthat comes from the database in DOP?\nTheo As generic data collections, I guess.\nJoe Exactly! In DOP, we always represent data with generic data collections.\nTheo Does that mean that we can manipulate data from the database with the same\nflexibility as we manipulate in-memory data?\nJoe Definitely.\nTIP In DOP, we represent data from the database with generic data collections, and\nwe manipulate it with generic functions.\nTheo Would you show me how to retrieve book search results when the catalog data\nis stored in an SQL database?\nJoe I’ll show you in a moment. First, tell me how you would design the tables that\nstore catalog data.\nTheo Do you mean the exact table schemas with the information about primary keys\nand nullability of each and every column?\nJoe No, I only need a rough overview of the tables, their columns, and the relation-\nships between the tables.\nTheo goes to the whiteboard. Figure 10.1 shows the diagram he draws as he explains his\nthinking to Joe.\n--- Page 227 ---\n10.1 Fetching data from the database 199\nT books\nT authors\nisbn VARCHAR[32]\nid VARCHAR[64]\ntitle VARCHAR[64]\nname VARCHAR[64]\npublication_year INTEGER\n1\nA book 1 An author\nmay have may author\nmany authors. many books.\n* *\nbook_authors\nT (relationships of books and authors)\nbook_isbn VARCHAR[32] Figure 10.1 The database model\nauthor_id VARCHAR[64]\nfor books and authors\nTheo I have a books table with three columns: title, isbn, and publication_\nyear. I also have an authors table with two columns: for id and name. Here,\nlet me draw these tables on the whiteboard to give you a visual (see tables 10.1\nand 10.2).\nTable 10.1 The books table filled with two books\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nTable 10.2 The authors table filled with three authors\nid name\nsean-covey Sean Covey\nstephen-covey Stephen Covey\ncharles-duhigg Charles Duhigg\nJoe What about the connection between books and authors?\nTheo Let’s see, a book could be written by multiple authors, and an author could write\nmultiple books. Therefore, I need a many-to-many book_authors table that con-\nnects authors and books with two columns, book_isbn and author_id.\nTheo once again turns to the whiteboard. He pens the book_authors table 10.3 to show Joe.\nTable 10.3 The book_authors table with rows connecting books with their authors\nbook_isbn author_id\n978-1982137274 sean-covey\n978-1982137274 stephen-covey\n978-0812981605 charles-duhigg\n--- Page 228 ---\n200 CHAPTER 10 Database operations\nJoe Great! Let’s start with the simplest case. We’re going to write code that searches\nfor books matching a title and that returns basic information about the books.\nBy basic information, I mean title, ISBN, and publication year.\nTheo What about the book authors?\nJoe We’ll deal with that later, as it’s a bit more complicated. Can you write an SQL\nquery for retrieving books that contain he word habit in their title?\nTheo Sure.\nThis assignment is quite easy for Theo. First, he jots down the SQL query, then he displays\nthe results in table 10.4.\nListing10.1 SQL query to retrieve books whose title contains habit\nSELECT\ntitle,\nisbn,\npublication_year\nFROM\nbooks\nWHERE title LIKE '%habit%';\nTable 10.4 Results of the SQL query for books whose title contains the word habit\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nJoe How would you describe these results as a data collection?\nTheo I would say it’s a list of maps.\nTIP In DOP, accessing data from a NoSQL database is similar to the way we access\ndata from a relational database.\nJoe Right! Now, can you write the search results as a list of maps?\nTheo It doesn’t sound too complicated. How about this?\nListing10.2 Search results as a list of maps\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"publication_year\": 1989\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"publication_year\": 2012\n}\n]\n--- Page 229 ---\n10.1 Fetching data from the database 201\nJoe What about the JSON schema for the search results?\nTheo It shouldn’t be too difficult if you allow me to take a look at the JSON schema\ncheat sheet you kindly offered me the other day.\nJoe Of course. The purpose of a gift is to be used by the one who receives it.\nTheo takes a look at the JSON Schema cheat sheet to refresh his memory about the JSON\nSchema syntax. After a few minutes, Theo comes up with a schema for the search results.\nHe certainly is putting Joe’s gift to good use.\nListing10.3 JSON schema cheat sheet\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"myNumber\": {\"type\": \"number\"},\n\"myString\": {\"type\": \"string\"},\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\n\"myBool\": {\"type\": \"boolean\"}\n},\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\n}\n}\nListing10.4 The JSON schema for search results from the database\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"publication_year\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"publication_year\": {\"type\": \"integer\"}\n}\n}\n};\nJoe Excellent. Now I’m going to show you how to implement searchBooks in a\nway that fetches data from the database and returns a JSON string with the\nresults. The cool thing is that we’re only going to use generic data collections\nfrom the database layer down to the JSON serialization.\nTheo Will it be similar to the implementation of searchBooks that we wrote when\nyou taught me the basis of DOP?\nJoe Absolutely. The only difference is that then the state of the system was stored\nlocally, and we queried it with a function like _.filter. Now, we use SQL\n--- Page 230 ---\n202 CHAPTER 10 Database operations\nqueries to fetch the state from the database. In terms of data representation\nand manipulation, it’s exactly the same.\nJoe goes to the whiteboard and sketches out the data flow in figure 10.2. Theo studies the\ndiagram.\nDatabase\nDatabase driver\nData (list of maps)\nData manipulation\nData Figure 10.2 Data flow for serving\na request that fetches data from\nJSON serialize\nthe database\nJoe The data manipulation step in the diagram is implemented via generic func-\ntions that manipulate data collections. As our examples get more elaborate, I\nthink you’ll see the benefits of being able to manipulate data collections with\ngeneric functions.\nTheo Sounds intriguing...\nJoe For the communication with the database, we use a driver that returns a list of\nmaps. In JavaScript, you could use an SQL driver like node-postgres.\n NOTE See https://node-postgres.com for more information about this collection of\nnode.js modules for interfacing with PostgreSQL databases.\nTheo And in Java?\nJoe In Java, you could use JDBC (Java database connectivity) in addition to a small\nutility function that converts a JDBC result set into a list of maps. If I can use\nyour laptop, I’ll show you what I mean.\nJoe pulls a piece of code from one of his personal GitHub repositories. He then shows the\ncode for the JDBC conversion to Theo, who seems a bit surprised.\nListing10.5 Converting a JDBC result set into a list of hash maps\nList<Map<String, Object>> convertJDBCResultSetToListOfMaps(ResultSet rs) {\nList<Map<String, Object>> listOfMaps =\nnew ArrayList<Map<String, Object>>();\nResultSetMetaData meta = rs.getMetaData();\nwhile (rs.next()) {\nMap map = new HashMap();\nfor (int i = 1; i <= meta.getColumnCount(); i++) {\nString key = meta.getColumnLabel(i);\nObject value = rs.getObject(i);\n--- Page 231 ---\n10.1 Fetching data from the database 203\nmap.put(key, value);\n}\nlistOfMaps.add(map);\n}\nreturn listOfMaps;\n}\nTIP Converting a JDBC result set into a list of hash maps is quite straightforward.\nTheo I expected it to be much more complicated to convert a JDBC result set into a\nlist of hash maps.\nJoe It’s straightforward because, in a sense, JDBC is data-oriented.\nTheo What about the field types?\nJoe When we convert a JDBC result set into a list of maps, each value is considered\nan Object.\nTheo That’s annoying because it means that in order to access the value, we need to\ncast it to its type.\nJoe Yes and no. Look at our book search use case. We pass all the values along with-\nout really looking at their type. The concrete value type only matters when we\nserialize the result into JSON and that’s handled by the JSON serialization\nlibrary. It’s called late binding.\n NOTE With late binding, we defer dealing with data types as long as possible.\nTheo Does that mean in my application that I’m allowed to manipulate data without\ndealing with concrete types?\nTIP In DOP, flexibility is increased as many parts of the system are free to manipulate\ndata without dealing with concrete types.\nJoe Exactly. You’ll see late binding in action in a moment. That’s one of the great-\nest benefits of DOP.\nTheo Interesting, I can’t wait to see that!\nJoe One last thing before I show you the code for retrieving search results from the\ndatabase. In order to make it easier to read, I’m going to write JavaScript code\nas if JavaScript were dealing with I/O is a synchronous way.\nTheo What do you mean?\nJoe In JavaScript, an I/O operation like sending a query to the database is done\nasynchronously. In real life, it means using either callback functions or using\nasync and await keywords.\nTheo Oh yeah, that’s because JavaScript is single-threaded.\n NOTE For sake of simplicity, the JavaScript snippets in this chapter are written as if\nJavaScript were dealing with I/O in a synchronous way. In real-life JavaScript, we need\nto use async and await around I/O calls.\nJoe Indeed, so I’ll be writing the code that communicates with the database as\nthough JavaScript were dealing with I/O synchronously. Here’s an example.\n--- Page 232 ---\n204 CHAPTER 10 Database operations\nListing10.6 Searching books in the database, returning the results in JSON\ndbClient holds the Initializes Ajv (a JSON schema validation\nvar dbClient; DB connection. library) with allErrors: true to catch all\nthe data validation errors\nvar ajv = new Ajv({allErrors: true});\nvar title = \"habit\";\nvar matchingBooksQuery = `SELECT title, isbn Uses a parameterized\nSQL query as a security\nFROM books\nbest practice\nWHERE title LIKE '%$1%'`;\nvar books = dbClient.query(matchingBooksQuery,\nPasses the parameters to the SQL\n[title]);\nquery as a list of values (in our\nif(!ajv.validate(dbSearchResultSchema, books)) {\ncase, a list with a single value)\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" + errors;\n}\nJSON.stringify(books);\nTheo In a dynamically-typed language like JavaScript, I understand that the types of\nthe values in the list of maps returned by dbClient.query are determined at\nrun time. How does it work in a statically-typed language like Java, and what are\nthe types of the data fields in books?\nJoe The function convertJDBCResultSetToListOfMaps we created earlier (see\nlisting 10.5) returns a list of Map<String, Object>. But JSON serialization\nlibraries like Gson know how to detect at run time the concrete type of the val-\nues in a map and serialize the values according to their type.\n NOTE See https://github.com/google/gson for information about Gson’s Java\nserialization/deserialization library.\nTheo What do you mean by serializing a value according to its type?\nJoe For instance, the value of the field publication_year is a number; therefore,\nit is not wrapped with quotes. However, the value of the field title is a string;\ntherefore, it is wrapped with quotes.\nTheo Nice! Now, I understand what you mean by late binding.\nJoe Cool! Now, let me show you how we store data in the database.\n10.2 Storing data in the database\nIn the previous section, we saw how to retrieve data from the database as a list of maps.\nNext, we’ll see how to store data in the database when data is represented with a map.\nTheo I guess that storing data in the database is quite similar to fetching data from\nthe database.\nJoe It’s similar in the sense that we deal only with generic data collections. Can you\nwrite a parameterized SQL query that inserts a row with user info using only\nemail and encrypted_password, please?\nTheo OK.",
        "sections_found": []
      },
      "accurate_page_range": "202-232"
    },
    {
      "text": "- 8.1 The complexity of locks",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "8 Advanced concurrency control",
      "raw_line": "- 8.1 The complexity of locks (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 65,
      "chapter_info": {
        "page": 202,
        "title": "Advanced concurrency control",
        "pattern_matched": "Chapter 8",
        "text_preview": "174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do yo"
      },
      "chapter_sections": {
        "start_page": 202,
        "end_page": 232,
        "content": "\n--- Page 202 ---\n174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do you mean?\nTheo I don’t know, but I am under the impression that mutexes are like phone calls,\nand atoms are like text messages.\nJoe smiles at Theo but doesn’t reveal the meaning of his smile. After the phone deadlock\nyesterday, Theo’s pretty sure that he and Joe are on the same page.\nSummary\n Managing concurrency with atoms is much simpler than managing concur-\nrency with locks because we don’t have to deal with the risk of deadlocks.\n Cloning data to avoid read locks doesn’t scale.\n When data is immutable, reads are always safe.\n Atoms provide a way to manage concurrency without locks.\n With atoms, deadlocks never happen.\n Using atoms for a thread-safe counter is trivial because the state of the counter\nis represented with a primitive type (an integer).\n We can manage composite data in a thread-safe way with atoms.\n We make the highly scalable state management approach from part 1 thread-\nsafe by keeping the whole system state inside an atom.\n It’s quite common to represent an in-memory cache as a string map.\n When data is immutable, it is safe (and fast) to compare by reference.\n In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing besides swapping an atom.\n In practice, once an atom is swapped, the threads do some real work (e.g.,\ndatabase access) to provide an opportunity for other threads to swap the atom\nsuccessfully.\n--- Page 203 ---\nPersistent data structures\nStanding on the shoulders of giants\nThis chapter covers\n The internal details of persistent data\nstructures\n The time and memory efficiency of persistent\ndata structures\n Using persistent data structures in an\napplication\nIn part 1, we illustrated how to manage the state of a system without mutating data,\nwhere immutability is maintained by constraining ourselves to manipulate the state\nonly with immutable functions using structural sharing. In this chapter, we present\na safer and more scalable way to preserve data immutability—representing data\nwith so-called persistent data structures. Efficient implementations of persistent\ndata structures exist for most programming languages via third-party libraries.\n9.1 The need for persistent data structures\nIt’s at the university where Theo meets Joe this time. When Theo asks Joe if today’s topic\nis academic in nature, Joe tells him that the use of persistent data structures only\nbecame possible in programming languages following a discovery in 2001 by a computer\n175\n--- Page 204 ---\n176 CHAPTER 9 Persistent data structures\nresearcher named Phil Bagwell.1 In 2007, Rich Hickey, the creator of Clojure, used this dis-\ncovery as the foundation of persistent data structures in Clojure. Unveiling the secrets of\nthese data structures to Theo in a university classroom is a way for Joe to honor the mem-\nory of Phil Bagwell, who unfortunately passed away in 2012. When they get to the univer-\nsity classroom, Joe starts the conversation with a question.\nJoe Are you getting used to DOP’s prohibition against mutating data in place and\ncreating new versions instead?\nTheo I think so, but two things bother me about the idea of structural sharing that\nyou showed me.\nJoe What bothers you, my friend?\nTheo Safety and performance.\nJoe What do you mean by safety?\nTheo I mean that using immutable functions to manipulate data doesn’t prevent it\nfrom being modified accidentally.\nJoe Right! Would you like me to show you the naive way to handle immutability or\nthe real way?\nTheo What are the pros and cons of each way?\nJoe The naive way is easy but not efficient, although the real way is efficient but\nnot easy.\nTheo Let’s start with the naive way then.\nJoe Each programming language provides its own way to protect data from being\nmutated.\nTheo How would I do that in Java, for instance?\nJoe Java provides immutable collections, and there is a way to convert a list or a\nmap to an immutable list or an immutable map.\n NOTE Immutable collections are not the same as persistent data structures.\nJoe opens his laptop and fires it up. He brings up two code examples, one for immutable\nlists and one for immutable maps.\nListing9.1 Converting a mutable list to an immutable list in Java\nvar myList = new ArrayList<Integer>();\nmyList.add(1);\nmyList.add(2);\nmyList.add(3);\nvar myImmutableList = List.of(myList.toArray());\n1 P. Bagwell, “Ideal hash trees” (No. REP_WORK), 2001. [Online]. Available: https://lampwww.epfl.ch/papers/\nidealhashtrees.pdf.\n--- Page 205 ---\n9.1 The need for persistent data structures 177\nListing9.2 Converting a mutable map to an immutable map in Java\nvar myMap = new HashMap<String, Object>();\nmyMap.put(\"name\", \"Isaac\");\nmyMap.put(\"age\", 42);\nvar myImmutableMap = Collections.unmodifiableMap(myMap);\nTheo What happens when you try to modify an immutable collection?\nJoe Java throws an UnsupportedOperationException.\nTheo And in JavaScript?\nJoe JavaScript provides an Object.freeze() function that prevents data from\nbeing mutated. It works both with JavaScript arrays and objects.\nJoe takes a minute to scroll through his laptop. When he finds what he’s looking for, he\nshows Theo the code.\nListing9.3 Making an object immutable in JavaScript\nvar a = [1, 2, 3];\nObject.freeze(a);\nvar b = {foo: 1};\nObject.freeze(b);\nTheo What happens when you try to modify a frozen object?\nJoe It depends. In JavaScript strict mode, a TypeError exception is thrown, and in\nnonstrict mode, it fails silently.\n NOTE JavaScript’s strict mode is a way to opt in to a restricted variant of JavaScript\nthat changes some silent errors to throw errors.\nTheo In case of a nested collection, are the nested collections also frozen?\nJoe No, but in JavaScript, one can write a deepFreeze() function that freezes an\nobject recursively. Here’s another example.\nListing9.4 Freezing an object recursively in JavaScript\nfunction deepFreeze(object) {\n// Retrieve the property names defined on object\nconst propNames = Object.getOwnPropertyNames(object);\n// Freeze properties before freezing self\nfor (const name of propNames) {\nconst value = object[name];\nif (value && typeof value === \"object\") {\ndeepFreeze(value);\n}\n}\n--- Page 206 ---\n178 CHAPTER 9 Persistent data structures\nreturn Object.freeze(object);\n}\nTheo I see that it’s possible to ensure that data is never mutated, which answers my\nconcerns about safety. Now, let me share my concerns about performance.\nTIP It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\nJoe Sure.\nTheo If I understand correctly, the main idea behind structural sharing is that most\ndata is usually shared between two versions.\nJoe Correct.\nTheo This insight allows us to create new versions of our collections using a shallow\ncopy instead of a deep copy, and you claimed that it was efficient.\nJoe Exactly!\nTheo Now, here is my concern. In the case of a collection with many entries, a shal-\nlow copy might be expensive.\nJoe Could you give me an example of a collection with many entries?\nTheo A catalog with 100,000 books, for instance.\nJoe On my machine, making a shallow copy of a collection with 100,000 entries\ndoesn’t take more than 50 milliseconds.\nTheo Sometimes, even 50 milliseconds per update isn’t acceptable.\nJoe I totally agree with you. When one needs data immutability at scale, naive struc-\ntural sharing is not appropriate.\nTheo Also, shallow copying an array of 100,000 elements on each update would\nincrease the program memory by 100 KB.\nJoe Indeed, at scale, we have a problem both with memory and computation.\nTIP At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\nTheo Is there a better solution?\nJoe Yes! For that, you’ll need to learn the real way to handle immutability. It’s\ncalled persistent data structures.\n9.2 The efficiency of persistent data structures\nTheo In what sense are those data structures persistent?\nJoe Persistent data structures are so named because they always preserve their pre-\nvious versions.\nTIP Persistent data structures always preserve the previous version of themselves\nwhen they are modified.\nJoe Persistent data structures address the two main limitations of naive structural\nsharing: safety and performance.\n--- Page 207 ---\n9.2 The efficiency of persistent data structures 179\nTheo Let’s start with safety. How do persistent data structures prevent data from\nbeing mutated accidentally?\nJoe In a language like Java, they implement the mutation methods of the collec-\ntion interfaces by throwing the run-time exception UnsupportedOperation-\nException.\nTheo And, in a language like JavaScript?\nJoe In JavaScript, persistent data structures provide their own methods to access\ndata, and none of those methods mutate data.\nTheo Does that mean that we can’t use the dot notation to access fields?\nJoe Correct. Fields of persistent data structures are accessed via a specific API.\nTheo What about efficiency? How do persistent data structures make it possible to\ncreate a new version of a huge collection in an efficient way?\nJoe Persistent data structures organize data in such a way that we can use structural\nsharing at the level of the data structure.\nTheo Could you explain?\nJoe Certainly. Let’s start with the simplest data structure: a linked list. Imagine that\nyou have a linked list with 100,000 elements.\nTheo OK.\nJoe What would it take to prepend an element to the head of the list?\nTheo You mean to create a new version of the list with an additional element?\nJoe Exactly!\nTheo Well, we could copy the list and then prepend an element to the list, but it\nwould be quite expensive.\nJoe What if I tell you that the original linked list is guaranteed to be immutable?\nTheo In that case, I could create a new list with a new head that points to the head of\nthe original list.\nTheo goes to the classroom blackboard. He picks up a piece of chalk and draws the dia-\ngram shown in figure 9.1.\nNew list Original list\nFigure 9.1 Structural sharing\n0 1 2 3 4 5 with linked lists\nJoe Would the efficiency of this operation depend on the size of the list?\nTheo No, it would be efficient, no matter the size of the list.\nJoe That’s what I mean by structural sharing at the level of the data structure itself.\nIt relies on a simple but powerful insight—when data is immutable, it is safe to\nshare it.\nTIP When data is immutable, it is safe to share it.\n--- Page 208 ---\n180 CHAPTER 9 Persistent data structures\nTheo I understand how to use structural sharing at the level of the data structure for\nlinked lists and prepend operations, but how would it work with operations\nlike appending or modifying an element in a list?\nJoe For that purpose, we need to be smarter and represent our list as a tree.\nTheo How does that help?\nJoe It helps because when a list is represented as a tree, most of the nodes in the\ntree can be shared between two versions of the list.\nTheo I am totally confused.\nJoe Imagine that you take a list with 100,000 elements and split it into two lists of\n50,000 elements each: elements 0 to 49,999 in list 1, and elements 50,000 to\n99,999 in list 2. How many operations would you need to create a new version\nof the list where a single element—let’s say, element at index 75,100—is\nmodified?\nIt’s hard for Theo to visualize this kind of stuff mentally. He goes back to the blackboard\nand draws a diagram (see figure 9.2). Once Theo looks at the diagram, it’s easy for him to\nanswer Joe’s question.\nList «Next»\nList\nList 1 List 2\n«Next»\n0...49,999 50,000...99,999\nList 2\nFigure 9.2 Structural sharing when\n50,000...99,999\na list of 100,000 elements is split\nTheo List 1 could be shared with one operation. I’d need to create a new version of\nlist 2, where element 75,100 is modified. It would take 50,000 operations, so it’s\none operation of sharing and one operation of copying 50,000 elements. Over-\nall, it’s 50,001 operations.\nJoe Correct. You see that by splitting our original list into two lists, we can create a\nnew version of the list with a number of operations in the order of the size of\nthe list divided by 2.\nTheo I agree, but 50,000 is still a big number.\nJoe Indeed, but nobody prevents us from applying the same trick again, splitting\nlist 1 and list 2 in two lists each.\nTheo How exactly?\nJoe We can make list 1.1 with elements 0 to 24,999, then list 1.2 with elements\n25,000 to 49,999, list 2.1 with elements 50,000 to 74,999, and list 2.2 with ele-\nments 75,000 to 99,999.\nTheo Can you draw that on the blackboard?\nJoe Sure.\n--- Page 209 ---\n9.2 The efficiency of persistent data structures 181\nNow, it’s Joe that goes to the blackboard. He draws the diagram in figure 9.3.\n«Next»\nList\nList\n«Next»\nList 1 List 2 List 2\nList 1.1 List 1.2 List 2.1 List 2.2 «Next»\n0...24,499 25,000...49,999 50,000...74,999 75,000...99,999 List 2.2\n75,000...99,999\nFigure 9.3 Structural sharing when a list of 100,000 elements is split twice\nTheo Let me count the number of operations for updating a single element. It takes\n2 operations of sharing and 1 operation of copying 25,000 elements. Overall, it\ntakes 25,002 operations to create a new version of the list.\nJoe Correct!\nTheo Let’s split the list again then!\nJoe Absolutely. In fact, we can split the list again and again until the size of the\nlists is at most 2. Can you guess what is the complexity of creating a new ver-\nsion then?\nTheo I’d say around log2 N operations.\nJoe I see that you remember well your material from school. Do you have a gut\nfeeling about what is log2 N when N is 100,000?\nTheo Let me see...2 to the power of 10 is around 1,000, and 2 to the power of 7 is\n128. So, it should be a bit less than 17.\nJoe It’s 16.6 to be precise. It means that in order to update an element in a per-\nsistent list of 100,000 elements, we need around 17 operations. The same goes\nfor accessing elements.\nTheo Nice, but 17 is still not negligible.\nJoe I agree. We can easily improve the performance of accessing elements by using\na higher branching factor in our tree.\nTheo What do you mean?\nJoe Instead of splitting by 2 at each level, we could split by 32.\nTheo But the running time of our algorithm would still grow with log N.\nJoe You’re right. From a theoretical perspective, it’s the same. From a practical\nperspective, however, it makes a big difference.\nTheo Why?\nJoe Because log32 N is 5 times lower than log2 N.\n--- Page 210 ---\n182 CHAPTER 9 Persistent data structures\nTheo That’s true: 2 to the power of 5 is 32.\nJoe Back to our list of 100,000 elements, can you tell me how many operations are\nrequired to access an element if the branching factor is 32?\nTheo With a branching factor of 2, it was 16.6. If I divide 16.6 by 5, I get 3.3.\nJoe Correct!\nTIP By using a branching factor of 32, we make elements accessed in persistent lists\nmore efficient.\nTheo Does this trick also improve the performance of updating an element in a list?\nJoe Yes, indeed, it does.\nTheo How? We’d have to copy 32 elements at each level instead of 2 elements. It’s a\n16× performance hit that’s not compensated for by the fact that the tree depth\nis reduced by 5×!\nJoe I see that you are quite sharp with numbers. There is another thing to take\ninto consideration in our practical analysis of the performance: modern CPU\narchitecture.\nTheo Interesting. The more you tell me about persistent data structures, the more I\nunderstand why you wanted to have this session at a university: it’s because\nwe’re dealing with all this academic stuff.\nJoe Yep. So, to continue, modern CPUs read and write data from and to the main\nmemory in units of cache lines, often 32 or 64 bytes long.\nTheo What difference does that make?\nJoe A nice consequence of this data access pattern is that copying an array of size\n32 is much faster than copying 16 arrays of size 2 that belong to different levels\nof the tree.\nTheo Why is that?\nJoe The reason is that copying an array of size 32 can be done in a single pair of\ncache accesses: one for read and one for write. Although for arrays that belong\nto different tree levels, each array requires its own pair of cache accesses, even\nif there are only 2 elements in the array.\nTheo In other words, the performance of updating a persistent list is dominated by\nthe depth of the tree.\nTIP In modern CPU architectures, the performance of updating a persistent list is\ndominated much more by the depth of the tree than by the number of nodes at each\nlevel of the tree.\nJoe That’s correct, up to a certain point. With today’s CPUs, using a branching fac-\ntor of 64 would, in fact, decrease the performance of update operations.\nTheo I see.\nJoe Now, I am going to make another interesting claim that is not accurate from a\ntheoretical perspective but accurate in practice.\nTheo What is it?\n--- Page 211 ---\n9.2 The efficiency of persistent data structures 183\nJoe The number of operations it takes to get or update an element in a persistent\nlist with branching factor 32 is constant.\nTheo How can that be? You just made the point that the number of operations is\nlog32 N.\nJoe Be patient, my friend. What is the highest number of elements that you can\nhave in a list, in practice?\nTheo I don’t know. I never thought about that.\nJoe Let’s assume that it takes 4 bytes to store an element in a list.\nTheo OK.\nJoe Now, can you tell me how much memory it would take to hold a list with 10 bil-\nlion elements?\nTheo You mean 1 with 10 zeros?\nJoe Yes.\nTheo Each element take 4 bytes, so it would be around 40 GB!\nJoe Correct. Do you agree that it doesn’t make sense to hold a list that takes 40 GB\nof memory?\nTheo I agree.\nJoe So let’s take 10 billion as an upper bound to the number of elements in a list.\nWhat is log32 of 10 billion?\nOnce again, Theo uses the blackboard to clarify his thoughts. With that, he quickly finds\nthe answer.\nTheo 1 billion is approximately 2^30. Therefore, 10 billion is around 2^33. That\nmeans that log2 of 10 billion is 33, so log32 of 10 billion should be around\n33/5, which is a bit less than 7.\nJoe I am impressed again by your sharpness with numbers. To be precise, log32 of\n10 billion is 6.64.\nTheo (smiling) I didn’t get that far.\nJoe Did I convince you that, in practice, accessing or updating an element in a per-\nsistent list is essentially constant?\nTheo Yes, and I find it quite amazing!\nTIP Persistent lists can be manipulated in near constant time.\nJoe Me too.\nTheo What about persistent maps?\nJoe It’s quite similar, but I don’t think we have time to discuss it now.\nStartled, Theo looks at his watch. This morning’s session has gone by so quickly. He notices\nthat it’s time to get back to the office and have lunch.\n--- Page 212 ---\n184 CHAPTER 9 Persistent data structures\n9.3 Persistent data structures libraries\nOn their way back to the office, Theo and Joe don’t talk too much. Theo’s thoughts take\nhim back to what he learned in the university classroom. He feels a lot of respect for Phil\nBagwell, who discovered how to manipulate persistent data structures efficiently, and for\nRich Hickey, who created a programming language incorporating that discovery as a core\nfeature and making it available to the world. Immediately after lunch, Theo asks Joe to\nshow him what it looks like to manipulate persistent data structures for real in a program-\nming language.\nTheo Are persistent data structures available in all programming languages?\nJoe A few programming languages like Clojure, Scala, and C# provide them as part\nof the language. In most programming languages, though, you need a third-\nparty library.\nTheo Could you give me a few references?\nJoe Sure.\nUsing Theo’s laptop, Joe bookmarks some sites. He knows exactly which URLs to look for.\nThen, while Theo is looking over the bookmarked sites, Joe goes to the whiteboard and\njots down the specific libraries in table 9.1.\n Immutable.js for JavaScript at https://immutable-js.com/\n Paguro for Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections for C# at http://mng.bz/QW51\n Pyrsistent for Python at https://github.com/tobgu/pyrsistent\n Hamster for Ruby at https://github.com/hamstergem/hamster\nTable 9.1 Persistent data structure libraries\nLanguage Library\nJavaScript Immutable.js\nJava Paguro\nC# Provided by the language\nPython Pyrsistent\nRuby Hamster\nTheo What does it take to integrate persistent data structures provided by a third-\nparty library into your code?\n9.3.1 Persistent data structures in Java\nJoe In an object-oriented language like Java, it’s quite straightforward to integrate\npersistent data structures in a program because persistent data structures\nimplement collection interfaces, besides the parts of the interface that mutate\nin place.\nTheo What do you mean?\n--- Page 213 ---\n9.3 Persistent data structures libraries 185\nJoe Take for instance, Paguro for Java. Paguro persistent maps implement the\nread-only methods of java.util.Map like get() and containsKey(), but not\nmethods like put() and remove(). On the other hand, Paguro vectors imple-\nment the read-only methods of java.util.List like get() and size(), but not\nmethods like set().\nTheo What happens when we call put() or remove() on a Paguro map?\nJoe It throws an UnSupportedOperationException exception.\nTheo What about iterating over the elements of a Paguro collection with a forEach()?\nJoe That works like it would in any Java collection. Here, let me show you an example.\nListing9.5 Iterating over a Paguro vector\nvar myVec = PersistentVector.ofIter(\nList.of(10, 2, 3));\nCreates a Paguro\nvector from a\nfor (Integer i : myVec) {\nJava list\nSystem.out.println(i);\n}\nTheo What about Java streams?\nJoe Paguro collections are Java collections, so they support the Java stream inter-\nface. Take a look at this code.\nListing9.6 Streaming a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvec1.stream().sorted().map(x -> x + 1);\nTIP Paguro collections implement the read-only parts of Java collection interfaces.\nTherefore, they can be passed to any methods that expect to receive a Java collection\nwithout mutating it.\nTheo So far, you told me how do use Paguro collections as Java read-only collections.\nHow do I make modifications to Paguro persistent data structures?\nJoe In a way similar to the _.set() function of Lodash FP that we talked about\nearlier. Instead of mutating in place, you create a new version.\nTheo What methods does Paguro expose for creating new versions of a data structure?\nJoe For vectors, you use replace(), and for maps, you use assoc().\nListing9.7 Creating a modified version of a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvar myNextVec = myVec.replace(0, 42);\n--- Page 214 ---\n186 CHAPTER 9 Persistent data structures\nListing9.8 Creating a modified version of a Paguro map\nvar myMap = PersistentHashMap.of(Map.of(\"aa\", 1, \"bb\", 2)\n.entrySet());\nCreates a Paguro map\nfrom a Java map entry set\nvar myNextMap = myMap.assoc(\"aa\", 42);\nTheo Yes! Now I see how to use persistent data structures in Java, but what about\nJavaScript?\n9.3.2 Persistent data structures in JavaScript\nJoe In a language like JavaScript, it’s a bit more cumbersome to integrate per-\nsistent data structures.\nTheo How so?\nJoe Because JavaScript objects and arrays don’t expose any interface.\nTheo Bummer.\nJoe It’s not as terrible as it sounds because Immutable.js exposes its own set of\nfunctions to manipulate its data structures.\nTheo What do you mean?\nJoe I’ll show you in a moment. But first, let me show you how to initiate Immutable.js\npersistent data structures.\nTheo OK!\nJoe Immutable.js provides a handy function that recursively converts a native data\nobject to an immutable one. It’s called Immutable.fromJS().\nTheo What do you mean by recursively?\nJoe Consider the map that holds library data from our Library Management Sys-\ntem: it has values that are themselves maps. Immutable.fromJS() converts the\nnested maps into immutable maps.\nTheo Could you show me some code?\nJoe Absolutely. Take a look at this JavaScript code for library data.\nListing9.9 Conversion to immutable data\nvar libraryData = Immutable.fromJS({\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n--- Page 215 ---\n9.3 Persistent data structures libraries 187\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n});\nTheo Do you mean that the catalog value in libraryData map is itself an immutable\nmap?\nJoe Yes, and the same for booksByIsbn, authorIds, and so forth.\nTheo Cool! So how do I access a field inside an immutable map?\nJoe As I told you, Immutable.js provides its own API for data access. For instance,\nin order to access a field inside an immutable map, you use Immutable.get()\nor Immutable.getIn() like the following.\nListing9.10 Accessing a field and a nested field in an immutable map\nImmutable.get(libraryData, \"catalog\");\nImmutable.getIn(libraryData,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nTheo How do I make a modification to a map?\nJoe Similar to what we did with Lodash FP, you use an Immutable.set() or\nImmutable.setIn() map to create a new version of the map where a field is\nmodified. Here’s how.\nListing9.11 Creating a new version of a map where a field is modified\nImmutable.setIn(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1988);\nTheo What happens when I try to access a field in the map using JavaScript’s dot or\nbracket notation?\nJoe You access the internal representation of the map instead of accessing a map\nfield.\nTheo Does that mean that we can’t pass data from Immutable.js to Lodash for data\nmanipulation?\nJoe Yes, but it’s quite easy to convert any immutable collection into a native Java-\nScript object back and forth.\nTheo How?\nJoe Immutable.js provides a toJS() method to convert an arbitrary deeply nested\nimmutable collection into a JavaScript object.\n--- Page 216 ---\n188 CHAPTER 9 Persistent data structures\nTheo But if I have a huge collection, it could take lots of time to convert it, right?\nJoe True. We need a better solution. Hopefully, Immutable.js provides its own set\nof data manipulation functions like map(), filter(), and reduce().\nTheo What if I need more data manipulation like Lodash’s _.groupBy()?\nJoe You could write your own data manipulation functions that work with the\nImmutable.js collections or use a library like mudash, which provides a port of\nLodash to Immutable.js.\n NOTE You can access the mudash library at https://github.com/brianneisler/mudash.\nTheo What would you advise?\nJoe A cup of coffee, then I’ll show you how to port functions from Lodash to\nImmutable.js and how to adapt the code from your Library Management System.\nYou can decide on whichever approach works best for your current project.\n9.4 Persistent data structures in action\nJoe Let’s start with our search query. Can you look at the current code and tell me\nthe Lodash functions that we used to implement the search query?\nTheo Including the code for the unit tests?\nJoe Of course!\n NOTE See chapter 6 for the unit test of the search query.\n9.4.1 Writing queries with persistent data structures\nTheo The Lodash functions we used were get, map, filter, and isEqual.\nJoe Here’s the port of those four functions from Lodash to Immutable.js.\nListing9.12 Porting some functions from Lodash to Immutable.js\nImmutable.map = function(coll, f) {\nreturn coll.map(f);\n};\nImmutable.filter = function(coll, f) {\nif(Immutable.isMap(coll)) {\nreturn coll.valueSeq().filter(f);\n}\nreturn coll.filter(f);\n};\nImmutable.isEqual = Immutable.is;\nTheo The code seems quite simple. But can you explain it to me, function by function?\nJoe Sure. Let’s start with get. For accessing a field in a map, Immutable.js provides\ntwo functions: get for direct fields and getIn for nested fields. It’s different\nfrom Lodash, where _.get works both on direct and nested fields.\n--- Page 217 ---\n9.4 Persistent data structures in action 189\nTheo What about map?\nJoe Immutable.js provides its own map function. The only difference is that it is a\nmethod of the collection, but it is something that we can easily adapt.\nTheo What about filter? How would you make it work both for arrays and maps\nlike Lodash’s filter?\nJoe Immutable.js provides a valueSeq method that returns the values of a map.\nTheo Cool. And what about isEqual to compare two collections?\nJoe That’s easy. Immutable.js provides a function named is that works exactly as\nisEqual.\nTheo So far, so good. What do I need to do now to make the code of the search\nquery work with Immutable.js?\nJoe You simply replace each occurrence of an _ with Immutable; _.map becomes\nImmutable.map, _.filter becomes Immutable.filter, and _.isEqual\nbecomes Immutable.isEqual.\nTheo I can’t believe it’s so easy!\nJoe Try it yourself; you’ll see. Sometimes, it’s a bit more cumbersome because\nyou need to convert the JavaScript objects to Immutable.js objects using\nImmutable.fromJS.\nTheo copies and pastes the snippets for the code and the unit tests of the search query.\nThen, he uses his IDE to replace the _ with Immutable. When Theo executes the tests and\nthey pass, he is surprised but satisfied. Joe smiles.\nListing9.13 Implementing book search with persistent data structures\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn Immutable.map(authorIds, function(authorId) {\nreturn Immutable.getIn(\ncatalogData,\n[\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = Immutable.Map({\n\"title\": Immutable.get(book, \"title\"),\n\"isbn\": Immutable.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(\ncatalogData,\nImmutable.get(book, \"authorIds\"))\n});\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = Immutable.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nvar matchingBooks = Immutable.filter(allBooks, function(book) {\n--- Page 218 ---\n190 CHAPTER 9 Persistent data structures\nreturn Immutable.get(book, \"title\").\ntoLowerCase().\nincludes(queryLowerCased);\n});\nvar bookInfos = Immutable.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nListing9.14 Testing book search with persistent data structures\nvar catalogData = Immutable.fromJS({\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n});\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Watchmen\"),\nImmutable.fromJS([bookInfo]));\n// → true\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Batman\"),\nImmutable.fromJS([]));\n// → true\n--- Page 219 ---\n9.4 Persistent data structures in action 191\n9.4.2 Writing mutations with persistent data structures\nTheo Shall we move forward and port the add member mutation?\nJoe Sure. Porting the add member mutation from Lodash to Immutable.js only\nrequires you to again replace the underscore (_) with Immutable. Let’s look at\nsome code.\nListing9.15 Implementing member addition with persistent data structures\nUserManagement.addMember = function(userManagement, member) {\nvar email = Immutable.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(Immutable.hasIn(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = Immutable.setIn(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo So, for the tests, I’d convert the JavaScript objects to Immutable.js objects with\nImmutable.fromJS(). How does this look?\nListing9.16 Testing member addition with persistent data structures\nvar jessie = Immutable.fromJS({\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n});\nvar franck = Immutable.fromJS({\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n});\nvar userManagementStateBefore = Immutable.fromJS({\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n});\nvar expectedUserManagementStateAfter = Immutable.fromJS({\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n--- Page 220 ---\n192 CHAPTER 9 Persistent data structures\n}\n}\n});\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\nImmutable.isEqual(result, expectedUserManagementStateAfter);\n// → true\nJoe Great!\n9.4.3 Serialization and deserialization\nTheo Does Immutable.js also support JSON serialization and deserialization?\nJoe It supports serialization out of the box. As for deserialization, we need to write\nour own function.\nTheo Does Immutable.js provide an Immutable.stringify() function?\nJoe That’s not necessary because the native JSON.stringify() function works\nwith Immutable.js objects. Here’s another example.\nListing9.17 JSON serialization of an Immutable.js collection\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nJSON.stringify(bookInfo);\n// → {\\\"isbn\\\":\\\"978-1779501127\\\",\\\"title\\\":\\\"Watchmen\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}\nTheo How does JSON.stringify() know how to handle an Immutable.js collection?\nJoe As an OOP developer, you shouldn’t be surprised by that.\nTheo Hmm...let me think a minute. OK, here’s my guess. Is that because JSON\n.stringify() calls some method on its argument?\nJoe Exactly! If the object passed to JSON.stringify() has a .toJSON() method,\nit’s called by JSON.stringify().\nTheo Nice. What about JSON deserialization?\nJoe That needs to be done in two steps. You first convert the JSON string to a Java-\nScript object and then to an immutable collection.\nTheo Something like this piece of code?\nListing9.18 Converting a JSON string into an immutable collection\nImmutable.parseJSON = function(jsonString) {\nreturn Immutable.fromJS(JSON.parse(jsonString));\n};\nJoe Exactly.\n--- Page 221 ---\n9.4 Persistent data structures in action 193\n9.4.4 Structural diff\nTheo So far, we have ported pieces of code that dealt with simple data manipula-\ntions. I’m curious to see how it goes with complex data manipulations such as\nthe code that computes the structural diff between two maps.\n NOTE Chapter 5 introduces structural diff.\nJoe That also works smoothly, but we need to port another eight functions.\nListing9.19 Porting Lodash functions involved in structural diff computation\nImmutable.reduce = function(coll, reducer, initialReduction) {\nreturn coll.reduce(reducer, initialReduction);\n};\nImmutable.isEmpty = function(coll) {\nreturn coll.isEmpty();\n};\nImmutable.keys = function(coll) {\nreturn coll.keySeq();\n};\nImmutable.isObject = function(coll) {\nreturn Immutable.Map.isMap(coll);\n};\nImmutable.isArray = Immutable.isIndexed;\nImmutable.union = function() {\nreturn Immutable.Set.union(arguments);\n};\nTheo Everything looks trivial with one exception: the use of arguments in Immutable\n.union.\nJoe In JavaScript, arguments is an implicit array-like object that contains the values\nof the function arguments.\nTheo I see. It’s one of those pieces of JavaScript magic!\nJoe Yep. We need to use arguments because Lodash and Immutable.js differ slightly\nin the signature of the union function. Immutable.Set.union receives an array\nof lists, whereas a Lodash _.union receives several arrays.\nTheo Makes sense. Let me give it a try.\nBlowing on his fingers like a seasoned safecracker, first one hand and then the next, Theo\nbegins typing. Once again, Theo is surprised to discover that after replacing the _ with\nImmutable in listing 9.20, the tests pass with the code in listing 9.21.\nListing9.20 Implementing structural diff with persistent data structures\nfunction diffObjects(data1, data2) {\nvar emptyObject = Immutable.isArray(data1) ?\nImmutable.fromJS([]) :\n--- Page 222 ---\n194 CHAPTER 9 Persistent data structures\nImmutable.fromJS({});\nif(data1 == data2) {\nreturn emptyObject;\n}\nvar keys = Immutable.union(Immutable.keys(data1), Immutable.keys(data2));\nreturn Immutable.reduce(keys,\nfunction (acc, k) {\nvar res = diff(Immutable.get(data1, k),\nImmutable.get(data2, k));\nif((Immutable.isObject(res) && Immutable.isEmpty(res)) ||\n(res == \"data-diff:no-diff\")) {\nreturn acc;\n}\nreturn Immutable.set(acc, k, res);\n},\nemptyObject);\n}\nfunction diff(data1, data2) {\nif(Immutable.isObject(data1) && Immutable.isObject(data2)) {\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"data-diff:no-diff\";\n}\nListing9.21 Testing structural diff with persistent data structures\nvar data1 = Immutable.fromJS({\ng: {\nc: 3\n},\nx: 2,\ny: {\nz: 1\n},\nw: [5]\n});\nvar data2 = Immutable.fromJS({\ng: {\nc:3\n},\nx: 2,\ny: {\nz: 2\n},\nw: [4]\n});\nImmutable.isEqual(diff(data1, data2),\nImmutable.fromJS({\n--- Page 223 ---\nSummary 195\n\"w\": [\n4\n],\n\"y\": {\n\"z\": 2\n}\n}));\nJoe What do you think of all this, my friend?\nTheo I think that using persistent data collections with a library like Immutable.js is\nmuch easier than understanding the internals of persistent data structures. But\nI’m also glad that I know how it works under the hood.\nAfter accompanying Joe to the office door, Theo meets Dave. Dave had been peering\nthrough the window in Theo’s office, looking at the whiteboard, anxious to catch a glimpse\nof today’s topic on DOP.\nDave What did Joe teach you today?\nTheo He took me to the university and taught me the foundations of persistent data\nstructures for dealing with immutability at scale.\nDave What’s wrong with the structural sharing that I implemented a couple of\nmonths ago?\nTheo When the number of elements in the collection is big enough, naive structural\nsharing has performance issues.\nDave I see. Could you tell me more about that?\nTheo I’d love to, but my brain isn’t functioning properly after this interesting but\nexhausting day. We’ll do it soon, promise.\nDave No worries. Have a nice evening, Theo.\nTheo You too, Dave.\nSummary\n It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\n At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\n Naive structural sharing doesn’t prevent data structures from being accidentally\nmutated.\n Immutable collections are not the same as persistent data structures.\n Immutable collections don’t provide an efficient way to create new versions of\nthe collections.\n Persistent data structures protect data from mutation.\n Persistent data structures provide an efficient way to create new versions of the\ncollections.\n Persistent data structures always preserve the previous version of themselves when\nthey are modified.\n--- Page 224 ---\n196 CHAPTER 9 Persistent data structures\n Persistent data structures represent data internally in such a way that structural\nsharing scales well, both in terms of memory and computation.\n When data is immutable, it is safe to share it.\n Internally, persistence uses a branching factor of 32.\n In practice, manipulation of persistent data structures is efficient even for col-\nlections with 10 billion entries!\n Due to modern architecture considerations, the performance of updating a\npersistent list is dominated much more by the depth of the tree than by the\nnumber of nodes at each level of the tree.\n Persistent lists can be manipulated in near constant time.\n In most languages, third-party libraries provide an implementation of persistent\ndata structures.\n Paguro collections implement the read-only parts of Java collection interfaces.\n Paguro collections can be passed to any methods that expect to receive a Java\ncollection without mutating them.\n--- Page 225 ---\nDatabase operations\nA cloud is a cloud\nThis chapter covers\n Fetching data from the database\n Storing data in the database\n Manipulating data fetched from the database\nTraditionally in OOP, we use design patterns and complex layers of objects to struc-\nture access to the database. In DOP, we prefer to represent data fetched from the\ndatabase with generic data collections, namely, lists of maps, where fields in the\nmaps correspond to database column values. As we’ll see throughout the chapter,\nthe fact that fields inside a map are accessible dynamically via their names allows us\nto use the same generic code for different data entities.\nTIP The best way to manipulate data is to represent data as data.\nIn this chapter, we’ll illustrate the application of data-oriented principles when\naccessing data from a relational database. Basic knowledge of relational database\nand SQL query syntax (like SELECT, AS, WHERE, and INNER JOIN) is assumed. This\napproach can be easily adapted to NoSQL databases.\n197\n--- Page 226 ---\n198 CHAPTER 10 Database operations\nApplications that run on the server usually store data in a database. In DOP, we\nrepresent data retrieved from the database the same way we represent any other data\nin our application—with generic data collections. This leads to\n Reduced system complexity.\n Increased genericity.\n10.1 Fetching data from the database\nTheo and Joe go for a walk in a park near the office. They sit on a bench close to a beau-\ntiful lake and gaze at the clouds in the sky. After a couple of minutes of meditative\nsilence, Joe asks Theo, “What do you see?” Theo tells him that this cloud looks to him\nlike a horse, and that one looks like a car. On their way back to the office, Theo asks Joe\nfor an explanation about the clouds. Joe answers with a mysterious smile on his lips, “A\ncloud is a cloud.”\nTheo So far you’ve shown me how DOP represents data that lives in the memory of\nthe application. What about data that comes from the outside?\nJoe What do you mean by outside?\nTheo Data that comes from the database.\nJoe I’ll return the question to you. How do you think that we should represent data\nthat comes from the database in DOP?\nTheo As generic data collections, I guess.\nJoe Exactly! In DOP, we always represent data with generic data collections.\nTheo Does that mean that we can manipulate data from the database with the same\nflexibility as we manipulate in-memory data?\nJoe Definitely.\nTIP In DOP, we represent data from the database with generic data collections, and\nwe manipulate it with generic functions.\nTheo Would you show me how to retrieve book search results when the catalog data\nis stored in an SQL database?\nJoe I’ll show you in a moment. First, tell me how you would design the tables that\nstore catalog data.\nTheo Do you mean the exact table schemas with the information about primary keys\nand nullability of each and every column?\nJoe No, I only need a rough overview of the tables, their columns, and the relation-\nships between the tables.\nTheo goes to the whiteboard. Figure 10.1 shows the diagram he draws as he explains his\nthinking to Joe.\n--- Page 227 ---\n10.1 Fetching data from the database 199\nT books\nT authors\nisbn VARCHAR[32]\nid VARCHAR[64]\ntitle VARCHAR[64]\nname VARCHAR[64]\npublication_year INTEGER\n1\nA book 1 An author\nmay have may author\nmany authors. many books.\n* *\nbook_authors\nT (relationships of books and authors)\nbook_isbn VARCHAR[32] Figure 10.1 The database model\nauthor_id VARCHAR[64]\nfor books and authors\nTheo I have a books table with three columns: title, isbn, and publication_\nyear. I also have an authors table with two columns: for id and name. Here,\nlet me draw these tables on the whiteboard to give you a visual (see tables 10.1\nand 10.2).\nTable 10.1 The books table filled with two books\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nTable 10.2 The authors table filled with three authors\nid name\nsean-covey Sean Covey\nstephen-covey Stephen Covey\ncharles-duhigg Charles Duhigg\nJoe What about the connection between books and authors?\nTheo Let’s see, a book could be written by multiple authors, and an author could write\nmultiple books. Therefore, I need a many-to-many book_authors table that con-\nnects authors and books with two columns, book_isbn and author_id.\nTheo once again turns to the whiteboard. He pens the book_authors table 10.3 to show Joe.\nTable 10.3 The book_authors table with rows connecting books with their authors\nbook_isbn author_id\n978-1982137274 sean-covey\n978-1982137274 stephen-covey\n978-0812981605 charles-duhigg\n--- Page 228 ---\n200 CHAPTER 10 Database operations\nJoe Great! Let’s start with the simplest case. We’re going to write code that searches\nfor books matching a title and that returns basic information about the books.\nBy basic information, I mean title, ISBN, and publication year.\nTheo What about the book authors?\nJoe We’ll deal with that later, as it’s a bit more complicated. Can you write an SQL\nquery for retrieving books that contain he word habit in their title?\nTheo Sure.\nThis assignment is quite easy for Theo. First, he jots down the SQL query, then he displays\nthe results in table 10.4.\nListing10.1 SQL query to retrieve books whose title contains habit\nSELECT\ntitle,\nisbn,\npublication_year\nFROM\nbooks\nWHERE title LIKE '%habit%';\nTable 10.4 Results of the SQL query for books whose title contains the word habit\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nJoe How would you describe these results as a data collection?\nTheo I would say it’s a list of maps.\nTIP In DOP, accessing data from a NoSQL database is similar to the way we access\ndata from a relational database.\nJoe Right! Now, can you write the search results as a list of maps?\nTheo It doesn’t sound too complicated. How about this?\nListing10.2 Search results as a list of maps\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"publication_year\": 1989\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"publication_year\": 2012\n}\n]\n--- Page 229 ---\n10.1 Fetching data from the database 201\nJoe What about the JSON schema for the search results?\nTheo It shouldn’t be too difficult if you allow me to take a look at the JSON schema\ncheat sheet you kindly offered me the other day.\nJoe Of course. The purpose of a gift is to be used by the one who receives it.\nTheo takes a look at the JSON Schema cheat sheet to refresh his memory about the JSON\nSchema syntax. After a few minutes, Theo comes up with a schema for the search results.\nHe certainly is putting Joe’s gift to good use.\nListing10.3 JSON schema cheat sheet\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"myNumber\": {\"type\": \"number\"},\n\"myString\": {\"type\": \"string\"},\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\n\"myBool\": {\"type\": \"boolean\"}\n},\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\n}\n}\nListing10.4 The JSON schema for search results from the database\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"publication_year\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"publication_year\": {\"type\": \"integer\"}\n}\n}\n};\nJoe Excellent. Now I’m going to show you how to implement searchBooks in a\nway that fetches data from the database and returns a JSON string with the\nresults. The cool thing is that we’re only going to use generic data collections\nfrom the database layer down to the JSON serialization.\nTheo Will it be similar to the implementation of searchBooks that we wrote when\nyou taught me the basis of DOP?\nJoe Absolutely. The only difference is that then the state of the system was stored\nlocally, and we queried it with a function like _.filter. Now, we use SQL\n--- Page 230 ---\n202 CHAPTER 10 Database operations\nqueries to fetch the state from the database. In terms of data representation\nand manipulation, it’s exactly the same.\nJoe goes to the whiteboard and sketches out the data flow in figure 10.2. Theo studies the\ndiagram.\nDatabase\nDatabase driver\nData (list of maps)\nData manipulation\nData Figure 10.2 Data flow for serving\na request that fetches data from\nJSON serialize\nthe database\nJoe The data manipulation step in the diagram is implemented via generic func-\ntions that manipulate data collections. As our examples get more elaborate, I\nthink you’ll see the benefits of being able to manipulate data collections with\ngeneric functions.\nTheo Sounds intriguing...\nJoe For the communication with the database, we use a driver that returns a list of\nmaps. In JavaScript, you could use an SQL driver like node-postgres.\n NOTE See https://node-postgres.com for more information about this collection of\nnode.js modules for interfacing with PostgreSQL databases.\nTheo And in Java?\nJoe In Java, you could use JDBC (Java database connectivity) in addition to a small\nutility function that converts a JDBC result set into a list of maps. If I can use\nyour laptop, I’ll show you what I mean.\nJoe pulls a piece of code from one of his personal GitHub repositories. He then shows the\ncode for the JDBC conversion to Theo, who seems a bit surprised.\nListing10.5 Converting a JDBC result set into a list of hash maps\nList<Map<String, Object>> convertJDBCResultSetToListOfMaps(ResultSet rs) {\nList<Map<String, Object>> listOfMaps =\nnew ArrayList<Map<String, Object>>();\nResultSetMetaData meta = rs.getMetaData();\nwhile (rs.next()) {\nMap map = new HashMap();\nfor (int i = 1; i <= meta.getColumnCount(); i++) {\nString key = meta.getColumnLabel(i);\nObject value = rs.getObject(i);\n--- Page 231 ---\n10.1 Fetching data from the database 203\nmap.put(key, value);\n}\nlistOfMaps.add(map);\n}\nreturn listOfMaps;\n}\nTIP Converting a JDBC result set into a list of hash maps is quite straightforward.\nTheo I expected it to be much more complicated to convert a JDBC result set into a\nlist of hash maps.\nJoe It’s straightforward because, in a sense, JDBC is data-oriented.\nTheo What about the field types?\nJoe When we convert a JDBC result set into a list of maps, each value is considered\nan Object.\nTheo That’s annoying because it means that in order to access the value, we need to\ncast it to its type.\nJoe Yes and no. Look at our book search use case. We pass all the values along with-\nout really looking at their type. The concrete value type only matters when we\nserialize the result into JSON and that’s handled by the JSON serialization\nlibrary. It’s called late binding.\n NOTE With late binding, we defer dealing with data types as long as possible.\nTheo Does that mean in my application that I’m allowed to manipulate data without\ndealing with concrete types?\nTIP In DOP, flexibility is increased as many parts of the system are free to manipulate\ndata without dealing with concrete types.\nJoe Exactly. You’ll see late binding in action in a moment. That’s one of the great-\nest benefits of DOP.\nTheo Interesting, I can’t wait to see that!\nJoe One last thing before I show you the code for retrieving search results from the\ndatabase. In order to make it easier to read, I’m going to write JavaScript code\nas if JavaScript were dealing with I/O is a synchronous way.\nTheo What do you mean?\nJoe In JavaScript, an I/O operation like sending a query to the database is done\nasynchronously. In real life, it means using either callback functions or using\nasync and await keywords.\nTheo Oh yeah, that’s because JavaScript is single-threaded.\n NOTE For sake of simplicity, the JavaScript snippets in this chapter are written as if\nJavaScript were dealing with I/O in a synchronous way. In real-life JavaScript, we need\nto use async and await around I/O calls.\nJoe Indeed, so I’ll be writing the code that communicates with the database as\nthough JavaScript were dealing with I/O synchronously. Here’s an example.\n--- Page 232 ---\n204 CHAPTER 10 Database operations\nListing10.6 Searching books in the database, returning the results in JSON\ndbClient holds the Initializes Ajv (a JSON schema validation\nvar dbClient; DB connection. library) with allErrors: true to catch all\nthe data validation errors\nvar ajv = new Ajv({allErrors: true});\nvar title = \"habit\";\nvar matchingBooksQuery = `SELECT title, isbn Uses a parameterized\nSQL query as a security\nFROM books\nbest practice\nWHERE title LIKE '%$1%'`;\nvar books = dbClient.query(matchingBooksQuery,\nPasses the parameters to the SQL\n[title]);\nquery as a list of values (in our\nif(!ajv.validate(dbSearchResultSchema, books)) {\ncase, a list with a single value)\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" + errors;\n}\nJSON.stringify(books);\nTheo In a dynamically-typed language like JavaScript, I understand that the types of\nthe values in the list of maps returned by dbClient.query are determined at\nrun time. How does it work in a statically-typed language like Java, and what are\nthe types of the data fields in books?\nJoe The function convertJDBCResultSetToListOfMaps we created earlier (see\nlisting 10.5) returns a list of Map<String, Object>. But JSON serialization\nlibraries like Gson know how to detect at run time the concrete type of the val-\nues in a map and serialize the values according to their type.\n NOTE See https://github.com/google/gson for information about Gson’s Java\nserialization/deserialization library.\nTheo What do you mean by serializing a value according to its type?\nJoe For instance, the value of the field publication_year is a number; therefore,\nit is not wrapped with quotes. However, the value of the field title is a string;\ntherefore, it is wrapped with quotes.\nTheo Nice! Now, I understand what you mean by late binding.\nJoe Cool! Now, let me show you how we store data in the database.\n10.2 Storing data in the database\nIn the previous section, we saw how to retrieve data from the database as a list of maps.\nNext, we’ll see how to store data in the database when data is represented with a map.\nTheo I guess that storing data in the database is quite similar to fetching data from\nthe database.\nJoe It’s similar in the sense that we deal only with generic data collections. Can you\nwrite a parameterized SQL query that inserts a row with user info using only\nemail and encrypted_password, please?\nTheo OK.",
        "sections_found": []
      },
      "accurate_page_range": "202-232"
    },
    {
      "text": "- 8.2 Thread-safe counter with atoms",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "8 Advanced concurrency control",
      "raw_line": "- 8.2 Thread-safe counter with atoms (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 66,
      "chapter_info": {
        "page": 202,
        "title": "Advanced concurrency control",
        "pattern_matched": "Chapter 8",
        "text_preview": "174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do yo"
      },
      "chapter_sections": {
        "start_page": 202,
        "end_page": 232,
        "content": "\n--- Page 202 ---\n174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do you mean?\nTheo I don’t know, but I am under the impression that mutexes are like phone calls,\nand atoms are like text messages.\nJoe smiles at Theo but doesn’t reveal the meaning of his smile. After the phone deadlock\nyesterday, Theo’s pretty sure that he and Joe are on the same page.\nSummary\n Managing concurrency with atoms is much simpler than managing concur-\nrency with locks because we don’t have to deal with the risk of deadlocks.\n Cloning data to avoid read locks doesn’t scale.\n When data is immutable, reads are always safe.\n Atoms provide a way to manage concurrency without locks.\n With atoms, deadlocks never happen.\n Using atoms for a thread-safe counter is trivial because the state of the counter\nis represented with a primitive type (an integer).\n We can manage composite data in a thread-safe way with atoms.\n We make the highly scalable state management approach from part 1 thread-\nsafe by keeping the whole system state inside an atom.\n It’s quite common to represent an in-memory cache as a string map.\n When data is immutable, it is safe (and fast) to compare by reference.\n In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing besides swapping an atom.\n In practice, once an atom is swapped, the threads do some real work (e.g.,\ndatabase access) to provide an opportunity for other threads to swap the atom\nsuccessfully.\n--- Page 203 ---\nPersistent data structures\nStanding on the shoulders of giants\nThis chapter covers\n The internal details of persistent data\nstructures\n The time and memory efficiency of persistent\ndata structures\n Using persistent data structures in an\napplication\nIn part 1, we illustrated how to manage the state of a system without mutating data,\nwhere immutability is maintained by constraining ourselves to manipulate the state\nonly with immutable functions using structural sharing. In this chapter, we present\na safer and more scalable way to preserve data immutability—representing data\nwith so-called persistent data structures. Efficient implementations of persistent\ndata structures exist for most programming languages via third-party libraries.\n9.1 The need for persistent data structures\nIt’s at the university where Theo meets Joe this time. When Theo asks Joe if today’s topic\nis academic in nature, Joe tells him that the use of persistent data structures only\nbecame possible in programming languages following a discovery in 2001 by a computer\n175\n--- Page 204 ---\n176 CHAPTER 9 Persistent data structures\nresearcher named Phil Bagwell.1 In 2007, Rich Hickey, the creator of Clojure, used this dis-\ncovery as the foundation of persistent data structures in Clojure. Unveiling the secrets of\nthese data structures to Theo in a university classroom is a way for Joe to honor the mem-\nory of Phil Bagwell, who unfortunately passed away in 2012. When they get to the univer-\nsity classroom, Joe starts the conversation with a question.\nJoe Are you getting used to DOP’s prohibition against mutating data in place and\ncreating new versions instead?\nTheo I think so, but two things bother me about the idea of structural sharing that\nyou showed me.\nJoe What bothers you, my friend?\nTheo Safety and performance.\nJoe What do you mean by safety?\nTheo I mean that using immutable functions to manipulate data doesn’t prevent it\nfrom being modified accidentally.\nJoe Right! Would you like me to show you the naive way to handle immutability or\nthe real way?\nTheo What are the pros and cons of each way?\nJoe The naive way is easy but not efficient, although the real way is efficient but\nnot easy.\nTheo Let’s start with the naive way then.\nJoe Each programming language provides its own way to protect data from being\nmutated.\nTheo How would I do that in Java, for instance?\nJoe Java provides immutable collections, and there is a way to convert a list or a\nmap to an immutable list or an immutable map.\n NOTE Immutable collections are not the same as persistent data structures.\nJoe opens his laptop and fires it up. He brings up two code examples, one for immutable\nlists and one for immutable maps.\nListing9.1 Converting a mutable list to an immutable list in Java\nvar myList = new ArrayList<Integer>();\nmyList.add(1);\nmyList.add(2);\nmyList.add(3);\nvar myImmutableList = List.of(myList.toArray());\n1 P. Bagwell, “Ideal hash trees” (No. REP_WORK), 2001. [Online]. Available: https://lampwww.epfl.ch/papers/\nidealhashtrees.pdf.\n--- Page 205 ---\n9.1 The need for persistent data structures 177\nListing9.2 Converting a mutable map to an immutable map in Java\nvar myMap = new HashMap<String, Object>();\nmyMap.put(\"name\", \"Isaac\");\nmyMap.put(\"age\", 42);\nvar myImmutableMap = Collections.unmodifiableMap(myMap);\nTheo What happens when you try to modify an immutable collection?\nJoe Java throws an UnsupportedOperationException.\nTheo And in JavaScript?\nJoe JavaScript provides an Object.freeze() function that prevents data from\nbeing mutated. It works both with JavaScript arrays and objects.\nJoe takes a minute to scroll through his laptop. When he finds what he’s looking for, he\nshows Theo the code.\nListing9.3 Making an object immutable in JavaScript\nvar a = [1, 2, 3];\nObject.freeze(a);\nvar b = {foo: 1};\nObject.freeze(b);\nTheo What happens when you try to modify a frozen object?\nJoe It depends. In JavaScript strict mode, a TypeError exception is thrown, and in\nnonstrict mode, it fails silently.\n NOTE JavaScript’s strict mode is a way to opt in to a restricted variant of JavaScript\nthat changes some silent errors to throw errors.\nTheo In case of a nested collection, are the nested collections also frozen?\nJoe No, but in JavaScript, one can write a deepFreeze() function that freezes an\nobject recursively. Here’s another example.\nListing9.4 Freezing an object recursively in JavaScript\nfunction deepFreeze(object) {\n// Retrieve the property names defined on object\nconst propNames = Object.getOwnPropertyNames(object);\n// Freeze properties before freezing self\nfor (const name of propNames) {\nconst value = object[name];\nif (value && typeof value === \"object\") {\ndeepFreeze(value);\n}\n}\n--- Page 206 ---\n178 CHAPTER 9 Persistent data structures\nreturn Object.freeze(object);\n}\nTheo I see that it’s possible to ensure that data is never mutated, which answers my\nconcerns about safety. Now, let me share my concerns about performance.\nTIP It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\nJoe Sure.\nTheo If I understand correctly, the main idea behind structural sharing is that most\ndata is usually shared between two versions.\nJoe Correct.\nTheo This insight allows us to create new versions of our collections using a shallow\ncopy instead of a deep copy, and you claimed that it was efficient.\nJoe Exactly!\nTheo Now, here is my concern. In the case of a collection with many entries, a shal-\nlow copy might be expensive.\nJoe Could you give me an example of a collection with many entries?\nTheo A catalog with 100,000 books, for instance.\nJoe On my machine, making a shallow copy of a collection with 100,000 entries\ndoesn’t take more than 50 milliseconds.\nTheo Sometimes, even 50 milliseconds per update isn’t acceptable.\nJoe I totally agree with you. When one needs data immutability at scale, naive struc-\ntural sharing is not appropriate.\nTheo Also, shallow copying an array of 100,000 elements on each update would\nincrease the program memory by 100 KB.\nJoe Indeed, at scale, we have a problem both with memory and computation.\nTIP At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\nTheo Is there a better solution?\nJoe Yes! For that, you’ll need to learn the real way to handle immutability. It’s\ncalled persistent data structures.\n9.2 The efficiency of persistent data structures\nTheo In what sense are those data structures persistent?\nJoe Persistent data structures are so named because they always preserve their pre-\nvious versions.\nTIP Persistent data structures always preserve the previous version of themselves\nwhen they are modified.\nJoe Persistent data structures address the two main limitations of naive structural\nsharing: safety and performance.\n--- Page 207 ---\n9.2 The efficiency of persistent data structures 179\nTheo Let’s start with safety. How do persistent data structures prevent data from\nbeing mutated accidentally?\nJoe In a language like Java, they implement the mutation methods of the collec-\ntion interfaces by throwing the run-time exception UnsupportedOperation-\nException.\nTheo And, in a language like JavaScript?\nJoe In JavaScript, persistent data structures provide their own methods to access\ndata, and none of those methods mutate data.\nTheo Does that mean that we can’t use the dot notation to access fields?\nJoe Correct. Fields of persistent data structures are accessed via a specific API.\nTheo What about efficiency? How do persistent data structures make it possible to\ncreate a new version of a huge collection in an efficient way?\nJoe Persistent data structures organize data in such a way that we can use structural\nsharing at the level of the data structure.\nTheo Could you explain?\nJoe Certainly. Let’s start with the simplest data structure: a linked list. Imagine that\nyou have a linked list with 100,000 elements.\nTheo OK.\nJoe What would it take to prepend an element to the head of the list?\nTheo You mean to create a new version of the list with an additional element?\nJoe Exactly!\nTheo Well, we could copy the list and then prepend an element to the list, but it\nwould be quite expensive.\nJoe What if I tell you that the original linked list is guaranteed to be immutable?\nTheo In that case, I could create a new list with a new head that points to the head of\nthe original list.\nTheo goes to the classroom blackboard. He picks up a piece of chalk and draws the dia-\ngram shown in figure 9.1.\nNew list Original list\nFigure 9.1 Structural sharing\n0 1 2 3 4 5 with linked lists\nJoe Would the efficiency of this operation depend on the size of the list?\nTheo No, it would be efficient, no matter the size of the list.\nJoe That’s what I mean by structural sharing at the level of the data structure itself.\nIt relies on a simple but powerful insight—when data is immutable, it is safe to\nshare it.\nTIP When data is immutable, it is safe to share it.\n--- Page 208 ---\n180 CHAPTER 9 Persistent data structures\nTheo I understand how to use structural sharing at the level of the data structure for\nlinked lists and prepend operations, but how would it work with operations\nlike appending or modifying an element in a list?\nJoe For that purpose, we need to be smarter and represent our list as a tree.\nTheo How does that help?\nJoe It helps because when a list is represented as a tree, most of the nodes in the\ntree can be shared between two versions of the list.\nTheo I am totally confused.\nJoe Imagine that you take a list with 100,000 elements and split it into two lists of\n50,000 elements each: elements 0 to 49,999 in list 1, and elements 50,000 to\n99,999 in list 2. How many operations would you need to create a new version\nof the list where a single element—let’s say, element at index 75,100—is\nmodified?\nIt’s hard for Theo to visualize this kind of stuff mentally. He goes back to the blackboard\nand draws a diagram (see figure 9.2). Once Theo looks at the diagram, it’s easy for him to\nanswer Joe’s question.\nList «Next»\nList\nList 1 List 2\n«Next»\n0...49,999 50,000...99,999\nList 2\nFigure 9.2 Structural sharing when\n50,000...99,999\na list of 100,000 elements is split\nTheo List 1 could be shared with one operation. I’d need to create a new version of\nlist 2, where element 75,100 is modified. It would take 50,000 operations, so it’s\none operation of sharing and one operation of copying 50,000 elements. Over-\nall, it’s 50,001 operations.\nJoe Correct. You see that by splitting our original list into two lists, we can create a\nnew version of the list with a number of operations in the order of the size of\nthe list divided by 2.\nTheo I agree, but 50,000 is still a big number.\nJoe Indeed, but nobody prevents us from applying the same trick again, splitting\nlist 1 and list 2 in two lists each.\nTheo How exactly?\nJoe We can make list 1.1 with elements 0 to 24,999, then list 1.2 with elements\n25,000 to 49,999, list 2.1 with elements 50,000 to 74,999, and list 2.2 with ele-\nments 75,000 to 99,999.\nTheo Can you draw that on the blackboard?\nJoe Sure.\n--- Page 209 ---\n9.2 The efficiency of persistent data structures 181\nNow, it’s Joe that goes to the blackboard. He draws the diagram in figure 9.3.\n«Next»\nList\nList\n«Next»\nList 1 List 2 List 2\nList 1.1 List 1.2 List 2.1 List 2.2 «Next»\n0...24,499 25,000...49,999 50,000...74,999 75,000...99,999 List 2.2\n75,000...99,999\nFigure 9.3 Structural sharing when a list of 100,000 elements is split twice\nTheo Let me count the number of operations for updating a single element. It takes\n2 operations of sharing and 1 operation of copying 25,000 elements. Overall, it\ntakes 25,002 operations to create a new version of the list.\nJoe Correct!\nTheo Let’s split the list again then!\nJoe Absolutely. In fact, we can split the list again and again until the size of the\nlists is at most 2. Can you guess what is the complexity of creating a new ver-\nsion then?\nTheo I’d say around log2 N operations.\nJoe I see that you remember well your material from school. Do you have a gut\nfeeling about what is log2 N when N is 100,000?\nTheo Let me see...2 to the power of 10 is around 1,000, and 2 to the power of 7 is\n128. So, it should be a bit less than 17.\nJoe It’s 16.6 to be precise. It means that in order to update an element in a per-\nsistent list of 100,000 elements, we need around 17 operations. The same goes\nfor accessing elements.\nTheo Nice, but 17 is still not negligible.\nJoe I agree. We can easily improve the performance of accessing elements by using\na higher branching factor in our tree.\nTheo What do you mean?\nJoe Instead of splitting by 2 at each level, we could split by 32.\nTheo But the running time of our algorithm would still grow with log N.\nJoe You’re right. From a theoretical perspective, it’s the same. From a practical\nperspective, however, it makes a big difference.\nTheo Why?\nJoe Because log32 N is 5 times lower than log2 N.\n--- Page 210 ---\n182 CHAPTER 9 Persistent data structures\nTheo That’s true: 2 to the power of 5 is 32.\nJoe Back to our list of 100,000 elements, can you tell me how many operations are\nrequired to access an element if the branching factor is 32?\nTheo With a branching factor of 2, it was 16.6. If I divide 16.6 by 5, I get 3.3.\nJoe Correct!\nTIP By using a branching factor of 32, we make elements accessed in persistent lists\nmore efficient.\nTheo Does this trick also improve the performance of updating an element in a list?\nJoe Yes, indeed, it does.\nTheo How? We’d have to copy 32 elements at each level instead of 2 elements. It’s a\n16× performance hit that’s not compensated for by the fact that the tree depth\nis reduced by 5×!\nJoe I see that you are quite sharp with numbers. There is another thing to take\ninto consideration in our practical analysis of the performance: modern CPU\narchitecture.\nTheo Interesting. The more you tell me about persistent data structures, the more I\nunderstand why you wanted to have this session at a university: it’s because\nwe’re dealing with all this academic stuff.\nJoe Yep. So, to continue, modern CPUs read and write data from and to the main\nmemory in units of cache lines, often 32 or 64 bytes long.\nTheo What difference does that make?\nJoe A nice consequence of this data access pattern is that copying an array of size\n32 is much faster than copying 16 arrays of size 2 that belong to different levels\nof the tree.\nTheo Why is that?\nJoe The reason is that copying an array of size 32 can be done in a single pair of\ncache accesses: one for read and one for write. Although for arrays that belong\nto different tree levels, each array requires its own pair of cache accesses, even\nif there are only 2 elements in the array.\nTheo In other words, the performance of updating a persistent list is dominated by\nthe depth of the tree.\nTIP In modern CPU architectures, the performance of updating a persistent list is\ndominated much more by the depth of the tree than by the number of nodes at each\nlevel of the tree.\nJoe That’s correct, up to a certain point. With today’s CPUs, using a branching fac-\ntor of 64 would, in fact, decrease the performance of update operations.\nTheo I see.\nJoe Now, I am going to make another interesting claim that is not accurate from a\ntheoretical perspective but accurate in practice.\nTheo What is it?\n--- Page 211 ---\n9.2 The efficiency of persistent data structures 183\nJoe The number of operations it takes to get or update an element in a persistent\nlist with branching factor 32 is constant.\nTheo How can that be? You just made the point that the number of operations is\nlog32 N.\nJoe Be patient, my friend. What is the highest number of elements that you can\nhave in a list, in practice?\nTheo I don’t know. I never thought about that.\nJoe Let’s assume that it takes 4 bytes to store an element in a list.\nTheo OK.\nJoe Now, can you tell me how much memory it would take to hold a list with 10 bil-\nlion elements?\nTheo You mean 1 with 10 zeros?\nJoe Yes.\nTheo Each element take 4 bytes, so it would be around 40 GB!\nJoe Correct. Do you agree that it doesn’t make sense to hold a list that takes 40 GB\nof memory?\nTheo I agree.\nJoe So let’s take 10 billion as an upper bound to the number of elements in a list.\nWhat is log32 of 10 billion?\nOnce again, Theo uses the blackboard to clarify his thoughts. With that, he quickly finds\nthe answer.\nTheo 1 billion is approximately 2^30. Therefore, 10 billion is around 2^33. That\nmeans that log2 of 10 billion is 33, so log32 of 10 billion should be around\n33/5, which is a bit less than 7.\nJoe I am impressed again by your sharpness with numbers. To be precise, log32 of\n10 billion is 6.64.\nTheo (smiling) I didn’t get that far.\nJoe Did I convince you that, in practice, accessing or updating an element in a per-\nsistent list is essentially constant?\nTheo Yes, and I find it quite amazing!\nTIP Persistent lists can be manipulated in near constant time.\nJoe Me too.\nTheo What about persistent maps?\nJoe It’s quite similar, but I don’t think we have time to discuss it now.\nStartled, Theo looks at his watch. This morning’s session has gone by so quickly. He notices\nthat it’s time to get back to the office and have lunch.\n--- Page 212 ---\n184 CHAPTER 9 Persistent data structures\n9.3 Persistent data structures libraries\nOn their way back to the office, Theo and Joe don’t talk too much. Theo’s thoughts take\nhim back to what he learned in the university classroom. He feels a lot of respect for Phil\nBagwell, who discovered how to manipulate persistent data structures efficiently, and for\nRich Hickey, who created a programming language incorporating that discovery as a core\nfeature and making it available to the world. Immediately after lunch, Theo asks Joe to\nshow him what it looks like to manipulate persistent data structures for real in a program-\nming language.\nTheo Are persistent data structures available in all programming languages?\nJoe A few programming languages like Clojure, Scala, and C# provide them as part\nof the language. In most programming languages, though, you need a third-\nparty library.\nTheo Could you give me a few references?\nJoe Sure.\nUsing Theo’s laptop, Joe bookmarks some sites. He knows exactly which URLs to look for.\nThen, while Theo is looking over the bookmarked sites, Joe goes to the whiteboard and\njots down the specific libraries in table 9.1.\n Immutable.js for JavaScript at https://immutable-js.com/\n Paguro for Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections for C# at http://mng.bz/QW51\n Pyrsistent for Python at https://github.com/tobgu/pyrsistent\n Hamster for Ruby at https://github.com/hamstergem/hamster\nTable 9.1 Persistent data structure libraries\nLanguage Library\nJavaScript Immutable.js\nJava Paguro\nC# Provided by the language\nPython Pyrsistent\nRuby Hamster\nTheo What does it take to integrate persistent data structures provided by a third-\nparty library into your code?\n9.3.1 Persistent data structures in Java\nJoe In an object-oriented language like Java, it’s quite straightforward to integrate\npersistent data structures in a program because persistent data structures\nimplement collection interfaces, besides the parts of the interface that mutate\nin place.\nTheo What do you mean?\n--- Page 213 ---\n9.3 Persistent data structures libraries 185\nJoe Take for instance, Paguro for Java. Paguro persistent maps implement the\nread-only methods of java.util.Map like get() and containsKey(), but not\nmethods like put() and remove(). On the other hand, Paguro vectors imple-\nment the read-only methods of java.util.List like get() and size(), but not\nmethods like set().\nTheo What happens when we call put() or remove() on a Paguro map?\nJoe It throws an UnSupportedOperationException exception.\nTheo What about iterating over the elements of a Paguro collection with a forEach()?\nJoe That works like it would in any Java collection. Here, let me show you an example.\nListing9.5 Iterating over a Paguro vector\nvar myVec = PersistentVector.ofIter(\nList.of(10, 2, 3));\nCreates a Paguro\nvector from a\nfor (Integer i : myVec) {\nJava list\nSystem.out.println(i);\n}\nTheo What about Java streams?\nJoe Paguro collections are Java collections, so they support the Java stream inter-\nface. Take a look at this code.\nListing9.6 Streaming a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvec1.stream().sorted().map(x -> x + 1);\nTIP Paguro collections implement the read-only parts of Java collection interfaces.\nTherefore, they can be passed to any methods that expect to receive a Java collection\nwithout mutating it.\nTheo So far, you told me how do use Paguro collections as Java read-only collections.\nHow do I make modifications to Paguro persistent data structures?\nJoe In a way similar to the _.set() function of Lodash FP that we talked about\nearlier. Instead of mutating in place, you create a new version.\nTheo What methods does Paguro expose for creating new versions of a data structure?\nJoe For vectors, you use replace(), and for maps, you use assoc().\nListing9.7 Creating a modified version of a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvar myNextVec = myVec.replace(0, 42);\n--- Page 214 ---\n186 CHAPTER 9 Persistent data structures\nListing9.8 Creating a modified version of a Paguro map\nvar myMap = PersistentHashMap.of(Map.of(\"aa\", 1, \"bb\", 2)\n.entrySet());\nCreates a Paguro map\nfrom a Java map entry set\nvar myNextMap = myMap.assoc(\"aa\", 42);\nTheo Yes! Now I see how to use persistent data structures in Java, but what about\nJavaScript?\n9.3.2 Persistent data structures in JavaScript\nJoe In a language like JavaScript, it’s a bit more cumbersome to integrate per-\nsistent data structures.\nTheo How so?\nJoe Because JavaScript objects and arrays don’t expose any interface.\nTheo Bummer.\nJoe It’s not as terrible as it sounds because Immutable.js exposes its own set of\nfunctions to manipulate its data structures.\nTheo What do you mean?\nJoe I’ll show you in a moment. But first, let me show you how to initiate Immutable.js\npersistent data structures.\nTheo OK!\nJoe Immutable.js provides a handy function that recursively converts a native data\nobject to an immutable one. It’s called Immutable.fromJS().\nTheo What do you mean by recursively?\nJoe Consider the map that holds library data from our Library Management Sys-\ntem: it has values that are themselves maps. Immutable.fromJS() converts the\nnested maps into immutable maps.\nTheo Could you show me some code?\nJoe Absolutely. Take a look at this JavaScript code for library data.\nListing9.9 Conversion to immutable data\nvar libraryData = Immutable.fromJS({\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n--- Page 215 ---\n9.3 Persistent data structures libraries 187\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n});\nTheo Do you mean that the catalog value in libraryData map is itself an immutable\nmap?\nJoe Yes, and the same for booksByIsbn, authorIds, and so forth.\nTheo Cool! So how do I access a field inside an immutable map?\nJoe As I told you, Immutable.js provides its own API for data access. For instance,\nin order to access a field inside an immutable map, you use Immutable.get()\nor Immutable.getIn() like the following.\nListing9.10 Accessing a field and a nested field in an immutable map\nImmutable.get(libraryData, \"catalog\");\nImmutable.getIn(libraryData,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nTheo How do I make a modification to a map?\nJoe Similar to what we did with Lodash FP, you use an Immutable.set() or\nImmutable.setIn() map to create a new version of the map where a field is\nmodified. Here’s how.\nListing9.11 Creating a new version of a map where a field is modified\nImmutable.setIn(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1988);\nTheo What happens when I try to access a field in the map using JavaScript’s dot or\nbracket notation?\nJoe You access the internal representation of the map instead of accessing a map\nfield.\nTheo Does that mean that we can’t pass data from Immutable.js to Lodash for data\nmanipulation?\nJoe Yes, but it’s quite easy to convert any immutable collection into a native Java-\nScript object back and forth.\nTheo How?\nJoe Immutable.js provides a toJS() method to convert an arbitrary deeply nested\nimmutable collection into a JavaScript object.\n--- Page 216 ---\n188 CHAPTER 9 Persistent data structures\nTheo But if I have a huge collection, it could take lots of time to convert it, right?\nJoe True. We need a better solution. Hopefully, Immutable.js provides its own set\nof data manipulation functions like map(), filter(), and reduce().\nTheo What if I need more data manipulation like Lodash’s _.groupBy()?\nJoe You could write your own data manipulation functions that work with the\nImmutable.js collections or use a library like mudash, which provides a port of\nLodash to Immutable.js.\n NOTE You can access the mudash library at https://github.com/brianneisler/mudash.\nTheo What would you advise?\nJoe A cup of coffee, then I’ll show you how to port functions from Lodash to\nImmutable.js and how to adapt the code from your Library Management System.\nYou can decide on whichever approach works best for your current project.\n9.4 Persistent data structures in action\nJoe Let’s start with our search query. Can you look at the current code and tell me\nthe Lodash functions that we used to implement the search query?\nTheo Including the code for the unit tests?\nJoe Of course!\n NOTE See chapter 6 for the unit test of the search query.\n9.4.1 Writing queries with persistent data structures\nTheo The Lodash functions we used were get, map, filter, and isEqual.\nJoe Here’s the port of those four functions from Lodash to Immutable.js.\nListing9.12 Porting some functions from Lodash to Immutable.js\nImmutable.map = function(coll, f) {\nreturn coll.map(f);\n};\nImmutable.filter = function(coll, f) {\nif(Immutable.isMap(coll)) {\nreturn coll.valueSeq().filter(f);\n}\nreturn coll.filter(f);\n};\nImmutable.isEqual = Immutable.is;\nTheo The code seems quite simple. But can you explain it to me, function by function?\nJoe Sure. Let’s start with get. For accessing a field in a map, Immutable.js provides\ntwo functions: get for direct fields and getIn for nested fields. It’s different\nfrom Lodash, where _.get works both on direct and nested fields.\n--- Page 217 ---\n9.4 Persistent data structures in action 189\nTheo What about map?\nJoe Immutable.js provides its own map function. The only difference is that it is a\nmethod of the collection, but it is something that we can easily adapt.\nTheo What about filter? How would you make it work both for arrays and maps\nlike Lodash’s filter?\nJoe Immutable.js provides a valueSeq method that returns the values of a map.\nTheo Cool. And what about isEqual to compare two collections?\nJoe That’s easy. Immutable.js provides a function named is that works exactly as\nisEqual.\nTheo So far, so good. What do I need to do now to make the code of the search\nquery work with Immutable.js?\nJoe You simply replace each occurrence of an _ with Immutable; _.map becomes\nImmutable.map, _.filter becomes Immutable.filter, and _.isEqual\nbecomes Immutable.isEqual.\nTheo I can’t believe it’s so easy!\nJoe Try it yourself; you’ll see. Sometimes, it’s a bit more cumbersome because\nyou need to convert the JavaScript objects to Immutable.js objects using\nImmutable.fromJS.\nTheo copies and pastes the snippets for the code and the unit tests of the search query.\nThen, he uses his IDE to replace the _ with Immutable. When Theo executes the tests and\nthey pass, he is surprised but satisfied. Joe smiles.\nListing9.13 Implementing book search with persistent data structures\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn Immutable.map(authorIds, function(authorId) {\nreturn Immutable.getIn(\ncatalogData,\n[\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = Immutable.Map({\n\"title\": Immutable.get(book, \"title\"),\n\"isbn\": Immutable.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(\ncatalogData,\nImmutable.get(book, \"authorIds\"))\n});\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = Immutable.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nvar matchingBooks = Immutable.filter(allBooks, function(book) {\n--- Page 218 ---\n190 CHAPTER 9 Persistent data structures\nreturn Immutable.get(book, \"title\").\ntoLowerCase().\nincludes(queryLowerCased);\n});\nvar bookInfos = Immutable.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nListing9.14 Testing book search with persistent data structures\nvar catalogData = Immutable.fromJS({\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n});\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Watchmen\"),\nImmutable.fromJS([bookInfo]));\n// → true\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Batman\"),\nImmutable.fromJS([]));\n// → true\n--- Page 219 ---\n9.4 Persistent data structures in action 191\n9.4.2 Writing mutations with persistent data structures\nTheo Shall we move forward and port the add member mutation?\nJoe Sure. Porting the add member mutation from Lodash to Immutable.js only\nrequires you to again replace the underscore (_) with Immutable. Let’s look at\nsome code.\nListing9.15 Implementing member addition with persistent data structures\nUserManagement.addMember = function(userManagement, member) {\nvar email = Immutable.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(Immutable.hasIn(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = Immutable.setIn(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo So, for the tests, I’d convert the JavaScript objects to Immutable.js objects with\nImmutable.fromJS(). How does this look?\nListing9.16 Testing member addition with persistent data structures\nvar jessie = Immutable.fromJS({\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n});\nvar franck = Immutable.fromJS({\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n});\nvar userManagementStateBefore = Immutable.fromJS({\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n});\nvar expectedUserManagementStateAfter = Immutable.fromJS({\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n--- Page 220 ---\n192 CHAPTER 9 Persistent data structures\n}\n}\n});\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\nImmutable.isEqual(result, expectedUserManagementStateAfter);\n// → true\nJoe Great!\n9.4.3 Serialization and deserialization\nTheo Does Immutable.js also support JSON serialization and deserialization?\nJoe It supports serialization out of the box. As for deserialization, we need to write\nour own function.\nTheo Does Immutable.js provide an Immutable.stringify() function?\nJoe That’s not necessary because the native JSON.stringify() function works\nwith Immutable.js objects. Here’s another example.\nListing9.17 JSON serialization of an Immutable.js collection\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nJSON.stringify(bookInfo);\n// → {\\\"isbn\\\":\\\"978-1779501127\\\",\\\"title\\\":\\\"Watchmen\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}\nTheo How does JSON.stringify() know how to handle an Immutable.js collection?\nJoe As an OOP developer, you shouldn’t be surprised by that.\nTheo Hmm...let me think a minute. OK, here’s my guess. Is that because JSON\n.stringify() calls some method on its argument?\nJoe Exactly! If the object passed to JSON.stringify() has a .toJSON() method,\nit’s called by JSON.stringify().\nTheo Nice. What about JSON deserialization?\nJoe That needs to be done in two steps. You first convert the JSON string to a Java-\nScript object and then to an immutable collection.\nTheo Something like this piece of code?\nListing9.18 Converting a JSON string into an immutable collection\nImmutable.parseJSON = function(jsonString) {\nreturn Immutable.fromJS(JSON.parse(jsonString));\n};\nJoe Exactly.\n--- Page 221 ---\n9.4 Persistent data structures in action 193\n9.4.4 Structural diff\nTheo So far, we have ported pieces of code that dealt with simple data manipula-\ntions. I’m curious to see how it goes with complex data manipulations such as\nthe code that computes the structural diff between two maps.\n NOTE Chapter 5 introduces structural diff.\nJoe That also works smoothly, but we need to port another eight functions.\nListing9.19 Porting Lodash functions involved in structural diff computation\nImmutable.reduce = function(coll, reducer, initialReduction) {\nreturn coll.reduce(reducer, initialReduction);\n};\nImmutable.isEmpty = function(coll) {\nreturn coll.isEmpty();\n};\nImmutable.keys = function(coll) {\nreturn coll.keySeq();\n};\nImmutable.isObject = function(coll) {\nreturn Immutable.Map.isMap(coll);\n};\nImmutable.isArray = Immutable.isIndexed;\nImmutable.union = function() {\nreturn Immutable.Set.union(arguments);\n};\nTheo Everything looks trivial with one exception: the use of arguments in Immutable\n.union.\nJoe In JavaScript, arguments is an implicit array-like object that contains the values\nof the function arguments.\nTheo I see. It’s one of those pieces of JavaScript magic!\nJoe Yep. We need to use arguments because Lodash and Immutable.js differ slightly\nin the signature of the union function. Immutable.Set.union receives an array\nof lists, whereas a Lodash _.union receives several arrays.\nTheo Makes sense. Let me give it a try.\nBlowing on his fingers like a seasoned safecracker, first one hand and then the next, Theo\nbegins typing. Once again, Theo is surprised to discover that after replacing the _ with\nImmutable in listing 9.20, the tests pass with the code in listing 9.21.\nListing9.20 Implementing structural diff with persistent data structures\nfunction diffObjects(data1, data2) {\nvar emptyObject = Immutable.isArray(data1) ?\nImmutable.fromJS([]) :\n--- Page 222 ---\n194 CHAPTER 9 Persistent data structures\nImmutable.fromJS({});\nif(data1 == data2) {\nreturn emptyObject;\n}\nvar keys = Immutable.union(Immutable.keys(data1), Immutable.keys(data2));\nreturn Immutable.reduce(keys,\nfunction (acc, k) {\nvar res = diff(Immutable.get(data1, k),\nImmutable.get(data2, k));\nif((Immutable.isObject(res) && Immutable.isEmpty(res)) ||\n(res == \"data-diff:no-diff\")) {\nreturn acc;\n}\nreturn Immutable.set(acc, k, res);\n},\nemptyObject);\n}\nfunction diff(data1, data2) {\nif(Immutable.isObject(data1) && Immutable.isObject(data2)) {\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"data-diff:no-diff\";\n}\nListing9.21 Testing structural diff with persistent data structures\nvar data1 = Immutable.fromJS({\ng: {\nc: 3\n},\nx: 2,\ny: {\nz: 1\n},\nw: [5]\n});\nvar data2 = Immutable.fromJS({\ng: {\nc:3\n},\nx: 2,\ny: {\nz: 2\n},\nw: [4]\n});\nImmutable.isEqual(diff(data1, data2),\nImmutable.fromJS({\n--- Page 223 ---\nSummary 195\n\"w\": [\n4\n],\n\"y\": {\n\"z\": 2\n}\n}));\nJoe What do you think of all this, my friend?\nTheo I think that using persistent data collections with a library like Immutable.js is\nmuch easier than understanding the internals of persistent data structures. But\nI’m also glad that I know how it works under the hood.\nAfter accompanying Joe to the office door, Theo meets Dave. Dave had been peering\nthrough the window in Theo’s office, looking at the whiteboard, anxious to catch a glimpse\nof today’s topic on DOP.\nDave What did Joe teach you today?\nTheo He took me to the university and taught me the foundations of persistent data\nstructures for dealing with immutability at scale.\nDave What’s wrong with the structural sharing that I implemented a couple of\nmonths ago?\nTheo When the number of elements in the collection is big enough, naive structural\nsharing has performance issues.\nDave I see. Could you tell me more about that?\nTheo I’d love to, but my brain isn’t functioning properly after this interesting but\nexhausting day. We’ll do it soon, promise.\nDave No worries. Have a nice evening, Theo.\nTheo You too, Dave.\nSummary\n It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\n At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\n Naive structural sharing doesn’t prevent data structures from being accidentally\nmutated.\n Immutable collections are not the same as persistent data structures.\n Immutable collections don’t provide an efficient way to create new versions of\nthe collections.\n Persistent data structures protect data from mutation.\n Persistent data structures provide an efficient way to create new versions of the\ncollections.\n Persistent data structures always preserve the previous version of themselves when\nthey are modified.\n--- Page 224 ---\n196 CHAPTER 9 Persistent data structures\n Persistent data structures represent data internally in such a way that structural\nsharing scales well, both in terms of memory and computation.\n When data is immutable, it is safe to share it.\n Internally, persistence uses a branching factor of 32.\n In practice, manipulation of persistent data structures is efficient even for col-\nlections with 10 billion entries!\n Due to modern architecture considerations, the performance of updating a\npersistent list is dominated much more by the depth of the tree than by the\nnumber of nodes at each level of the tree.\n Persistent lists can be manipulated in near constant time.\n In most languages, third-party libraries provide an implementation of persistent\ndata structures.\n Paguro collections implement the read-only parts of Java collection interfaces.\n Paguro collections can be passed to any methods that expect to receive a Java\ncollection without mutating them.\n--- Page 225 ---\nDatabase operations\nA cloud is a cloud\nThis chapter covers\n Fetching data from the database\n Storing data in the database\n Manipulating data fetched from the database\nTraditionally in OOP, we use design patterns and complex layers of objects to struc-\nture access to the database. In DOP, we prefer to represent data fetched from the\ndatabase with generic data collections, namely, lists of maps, where fields in the\nmaps correspond to database column values. As we’ll see throughout the chapter,\nthe fact that fields inside a map are accessible dynamically via their names allows us\nto use the same generic code for different data entities.\nTIP The best way to manipulate data is to represent data as data.\nIn this chapter, we’ll illustrate the application of data-oriented principles when\naccessing data from a relational database. Basic knowledge of relational database\nand SQL query syntax (like SELECT, AS, WHERE, and INNER JOIN) is assumed. This\napproach can be easily adapted to NoSQL databases.\n197\n--- Page 226 ---\n198 CHAPTER 10 Database operations\nApplications that run on the server usually store data in a database. In DOP, we\nrepresent data retrieved from the database the same way we represent any other data\nin our application—with generic data collections. This leads to\n Reduced system complexity.\n Increased genericity.\n10.1 Fetching data from the database\nTheo and Joe go for a walk in a park near the office. They sit on a bench close to a beau-\ntiful lake and gaze at the clouds in the sky. After a couple of minutes of meditative\nsilence, Joe asks Theo, “What do you see?” Theo tells him that this cloud looks to him\nlike a horse, and that one looks like a car. On their way back to the office, Theo asks Joe\nfor an explanation about the clouds. Joe answers with a mysterious smile on his lips, “A\ncloud is a cloud.”\nTheo So far you’ve shown me how DOP represents data that lives in the memory of\nthe application. What about data that comes from the outside?\nJoe What do you mean by outside?\nTheo Data that comes from the database.\nJoe I’ll return the question to you. How do you think that we should represent data\nthat comes from the database in DOP?\nTheo As generic data collections, I guess.\nJoe Exactly! In DOP, we always represent data with generic data collections.\nTheo Does that mean that we can manipulate data from the database with the same\nflexibility as we manipulate in-memory data?\nJoe Definitely.\nTIP In DOP, we represent data from the database with generic data collections, and\nwe manipulate it with generic functions.\nTheo Would you show me how to retrieve book search results when the catalog data\nis stored in an SQL database?\nJoe I’ll show you in a moment. First, tell me how you would design the tables that\nstore catalog data.\nTheo Do you mean the exact table schemas with the information about primary keys\nand nullability of each and every column?\nJoe No, I only need a rough overview of the tables, their columns, and the relation-\nships between the tables.\nTheo goes to the whiteboard. Figure 10.1 shows the diagram he draws as he explains his\nthinking to Joe.\n--- Page 227 ---\n10.1 Fetching data from the database 199\nT books\nT authors\nisbn VARCHAR[32]\nid VARCHAR[64]\ntitle VARCHAR[64]\nname VARCHAR[64]\npublication_year INTEGER\n1\nA book 1 An author\nmay have may author\nmany authors. many books.\n* *\nbook_authors\nT (relationships of books and authors)\nbook_isbn VARCHAR[32] Figure 10.1 The database model\nauthor_id VARCHAR[64]\nfor books and authors\nTheo I have a books table with three columns: title, isbn, and publication_\nyear. I also have an authors table with two columns: for id and name. Here,\nlet me draw these tables on the whiteboard to give you a visual (see tables 10.1\nand 10.2).\nTable 10.1 The books table filled with two books\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nTable 10.2 The authors table filled with three authors\nid name\nsean-covey Sean Covey\nstephen-covey Stephen Covey\ncharles-duhigg Charles Duhigg\nJoe What about the connection between books and authors?\nTheo Let’s see, a book could be written by multiple authors, and an author could write\nmultiple books. Therefore, I need a many-to-many book_authors table that con-\nnects authors and books with two columns, book_isbn and author_id.\nTheo once again turns to the whiteboard. He pens the book_authors table 10.3 to show Joe.\nTable 10.3 The book_authors table with rows connecting books with their authors\nbook_isbn author_id\n978-1982137274 sean-covey\n978-1982137274 stephen-covey\n978-0812981605 charles-duhigg\n--- Page 228 ---\n200 CHAPTER 10 Database operations\nJoe Great! Let’s start with the simplest case. We’re going to write code that searches\nfor books matching a title and that returns basic information about the books.\nBy basic information, I mean title, ISBN, and publication year.\nTheo What about the book authors?\nJoe We’ll deal with that later, as it’s a bit more complicated. Can you write an SQL\nquery for retrieving books that contain he word habit in their title?\nTheo Sure.\nThis assignment is quite easy for Theo. First, he jots down the SQL query, then he displays\nthe results in table 10.4.\nListing10.1 SQL query to retrieve books whose title contains habit\nSELECT\ntitle,\nisbn,\npublication_year\nFROM\nbooks\nWHERE title LIKE '%habit%';\nTable 10.4 Results of the SQL query for books whose title contains the word habit\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nJoe How would you describe these results as a data collection?\nTheo I would say it’s a list of maps.\nTIP In DOP, accessing data from a NoSQL database is similar to the way we access\ndata from a relational database.\nJoe Right! Now, can you write the search results as a list of maps?\nTheo It doesn’t sound too complicated. How about this?\nListing10.2 Search results as a list of maps\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"publication_year\": 1989\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"publication_year\": 2012\n}\n]\n--- Page 229 ---\n10.1 Fetching data from the database 201\nJoe What about the JSON schema for the search results?\nTheo It shouldn’t be too difficult if you allow me to take a look at the JSON schema\ncheat sheet you kindly offered me the other day.\nJoe Of course. The purpose of a gift is to be used by the one who receives it.\nTheo takes a look at the JSON Schema cheat sheet to refresh his memory about the JSON\nSchema syntax. After a few minutes, Theo comes up with a schema for the search results.\nHe certainly is putting Joe’s gift to good use.\nListing10.3 JSON schema cheat sheet\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"myNumber\": {\"type\": \"number\"},\n\"myString\": {\"type\": \"string\"},\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\n\"myBool\": {\"type\": \"boolean\"}\n},\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\n}\n}\nListing10.4 The JSON schema for search results from the database\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"publication_year\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"publication_year\": {\"type\": \"integer\"}\n}\n}\n};\nJoe Excellent. Now I’m going to show you how to implement searchBooks in a\nway that fetches data from the database and returns a JSON string with the\nresults. The cool thing is that we’re only going to use generic data collections\nfrom the database layer down to the JSON serialization.\nTheo Will it be similar to the implementation of searchBooks that we wrote when\nyou taught me the basis of DOP?\nJoe Absolutely. The only difference is that then the state of the system was stored\nlocally, and we queried it with a function like _.filter. Now, we use SQL\n--- Page 230 ---\n202 CHAPTER 10 Database operations\nqueries to fetch the state from the database. In terms of data representation\nand manipulation, it’s exactly the same.\nJoe goes to the whiteboard and sketches out the data flow in figure 10.2. Theo studies the\ndiagram.\nDatabase\nDatabase driver\nData (list of maps)\nData manipulation\nData Figure 10.2 Data flow for serving\na request that fetches data from\nJSON serialize\nthe database\nJoe The data manipulation step in the diagram is implemented via generic func-\ntions that manipulate data collections. As our examples get more elaborate, I\nthink you’ll see the benefits of being able to manipulate data collections with\ngeneric functions.\nTheo Sounds intriguing...\nJoe For the communication with the database, we use a driver that returns a list of\nmaps. In JavaScript, you could use an SQL driver like node-postgres.\n NOTE See https://node-postgres.com for more information about this collection of\nnode.js modules for interfacing with PostgreSQL databases.\nTheo And in Java?\nJoe In Java, you could use JDBC (Java database connectivity) in addition to a small\nutility function that converts a JDBC result set into a list of maps. If I can use\nyour laptop, I’ll show you what I mean.\nJoe pulls a piece of code from one of his personal GitHub repositories. He then shows the\ncode for the JDBC conversion to Theo, who seems a bit surprised.\nListing10.5 Converting a JDBC result set into a list of hash maps\nList<Map<String, Object>> convertJDBCResultSetToListOfMaps(ResultSet rs) {\nList<Map<String, Object>> listOfMaps =\nnew ArrayList<Map<String, Object>>();\nResultSetMetaData meta = rs.getMetaData();\nwhile (rs.next()) {\nMap map = new HashMap();\nfor (int i = 1; i <= meta.getColumnCount(); i++) {\nString key = meta.getColumnLabel(i);\nObject value = rs.getObject(i);\n--- Page 231 ---\n10.1 Fetching data from the database 203\nmap.put(key, value);\n}\nlistOfMaps.add(map);\n}\nreturn listOfMaps;\n}\nTIP Converting a JDBC result set into a list of hash maps is quite straightforward.\nTheo I expected it to be much more complicated to convert a JDBC result set into a\nlist of hash maps.\nJoe It’s straightforward because, in a sense, JDBC is data-oriented.\nTheo What about the field types?\nJoe When we convert a JDBC result set into a list of maps, each value is considered\nan Object.\nTheo That’s annoying because it means that in order to access the value, we need to\ncast it to its type.\nJoe Yes and no. Look at our book search use case. We pass all the values along with-\nout really looking at their type. The concrete value type only matters when we\nserialize the result into JSON and that’s handled by the JSON serialization\nlibrary. It’s called late binding.\n NOTE With late binding, we defer dealing with data types as long as possible.\nTheo Does that mean in my application that I’m allowed to manipulate data without\ndealing with concrete types?\nTIP In DOP, flexibility is increased as many parts of the system are free to manipulate\ndata without dealing with concrete types.\nJoe Exactly. You’ll see late binding in action in a moment. That’s one of the great-\nest benefits of DOP.\nTheo Interesting, I can’t wait to see that!\nJoe One last thing before I show you the code for retrieving search results from the\ndatabase. In order to make it easier to read, I’m going to write JavaScript code\nas if JavaScript were dealing with I/O is a synchronous way.\nTheo What do you mean?\nJoe In JavaScript, an I/O operation like sending a query to the database is done\nasynchronously. In real life, it means using either callback functions or using\nasync and await keywords.\nTheo Oh yeah, that’s because JavaScript is single-threaded.\n NOTE For sake of simplicity, the JavaScript snippets in this chapter are written as if\nJavaScript were dealing with I/O in a synchronous way. In real-life JavaScript, we need\nto use async and await around I/O calls.\nJoe Indeed, so I’ll be writing the code that communicates with the database as\nthough JavaScript were dealing with I/O synchronously. Here’s an example.\n--- Page 232 ---\n204 CHAPTER 10 Database operations\nListing10.6 Searching books in the database, returning the results in JSON\ndbClient holds the Initializes Ajv (a JSON schema validation\nvar dbClient; DB connection. library) with allErrors: true to catch all\nthe data validation errors\nvar ajv = new Ajv({allErrors: true});\nvar title = \"habit\";\nvar matchingBooksQuery = `SELECT title, isbn Uses a parameterized\nSQL query as a security\nFROM books\nbest practice\nWHERE title LIKE '%$1%'`;\nvar books = dbClient.query(matchingBooksQuery,\nPasses the parameters to the SQL\n[title]);\nquery as a list of values (in our\nif(!ajv.validate(dbSearchResultSchema, books)) {\ncase, a list with a single value)\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" + errors;\n}\nJSON.stringify(books);\nTheo In a dynamically-typed language like JavaScript, I understand that the types of\nthe values in the list of maps returned by dbClient.query are determined at\nrun time. How does it work in a statically-typed language like Java, and what are\nthe types of the data fields in books?\nJoe The function convertJDBCResultSetToListOfMaps we created earlier (see\nlisting 10.5) returns a list of Map<String, Object>. But JSON serialization\nlibraries like Gson know how to detect at run time the concrete type of the val-\nues in a map and serialize the values according to their type.\n NOTE See https://github.com/google/gson for information about Gson’s Java\nserialization/deserialization library.\nTheo What do you mean by serializing a value according to its type?\nJoe For instance, the value of the field publication_year is a number; therefore,\nit is not wrapped with quotes. However, the value of the field title is a string;\ntherefore, it is wrapped with quotes.\nTheo Nice! Now, I understand what you mean by late binding.\nJoe Cool! Now, let me show you how we store data in the database.\n10.2 Storing data in the database\nIn the previous section, we saw how to retrieve data from the database as a list of maps.\nNext, we’ll see how to store data in the database when data is represented with a map.\nTheo I guess that storing data in the database is quite similar to fetching data from\nthe database.\nJoe It’s similar in the sense that we deal only with generic data collections. Can you\nwrite a parameterized SQL query that inserts a row with user info using only\nemail and encrypted_password, please?\nTheo OK.",
        "sections_found": []
      },
      "accurate_page_range": "202-232"
    },
    {
      "text": "- 8.3 Thread-safe cache with atoms",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "8 Advanced concurrency control",
      "raw_line": "- 8.3 Thread-safe cache with atoms (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 67,
      "chapter_info": {
        "page": 202,
        "title": "Advanced concurrency control",
        "pattern_matched": "Chapter 8",
        "text_preview": "174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do yo"
      },
      "chapter_sections": {
        "start_page": 202,
        "end_page": 232,
        "content": "\n--- Page 202 ---\n174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do you mean?\nTheo I don’t know, but I am under the impression that mutexes are like phone calls,\nand atoms are like text messages.\nJoe smiles at Theo but doesn’t reveal the meaning of his smile. After the phone deadlock\nyesterday, Theo’s pretty sure that he and Joe are on the same page.\nSummary\n Managing concurrency with atoms is much simpler than managing concur-\nrency with locks because we don’t have to deal with the risk of deadlocks.\n Cloning data to avoid read locks doesn’t scale.\n When data is immutable, reads are always safe.\n Atoms provide a way to manage concurrency without locks.\n With atoms, deadlocks never happen.\n Using atoms for a thread-safe counter is trivial because the state of the counter\nis represented with a primitive type (an integer).\n We can manage composite data in a thread-safe way with atoms.\n We make the highly scalable state management approach from part 1 thread-\nsafe by keeping the whole system state inside an atom.\n It’s quite common to represent an in-memory cache as a string map.\n When data is immutable, it is safe (and fast) to compare by reference.\n In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing besides swapping an atom.\n In practice, once an atom is swapped, the threads do some real work (e.g.,\ndatabase access) to provide an opportunity for other threads to swap the atom\nsuccessfully.\n--- Page 203 ---\nPersistent data structures\nStanding on the shoulders of giants\nThis chapter covers\n The internal details of persistent data\nstructures\n The time and memory efficiency of persistent\ndata structures\n Using persistent data structures in an\napplication\nIn part 1, we illustrated how to manage the state of a system without mutating data,\nwhere immutability is maintained by constraining ourselves to manipulate the state\nonly with immutable functions using structural sharing. In this chapter, we present\na safer and more scalable way to preserve data immutability—representing data\nwith so-called persistent data structures. Efficient implementations of persistent\ndata structures exist for most programming languages via third-party libraries.\n9.1 The need for persistent data structures\nIt’s at the university where Theo meets Joe this time. When Theo asks Joe if today’s topic\nis academic in nature, Joe tells him that the use of persistent data structures only\nbecame possible in programming languages following a discovery in 2001 by a computer\n175\n--- Page 204 ---\n176 CHAPTER 9 Persistent data structures\nresearcher named Phil Bagwell.1 In 2007, Rich Hickey, the creator of Clojure, used this dis-\ncovery as the foundation of persistent data structures in Clojure. Unveiling the secrets of\nthese data structures to Theo in a university classroom is a way for Joe to honor the mem-\nory of Phil Bagwell, who unfortunately passed away in 2012. When they get to the univer-\nsity classroom, Joe starts the conversation with a question.\nJoe Are you getting used to DOP’s prohibition against mutating data in place and\ncreating new versions instead?\nTheo I think so, but two things bother me about the idea of structural sharing that\nyou showed me.\nJoe What bothers you, my friend?\nTheo Safety and performance.\nJoe What do you mean by safety?\nTheo I mean that using immutable functions to manipulate data doesn’t prevent it\nfrom being modified accidentally.\nJoe Right! Would you like me to show you the naive way to handle immutability or\nthe real way?\nTheo What are the pros and cons of each way?\nJoe The naive way is easy but not efficient, although the real way is efficient but\nnot easy.\nTheo Let’s start with the naive way then.\nJoe Each programming language provides its own way to protect data from being\nmutated.\nTheo How would I do that in Java, for instance?\nJoe Java provides immutable collections, and there is a way to convert a list or a\nmap to an immutable list or an immutable map.\n NOTE Immutable collections are not the same as persistent data structures.\nJoe opens his laptop and fires it up. He brings up two code examples, one for immutable\nlists and one for immutable maps.\nListing9.1 Converting a mutable list to an immutable list in Java\nvar myList = new ArrayList<Integer>();\nmyList.add(1);\nmyList.add(2);\nmyList.add(3);\nvar myImmutableList = List.of(myList.toArray());\n1 P. Bagwell, “Ideal hash trees” (No. REP_WORK), 2001. [Online]. Available: https://lampwww.epfl.ch/papers/\nidealhashtrees.pdf.\n--- Page 205 ---\n9.1 The need for persistent data structures 177\nListing9.2 Converting a mutable map to an immutable map in Java\nvar myMap = new HashMap<String, Object>();\nmyMap.put(\"name\", \"Isaac\");\nmyMap.put(\"age\", 42);\nvar myImmutableMap = Collections.unmodifiableMap(myMap);\nTheo What happens when you try to modify an immutable collection?\nJoe Java throws an UnsupportedOperationException.\nTheo And in JavaScript?\nJoe JavaScript provides an Object.freeze() function that prevents data from\nbeing mutated. It works both with JavaScript arrays and objects.\nJoe takes a minute to scroll through his laptop. When he finds what he’s looking for, he\nshows Theo the code.\nListing9.3 Making an object immutable in JavaScript\nvar a = [1, 2, 3];\nObject.freeze(a);\nvar b = {foo: 1};\nObject.freeze(b);\nTheo What happens when you try to modify a frozen object?\nJoe It depends. In JavaScript strict mode, a TypeError exception is thrown, and in\nnonstrict mode, it fails silently.\n NOTE JavaScript’s strict mode is a way to opt in to a restricted variant of JavaScript\nthat changes some silent errors to throw errors.\nTheo In case of a nested collection, are the nested collections also frozen?\nJoe No, but in JavaScript, one can write a deepFreeze() function that freezes an\nobject recursively. Here’s another example.\nListing9.4 Freezing an object recursively in JavaScript\nfunction deepFreeze(object) {\n// Retrieve the property names defined on object\nconst propNames = Object.getOwnPropertyNames(object);\n// Freeze properties before freezing self\nfor (const name of propNames) {\nconst value = object[name];\nif (value && typeof value === \"object\") {\ndeepFreeze(value);\n}\n}\n--- Page 206 ---\n178 CHAPTER 9 Persistent data structures\nreturn Object.freeze(object);\n}\nTheo I see that it’s possible to ensure that data is never mutated, which answers my\nconcerns about safety. Now, let me share my concerns about performance.\nTIP It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\nJoe Sure.\nTheo If I understand correctly, the main idea behind structural sharing is that most\ndata is usually shared between two versions.\nJoe Correct.\nTheo This insight allows us to create new versions of our collections using a shallow\ncopy instead of a deep copy, and you claimed that it was efficient.\nJoe Exactly!\nTheo Now, here is my concern. In the case of a collection with many entries, a shal-\nlow copy might be expensive.\nJoe Could you give me an example of a collection with many entries?\nTheo A catalog with 100,000 books, for instance.\nJoe On my machine, making a shallow copy of a collection with 100,000 entries\ndoesn’t take more than 50 milliseconds.\nTheo Sometimes, even 50 milliseconds per update isn’t acceptable.\nJoe I totally agree with you. When one needs data immutability at scale, naive struc-\ntural sharing is not appropriate.\nTheo Also, shallow copying an array of 100,000 elements on each update would\nincrease the program memory by 100 KB.\nJoe Indeed, at scale, we have a problem both with memory and computation.\nTIP At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\nTheo Is there a better solution?\nJoe Yes! For that, you’ll need to learn the real way to handle immutability. It’s\ncalled persistent data structures.\n9.2 The efficiency of persistent data structures\nTheo In what sense are those data structures persistent?\nJoe Persistent data structures are so named because they always preserve their pre-\nvious versions.\nTIP Persistent data structures always preserve the previous version of themselves\nwhen they are modified.\nJoe Persistent data structures address the two main limitations of naive structural\nsharing: safety and performance.\n--- Page 207 ---\n9.2 The efficiency of persistent data structures 179\nTheo Let’s start with safety. How do persistent data structures prevent data from\nbeing mutated accidentally?\nJoe In a language like Java, they implement the mutation methods of the collec-\ntion interfaces by throwing the run-time exception UnsupportedOperation-\nException.\nTheo And, in a language like JavaScript?\nJoe In JavaScript, persistent data structures provide their own methods to access\ndata, and none of those methods mutate data.\nTheo Does that mean that we can’t use the dot notation to access fields?\nJoe Correct. Fields of persistent data structures are accessed via a specific API.\nTheo What about efficiency? How do persistent data structures make it possible to\ncreate a new version of a huge collection in an efficient way?\nJoe Persistent data structures organize data in such a way that we can use structural\nsharing at the level of the data structure.\nTheo Could you explain?\nJoe Certainly. Let’s start with the simplest data structure: a linked list. Imagine that\nyou have a linked list with 100,000 elements.\nTheo OK.\nJoe What would it take to prepend an element to the head of the list?\nTheo You mean to create a new version of the list with an additional element?\nJoe Exactly!\nTheo Well, we could copy the list and then prepend an element to the list, but it\nwould be quite expensive.\nJoe What if I tell you that the original linked list is guaranteed to be immutable?\nTheo In that case, I could create a new list with a new head that points to the head of\nthe original list.\nTheo goes to the classroom blackboard. He picks up a piece of chalk and draws the dia-\ngram shown in figure 9.1.\nNew list Original list\nFigure 9.1 Structural sharing\n0 1 2 3 4 5 with linked lists\nJoe Would the efficiency of this operation depend on the size of the list?\nTheo No, it would be efficient, no matter the size of the list.\nJoe That’s what I mean by structural sharing at the level of the data structure itself.\nIt relies on a simple but powerful insight—when data is immutable, it is safe to\nshare it.\nTIP When data is immutable, it is safe to share it.\n--- Page 208 ---\n180 CHAPTER 9 Persistent data structures\nTheo I understand how to use structural sharing at the level of the data structure for\nlinked lists and prepend operations, but how would it work with operations\nlike appending or modifying an element in a list?\nJoe For that purpose, we need to be smarter and represent our list as a tree.\nTheo How does that help?\nJoe It helps because when a list is represented as a tree, most of the nodes in the\ntree can be shared between two versions of the list.\nTheo I am totally confused.\nJoe Imagine that you take a list with 100,000 elements and split it into two lists of\n50,000 elements each: elements 0 to 49,999 in list 1, and elements 50,000 to\n99,999 in list 2. How many operations would you need to create a new version\nof the list where a single element—let’s say, element at index 75,100—is\nmodified?\nIt’s hard for Theo to visualize this kind of stuff mentally. He goes back to the blackboard\nand draws a diagram (see figure 9.2). Once Theo looks at the diagram, it’s easy for him to\nanswer Joe’s question.\nList «Next»\nList\nList 1 List 2\n«Next»\n0...49,999 50,000...99,999\nList 2\nFigure 9.2 Structural sharing when\n50,000...99,999\na list of 100,000 elements is split\nTheo List 1 could be shared with one operation. I’d need to create a new version of\nlist 2, where element 75,100 is modified. It would take 50,000 operations, so it’s\none operation of sharing and one operation of copying 50,000 elements. Over-\nall, it’s 50,001 operations.\nJoe Correct. You see that by splitting our original list into two lists, we can create a\nnew version of the list with a number of operations in the order of the size of\nthe list divided by 2.\nTheo I agree, but 50,000 is still a big number.\nJoe Indeed, but nobody prevents us from applying the same trick again, splitting\nlist 1 and list 2 in two lists each.\nTheo How exactly?\nJoe We can make list 1.1 with elements 0 to 24,999, then list 1.2 with elements\n25,000 to 49,999, list 2.1 with elements 50,000 to 74,999, and list 2.2 with ele-\nments 75,000 to 99,999.\nTheo Can you draw that on the blackboard?\nJoe Sure.\n--- Page 209 ---\n9.2 The efficiency of persistent data structures 181\nNow, it’s Joe that goes to the blackboard. He draws the diagram in figure 9.3.\n«Next»\nList\nList\n«Next»\nList 1 List 2 List 2\nList 1.1 List 1.2 List 2.1 List 2.2 «Next»\n0...24,499 25,000...49,999 50,000...74,999 75,000...99,999 List 2.2\n75,000...99,999\nFigure 9.3 Structural sharing when a list of 100,000 elements is split twice\nTheo Let me count the number of operations for updating a single element. It takes\n2 operations of sharing and 1 operation of copying 25,000 elements. Overall, it\ntakes 25,002 operations to create a new version of the list.\nJoe Correct!\nTheo Let’s split the list again then!\nJoe Absolutely. In fact, we can split the list again and again until the size of the\nlists is at most 2. Can you guess what is the complexity of creating a new ver-\nsion then?\nTheo I’d say around log2 N operations.\nJoe I see that you remember well your material from school. Do you have a gut\nfeeling about what is log2 N when N is 100,000?\nTheo Let me see...2 to the power of 10 is around 1,000, and 2 to the power of 7 is\n128. So, it should be a bit less than 17.\nJoe It’s 16.6 to be precise. It means that in order to update an element in a per-\nsistent list of 100,000 elements, we need around 17 operations. The same goes\nfor accessing elements.\nTheo Nice, but 17 is still not negligible.\nJoe I agree. We can easily improve the performance of accessing elements by using\na higher branching factor in our tree.\nTheo What do you mean?\nJoe Instead of splitting by 2 at each level, we could split by 32.\nTheo But the running time of our algorithm would still grow with log N.\nJoe You’re right. From a theoretical perspective, it’s the same. From a practical\nperspective, however, it makes a big difference.\nTheo Why?\nJoe Because log32 N is 5 times lower than log2 N.\n--- Page 210 ---\n182 CHAPTER 9 Persistent data structures\nTheo That’s true: 2 to the power of 5 is 32.\nJoe Back to our list of 100,000 elements, can you tell me how many operations are\nrequired to access an element if the branching factor is 32?\nTheo With a branching factor of 2, it was 16.6. If I divide 16.6 by 5, I get 3.3.\nJoe Correct!\nTIP By using a branching factor of 32, we make elements accessed in persistent lists\nmore efficient.\nTheo Does this trick also improve the performance of updating an element in a list?\nJoe Yes, indeed, it does.\nTheo How? We’d have to copy 32 elements at each level instead of 2 elements. It’s a\n16× performance hit that’s not compensated for by the fact that the tree depth\nis reduced by 5×!\nJoe I see that you are quite sharp with numbers. There is another thing to take\ninto consideration in our practical analysis of the performance: modern CPU\narchitecture.\nTheo Interesting. The more you tell me about persistent data structures, the more I\nunderstand why you wanted to have this session at a university: it’s because\nwe’re dealing with all this academic stuff.\nJoe Yep. So, to continue, modern CPUs read and write data from and to the main\nmemory in units of cache lines, often 32 or 64 bytes long.\nTheo What difference does that make?\nJoe A nice consequence of this data access pattern is that copying an array of size\n32 is much faster than copying 16 arrays of size 2 that belong to different levels\nof the tree.\nTheo Why is that?\nJoe The reason is that copying an array of size 32 can be done in a single pair of\ncache accesses: one for read and one for write. Although for arrays that belong\nto different tree levels, each array requires its own pair of cache accesses, even\nif there are only 2 elements in the array.\nTheo In other words, the performance of updating a persistent list is dominated by\nthe depth of the tree.\nTIP In modern CPU architectures, the performance of updating a persistent list is\ndominated much more by the depth of the tree than by the number of nodes at each\nlevel of the tree.\nJoe That’s correct, up to a certain point. With today’s CPUs, using a branching fac-\ntor of 64 would, in fact, decrease the performance of update operations.\nTheo I see.\nJoe Now, I am going to make another interesting claim that is not accurate from a\ntheoretical perspective but accurate in practice.\nTheo What is it?\n--- Page 211 ---\n9.2 The efficiency of persistent data structures 183\nJoe The number of operations it takes to get or update an element in a persistent\nlist with branching factor 32 is constant.\nTheo How can that be? You just made the point that the number of operations is\nlog32 N.\nJoe Be patient, my friend. What is the highest number of elements that you can\nhave in a list, in practice?\nTheo I don’t know. I never thought about that.\nJoe Let’s assume that it takes 4 bytes to store an element in a list.\nTheo OK.\nJoe Now, can you tell me how much memory it would take to hold a list with 10 bil-\nlion elements?\nTheo You mean 1 with 10 zeros?\nJoe Yes.\nTheo Each element take 4 bytes, so it would be around 40 GB!\nJoe Correct. Do you agree that it doesn’t make sense to hold a list that takes 40 GB\nof memory?\nTheo I agree.\nJoe So let’s take 10 billion as an upper bound to the number of elements in a list.\nWhat is log32 of 10 billion?\nOnce again, Theo uses the blackboard to clarify his thoughts. With that, he quickly finds\nthe answer.\nTheo 1 billion is approximately 2^30. Therefore, 10 billion is around 2^33. That\nmeans that log2 of 10 billion is 33, so log32 of 10 billion should be around\n33/5, which is a bit less than 7.\nJoe I am impressed again by your sharpness with numbers. To be precise, log32 of\n10 billion is 6.64.\nTheo (smiling) I didn’t get that far.\nJoe Did I convince you that, in practice, accessing or updating an element in a per-\nsistent list is essentially constant?\nTheo Yes, and I find it quite amazing!\nTIP Persistent lists can be manipulated in near constant time.\nJoe Me too.\nTheo What about persistent maps?\nJoe It’s quite similar, but I don’t think we have time to discuss it now.\nStartled, Theo looks at his watch. This morning’s session has gone by so quickly. He notices\nthat it’s time to get back to the office and have lunch.\n--- Page 212 ---\n184 CHAPTER 9 Persistent data structures\n9.3 Persistent data structures libraries\nOn their way back to the office, Theo and Joe don’t talk too much. Theo’s thoughts take\nhim back to what he learned in the university classroom. He feels a lot of respect for Phil\nBagwell, who discovered how to manipulate persistent data structures efficiently, and for\nRich Hickey, who created a programming language incorporating that discovery as a core\nfeature and making it available to the world. Immediately after lunch, Theo asks Joe to\nshow him what it looks like to manipulate persistent data structures for real in a program-\nming language.\nTheo Are persistent data structures available in all programming languages?\nJoe A few programming languages like Clojure, Scala, and C# provide them as part\nof the language. In most programming languages, though, you need a third-\nparty library.\nTheo Could you give me a few references?\nJoe Sure.\nUsing Theo’s laptop, Joe bookmarks some sites. He knows exactly which URLs to look for.\nThen, while Theo is looking over the bookmarked sites, Joe goes to the whiteboard and\njots down the specific libraries in table 9.1.\n Immutable.js for JavaScript at https://immutable-js.com/\n Paguro for Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections for C# at http://mng.bz/QW51\n Pyrsistent for Python at https://github.com/tobgu/pyrsistent\n Hamster for Ruby at https://github.com/hamstergem/hamster\nTable 9.1 Persistent data structure libraries\nLanguage Library\nJavaScript Immutable.js\nJava Paguro\nC# Provided by the language\nPython Pyrsistent\nRuby Hamster\nTheo What does it take to integrate persistent data structures provided by a third-\nparty library into your code?\n9.3.1 Persistent data structures in Java\nJoe In an object-oriented language like Java, it’s quite straightforward to integrate\npersistent data structures in a program because persistent data structures\nimplement collection interfaces, besides the parts of the interface that mutate\nin place.\nTheo What do you mean?\n--- Page 213 ---\n9.3 Persistent data structures libraries 185\nJoe Take for instance, Paguro for Java. Paguro persistent maps implement the\nread-only methods of java.util.Map like get() and containsKey(), but not\nmethods like put() and remove(). On the other hand, Paguro vectors imple-\nment the read-only methods of java.util.List like get() and size(), but not\nmethods like set().\nTheo What happens when we call put() or remove() on a Paguro map?\nJoe It throws an UnSupportedOperationException exception.\nTheo What about iterating over the elements of a Paguro collection with a forEach()?\nJoe That works like it would in any Java collection. Here, let me show you an example.\nListing9.5 Iterating over a Paguro vector\nvar myVec = PersistentVector.ofIter(\nList.of(10, 2, 3));\nCreates a Paguro\nvector from a\nfor (Integer i : myVec) {\nJava list\nSystem.out.println(i);\n}\nTheo What about Java streams?\nJoe Paguro collections are Java collections, so they support the Java stream inter-\nface. Take a look at this code.\nListing9.6 Streaming a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvec1.stream().sorted().map(x -> x + 1);\nTIP Paguro collections implement the read-only parts of Java collection interfaces.\nTherefore, they can be passed to any methods that expect to receive a Java collection\nwithout mutating it.\nTheo So far, you told me how do use Paguro collections as Java read-only collections.\nHow do I make modifications to Paguro persistent data structures?\nJoe In a way similar to the _.set() function of Lodash FP that we talked about\nearlier. Instead of mutating in place, you create a new version.\nTheo What methods does Paguro expose for creating new versions of a data structure?\nJoe For vectors, you use replace(), and for maps, you use assoc().\nListing9.7 Creating a modified version of a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvar myNextVec = myVec.replace(0, 42);\n--- Page 214 ---\n186 CHAPTER 9 Persistent data structures\nListing9.8 Creating a modified version of a Paguro map\nvar myMap = PersistentHashMap.of(Map.of(\"aa\", 1, \"bb\", 2)\n.entrySet());\nCreates a Paguro map\nfrom a Java map entry set\nvar myNextMap = myMap.assoc(\"aa\", 42);\nTheo Yes! Now I see how to use persistent data structures in Java, but what about\nJavaScript?\n9.3.2 Persistent data structures in JavaScript\nJoe In a language like JavaScript, it’s a bit more cumbersome to integrate per-\nsistent data structures.\nTheo How so?\nJoe Because JavaScript objects and arrays don’t expose any interface.\nTheo Bummer.\nJoe It’s not as terrible as it sounds because Immutable.js exposes its own set of\nfunctions to manipulate its data structures.\nTheo What do you mean?\nJoe I’ll show you in a moment. But first, let me show you how to initiate Immutable.js\npersistent data structures.\nTheo OK!\nJoe Immutable.js provides a handy function that recursively converts a native data\nobject to an immutable one. It’s called Immutable.fromJS().\nTheo What do you mean by recursively?\nJoe Consider the map that holds library data from our Library Management Sys-\ntem: it has values that are themselves maps. Immutable.fromJS() converts the\nnested maps into immutable maps.\nTheo Could you show me some code?\nJoe Absolutely. Take a look at this JavaScript code for library data.\nListing9.9 Conversion to immutable data\nvar libraryData = Immutable.fromJS({\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n--- Page 215 ---\n9.3 Persistent data structures libraries 187\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n});\nTheo Do you mean that the catalog value in libraryData map is itself an immutable\nmap?\nJoe Yes, and the same for booksByIsbn, authorIds, and so forth.\nTheo Cool! So how do I access a field inside an immutable map?\nJoe As I told you, Immutable.js provides its own API for data access. For instance,\nin order to access a field inside an immutable map, you use Immutable.get()\nor Immutable.getIn() like the following.\nListing9.10 Accessing a field and a nested field in an immutable map\nImmutable.get(libraryData, \"catalog\");\nImmutable.getIn(libraryData,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nTheo How do I make a modification to a map?\nJoe Similar to what we did with Lodash FP, you use an Immutable.set() or\nImmutable.setIn() map to create a new version of the map where a field is\nmodified. Here’s how.\nListing9.11 Creating a new version of a map where a field is modified\nImmutable.setIn(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1988);\nTheo What happens when I try to access a field in the map using JavaScript’s dot or\nbracket notation?\nJoe You access the internal representation of the map instead of accessing a map\nfield.\nTheo Does that mean that we can’t pass data from Immutable.js to Lodash for data\nmanipulation?\nJoe Yes, but it’s quite easy to convert any immutable collection into a native Java-\nScript object back and forth.\nTheo How?\nJoe Immutable.js provides a toJS() method to convert an arbitrary deeply nested\nimmutable collection into a JavaScript object.\n--- Page 216 ---\n188 CHAPTER 9 Persistent data structures\nTheo But if I have a huge collection, it could take lots of time to convert it, right?\nJoe True. We need a better solution. Hopefully, Immutable.js provides its own set\nof data manipulation functions like map(), filter(), and reduce().\nTheo What if I need more data manipulation like Lodash’s _.groupBy()?\nJoe You could write your own data manipulation functions that work with the\nImmutable.js collections or use a library like mudash, which provides a port of\nLodash to Immutable.js.\n NOTE You can access the mudash library at https://github.com/brianneisler/mudash.\nTheo What would you advise?\nJoe A cup of coffee, then I’ll show you how to port functions from Lodash to\nImmutable.js and how to adapt the code from your Library Management System.\nYou can decide on whichever approach works best for your current project.\n9.4 Persistent data structures in action\nJoe Let’s start with our search query. Can you look at the current code and tell me\nthe Lodash functions that we used to implement the search query?\nTheo Including the code for the unit tests?\nJoe Of course!\n NOTE See chapter 6 for the unit test of the search query.\n9.4.1 Writing queries with persistent data structures\nTheo The Lodash functions we used were get, map, filter, and isEqual.\nJoe Here’s the port of those four functions from Lodash to Immutable.js.\nListing9.12 Porting some functions from Lodash to Immutable.js\nImmutable.map = function(coll, f) {\nreturn coll.map(f);\n};\nImmutable.filter = function(coll, f) {\nif(Immutable.isMap(coll)) {\nreturn coll.valueSeq().filter(f);\n}\nreturn coll.filter(f);\n};\nImmutable.isEqual = Immutable.is;\nTheo The code seems quite simple. But can you explain it to me, function by function?\nJoe Sure. Let’s start with get. For accessing a field in a map, Immutable.js provides\ntwo functions: get for direct fields and getIn for nested fields. It’s different\nfrom Lodash, where _.get works both on direct and nested fields.\n--- Page 217 ---\n9.4 Persistent data structures in action 189\nTheo What about map?\nJoe Immutable.js provides its own map function. The only difference is that it is a\nmethod of the collection, but it is something that we can easily adapt.\nTheo What about filter? How would you make it work both for arrays and maps\nlike Lodash’s filter?\nJoe Immutable.js provides a valueSeq method that returns the values of a map.\nTheo Cool. And what about isEqual to compare two collections?\nJoe That’s easy. Immutable.js provides a function named is that works exactly as\nisEqual.\nTheo So far, so good. What do I need to do now to make the code of the search\nquery work with Immutable.js?\nJoe You simply replace each occurrence of an _ with Immutable; _.map becomes\nImmutable.map, _.filter becomes Immutable.filter, and _.isEqual\nbecomes Immutable.isEqual.\nTheo I can’t believe it’s so easy!\nJoe Try it yourself; you’ll see. Sometimes, it’s a bit more cumbersome because\nyou need to convert the JavaScript objects to Immutable.js objects using\nImmutable.fromJS.\nTheo copies and pastes the snippets for the code and the unit tests of the search query.\nThen, he uses his IDE to replace the _ with Immutable. When Theo executes the tests and\nthey pass, he is surprised but satisfied. Joe smiles.\nListing9.13 Implementing book search with persistent data structures\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn Immutable.map(authorIds, function(authorId) {\nreturn Immutable.getIn(\ncatalogData,\n[\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = Immutable.Map({\n\"title\": Immutable.get(book, \"title\"),\n\"isbn\": Immutable.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(\ncatalogData,\nImmutable.get(book, \"authorIds\"))\n});\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = Immutable.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nvar matchingBooks = Immutable.filter(allBooks, function(book) {\n--- Page 218 ---\n190 CHAPTER 9 Persistent data structures\nreturn Immutable.get(book, \"title\").\ntoLowerCase().\nincludes(queryLowerCased);\n});\nvar bookInfos = Immutable.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nListing9.14 Testing book search with persistent data structures\nvar catalogData = Immutable.fromJS({\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n});\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Watchmen\"),\nImmutable.fromJS([bookInfo]));\n// → true\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Batman\"),\nImmutable.fromJS([]));\n// → true\n--- Page 219 ---\n9.4 Persistent data structures in action 191\n9.4.2 Writing mutations with persistent data structures\nTheo Shall we move forward and port the add member mutation?\nJoe Sure. Porting the add member mutation from Lodash to Immutable.js only\nrequires you to again replace the underscore (_) with Immutable. Let’s look at\nsome code.\nListing9.15 Implementing member addition with persistent data structures\nUserManagement.addMember = function(userManagement, member) {\nvar email = Immutable.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(Immutable.hasIn(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = Immutable.setIn(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo So, for the tests, I’d convert the JavaScript objects to Immutable.js objects with\nImmutable.fromJS(). How does this look?\nListing9.16 Testing member addition with persistent data structures\nvar jessie = Immutable.fromJS({\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n});\nvar franck = Immutable.fromJS({\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n});\nvar userManagementStateBefore = Immutable.fromJS({\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n});\nvar expectedUserManagementStateAfter = Immutable.fromJS({\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n--- Page 220 ---\n192 CHAPTER 9 Persistent data structures\n}\n}\n});\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\nImmutable.isEqual(result, expectedUserManagementStateAfter);\n// → true\nJoe Great!\n9.4.3 Serialization and deserialization\nTheo Does Immutable.js also support JSON serialization and deserialization?\nJoe It supports serialization out of the box. As for deserialization, we need to write\nour own function.\nTheo Does Immutable.js provide an Immutable.stringify() function?\nJoe That’s not necessary because the native JSON.stringify() function works\nwith Immutable.js objects. Here’s another example.\nListing9.17 JSON serialization of an Immutable.js collection\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nJSON.stringify(bookInfo);\n// → {\\\"isbn\\\":\\\"978-1779501127\\\",\\\"title\\\":\\\"Watchmen\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}\nTheo How does JSON.stringify() know how to handle an Immutable.js collection?\nJoe As an OOP developer, you shouldn’t be surprised by that.\nTheo Hmm...let me think a minute. OK, here’s my guess. Is that because JSON\n.stringify() calls some method on its argument?\nJoe Exactly! If the object passed to JSON.stringify() has a .toJSON() method,\nit’s called by JSON.stringify().\nTheo Nice. What about JSON deserialization?\nJoe That needs to be done in two steps. You first convert the JSON string to a Java-\nScript object and then to an immutable collection.\nTheo Something like this piece of code?\nListing9.18 Converting a JSON string into an immutable collection\nImmutable.parseJSON = function(jsonString) {\nreturn Immutable.fromJS(JSON.parse(jsonString));\n};\nJoe Exactly.\n--- Page 221 ---\n9.4 Persistent data structures in action 193\n9.4.4 Structural diff\nTheo So far, we have ported pieces of code that dealt with simple data manipula-\ntions. I’m curious to see how it goes with complex data manipulations such as\nthe code that computes the structural diff between two maps.\n NOTE Chapter 5 introduces structural diff.\nJoe That also works smoothly, but we need to port another eight functions.\nListing9.19 Porting Lodash functions involved in structural diff computation\nImmutable.reduce = function(coll, reducer, initialReduction) {\nreturn coll.reduce(reducer, initialReduction);\n};\nImmutable.isEmpty = function(coll) {\nreturn coll.isEmpty();\n};\nImmutable.keys = function(coll) {\nreturn coll.keySeq();\n};\nImmutable.isObject = function(coll) {\nreturn Immutable.Map.isMap(coll);\n};\nImmutable.isArray = Immutable.isIndexed;\nImmutable.union = function() {\nreturn Immutable.Set.union(arguments);\n};\nTheo Everything looks trivial with one exception: the use of arguments in Immutable\n.union.\nJoe In JavaScript, arguments is an implicit array-like object that contains the values\nof the function arguments.\nTheo I see. It’s one of those pieces of JavaScript magic!\nJoe Yep. We need to use arguments because Lodash and Immutable.js differ slightly\nin the signature of the union function. Immutable.Set.union receives an array\nof lists, whereas a Lodash _.union receives several arrays.\nTheo Makes sense. Let me give it a try.\nBlowing on his fingers like a seasoned safecracker, first one hand and then the next, Theo\nbegins typing. Once again, Theo is surprised to discover that after replacing the _ with\nImmutable in listing 9.20, the tests pass with the code in listing 9.21.\nListing9.20 Implementing structural diff with persistent data structures\nfunction diffObjects(data1, data2) {\nvar emptyObject = Immutable.isArray(data1) ?\nImmutable.fromJS([]) :\n--- Page 222 ---\n194 CHAPTER 9 Persistent data structures\nImmutable.fromJS({});\nif(data1 == data2) {\nreturn emptyObject;\n}\nvar keys = Immutable.union(Immutable.keys(data1), Immutable.keys(data2));\nreturn Immutable.reduce(keys,\nfunction (acc, k) {\nvar res = diff(Immutable.get(data1, k),\nImmutable.get(data2, k));\nif((Immutable.isObject(res) && Immutable.isEmpty(res)) ||\n(res == \"data-diff:no-diff\")) {\nreturn acc;\n}\nreturn Immutable.set(acc, k, res);\n},\nemptyObject);\n}\nfunction diff(data1, data2) {\nif(Immutable.isObject(data1) && Immutable.isObject(data2)) {\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"data-diff:no-diff\";\n}\nListing9.21 Testing structural diff with persistent data structures\nvar data1 = Immutable.fromJS({\ng: {\nc: 3\n},\nx: 2,\ny: {\nz: 1\n},\nw: [5]\n});\nvar data2 = Immutable.fromJS({\ng: {\nc:3\n},\nx: 2,\ny: {\nz: 2\n},\nw: [4]\n});\nImmutable.isEqual(diff(data1, data2),\nImmutable.fromJS({\n--- Page 223 ---\nSummary 195\n\"w\": [\n4\n],\n\"y\": {\n\"z\": 2\n}\n}));\nJoe What do you think of all this, my friend?\nTheo I think that using persistent data collections with a library like Immutable.js is\nmuch easier than understanding the internals of persistent data structures. But\nI’m also glad that I know how it works under the hood.\nAfter accompanying Joe to the office door, Theo meets Dave. Dave had been peering\nthrough the window in Theo’s office, looking at the whiteboard, anxious to catch a glimpse\nof today’s topic on DOP.\nDave What did Joe teach you today?\nTheo He took me to the university and taught me the foundations of persistent data\nstructures for dealing with immutability at scale.\nDave What’s wrong with the structural sharing that I implemented a couple of\nmonths ago?\nTheo When the number of elements in the collection is big enough, naive structural\nsharing has performance issues.\nDave I see. Could you tell me more about that?\nTheo I’d love to, but my brain isn’t functioning properly after this interesting but\nexhausting day. We’ll do it soon, promise.\nDave No worries. Have a nice evening, Theo.\nTheo You too, Dave.\nSummary\n It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\n At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\n Naive structural sharing doesn’t prevent data structures from being accidentally\nmutated.\n Immutable collections are not the same as persistent data structures.\n Immutable collections don’t provide an efficient way to create new versions of\nthe collections.\n Persistent data structures protect data from mutation.\n Persistent data structures provide an efficient way to create new versions of the\ncollections.\n Persistent data structures always preserve the previous version of themselves when\nthey are modified.\n--- Page 224 ---\n196 CHAPTER 9 Persistent data structures\n Persistent data structures represent data internally in such a way that structural\nsharing scales well, both in terms of memory and computation.\n When data is immutable, it is safe to share it.\n Internally, persistence uses a branching factor of 32.\n In practice, manipulation of persistent data structures is efficient even for col-\nlections with 10 billion entries!\n Due to modern architecture considerations, the performance of updating a\npersistent list is dominated much more by the depth of the tree than by the\nnumber of nodes at each level of the tree.\n Persistent lists can be manipulated in near constant time.\n In most languages, third-party libraries provide an implementation of persistent\ndata structures.\n Paguro collections implement the read-only parts of Java collection interfaces.\n Paguro collections can be passed to any methods that expect to receive a Java\ncollection without mutating them.\n--- Page 225 ---\nDatabase operations\nA cloud is a cloud\nThis chapter covers\n Fetching data from the database\n Storing data in the database\n Manipulating data fetched from the database\nTraditionally in OOP, we use design patterns and complex layers of objects to struc-\nture access to the database. In DOP, we prefer to represent data fetched from the\ndatabase with generic data collections, namely, lists of maps, where fields in the\nmaps correspond to database column values. As we’ll see throughout the chapter,\nthe fact that fields inside a map are accessible dynamically via their names allows us\nto use the same generic code for different data entities.\nTIP The best way to manipulate data is to represent data as data.\nIn this chapter, we’ll illustrate the application of data-oriented principles when\naccessing data from a relational database. Basic knowledge of relational database\nand SQL query syntax (like SELECT, AS, WHERE, and INNER JOIN) is assumed. This\napproach can be easily adapted to NoSQL databases.\n197\n--- Page 226 ---\n198 CHAPTER 10 Database operations\nApplications that run on the server usually store data in a database. In DOP, we\nrepresent data retrieved from the database the same way we represent any other data\nin our application—with generic data collections. This leads to\n Reduced system complexity.\n Increased genericity.\n10.1 Fetching data from the database\nTheo and Joe go for a walk in a park near the office. They sit on a bench close to a beau-\ntiful lake and gaze at the clouds in the sky. After a couple of minutes of meditative\nsilence, Joe asks Theo, “What do you see?” Theo tells him that this cloud looks to him\nlike a horse, and that one looks like a car. On their way back to the office, Theo asks Joe\nfor an explanation about the clouds. Joe answers with a mysterious smile on his lips, “A\ncloud is a cloud.”\nTheo So far you’ve shown me how DOP represents data that lives in the memory of\nthe application. What about data that comes from the outside?\nJoe What do you mean by outside?\nTheo Data that comes from the database.\nJoe I’ll return the question to you. How do you think that we should represent data\nthat comes from the database in DOP?\nTheo As generic data collections, I guess.\nJoe Exactly! In DOP, we always represent data with generic data collections.\nTheo Does that mean that we can manipulate data from the database with the same\nflexibility as we manipulate in-memory data?\nJoe Definitely.\nTIP In DOP, we represent data from the database with generic data collections, and\nwe manipulate it with generic functions.\nTheo Would you show me how to retrieve book search results when the catalog data\nis stored in an SQL database?\nJoe I’ll show you in a moment. First, tell me how you would design the tables that\nstore catalog data.\nTheo Do you mean the exact table schemas with the information about primary keys\nand nullability of each and every column?\nJoe No, I only need a rough overview of the tables, their columns, and the relation-\nships between the tables.\nTheo goes to the whiteboard. Figure 10.1 shows the diagram he draws as he explains his\nthinking to Joe.\n--- Page 227 ---\n10.1 Fetching data from the database 199\nT books\nT authors\nisbn VARCHAR[32]\nid VARCHAR[64]\ntitle VARCHAR[64]\nname VARCHAR[64]\npublication_year INTEGER\n1\nA book 1 An author\nmay have may author\nmany authors. many books.\n* *\nbook_authors\nT (relationships of books and authors)\nbook_isbn VARCHAR[32] Figure 10.1 The database model\nauthor_id VARCHAR[64]\nfor books and authors\nTheo I have a books table with three columns: title, isbn, and publication_\nyear. I also have an authors table with two columns: for id and name. Here,\nlet me draw these tables on the whiteboard to give you a visual (see tables 10.1\nand 10.2).\nTable 10.1 The books table filled with two books\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nTable 10.2 The authors table filled with three authors\nid name\nsean-covey Sean Covey\nstephen-covey Stephen Covey\ncharles-duhigg Charles Duhigg\nJoe What about the connection between books and authors?\nTheo Let’s see, a book could be written by multiple authors, and an author could write\nmultiple books. Therefore, I need a many-to-many book_authors table that con-\nnects authors and books with two columns, book_isbn and author_id.\nTheo once again turns to the whiteboard. He pens the book_authors table 10.3 to show Joe.\nTable 10.3 The book_authors table with rows connecting books with their authors\nbook_isbn author_id\n978-1982137274 sean-covey\n978-1982137274 stephen-covey\n978-0812981605 charles-duhigg\n--- Page 228 ---\n200 CHAPTER 10 Database operations\nJoe Great! Let’s start with the simplest case. We’re going to write code that searches\nfor books matching a title and that returns basic information about the books.\nBy basic information, I mean title, ISBN, and publication year.\nTheo What about the book authors?\nJoe We’ll deal with that later, as it’s a bit more complicated. Can you write an SQL\nquery for retrieving books that contain he word habit in their title?\nTheo Sure.\nThis assignment is quite easy for Theo. First, he jots down the SQL query, then he displays\nthe results in table 10.4.\nListing10.1 SQL query to retrieve books whose title contains habit\nSELECT\ntitle,\nisbn,\npublication_year\nFROM\nbooks\nWHERE title LIKE '%habit%';\nTable 10.4 Results of the SQL query for books whose title contains the word habit\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nJoe How would you describe these results as a data collection?\nTheo I would say it’s a list of maps.\nTIP In DOP, accessing data from a NoSQL database is similar to the way we access\ndata from a relational database.\nJoe Right! Now, can you write the search results as a list of maps?\nTheo It doesn’t sound too complicated. How about this?\nListing10.2 Search results as a list of maps\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"publication_year\": 1989\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"publication_year\": 2012\n}\n]\n--- Page 229 ---\n10.1 Fetching data from the database 201\nJoe What about the JSON schema for the search results?\nTheo It shouldn’t be too difficult if you allow me to take a look at the JSON schema\ncheat sheet you kindly offered me the other day.\nJoe Of course. The purpose of a gift is to be used by the one who receives it.\nTheo takes a look at the JSON Schema cheat sheet to refresh his memory about the JSON\nSchema syntax. After a few minutes, Theo comes up with a schema for the search results.\nHe certainly is putting Joe’s gift to good use.\nListing10.3 JSON schema cheat sheet\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"myNumber\": {\"type\": \"number\"},\n\"myString\": {\"type\": \"string\"},\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\n\"myBool\": {\"type\": \"boolean\"}\n},\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\n}\n}\nListing10.4 The JSON schema for search results from the database\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"publication_year\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"publication_year\": {\"type\": \"integer\"}\n}\n}\n};\nJoe Excellent. Now I’m going to show you how to implement searchBooks in a\nway that fetches data from the database and returns a JSON string with the\nresults. The cool thing is that we’re only going to use generic data collections\nfrom the database layer down to the JSON serialization.\nTheo Will it be similar to the implementation of searchBooks that we wrote when\nyou taught me the basis of DOP?\nJoe Absolutely. The only difference is that then the state of the system was stored\nlocally, and we queried it with a function like _.filter. Now, we use SQL\n--- Page 230 ---\n202 CHAPTER 10 Database operations\nqueries to fetch the state from the database. In terms of data representation\nand manipulation, it’s exactly the same.\nJoe goes to the whiteboard and sketches out the data flow in figure 10.2. Theo studies the\ndiagram.\nDatabase\nDatabase driver\nData (list of maps)\nData manipulation\nData Figure 10.2 Data flow for serving\na request that fetches data from\nJSON serialize\nthe database\nJoe The data manipulation step in the diagram is implemented via generic func-\ntions that manipulate data collections. As our examples get more elaborate, I\nthink you’ll see the benefits of being able to manipulate data collections with\ngeneric functions.\nTheo Sounds intriguing...\nJoe For the communication with the database, we use a driver that returns a list of\nmaps. In JavaScript, you could use an SQL driver like node-postgres.\n NOTE See https://node-postgres.com for more information about this collection of\nnode.js modules for interfacing with PostgreSQL databases.\nTheo And in Java?\nJoe In Java, you could use JDBC (Java database connectivity) in addition to a small\nutility function that converts a JDBC result set into a list of maps. If I can use\nyour laptop, I’ll show you what I mean.\nJoe pulls a piece of code from one of his personal GitHub repositories. He then shows the\ncode for the JDBC conversion to Theo, who seems a bit surprised.\nListing10.5 Converting a JDBC result set into a list of hash maps\nList<Map<String, Object>> convertJDBCResultSetToListOfMaps(ResultSet rs) {\nList<Map<String, Object>> listOfMaps =\nnew ArrayList<Map<String, Object>>();\nResultSetMetaData meta = rs.getMetaData();\nwhile (rs.next()) {\nMap map = new HashMap();\nfor (int i = 1; i <= meta.getColumnCount(); i++) {\nString key = meta.getColumnLabel(i);\nObject value = rs.getObject(i);\n--- Page 231 ---\n10.1 Fetching data from the database 203\nmap.put(key, value);\n}\nlistOfMaps.add(map);\n}\nreturn listOfMaps;\n}\nTIP Converting a JDBC result set into a list of hash maps is quite straightforward.\nTheo I expected it to be much more complicated to convert a JDBC result set into a\nlist of hash maps.\nJoe It’s straightforward because, in a sense, JDBC is data-oriented.\nTheo What about the field types?\nJoe When we convert a JDBC result set into a list of maps, each value is considered\nan Object.\nTheo That’s annoying because it means that in order to access the value, we need to\ncast it to its type.\nJoe Yes and no. Look at our book search use case. We pass all the values along with-\nout really looking at their type. The concrete value type only matters when we\nserialize the result into JSON and that’s handled by the JSON serialization\nlibrary. It’s called late binding.\n NOTE With late binding, we defer dealing with data types as long as possible.\nTheo Does that mean in my application that I’m allowed to manipulate data without\ndealing with concrete types?\nTIP In DOP, flexibility is increased as many parts of the system are free to manipulate\ndata without dealing with concrete types.\nJoe Exactly. You’ll see late binding in action in a moment. That’s one of the great-\nest benefits of DOP.\nTheo Interesting, I can’t wait to see that!\nJoe One last thing before I show you the code for retrieving search results from the\ndatabase. In order to make it easier to read, I’m going to write JavaScript code\nas if JavaScript were dealing with I/O is a synchronous way.\nTheo What do you mean?\nJoe In JavaScript, an I/O operation like sending a query to the database is done\nasynchronously. In real life, it means using either callback functions or using\nasync and await keywords.\nTheo Oh yeah, that’s because JavaScript is single-threaded.\n NOTE For sake of simplicity, the JavaScript snippets in this chapter are written as if\nJavaScript were dealing with I/O in a synchronous way. In real-life JavaScript, we need\nto use async and await around I/O calls.\nJoe Indeed, so I’ll be writing the code that communicates with the database as\nthough JavaScript were dealing with I/O synchronously. Here’s an example.\n--- Page 232 ---\n204 CHAPTER 10 Database operations\nListing10.6 Searching books in the database, returning the results in JSON\ndbClient holds the Initializes Ajv (a JSON schema validation\nvar dbClient; DB connection. library) with allErrors: true to catch all\nthe data validation errors\nvar ajv = new Ajv({allErrors: true});\nvar title = \"habit\";\nvar matchingBooksQuery = `SELECT title, isbn Uses a parameterized\nSQL query as a security\nFROM books\nbest practice\nWHERE title LIKE '%$1%'`;\nvar books = dbClient.query(matchingBooksQuery,\nPasses the parameters to the SQL\n[title]);\nquery as a list of values (in our\nif(!ajv.validate(dbSearchResultSchema, books)) {\ncase, a list with a single value)\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" + errors;\n}\nJSON.stringify(books);\nTheo In a dynamically-typed language like JavaScript, I understand that the types of\nthe values in the list of maps returned by dbClient.query are determined at\nrun time. How does it work in a statically-typed language like Java, and what are\nthe types of the data fields in books?\nJoe The function convertJDBCResultSetToListOfMaps we created earlier (see\nlisting 10.5) returns a list of Map<String, Object>. But JSON serialization\nlibraries like Gson know how to detect at run time the concrete type of the val-\nues in a map and serialize the values according to their type.\n NOTE See https://github.com/google/gson for information about Gson’s Java\nserialization/deserialization library.\nTheo What do you mean by serializing a value according to its type?\nJoe For instance, the value of the field publication_year is a number; therefore,\nit is not wrapped with quotes. However, the value of the field title is a string;\ntherefore, it is wrapped with quotes.\nTheo Nice! Now, I understand what you mean by late binding.\nJoe Cool! Now, let me show you how we store data in the database.\n10.2 Storing data in the database\nIn the previous section, we saw how to retrieve data from the database as a list of maps.\nNext, we’ll see how to store data in the database when data is represented with a map.\nTheo I guess that storing data in the database is quite similar to fetching data from\nthe database.\nJoe It’s similar in the sense that we deal only with generic data collections. Can you\nwrite a parameterized SQL query that inserts a row with user info using only\nemail and encrypted_password, please?\nTheo OK.",
        "sections_found": []
      },
      "accurate_page_range": "202-232"
    },
    {
      "text": "- 8.4 State management with atoms",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "8 Advanced concurrency control",
      "raw_line": "- 8.4 State management with atoms (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 68,
      "chapter_info": {
        "page": 202,
        "title": "Advanced concurrency control",
        "pattern_matched": "Chapter 8",
        "text_preview": "174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do yo"
      },
      "chapter_sections": {
        "start_page": 202,
        "end_page": 232,
        "content": "\n--- Page 202 ---\n174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do you mean?\nTheo I don’t know, but I am under the impression that mutexes are like phone calls,\nand atoms are like text messages.\nJoe smiles at Theo but doesn’t reveal the meaning of his smile. After the phone deadlock\nyesterday, Theo’s pretty sure that he and Joe are on the same page.\nSummary\n Managing concurrency with atoms is much simpler than managing concur-\nrency with locks because we don’t have to deal with the risk of deadlocks.\n Cloning data to avoid read locks doesn’t scale.\n When data is immutable, reads are always safe.\n Atoms provide a way to manage concurrency without locks.\n With atoms, deadlocks never happen.\n Using atoms for a thread-safe counter is trivial because the state of the counter\nis represented with a primitive type (an integer).\n We can manage composite data in a thread-safe way with atoms.\n We make the highly scalable state management approach from part 1 thread-\nsafe by keeping the whole system state inside an atom.\n It’s quite common to represent an in-memory cache as a string map.\n When data is immutable, it is safe (and fast) to compare by reference.\n In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing besides swapping an atom.\n In practice, once an atom is swapped, the threads do some real work (e.g.,\ndatabase access) to provide an opportunity for other threads to swap the atom\nsuccessfully.\n--- Page 203 ---\nPersistent data structures\nStanding on the shoulders of giants\nThis chapter covers\n The internal details of persistent data\nstructures\n The time and memory efficiency of persistent\ndata structures\n Using persistent data structures in an\napplication\nIn part 1, we illustrated how to manage the state of a system without mutating data,\nwhere immutability is maintained by constraining ourselves to manipulate the state\nonly with immutable functions using structural sharing. In this chapter, we present\na safer and more scalable way to preserve data immutability—representing data\nwith so-called persistent data structures. Efficient implementations of persistent\ndata structures exist for most programming languages via third-party libraries.\n9.1 The need for persistent data structures\nIt’s at the university where Theo meets Joe this time. When Theo asks Joe if today’s topic\nis academic in nature, Joe tells him that the use of persistent data structures only\nbecame possible in programming languages following a discovery in 2001 by a computer\n175\n--- Page 204 ---\n176 CHAPTER 9 Persistent data structures\nresearcher named Phil Bagwell.1 In 2007, Rich Hickey, the creator of Clojure, used this dis-\ncovery as the foundation of persistent data structures in Clojure. Unveiling the secrets of\nthese data structures to Theo in a university classroom is a way for Joe to honor the mem-\nory of Phil Bagwell, who unfortunately passed away in 2012. When they get to the univer-\nsity classroom, Joe starts the conversation with a question.\nJoe Are you getting used to DOP’s prohibition against mutating data in place and\ncreating new versions instead?\nTheo I think so, but two things bother me about the idea of structural sharing that\nyou showed me.\nJoe What bothers you, my friend?\nTheo Safety and performance.\nJoe What do you mean by safety?\nTheo I mean that using immutable functions to manipulate data doesn’t prevent it\nfrom being modified accidentally.\nJoe Right! Would you like me to show you the naive way to handle immutability or\nthe real way?\nTheo What are the pros and cons of each way?\nJoe The naive way is easy but not efficient, although the real way is efficient but\nnot easy.\nTheo Let’s start with the naive way then.\nJoe Each programming language provides its own way to protect data from being\nmutated.\nTheo How would I do that in Java, for instance?\nJoe Java provides immutable collections, and there is a way to convert a list or a\nmap to an immutable list or an immutable map.\n NOTE Immutable collections are not the same as persistent data structures.\nJoe opens his laptop and fires it up. He brings up two code examples, one for immutable\nlists and one for immutable maps.\nListing9.1 Converting a mutable list to an immutable list in Java\nvar myList = new ArrayList<Integer>();\nmyList.add(1);\nmyList.add(2);\nmyList.add(3);\nvar myImmutableList = List.of(myList.toArray());\n1 P. Bagwell, “Ideal hash trees” (No. REP_WORK), 2001. [Online]. Available: https://lampwww.epfl.ch/papers/\nidealhashtrees.pdf.\n--- Page 205 ---\n9.1 The need for persistent data structures 177\nListing9.2 Converting a mutable map to an immutable map in Java\nvar myMap = new HashMap<String, Object>();\nmyMap.put(\"name\", \"Isaac\");\nmyMap.put(\"age\", 42);\nvar myImmutableMap = Collections.unmodifiableMap(myMap);\nTheo What happens when you try to modify an immutable collection?\nJoe Java throws an UnsupportedOperationException.\nTheo And in JavaScript?\nJoe JavaScript provides an Object.freeze() function that prevents data from\nbeing mutated. It works both with JavaScript arrays and objects.\nJoe takes a minute to scroll through his laptop. When he finds what he’s looking for, he\nshows Theo the code.\nListing9.3 Making an object immutable in JavaScript\nvar a = [1, 2, 3];\nObject.freeze(a);\nvar b = {foo: 1};\nObject.freeze(b);\nTheo What happens when you try to modify a frozen object?\nJoe It depends. In JavaScript strict mode, a TypeError exception is thrown, and in\nnonstrict mode, it fails silently.\n NOTE JavaScript’s strict mode is a way to opt in to a restricted variant of JavaScript\nthat changes some silent errors to throw errors.\nTheo In case of a nested collection, are the nested collections also frozen?\nJoe No, but in JavaScript, one can write a deepFreeze() function that freezes an\nobject recursively. Here’s another example.\nListing9.4 Freezing an object recursively in JavaScript\nfunction deepFreeze(object) {\n// Retrieve the property names defined on object\nconst propNames = Object.getOwnPropertyNames(object);\n// Freeze properties before freezing self\nfor (const name of propNames) {\nconst value = object[name];\nif (value && typeof value === \"object\") {\ndeepFreeze(value);\n}\n}\n--- Page 206 ---\n178 CHAPTER 9 Persistent data structures\nreturn Object.freeze(object);\n}\nTheo I see that it’s possible to ensure that data is never mutated, which answers my\nconcerns about safety. Now, let me share my concerns about performance.\nTIP It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\nJoe Sure.\nTheo If I understand correctly, the main idea behind structural sharing is that most\ndata is usually shared between two versions.\nJoe Correct.\nTheo This insight allows us to create new versions of our collections using a shallow\ncopy instead of a deep copy, and you claimed that it was efficient.\nJoe Exactly!\nTheo Now, here is my concern. In the case of a collection with many entries, a shal-\nlow copy might be expensive.\nJoe Could you give me an example of a collection with many entries?\nTheo A catalog with 100,000 books, for instance.\nJoe On my machine, making a shallow copy of a collection with 100,000 entries\ndoesn’t take more than 50 milliseconds.\nTheo Sometimes, even 50 milliseconds per update isn’t acceptable.\nJoe I totally agree with you. When one needs data immutability at scale, naive struc-\ntural sharing is not appropriate.\nTheo Also, shallow copying an array of 100,000 elements on each update would\nincrease the program memory by 100 KB.\nJoe Indeed, at scale, we have a problem both with memory and computation.\nTIP At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\nTheo Is there a better solution?\nJoe Yes! For that, you’ll need to learn the real way to handle immutability. It’s\ncalled persistent data structures.\n9.2 The efficiency of persistent data structures\nTheo In what sense are those data structures persistent?\nJoe Persistent data structures are so named because they always preserve their pre-\nvious versions.\nTIP Persistent data structures always preserve the previous version of themselves\nwhen they are modified.\nJoe Persistent data structures address the two main limitations of naive structural\nsharing: safety and performance.\n--- Page 207 ---\n9.2 The efficiency of persistent data structures 179\nTheo Let’s start with safety. How do persistent data structures prevent data from\nbeing mutated accidentally?\nJoe In a language like Java, they implement the mutation methods of the collec-\ntion interfaces by throwing the run-time exception UnsupportedOperation-\nException.\nTheo And, in a language like JavaScript?\nJoe In JavaScript, persistent data structures provide their own methods to access\ndata, and none of those methods mutate data.\nTheo Does that mean that we can’t use the dot notation to access fields?\nJoe Correct. Fields of persistent data structures are accessed via a specific API.\nTheo What about efficiency? How do persistent data structures make it possible to\ncreate a new version of a huge collection in an efficient way?\nJoe Persistent data structures organize data in such a way that we can use structural\nsharing at the level of the data structure.\nTheo Could you explain?\nJoe Certainly. Let’s start with the simplest data structure: a linked list. Imagine that\nyou have a linked list with 100,000 elements.\nTheo OK.\nJoe What would it take to prepend an element to the head of the list?\nTheo You mean to create a new version of the list with an additional element?\nJoe Exactly!\nTheo Well, we could copy the list and then prepend an element to the list, but it\nwould be quite expensive.\nJoe What if I tell you that the original linked list is guaranteed to be immutable?\nTheo In that case, I could create a new list with a new head that points to the head of\nthe original list.\nTheo goes to the classroom blackboard. He picks up a piece of chalk and draws the dia-\ngram shown in figure 9.1.\nNew list Original list\nFigure 9.1 Structural sharing\n0 1 2 3 4 5 with linked lists\nJoe Would the efficiency of this operation depend on the size of the list?\nTheo No, it would be efficient, no matter the size of the list.\nJoe That’s what I mean by structural sharing at the level of the data structure itself.\nIt relies on a simple but powerful insight—when data is immutable, it is safe to\nshare it.\nTIP When data is immutable, it is safe to share it.\n--- Page 208 ---\n180 CHAPTER 9 Persistent data structures\nTheo I understand how to use structural sharing at the level of the data structure for\nlinked lists and prepend operations, but how would it work with operations\nlike appending or modifying an element in a list?\nJoe For that purpose, we need to be smarter and represent our list as a tree.\nTheo How does that help?\nJoe It helps because when a list is represented as a tree, most of the nodes in the\ntree can be shared between two versions of the list.\nTheo I am totally confused.\nJoe Imagine that you take a list with 100,000 elements and split it into two lists of\n50,000 elements each: elements 0 to 49,999 in list 1, and elements 50,000 to\n99,999 in list 2. How many operations would you need to create a new version\nof the list where a single element—let’s say, element at index 75,100—is\nmodified?\nIt’s hard for Theo to visualize this kind of stuff mentally. He goes back to the blackboard\nand draws a diagram (see figure 9.2). Once Theo looks at the diagram, it’s easy for him to\nanswer Joe’s question.\nList «Next»\nList\nList 1 List 2\n«Next»\n0...49,999 50,000...99,999\nList 2\nFigure 9.2 Structural sharing when\n50,000...99,999\na list of 100,000 elements is split\nTheo List 1 could be shared with one operation. I’d need to create a new version of\nlist 2, where element 75,100 is modified. It would take 50,000 operations, so it’s\none operation of sharing and one operation of copying 50,000 elements. Over-\nall, it’s 50,001 operations.\nJoe Correct. You see that by splitting our original list into two lists, we can create a\nnew version of the list with a number of operations in the order of the size of\nthe list divided by 2.\nTheo I agree, but 50,000 is still a big number.\nJoe Indeed, but nobody prevents us from applying the same trick again, splitting\nlist 1 and list 2 in two lists each.\nTheo How exactly?\nJoe We can make list 1.1 with elements 0 to 24,999, then list 1.2 with elements\n25,000 to 49,999, list 2.1 with elements 50,000 to 74,999, and list 2.2 with ele-\nments 75,000 to 99,999.\nTheo Can you draw that on the blackboard?\nJoe Sure.\n--- Page 209 ---\n9.2 The efficiency of persistent data structures 181\nNow, it’s Joe that goes to the blackboard. He draws the diagram in figure 9.3.\n«Next»\nList\nList\n«Next»\nList 1 List 2 List 2\nList 1.1 List 1.2 List 2.1 List 2.2 «Next»\n0...24,499 25,000...49,999 50,000...74,999 75,000...99,999 List 2.2\n75,000...99,999\nFigure 9.3 Structural sharing when a list of 100,000 elements is split twice\nTheo Let me count the number of operations for updating a single element. It takes\n2 operations of sharing and 1 operation of copying 25,000 elements. Overall, it\ntakes 25,002 operations to create a new version of the list.\nJoe Correct!\nTheo Let’s split the list again then!\nJoe Absolutely. In fact, we can split the list again and again until the size of the\nlists is at most 2. Can you guess what is the complexity of creating a new ver-\nsion then?\nTheo I’d say around log2 N operations.\nJoe I see that you remember well your material from school. Do you have a gut\nfeeling about what is log2 N when N is 100,000?\nTheo Let me see...2 to the power of 10 is around 1,000, and 2 to the power of 7 is\n128. So, it should be a bit less than 17.\nJoe It’s 16.6 to be precise. It means that in order to update an element in a per-\nsistent list of 100,000 elements, we need around 17 operations. The same goes\nfor accessing elements.\nTheo Nice, but 17 is still not negligible.\nJoe I agree. We can easily improve the performance of accessing elements by using\na higher branching factor in our tree.\nTheo What do you mean?\nJoe Instead of splitting by 2 at each level, we could split by 32.\nTheo But the running time of our algorithm would still grow with log N.\nJoe You’re right. From a theoretical perspective, it’s the same. From a practical\nperspective, however, it makes a big difference.\nTheo Why?\nJoe Because log32 N is 5 times lower than log2 N.\n--- Page 210 ---\n182 CHAPTER 9 Persistent data structures\nTheo That’s true: 2 to the power of 5 is 32.\nJoe Back to our list of 100,000 elements, can you tell me how many operations are\nrequired to access an element if the branching factor is 32?\nTheo With a branching factor of 2, it was 16.6. If I divide 16.6 by 5, I get 3.3.\nJoe Correct!\nTIP By using a branching factor of 32, we make elements accessed in persistent lists\nmore efficient.\nTheo Does this trick also improve the performance of updating an element in a list?\nJoe Yes, indeed, it does.\nTheo How? We’d have to copy 32 elements at each level instead of 2 elements. It’s a\n16× performance hit that’s not compensated for by the fact that the tree depth\nis reduced by 5×!\nJoe I see that you are quite sharp with numbers. There is another thing to take\ninto consideration in our practical analysis of the performance: modern CPU\narchitecture.\nTheo Interesting. The more you tell me about persistent data structures, the more I\nunderstand why you wanted to have this session at a university: it’s because\nwe’re dealing with all this academic stuff.\nJoe Yep. So, to continue, modern CPUs read and write data from and to the main\nmemory in units of cache lines, often 32 or 64 bytes long.\nTheo What difference does that make?\nJoe A nice consequence of this data access pattern is that copying an array of size\n32 is much faster than copying 16 arrays of size 2 that belong to different levels\nof the tree.\nTheo Why is that?\nJoe The reason is that copying an array of size 32 can be done in a single pair of\ncache accesses: one for read and one for write. Although for arrays that belong\nto different tree levels, each array requires its own pair of cache accesses, even\nif there are only 2 elements in the array.\nTheo In other words, the performance of updating a persistent list is dominated by\nthe depth of the tree.\nTIP In modern CPU architectures, the performance of updating a persistent list is\ndominated much more by the depth of the tree than by the number of nodes at each\nlevel of the tree.\nJoe That’s correct, up to a certain point. With today’s CPUs, using a branching fac-\ntor of 64 would, in fact, decrease the performance of update operations.\nTheo I see.\nJoe Now, I am going to make another interesting claim that is not accurate from a\ntheoretical perspective but accurate in practice.\nTheo What is it?\n--- Page 211 ---\n9.2 The efficiency of persistent data structures 183\nJoe The number of operations it takes to get or update an element in a persistent\nlist with branching factor 32 is constant.\nTheo How can that be? You just made the point that the number of operations is\nlog32 N.\nJoe Be patient, my friend. What is the highest number of elements that you can\nhave in a list, in practice?\nTheo I don’t know. I never thought about that.\nJoe Let’s assume that it takes 4 bytes to store an element in a list.\nTheo OK.\nJoe Now, can you tell me how much memory it would take to hold a list with 10 bil-\nlion elements?\nTheo You mean 1 with 10 zeros?\nJoe Yes.\nTheo Each element take 4 bytes, so it would be around 40 GB!\nJoe Correct. Do you agree that it doesn’t make sense to hold a list that takes 40 GB\nof memory?\nTheo I agree.\nJoe So let’s take 10 billion as an upper bound to the number of elements in a list.\nWhat is log32 of 10 billion?\nOnce again, Theo uses the blackboard to clarify his thoughts. With that, he quickly finds\nthe answer.\nTheo 1 billion is approximately 2^30. Therefore, 10 billion is around 2^33. That\nmeans that log2 of 10 billion is 33, so log32 of 10 billion should be around\n33/5, which is a bit less than 7.\nJoe I am impressed again by your sharpness with numbers. To be precise, log32 of\n10 billion is 6.64.\nTheo (smiling) I didn’t get that far.\nJoe Did I convince you that, in practice, accessing or updating an element in a per-\nsistent list is essentially constant?\nTheo Yes, and I find it quite amazing!\nTIP Persistent lists can be manipulated in near constant time.\nJoe Me too.\nTheo What about persistent maps?\nJoe It’s quite similar, but I don’t think we have time to discuss it now.\nStartled, Theo looks at his watch. This morning’s session has gone by so quickly. He notices\nthat it’s time to get back to the office and have lunch.\n--- Page 212 ---\n184 CHAPTER 9 Persistent data structures\n9.3 Persistent data structures libraries\nOn their way back to the office, Theo and Joe don’t talk too much. Theo’s thoughts take\nhim back to what he learned in the university classroom. He feels a lot of respect for Phil\nBagwell, who discovered how to manipulate persistent data structures efficiently, and for\nRich Hickey, who created a programming language incorporating that discovery as a core\nfeature and making it available to the world. Immediately after lunch, Theo asks Joe to\nshow him what it looks like to manipulate persistent data structures for real in a program-\nming language.\nTheo Are persistent data structures available in all programming languages?\nJoe A few programming languages like Clojure, Scala, and C# provide them as part\nof the language. In most programming languages, though, you need a third-\nparty library.\nTheo Could you give me a few references?\nJoe Sure.\nUsing Theo’s laptop, Joe bookmarks some sites. He knows exactly which URLs to look for.\nThen, while Theo is looking over the bookmarked sites, Joe goes to the whiteboard and\njots down the specific libraries in table 9.1.\n Immutable.js for JavaScript at https://immutable-js.com/\n Paguro for Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections for C# at http://mng.bz/QW51\n Pyrsistent for Python at https://github.com/tobgu/pyrsistent\n Hamster for Ruby at https://github.com/hamstergem/hamster\nTable 9.1 Persistent data structure libraries\nLanguage Library\nJavaScript Immutable.js\nJava Paguro\nC# Provided by the language\nPython Pyrsistent\nRuby Hamster\nTheo What does it take to integrate persistent data structures provided by a third-\nparty library into your code?\n9.3.1 Persistent data structures in Java\nJoe In an object-oriented language like Java, it’s quite straightforward to integrate\npersistent data structures in a program because persistent data structures\nimplement collection interfaces, besides the parts of the interface that mutate\nin place.\nTheo What do you mean?\n--- Page 213 ---\n9.3 Persistent data structures libraries 185\nJoe Take for instance, Paguro for Java. Paguro persistent maps implement the\nread-only methods of java.util.Map like get() and containsKey(), but not\nmethods like put() and remove(). On the other hand, Paguro vectors imple-\nment the read-only methods of java.util.List like get() and size(), but not\nmethods like set().\nTheo What happens when we call put() or remove() on a Paguro map?\nJoe It throws an UnSupportedOperationException exception.\nTheo What about iterating over the elements of a Paguro collection with a forEach()?\nJoe That works like it would in any Java collection. Here, let me show you an example.\nListing9.5 Iterating over a Paguro vector\nvar myVec = PersistentVector.ofIter(\nList.of(10, 2, 3));\nCreates a Paguro\nvector from a\nfor (Integer i : myVec) {\nJava list\nSystem.out.println(i);\n}\nTheo What about Java streams?\nJoe Paguro collections are Java collections, so they support the Java stream inter-\nface. Take a look at this code.\nListing9.6 Streaming a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvec1.stream().sorted().map(x -> x + 1);\nTIP Paguro collections implement the read-only parts of Java collection interfaces.\nTherefore, they can be passed to any methods that expect to receive a Java collection\nwithout mutating it.\nTheo So far, you told me how do use Paguro collections as Java read-only collections.\nHow do I make modifications to Paguro persistent data structures?\nJoe In a way similar to the _.set() function of Lodash FP that we talked about\nearlier. Instead of mutating in place, you create a new version.\nTheo What methods does Paguro expose for creating new versions of a data structure?\nJoe For vectors, you use replace(), and for maps, you use assoc().\nListing9.7 Creating a modified version of a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvar myNextVec = myVec.replace(0, 42);\n--- Page 214 ---\n186 CHAPTER 9 Persistent data structures\nListing9.8 Creating a modified version of a Paguro map\nvar myMap = PersistentHashMap.of(Map.of(\"aa\", 1, \"bb\", 2)\n.entrySet());\nCreates a Paguro map\nfrom a Java map entry set\nvar myNextMap = myMap.assoc(\"aa\", 42);\nTheo Yes! Now I see how to use persistent data structures in Java, but what about\nJavaScript?\n9.3.2 Persistent data structures in JavaScript\nJoe In a language like JavaScript, it’s a bit more cumbersome to integrate per-\nsistent data structures.\nTheo How so?\nJoe Because JavaScript objects and arrays don’t expose any interface.\nTheo Bummer.\nJoe It’s not as terrible as it sounds because Immutable.js exposes its own set of\nfunctions to manipulate its data structures.\nTheo What do you mean?\nJoe I’ll show you in a moment. But first, let me show you how to initiate Immutable.js\npersistent data structures.\nTheo OK!\nJoe Immutable.js provides a handy function that recursively converts a native data\nobject to an immutable one. It’s called Immutable.fromJS().\nTheo What do you mean by recursively?\nJoe Consider the map that holds library data from our Library Management Sys-\ntem: it has values that are themselves maps. Immutable.fromJS() converts the\nnested maps into immutable maps.\nTheo Could you show me some code?\nJoe Absolutely. Take a look at this JavaScript code for library data.\nListing9.9 Conversion to immutable data\nvar libraryData = Immutable.fromJS({\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n--- Page 215 ---\n9.3 Persistent data structures libraries 187\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n});\nTheo Do you mean that the catalog value in libraryData map is itself an immutable\nmap?\nJoe Yes, and the same for booksByIsbn, authorIds, and so forth.\nTheo Cool! So how do I access a field inside an immutable map?\nJoe As I told you, Immutable.js provides its own API for data access. For instance,\nin order to access a field inside an immutable map, you use Immutable.get()\nor Immutable.getIn() like the following.\nListing9.10 Accessing a field and a nested field in an immutable map\nImmutable.get(libraryData, \"catalog\");\nImmutable.getIn(libraryData,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nTheo How do I make a modification to a map?\nJoe Similar to what we did with Lodash FP, you use an Immutable.set() or\nImmutable.setIn() map to create a new version of the map where a field is\nmodified. Here’s how.\nListing9.11 Creating a new version of a map where a field is modified\nImmutable.setIn(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1988);\nTheo What happens when I try to access a field in the map using JavaScript’s dot or\nbracket notation?\nJoe You access the internal representation of the map instead of accessing a map\nfield.\nTheo Does that mean that we can’t pass data from Immutable.js to Lodash for data\nmanipulation?\nJoe Yes, but it’s quite easy to convert any immutable collection into a native Java-\nScript object back and forth.\nTheo How?\nJoe Immutable.js provides a toJS() method to convert an arbitrary deeply nested\nimmutable collection into a JavaScript object.\n--- Page 216 ---\n188 CHAPTER 9 Persistent data structures\nTheo But if I have a huge collection, it could take lots of time to convert it, right?\nJoe True. We need a better solution. Hopefully, Immutable.js provides its own set\nof data manipulation functions like map(), filter(), and reduce().\nTheo What if I need more data manipulation like Lodash’s _.groupBy()?\nJoe You could write your own data manipulation functions that work with the\nImmutable.js collections or use a library like mudash, which provides a port of\nLodash to Immutable.js.\n NOTE You can access the mudash library at https://github.com/brianneisler/mudash.\nTheo What would you advise?\nJoe A cup of coffee, then I’ll show you how to port functions from Lodash to\nImmutable.js and how to adapt the code from your Library Management System.\nYou can decide on whichever approach works best for your current project.\n9.4 Persistent data structures in action\nJoe Let’s start with our search query. Can you look at the current code and tell me\nthe Lodash functions that we used to implement the search query?\nTheo Including the code for the unit tests?\nJoe Of course!\n NOTE See chapter 6 for the unit test of the search query.\n9.4.1 Writing queries with persistent data structures\nTheo The Lodash functions we used were get, map, filter, and isEqual.\nJoe Here’s the port of those four functions from Lodash to Immutable.js.\nListing9.12 Porting some functions from Lodash to Immutable.js\nImmutable.map = function(coll, f) {\nreturn coll.map(f);\n};\nImmutable.filter = function(coll, f) {\nif(Immutable.isMap(coll)) {\nreturn coll.valueSeq().filter(f);\n}\nreturn coll.filter(f);\n};\nImmutable.isEqual = Immutable.is;\nTheo The code seems quite simple. But can you explain it to me, function by function?\nJoe Sure. Let’s start with get. For accessing a field in a map, Immutable.js provides\ntwo functions: get for direct fields and getIn for nested fields. It’s different\nfrom Lodash, where _.get works both on direct and nested fields.\n--- Page 217 ---\n9.4 Persistent data structures in action 189\nTheo What about map?\nJoe Immutable.js provides its own map function. The only difference is that it is a\nmethod of the collection, but it is something that we can easily adapt.\nTheo What about filter? How would you make it work both for arrays and maps\nlike Lodash’s filter?\nJoe Immutable.js provides a valueSeq method that returns the values of a map.\nTheo Cool. And what about isEqual to compare two collections?\nJoe That’s easy. Immutable.js provides a function named is that works exactly as\nisEqual.\nTheo So far, so good. What do I need to do now to make the code of the search\nquery work with Immutable.js?\nJoe You simply replace each occurrence of an _ with Immutable; _.map becomes\nImmutable.map, _.filter becomes Immutable.filter, and _.isEqual\nbecomes Immutable.isEqual.\nTheo I can’t believe it’s so easy!\nJoe Try it yourself; you’ll see. Sometimes, it’s a bit more cumbersome because\nyou need to convert the JavaScript objects to Immutable.js objects using\nImmutable.fromJS.\nTheo copies and pastes the snippets for the code and the unit tests of the search query.\nThen, he uses his IDE to replace the _ with Immutable. When Theo executes the tests and\nthey pass, he is surprised but satisfied. Joe smiles.\nListing9.13 Implementing book search with persistent data structures\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn Immutable.map(authorIds, function(authorId) {\nreturn Immutable.getIn(\ncatalogData,\n[\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = Immutable.Map({\n\"title\": Immutable.get(book, \"title\"),\n\"isbn\": Immutable.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(\ncatalogData,\nImmutable.get(book, \"authorIds\"))\n});\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = Immutable.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nvar matchingBooks = Immutable.filter(allBooks, function(book) {\n--- Page 218 ---\n190 CHAPTER 9 Persistent data structures\nreturn Immutable.get(book, \"title\").\ntoLowerCase().\nincludes(queryLowerCased);\n});\nvar bookInfos = Immutable.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nListing9.14 Testing book search with persistent data structures\nvar catalogData = Immutable.fromJS({\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n});\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Watchmen\"),\nImmutable.fromJS([bookInfo]));\n// → true\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Batman\"),\nImmutable.fromJS([]));\n// → true\n--- Page 219 ---\n9.4 Persistent data structures in action 191\n9.4.2 Writing mutations with persistent data structures\nTheo Shall we move forward and port the add member mutation?\nJoe Sure. Porting the add member mutation from Lodash to Immutable.js only\nrequires you to again replace the underscore (_) with Immutable. Let’s look at\nsome code.\nListing9.15 Implementing member addition with persistent data structures\nUserManagement.addMember = function(userManagement, member) {\nvar email = Immutable.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(Immutable.hasIn(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = Immutable.setIn(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo So, for the tests, I’d convert the JavaScript objects to Immutable.js objects with\nImmutable.fromJS(). How does this look?\nListing9.16 Testing member addition with persistent data structures\nvar jessie = Immutable.fromJS({\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n});\nvar franck = Immutable.fromJS({\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n});\nvar userManagementStateBefore = Immutable.fromJS({\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n});\nvar expectedUserManagementStateAfter = Immutable.fromJS({\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n--- Page 220 ---\n192 CHAPTER 9 Persistent data structures\n}\n}\n});\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\nImmutable.isEqual(result, expectedUserManagementStateAfter);\n// → true\nJoe Great!\n9.4.3 Serialization and deserialization\nTheo Does Immutable.js also support JSON serialization and deserialization?\nJoe It supports serialization out of the box. As for deserialization, we need to write\nour own function.\nTheo Does Immutable.js provide an Immutable.stringify() function?\nJoe That’s not necessary because the native JSON.stringify() function works\nwith Immutable.js objects. Here’s another example.\nListing9.17 JSON serialization of an Immutable.js collection\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nJSON.stringify(bookInfo);\n// → {\\\"isbn\\\":\\\"978-1779501127\\\",\\\"title\\\":\\\"Watchmen\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}\nTheo How does JSON.stringify() know how to handle an Immutable.js collection?\nJoe As an OOP developer, you shouldn’t be surprised by that.\nTheo Hmm...let me think a minute. OK, here’s my guess. Is that because JSON\n.stringify() calls some method on its argument?\nJoe Exactly! If the object passed to JSON.stringify() has a .toJSON() method,\nit’s called by JSON.stringify().\nTheo Nice. What about JSON deserialization?\nJoe That needs to be done in two steps. You first convert the JSON string to a Java-\nScript object and then to an immutable collection.\nTheo Something like this piece of code?\nListing9.18 Converting a JSON string into an immutable collection\nImmutable.parseJSON = function(jsonString) {\nreturn Immutable.fromJS(JSON.parse(jsonString));\n};\nJoe Exactly.\n--- Page 221 ---\n9.4 Persistent data structures in action 193\n9.4.4 Structural diff\nTheo So far, we have ported pieces of code that dealt with simple data manipula-\ntions. I’m curious to see how it goes with complex data manipulations such as\nthe code that computes the structural diff between two maps.\n NOTE Chapter 5 introduces structural diff.\nJoe That also works smoothly, but we need to port another eight functions.\nListing9.19 Porting Lodash functions involved in structural diff computation\nImmutable.reduce = function(coll, reducer, initialReduction) {\nreturn coll.reduce(reducer, initialReduction);\n};\nImmutable.isEmpty = function(coll) {\nreturn coll.isEmpty();\n};\nImmutable.keys = function(coll) {\nreturn coll.keySeq();\n};\nImmutable.isObject = function(coll) {\nreturn Immutable.Map.isMap(coll);\n};\nImmutable.isArray = Immutable.isIndexed;\nImmutable.union = function() {\nreturn Immutable.Set.union(arguments);\n};\nTheo Everything looks trivial with one exception: the use of arguments in Immutable\n.union.\nJoe In JavaScript, arguments is an implicit array-like object that contains the values\nof the function arguments.\nTheo I see. It’s one of those pieces of JavaScript magic!\nJoe Yep. We need to use arguments because Lodash and Immutable.js differ slightly\nin the signature of the union function. Immutable.Set.union receives an array\nof lists, whereas a Lodash _.union receives several arrays.\nTheo Makes sense. Let me give it a try.\nBlowing on his fingers like a seasoned safecracker, first one hand and then the next, Theo\nbegins typing. Once again, Theo is surprised to discover that after replacing the _ with\nImmutable in listing 9.20, the tests pass with the code in listing 9.21.\nListing9.20 Implementing structural diff with persistent data structures\nfunction diffObjects(data1, data2) {\nvar emptyObject = Immutable.isArray(data1) ?\nImmutable.fromJS([]) :\n--- Page 222 ---\n194 CHAPTER 9 Persistent data structures\nImmutable.fromJS({});\nif(data1 == data2) {\nreturn emptyObject;\n}\nvar keys = Immutable.union(Immutable.keys(data1), Immutable.keys(data2));\nreturn Immutable.reduce(keys,\nfunction (acc, k) {\nvar res = diff(Immutable.get(data1, k),\nImmutable.get(data2, k));\nif((Immutable.isObject(res) && Immutable.isEmpty(res)) ||\n(res == \"data-diff:no-diff\")) {\nreturn acc;\n}\nreturn Immutable.set(acc, k, res);\n},\nemptyObject);\n}\nfunction diff(data1, data2) {\nif(Immutable.isObject(data1) && Immutable.isObject(data2)) {\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"data-diff:no-diff\";\n}\nListing9.21 Testing structural diff with persistent data structures\nvar data1 = Immutable.fromJS({\ng: {\nc: 3\n},\nx: 2,\ny: {\nz: 1\n},\nw: [5]\n});\nvar data2 = Immutable.fromJS({\ng: {\nc:3\n},\nx: 2,\ny: {\nz: 2\n},\nw: [4]\n});\nImmutable.isEqual(diff(data1, data2),\nImmutable.fromJS({\n--- Page 223 ---\nSummary 195\n\"w\": [\n4\n],\n\"y\": {\n\"z\": 2\n}\n}));\nJoe What do you think of all this, my friend?\nTheo I think that using persistent data collections with a library like Immutable.js is\nmuch easier than understanding the internals of persistent data structures. But\nI’m also glad that I know how it works under the hood.\nAfter accompanying Joe to the office door, Theo meets Dave. Dave had been peering\nthrough the window in Theo’s office, looking at the whiteboard, anxious to catch a glimpse\nof today’s topic on DOP.\nDave What did Joe teach you today?\nTheo He took me to the university and taught me the foundations of persistent data\nstructures for dealing with immutability at scale.\nDave What’s wrong with the structural sharing that I implemented a couple of\nmonths ago?\nTheo When the number of elements in the collection is big enough, naive structural\nsharing has performance issues.\nDave I see. Could you tell me more about that?\nTheo I’d love to, but my brain isn’t functioning properly after this interesting but\nexhausting day. We’ll do it soon, promise.\nDave No worries. Have a nice evening, Theo.\nTheo You too, Dave.\nSummary\n It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\n At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\n Naive structural sharing doesn’t prevent data structures from being accidentally\nmutated.\n Immutable collections are not the same as persistent data structures.\n Immutable collections don’t provide an efficient way to create new versions of\nthe collections.\n Persistent data structures protect data from mutation.\n Persistent data structures provide an efficient way to create new versions of the\ncollections.\n Persistent data structures always preserve the previous version of themselves when\nthey are modified.\n--- Page 224 ---\n196 CHAPTER 9 Persistent data structures\n Persistent data structures represent data internally in such a way that structural\nsharing scales well, both in terms of memory and computation.\n When data is immutable, it is safe to share it.\n Internally, persistence uses a branching factor of 32.\n In practice, manipulation of persistent data structures is efficient even for col-\nlections with 10 billion entries!\n Due to modern architecture considerations, the performance of updating a\npersistent list is dominated much more by the depth of the tree than by the\nnumber of nodes at each level of the tree.\n Persistent lists can be manipulated in near constant time.\n In most languages, third-party libraries provide an implementation of persistent\ndata structures.\n Paguro collections implement the read-only parts of Java collection interfaces.\n Paguro collections can be passed to any methods that expect to receive a Java\ncollection without mutating them.\n--- Page 225 ---\nDatabase operations\nA cloud is a cloud\nThis chapter covers\n Fetching data from the database\n Storing data in the database\n Manipulating data fetched from the database\nTraditionally in OOP, we use design patterns and complex layers of objects to struc-\nture access to the database. In DOP, we prefer to represent data fetched from the\ndatabase with generic data collections, namely, lists of maps, where fields in the\nmaps correspond to database column values. As we’ll see throughout the chapter,\nthe fact that fields inside a map are accessible dynamically via their names allows us\nto use the same generic code for different data entities.\nTIP The best way to manipulate data is to represent data as data.\nIn this chapter, we’ll illustrate the application of data-oriented principles when\naccessing data from a relational database. Basic knowledge of relational database\nand SQL query syntax (like SELECT, AS, WHERE, and INNER JOIN) is assumed. This\napproach can be easily adapted to NoSQL databases.\n197\n--- Page 226 ---\n198 CHAPTER 10 Database operations\nApplications that run on the server usually store data in a database. In DOP, we\nrepresent data retrieved from the database the same way we represent any other data\nin our application—with generic data collections. This leads to\n Reduced system complexity.\n Increased genericity.\n10.1 Fetching data from the database\nTheo and Joe go for a walk in a park near the office. They sit on a bench close to a beau-\ntiful lake and gaze at the clouds in the sky. After a couple of minutes of meditative\nsilence, Joe asks Theo, “What do you see?” Theo tells him that this cloud looks to him\nlike a horse, and that one looks like a car. On their way back to the office, Theo asks Joe\nfor an explanation about the clouds. Joe answers with a mysterious smile on his lips, “A\ncloud is a cloud.”\nTheo So far you’ve shown me how DOP represents data that lives in the memory of\nthe application. What about data that comes from the outside?\nJoe What do you mean by outside?\nTheo Data that comes from the database.\nJoe I’ll return the question to you. How do you think that we should represent data\nthat comes from the database in DOP?\nTheo As generic data collections, I guess.\nJoe Exactly! In DOP, we always represent data with generic data collections.\nTheo Does that mean that we can manipulate data from the database with the same\nflexibility as we manipulate in-memory data?\nJoe Definitely.\nTIP In DOP, we represent data from the database with generic data collections, and\nwe manipulate it with generic functions.\nTheo Would you show me how to retrieve book search results when the catalog data\nis stored in an SQL database?\nJoe I’ll show you in a moment. First, tell me how you would design the tables that\nstore catalog data.\nTheo Do you mean the exact table schemas with the information about primary keys\nand nullability of each and every column?\nJoe No, I only need a rough overview of the tables, their columns, and the relation-\nships between the tables.\nTheo goes to the whiteboard. Figure 10.1 shows the diagram he draws as he explains his\nthinking to Joe.\n--- Page 227 ---\n10.1 Fetching data from the database 199\nT books\nT authors\nisbn VARCHAR[32]\nid VARCHAR[64]\ntitle VARCHAR[64]\nname VARCHAR[64]\npublication_year INTEGER\n1\nA book 1 An author\nmay have may author\nmany authors. many books.\n* *\nbook_authors\nT (relationships of books and authors)\nbook_isbn VARCHAR[32] Figure 10.1 The database model\nauthor_id VARCHAR[64]\nfor books and authors\nTheo I have a books table with three columns: title, isbn, and publication_\nyear. I also have an authors table with two columns: for id and name. Here,\nlet me draw these tables on the whiteboard to give you a visual (see tables 10.1\nand 10.2).\nTable 10.1 The books table filled with two books\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nTable 10.2 The authors table filled with three authors\nid name\nsean-covey Sean Covey\nstephen-covey Stephen Covey\ncharles-duhigg Charles Duhigg\nJoe What about the connection between books and authors?\nTheo Let’s see, a book could be written by multiple authors, and an author could write\nmultiple books. Therefore, I need a many-to-many book_authors table that con-\nnects authors and books with two columns, book_isbn and author_id.\nTheo once again turns to the whiteboard. He pens the book_authors table 10.3 to show Joe.\nTable 10.3 The book_authors table with rows connecting books with their authors\nbook_isbn author_id\n978-1982137274 sean-covey\n978-1982137274 stephen-covey\n978-0812981605 charles-duhigg\n--- Page 228 ---\n200 CHAPTER 10 Database operations\nJoe Great! Let’s start with the simplest case. We’re going to write code that searches\nfor books matching a title and that returns basic information about the books.\nBy basic information, I mean title, ISBN, and publication year.\nTheo What about the book authors?\nJoe We’ll deal with that later, as it’s a bit more complicated. Can you write an SQL\nquery for retrieving books that contain he word habit in their title?\nTheo Sure.\nThis assignment is quite easy for Theo. First, he jots down the SQL query, then he displays\nthe results in table 10.4.\nListing10.1 SQL query to retrieve books whose title contains habit\nSELECT\ntitle,\nisbn,\npublication_year\nFROM\nbooks\nWHERE title LIKE '%habit%';\nTable 10.4 Results of the SQL query for books whose title contains the word habit\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nJoe How would you describe these results as a data collection?\nTheo I would say it’s a list of maps.\nTIP In DOP, accessing data from a NoSQL database is similar to the way we access\ndata from a relational database.\nJoe Right! Now, can you write the search results as a list of maps?\nTheo It doesn’t sound too complicated. How about this?\nListing10.2 Search results as a list of maps\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"publication_year\": 1989\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"publication_year\": 2012\n}\n]\n--- Page 229 ---\n10.1 Fetching data from the database 201\nJoe What about the JSON schema for the search results?\nTheo It shouldn’t be too difficult if you allow me to take a look at the JSON schema\ncheat sheet you kindly offered me the other day.\nJoe Of course. The purpose of a gift is to be used by the one who receives it.\nTheo takes a look at the JSON Schema cheat sheet to refresh his memory about the JSON\nSchema syntax. After a few minutes, Theo comes up with a schema for the search results.\nHe certainly is putting Joe’s gift to good use.\nListing10.3 JSON schema cheat sheet\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"myNumber\": {\"type\": \"number\"},\n\"myString\": {\"type\": \"string\"},\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\n\"myBool\": {\"type\": \"boolean\"}\n},\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\n}\n}\nListing10.4 The JSON schema for search results from the database\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"publication_year\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"publication_year\": {\"type\": \"integer\"}\n}\n}\n};\nJoe Excellent. Now I’m going to show you how to implement searchBooks in a\nway that fetches data from the database and returns a JSON string with the\nresults. The cool thing is that we’re only going to use generic data collections\nfrom the database layer down to the JSON serialization.\nTheo Will it be similar to the implementation of searchBooks that we wrote when\nyou taught me the basis of DOP?\nJoe Absolutely. The only difference is that then the state of the system was stored\nlocally, and we queried it with a function like _.filter. Now, we use SQL\n--- Page 230 ---\n202 CHAPTER 10 Database operations\nqueries to fetch the state from the database. In terms of data representation\nand manipulation, it’s exactly the same.\nJoe goes to the whiteboard and sketches out the data flow in figure 10.2. Theo studies the\ndiagram.\nDatabase\nDatabase driver\nData (list of maps)\nData manipulation\nData Figure 10.2 Data flow for serving\na request that fetches data from\nJSON serialize\nthe database\nJoe The data manipulation step in the diagram is implemented via generic func-\ntions that manipulate data collections. As our examples get more elaborate, I\nthink you’ll see the benefits of being able to manipulate data collections with\ngeneric functions.\nTheo Sounds intriguing...\nJoe For the communication with the database, we use a driver that returns a list of\nmaps. In JavaScript, you could use an SQL driver like node-postgres.\n NOTE See https://node-postgres.com for more information about this collection of\nnode.js modules for interfacing with PostgreSQL databases.\nTheo And in Java?\nJoe In Java, you could use JDBC (Java database connectivity) in addition to a small\nutility function that converts a JDBC result set into a list of maps. If I can use\nyour laptop, I’ll show you what I mean.\nJoe pulls a piece of code from one of his personal GitHub repositories. He then shows the\ncode for the JDBC conversion to Theo, who seems a bit surprised.\nListing10.5 Converting a JDBC result set into a list of hash maps\nList<Map<String, Object>> convertJDBCResultSetToListOfMaps(ResultSet rs) {\nList<Map<String, Object>> listOfMaps =\nnew ArrayList<Map<String, Object>>();\nResultSetMetaData meta = rs.getMetaData();\nwhile (rs.next()) {\nMap map = new HashMap();\nfor (int i = 1; i <= meta.getColumnCount(); i++) {\nString key = meta.getColumnLabel(i);\nObject value = rs.getObject(i);\n--- Page 231 ---\n10.1 Fetching data from the database 203\nmap.put(key, value);\n}\nlistOfMaps.add(map);\n}\nreturn listOfMaps;\n}\nTIP Converting a JDBC result set into a list of hash maps is quite straightforward.\nTheo I expected it to be much more complicated to convert a JDBC result set into a\nlist of hash maps.\nJoe It’s straightforward because, in a sense, JDBC is data-oriented.\nTheo What about the field types?\nJoe When we convert a JDBC result set into a list of maps, each value is considered\nan Object.\nTheo That’s annoying because it means that in order to access the value, we need to\ncast it to its type.\nJoe Yes and no. Look at our book search use case. We pass all the values along with-\nout really looking at their type. The concrete value type only matters when we\nserialize the result into JSON and that’s handled by the JSON serialization\nlibrary. It’s called late binding.\n NOTE With late binding, we defer dealing with data types as long as possible.\nTheo Does that mean in my application that I’m allowed to manipulate data without\ndealing with concrete types?\nTIP In DOP, flexibility is increased as many parts of the system are free to manipulate\ndata without dealing with concrete types.\nJoe Exactly. You’ll see late binding in action in a moment. That’s one of the great-\nest benefits of DOP.\nTheo Interesting, I can’t wait to see that!\nJoe One last thing before I show you the code for retrieving search results from the\ndatabase. In order to make it easier to read, I’m going to write JavaScript code\nas if JavaScript were dealing with I/O is a synchronous way.\nTheo What do you mean?\nJoe In JavaScript, an I/O operation like sending a query to the database is done\nasynchronously. In real life, it means using either callback functions or using\nasync and await keywords.\nTheo Oh yeah, that’s because JavaScript is single-threaded.\n NOTE For sake of simplicity, the JavaScript snippets in this chapter are written as if\nJavaScript were dealing with I/O in a synchronous way. In real-life JavaScript, we need\nto use async and await around I/O calls.\nJoe Indeed, so I’ll be writing the code that communicates with the database as\nthough JavaScript were dealing with I/O synchronously. Here’s an example.\n--- Page 232 ---\n204 CHAPTER 10 Database operations\nListing10.6 Searching books in the database, returning the results in JSON\ndbClient holds the Initializes Ajv (a JSON schema validation\nvar dbClient; DB connection. library) with allErrors: true to catch all\nthe data validation errors\nvar ajv = new Ajv({allErrors: true});\nvar title = \"habit\";\nvar matchingBooksQuery = `SELECT title, isbn Uses a parameterized\nSQL query as a security\nFROM books\nbest practice\nWHERE title LIKE '%$1%'`;\nvar books = dbClient.query(matchingBooksQuery,\nPasses the parameters to the SQL\n[title]);\nquery as a list of values (in our\nif(!ajv.validate(dbSearchResultSchema, books)) {\ncase, a list with a single value)\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" + errors;\n}\nJSON.stringify(books);\nTheo In a dynamically-typed language like JavaScript, I understand that the types of\nthe values in the list of maps returned by dbClient.query are determined at\nrun time. How does it work in a statically-typed language like Java, and what are\nthe types of the data fields in books?\nJoe The function convertJDBCResultSetToListOfMaps we created earlier (see\nlisting 10.5) returns a list of Map<String, Object>. But JSON serialization\nlibraries like Gson know how to detect at run time the concrete type of the val-\nues in a map and serialize the values according to their type.\n NOTE See https://github.com/google/gson for information about Gson’s Java\nserialization/deserialization library.\nTheo What do you mean by serializing a value according to its type?\nJoe For instance, the value of the field publication_year is a number; therefore,\nit is not wrapped with quotes. However, the value of the field title is a string;\ntherefore, it is wrapped with quotes.\nTheo Nice! Now, I understand what you mean by late binding.\nJoe Cool! Now, let me show you how we store data in the database.\n10.2 Storing data in the database\nIn the previous section, we saw how to retrieve data from the database as a list of maps.\nNext, we’ll see how to store data in the database when data is represented with a map.\nTheo I guess that storing data in the database is quite similar to fetching data from\nthe database.\nJoe It’s similar in the sense that we deal only with generic data collections. Can you\nwrite a parameterized SQL query that inserts a row with user info using only\nemail and encrypted_password, please?\nTheo OK.",
        "sections_found": []
      },
      "accurate_page_range": "202-232"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "8 Advanced concurrency control",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 69,
      "chapter_info": {
        "page": 202,
        "title": "Advanced concurrency control",
        "pattern_matched": "Chapter 8",
        "text_preview": "174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do yo"
      },
      "chapter_sections": {
        "start_page": 202,
        "end_page": 232,
        "content": "\n--- Page 202 ---\n174 CHAPTER 8 Advanced concurrency control\nJoe Perfect.\nTheo This atom stuff makes me think about what happened to us yesterday, when we\ntried to call each other at the exact same time.\nJoe What do you mean?\nTheo I don’t know, but I am under the impression that mutexes are like phone calls,\nand atoms are like text messages.\nJoe smiles at Theo but doesn’t reveal the meaning of his smile. After the phone deadlock\nyesterday, Theo’s pretty sure that he and Joe are on the same page.\nSummary\n Managing concurrency with atoms is much simpler than managing concur-\nrency with locks because we don’t have to deal with the risk of deadlocks.\n Cloning data to avoid read locks doesn’t scale.\n When data is immutable, reads are always safe.\n Atoms provide a way to manage concurrency without locks.\n With atoms, deadlocks never happen.\n Using atoms for a thread-safe counter is trivial because the state of the counter\nis represented with a primitive type (an integer).\n We can manage composite data in a thread-safe way with atoms.\n We make the highly scalable state management approach from part 1 thread-\nsafe by keeping the whole system state inside an atom.\n It’s quite common to represent an in-memory cache as a string map.\n When data is immutable, it is safe (and fast) to compare by reference.\n In theory, atoms could create starvation in a system with thousands of threads\nthat do nothing besides swapping an atom.\n In practice, once an atom is swapped, the threads do some real work (e.g.,\ndatabase access) to provide an opportunity for other threads to swap the atom\nsuccessfully.\n--- Page 203 ---\nPersistent data structures\nStanding on the shoulders of giants\nThis chapter covers\n The internal details of persistent data\nstructures\n The time and memory efficiency of persistent\ndata structures\n Using persistent data structures in an\napplication\nIn part 1, we illustrated how to manage the state of a system without mutating data,\nwhere immutability is maintained by constraining ourselves to manipulate the state\nonly with immutable functions using structural sharing. In this chapter, we present\na safer and more scalable way to preserve data immutability—representing data\nwith so-called persistent data structures. Efficient implementations of persistent\ndata structures exist for most programming languages via third-party libraries.\n9.1 The need for persistent data structures\nIt’s at the university where Theo meets Joe this time. When Theo asks Joe if today’s topic\nis academic in nature, Joe tells him that the use of persistent data structures only\nbecame possible in programming languages following a discovery in 2001 by a computer\n175\n--- Page 204 ---\n176 CHAPTER 9 Persistent data structures\nresearcher named Phil Bagwell.1 In 2007, Rich Hickey, the creator of Clojure, used this dis-\ncovery as the foundation of persistent data structures in Clojure. Unveiling the secrets of\nthese data structures to Theo in a university classroom is a way for Joe to honor the mem-\nory of Phil Bagwell, who unfortunately passed away in 2012. When they get to the univer-\nsity classroom, Joe starts the conversation with a question.\nJoe Are you getting used to DOP’s prohibition against mutating data in place and\ncreating new versions instead?\nTheo I think so, but two things bother me about the idea of structural sharing that\nyou showed me.\nJoe What bothers you, my friend?\nTheo Safety and performance.\nJoe What do you mean by safety?\nTheo I mean that using immutable functions to manipulate data doesn’t prevent it\nfrom being modified accidentally.\nJoe Right! Would you like me to show you the naive way to handle immutability or\nthe real way?\nTheo What are the pros and cons of each way?\nJoe The naive way is easy but not efficient, although the real way is efficient but\nnot easy.\nTheo Let’s start with the naive way then.\nJoe Each programming language provides its own way to protect data from being\nmutated.\nTheo How would I do that in Java, for instance?\nJoe Java provides immutable collections, and there is a way to convert a list or a\nmap to an immutable list or an immutable map.\n NOTE Immutable collections are not the same as persistent data structures.\nJoe opens his laptop and fires it up. He brings up two code examples, one for immutable\nlists and one for immutable maps.\nListing9.1 Converting a mutable list to an immutable list in Java\nvar myList = new ArrayList<Integer>();\nmyList.add(1);\nmyList.add(2);\nmyList.add(3);\nvar myImmutableList = List.of(myList.toArray());\n1 P. Bagwell, “Ideal hash trees” (No. REP_WORK), 2001. [Online]. Available: https://lampwww.epfl.ch/papers/\nidealhashtrees.pdf.\n--- Page 205 ---\n9.1 The need for persistent data structures 177\nListing9.2 Converting a mutable map to an immutable map in Java\nvar myMap = new HashMap<String, Object>();\nmyMap.put(\"name\", \"Isaac\");\nmyMap.put(\"age\", 42);\nvar myImmutableMap = Collections.unmodifiableMap(myMap);\nTheo What happens when you try to modify an immutable collection?\nJoe Java throws an UnsupportedOperationException.\nTheo And in JavaScript?\nJoe JavaScript provides an Object.freeze() function that prevents data from\nbeing mutated. It works both with JavaScript arrays and objects.\nJoe takes a minute to scroll through his laptop. When he finds what he’s looking for, he\nshows Theo the code.\nListing9.3 Making an object immutable in JavaScript\nvar a = [1, 2, 3];\nObject.freeze(a);\nvar b = {foo: 1};\nObject.freeze(b);\nTheo What happens when you try to modify a frozen object?\nJoe It depends. In JavaScript strict mode, a TypeError exception is thrown, and in\nnonstrict mode, it fails silently.\n NOTE JavaScript’s strict mode is a way to opt in to a restricted variant of JavaScript\nthat changes some silent errors to throw errors.\nTheo In case of a nested collection, are the nested collections also frozen?\nJoe No, but in JavaScript, one can write a deepFreeze() function that freezes an\nobject recursively. Here’s another example.\nListing9.4 Freezing an object recursively in JavaScript\nfunction deepFreeze(object) {\n// Retrieve the property names defined on object\nconst propNames = Object.getOwnPropertyNames(object);\n// Freeze properties before freezing self\nfor (const name of propNames) {\nconst value = object[name];\nif (value && typeof value === \"object\") {\ndeepFreeze(value);\n}\n}\n--- Page 206 ---\n178 CHAPTER 9 Persistent data structures\nreturn Object.freeze(object);\n}\nTheo I see that it’s possible to ensure that data is never mutated, which answers my\nconcerns about safety. Now, let me share my concerns about performance.\nTIP It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\nJoe Sure.\nTheo If I understand correctly, the main idea behind structural sharing is that most\ndata is usually shared between two versions.\nJoe Correct.\nTheo This insight allows us to create new versions of our collections using a shallow\ncopy instead of a deep copy, and you claimed that it was efficient.\nJoe Exactly!\nTheo Now, here is my concern. In the case of a collection with many entries, a shal-\nlow copy might be expensive.\nJoe Could you give me an example of a collection with many entries?\nTheo A catalog with 100,000 books, for instance.\nJoe On my machine, making a shallow copy of a collection with 100,000 entries\ndoesn’t take more than 50 milliseconds.\nTheo Sometimes, even 50 milliseconds per update isn’t acceptable.\nJoe I totally agree with you. When one needs data immutability at scale, naive struc-\ntural sharing is not appropriate.\nTheo Also, shallow copying an array of 100,000 elements on each update would\nincrease the program memory by 100 KB.\nJoe Indeed, at scale, we have a problem both with memory and computation.\nTIP At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\nTheo Is there a better solution?\nJoe Yes! For that, you’ll need to learn the real way to handle immutability. It’s\ncalled persistent data structures.\n9.2 The efficiency of persistent data structures\nTheo In what sense are those data structures persistent?\nJoe Persistent data structures are so named because they always preserve their pre-\nvious versions.\nTIP Persistent data structures always preserve the previous version of themselves\nwhen they are modified.\nJoe Persistent data structures address the two main limitations of naive structural\nsharing: safety and performance.\n--- Page 207 ---\n9.2 The efficiency of persistent data structures 179\nTheo Let’s start with safety. How do persistent data structures prevent data from\nbeing mutated accidentally?\nJoe In a language like Java, they implement the mutation methods of the collec-\ntion interfaces by throwing the run-time exception UnsupportedOperation-\nException.\nTheo And, in a language like JavaScript?\nJoe In JavaScript, persistent data structures provide their own methods to access\ndata, and none of those methods mutate data.\nTheo Does that mean that we can’t use the dot notation to access fields?\nJoe Correct. Fields of persistent data structures are accessed via a specific API.\nTheo What about efficiency? How do persistent data structures make it possible to\ncreate a new version of a huge collection in an efficient way?\nJoe Persistent data structures organize data in such a way that we can use structural\nsharing at the level of the data structure.\nTheo Could you explain?\nJoe Certainly. Let’s start with the simplest data structure: a linked list. Imagine that\nyou have a linked list with 100,000 elements.\nTheo OK.\nJoe What would it take to prepend an element to the head of the list?\nTheo You mean to create a new version of the list with an additional element?\nJoe Exactly!\nTheo Well, we could copy the list and then prepend an element to the list, but it\nwould be quite expensive.\nJoe What if I tell you that the original linked list is guaranteed to be immutable?\nTheo In that case, I could create a new list with a new head that points to the head of\nthe original list.\nTheo goes to the classroom blackboard. He picks up a piece of chalk and draws the dia-\ngram shown in figure 9.1.\nNew list Original list\nFigure 9.1 Structural sharing\n0 1 2 3 4 5 with linked lists\nJoe Would the efficiency of this operation depend on the size of the list?\nTheo No, it would be efficient, no matter the size of the list.\nJoe That’s what I mean by structural sharing at the level of the data structure itself.\nIt relies on a simple but powerful insight—when data is immutable, it is safe to\nshare it.\nTIP When data is immutable, it is safe to share it.\n--- Page 208 ---\n180 CHAPTER 9 Persistent data structures\nTheo I understand how to use structural sharing at the level of the data structure for\nlinked lists and prepend operations, but how would it work with operations\nlike appending or modifying an element in a list?\nJoe For that purpose, we need to be smarter and represent our list as a tree.\nTheo How does that help?\nJoe It helps because when a list is represented as a tree, most of the nodes in the\ntree can be shared between two versions of the list.\nTheo I am totally confused.\nJoe Imagine that you take a list with 100,000 elements and split it into two lists of\n50,000 elements each: elements 0 to 49,999 in list 1, and elements 50,000 to\n99,999 in list 2. How many operations would you need to create a new version\nof the list where a single element—let’s say, element at index 75,100—is\nmodified?\nIt’s hard for Theo to visualize this kind of stuff mentally. He goes back to the blackboard\nand draws a diagram (see figure 9.2). Once Theo looks at the diagram, it’s easy for him to\nanswer Joe’s question.\nList «Next»\nList\nList 1 List 2\n«Next»\n0...49,999 50,000...99,999\nList 2\nFigure 9.2 Structural sharing when\n50,000...99,999\na list of 100,000 elements is split\nTheo List 1 could be shared with one operation. I’d need to create a new version of\nlist 2, where element 75,100 is modified. It would take 50,000 operations, so it’s\none operation of sharing and one operation of copying 50,000 elements. Over-\nall, it’s 50,001 operations.\nJoe Correct. You see that by splitting our original list into two lists, we can create a\nnew version of the list with a number of operations in the order of the size of\nthe list divided by 2.\nTheo I agree, but 50,000 is still a big number.\nJoe Indeed, but nobody prevents us from applying the same trick again, splitting\nlist 1 and list 2 in two lists each.\nTheo How exactly?\nJoe We can make list 1.1 with elements 0 to 24,999, then list 1.2 with elements\n25,000 to 49,999, list 2.1 with elements 50,000 to 74,999, and list 2.2 with ele-\nments 75,000 to 99,999.\nTheo Can you draw that on the blackboard?\nJoe Sure.\n--- Page 209 ---\n9.2 The efficiency of persistent data structures 181\nNow, it’s Joe that goes to the blackboard. He draws the diagram in figure 9.3.\n«Next»\nList\nList\n«Next»\nList 1 List 2 List 2\nList 1.1 List 1.2 List 2.1 List 2.2 «Next»\n0...24,499 25,000...49,999 50,000...74,999 75,000...99,999 List 2.2\n75,000...99,999\nFigure 9.3 Structural sharing when a list of 100,000 elements is split twice\nTheo Let me count the number of operations for updating a single element. It takes\n2 operations of sharing and 1 operation of copying 25,000 elements. Overall, it\ntakes 25,002 operations to create a new version of the list.\nJoe Correct!\nTheo Let’s split the list again then!\nJoe Absolutely. In fact, we can split the list again and again until the size of the\nlists is at most 2. Can you guess what is the complexity of creating a new ver-\nsion then?\nTheo I’d say around log2 N operations.\nJoe I see that you remember well your material from school. Do you have a gut\nfeeling about what is log2 N when N is 100,000?\nTheo Let me see...2 to the power of 10 is around 1,000, and 2 to the power of 7 is\n128. So, it should be a bit less than 17.\nJoe It’s 16.6 to be precise. It means that in order to update an element in a per-\nsistent list of 100,000 elements, we need around 17 operations. The same goes\nfor accessing elements.\nTheo Nice, but 17 is still not negligible.\nJoe I agree. We can easily improve the performance of accessing elements by using\na higher branching factor in our tree.\nTheo What do you mean?\nJoe Instead of splitting by 2 at each level, we could split by 32.\nTheo But the running time of our algorithm would still grow with log N.\nJoe You’re right. From a theoretical perspective, it’s the same. From a practical\nperspective, however, it makes a big difference.\nTheo Why?\nJoe Because log32 N is 5 times lower than log2 N.\n--- Page 210 ---\n182 CHAPTER 9 Persistent data structures\nTheo That’s true: 2 to the power of 5 is 32.\nJoe Back to our list of 100,000 elements, can you tell me how many operations are\nrequired to access an element if the branching factor is 32?\nTheo With a branching factor of 2, it was 16.6. If I divide 16.6 by 5, I get 3.3.\nJoe Correct!\nTIP By using a branching factor of 32, we make elements accessed in persistent lists\nmore efficient.\nTheo Does this trick also improve the performance of updating an element in a list?\nJoe Yes, indeed, it does.\nTheo How? We’d have to copy 32 elements at each level instead of 2 elements. It’s a\n16× performance hit that’s not compensated for by the fact that the tree depth\nis reduced by 5×!\nJoe I see that you are quite sharp with numbers. There is another thing to take\ninto consideration in our practical analysis of the performance: modern CPU\narchitecture.\nTheo Interesting. The more you tell me about persistent data structures, the more I\nunderstand why you wanted to have this session at a university: it’s because\nwe’re dealing with all this academic stuff.\nJoe Yep. So, to continue, modern CPUs read and write data from and to the main\nmemory in units of cache lines, often 32 or 64 bytes long.\nTheo What difference does that make?\nJoe A nice consequence of this data access pattern is that copying an array of size\n32 is much faster than copying 16 arrays of size 2 that belong to different levels\nof the tree.\nTheo Why is that?\nJoe The reason is that copying an array of size 32 can be done in a single pair of\ncache accesses: one for read and one for write. Although for arrays that belong\nto different tree levels, each array requires its own pair of cache accesses, even\nif there are only 2 elements in the array.\nTheo In other words, the performance of updating a persistent list is dominated by\nthe depth of the tree.\nTIP In modern CPU architectures, the performance of updating a persistent list is\ndominated much more by the depth of the tree than by the number of nodes at each\nlevel of the tree.\nJoe That’s correct, up to a certain point. With today’s CPUs, using a branching fac-\ntor of 64 would, in fact, decrease the performance of update operations.\nTheo I see.\nJoe Now, I am going to make another interesting claim that is not accurate from a\ntheoretical perspective but accurate in practice.\nTheo What is it?\n--- Page 211 ---\n9.2 The efficiency of persistent data structures 183\nJoe The number of operations it takes to get or update an element in a persistent\nlist with branching factor 32 is constant.\nTheo How can that be? You just made the point that the number of operations is\nlog32 N.\nJoe Be patient, my friend. What is the highest number of elements that you can\nhave in a list, in practice?\nTheo I don’t know. I never thought about that.\nJoe Let’s assume that it takes 4 bytes to store an element in a list.\nTheo OK.\nJoe Now, can you tell me how much memory it would take to hold a list with 10 bil-\nlion elements?\nTheo You mean 1 with 10 zeros?\nJoe Yes.\nTheo Each element take 4 bytes, so it would be around 40 GB!\nJoe Correct. Do you agree that it doesn’t make sense to hold a list that takes 40 GB\nof memory?\nTheo I agree.\nJoe So let’s take 10 billion as an upper bound to the number of elements in a list.\nWhat is log32 of 10 billion?\nOnce again, Theo uses the blackboard to clarify his thoughts. With that, he quickly finds\nthe answer.\nTheo 1 billion is approximately 2^30. Therefore, 10 billion is around 2^33. That\nmeans that log2 of 10 billion is 33, so log32 of 10 billion should be around\n33/5, which is a bit less than 7.\nJoe I am impressed again by your sharpness with numbers. To be precise, log32 of\n10 billion is 6.64.\nTheo (smiling) I didn’t get that far.\nJoe Did I convince you that, in practice, accessing or updating an element in a per-\nsistent list is essentially constant?\nTheo Yes, and I find it quite amazing!\nTIP Persistent lists can be manipulated in near constant time.\nJoe Me too.\nTheo What about persistent maps?\nJoe It’s quite similar, but I don’t think we have time to discuss it now.\nStartled, Theo looks at his watch. This morning’s session has gone by so quickly. He notices\nthat it’s time to get back to the office and have lunch.\n--- Page 212 ---\n184 CHAPTER 9 Persistent data structures\n9.3 Persistent data structures libraries\nOn their way back to the office, Theo and Joe don’t talk too much. Theo’s thoughts take\nhim back to what he learned in the university classroom. He feels a lot of respect for Phil\nBagwell, who discovered how to manipulate persistent data structures efficiently, and for\nRich Hickey, who created a programming language incorporating that discovery as a core\nfeature and making it available to the world. Immediately after lunch, Theo asks Joe to\nshow him what it looks like to manipulate persistent data structures for real in a program-\nming language.\nTheo Are persistent data structures available in all programming languages?\nJoe A few programming languages like Clojure, Scala, and C# provide them as part\nof the language. In most programming languages, though, you need a third-\nparty library.\nTheo Could you give me a few references?\nJoe Sure.\nUsing Theo’s laptop, Joe bookmarks some sites. He knows exactly which URLs to look for.\nThen, while Theo is looking over the bookmarked sites, Joe goes to the whiteboard and\njots down the specific libraries in table 9.1.\n Immutable.js for JavaScript at https://immutable-js.com/\n Paguro for Java at https://github.com/GlenKPeterson/Paguro\n Immutable Collections for C# at http://mng.bz/QW51\n Pyrsistent for Python at https://github.com/tobgu/pyrsistent\n Hamster for Ruby at https://github.com/hamstergem/hamster\nTable 9.1 Persistent data structure libraries\nLanguage Library\nJavaScript Immutable.js\nJava Paguro\nC# Provided by the language\nPython Pyrsistent\nRuby Hamster\nTheo What does it take to integrate persistent data structures provided by a third-\nparty library into your code?\n9.3.1 Persistent data structures in Java\nJoe In an object-oriented language like Java, it’s quite straightforward to integrate\npersistent data structures in a program because persistent data structures\nimplement collection interfaces, besides the parts of the interface that mutate\nin place.\nTheo What do you mean?\n--- Page 213 ---\n9.3 Persistent data structures libraries 185\nJoe Take for instance, Paguro for Java. Paguro persistent maps implement the\nread-only methods of java.util.Map like get() and containsKey(), but not\nmethods like put() and remove(). On the other hand, Paguro vectors imple-\nment the read-only methods of java.util.List like get() and size(), but not\nmethods like set().\nTheo What happens when we call put() or remove() on a Paguro map?\nJoe It throws an UnSupportedOperationException exception.\nTheo What about iterating over the elements of a Paguro collection with a forEach()?\nJoe That works like it would in any Java collection. Here, let me show you an example.\nListing9.5 Iterating over a Paguro vector\nvar myVec = PersistentVector.ofIter(\nList.of(10, 2, 3));\nCreates a Paguro\nvector from a\nfor (Integer i : myVec) {\nJava list\nSystem.out.println(i);\n}\nTheo What about Java streams?\nJoe Paguro collections are Java collections, so they support the Java stream inter-\nface. Take a look at this code.\nListing9.6 Streaming a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvec1.stream().sorted().map(x -> x + 1);\nTIP Paguro collections implement the read-only parts of Java collection interfaces.\nTherefore, they can be passed to any methods that expect to receive a Java collection\nwithout mutating it.\nTheo So far, you told me how do use Paguro collections as Java read-only collections.\nHow do I make modifications to Paguro persistent data structures?\nJoe In a way similar to the _.set() function of Lodash FP that we talked about\nearlier. Instead of mutating in place, you create a new version.\nTheo What methods does Paguro expose for creating new versions of a data structure?\nJoe For vectors, you use replace(), and for maps, you use assoc().\nListing9.7 Creating a modified version of a Paguro vector\nvar myVec = PersistentVector.ofIter(List.of(10, 2, 3));\nvar myNextVec = myVec.replace(0, 42);\n--- Page 214 ---\n186 CHAPTER 9 Persistent data structures\nListing9.8 Creating a modified version of a Paguro map\nvar myMap = PersistentHashMap.of(Map.of(\"aa\", 1, \"bb\", 2)\n.entrySet());\nCreates a Paguro map\nfrom a Java map entry set\nvar myNextMap = myMap.assoc(\"aa\", 42);\nTheo Yes! Now I see how to use persistent data structures in Java, but what about\nJavaScript?\n9.3.2 Persistent data structures in JavaScript\nJoe In a language like JavaScript, it’s a bit more cumbersome to integrate per-\nsistent data structures.\nTheo How so?\nJoe Because JavaScript objects and arrays don’t expose any interface.\nTheo Bummer.\nJoe It’s not as terrible as it sounds because Immutable.js exposes its own set of\nfunctions to manipulate its data structures.\nTheo What do you mean?\nJoe I’ll show you in a moment. But first, let me show you how to initiate Immutable.js\npersistent data structures.\nTheo OK!\nJoe Immutable.js provides a handy function that recursively converts a native data\nobject to an immutable one. It’s called Immutable.fromJS().\nTheo What do you mean by recursively?\nJoe Consider the map that holds library data from our Library Management Sys-\ntem: it has values that are themselves maps. Immutable.fromJS() converts the\nnested maps into immutable maps.\nTheo Could you show me some code?\nJoe Absolutely. Take a look at this JavaScript code for library data.\nListing9.9 Conversion to immutable data\nvar libraryData = Immutable.fromJS({\n\"catalog\": {\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n--- Page 215 ---\n9.3 Persistent data structures libraries 187\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n}\n});\nTheo Do you mean that the catalog value in libraryData map is itself an immutable\nmap?\nJoe Yes, and the same for booksByIsbn, authorIds, and so forth.\nTheo Cool! So how do I access a field inside an immutable map?\nJoe As I told you, Immutable.js provides its own API for data access. For instance,\nin order to access a field inside an immutable map, you use Immutable.get()\nor Immutable.getIn() like the following.\nListing9.10 Accessing a field and a nested field in an immutable map\nImmutable.get(libraryData, \"catalog\");\nImmutable.getIn(libraryData,\n[\"catalog\", \"booksByIsbn\", \"978-1779501127\", \"title\"]);\n// → \"Watchmen\"\nTheo How do I make a modification to a map?\nJoe Similar to what we did with Lodash FP, you use an Immutable.set() or\nImmutable.setIn() map to create a new version of the map where a field is\nmodified. Here’s how.\nListing9.11 Creating a new version of a map where a field is modified\nImmutable.setIn(libraryData,\n[\"catalog\", \"booksByIsbn\",\n\"978-1779501127\", \"publicationYear\"],\n1988);\nTheo What happens when I try to access a field in the map using JavaScript’s dot or\nbracket notation?\nJoe You access the internal representation of the map instead of accessing a map\nfield.\nTheo Does that mean that we can’t pass data from Immutable.js to Lodash for data\nmanipulation?\nJoe Yes, but it’s quite easy to convert any immutable collection into a native Java-\nScript object back and forth.\nTheo How?\nJoe Immutable.js provides a toJS() method to convert an arbitrary deeply nested\nimmutable collection into a JavaScript object.\n--- Page 216 ---\n188 CHAPTER 9 Persistent data structures\nTheo But if I have a huge collection, it could take lots of time to convert it, right?\nJoe True. We need a better solution. Hopefully, Immutable.js provides its own set\nof data manipulation functions like map(), filter(), and reduce().\nTheo What if I need more data manipulation like Lodash’s _.groupBy()?\nJoe You could write your own data manipulation functions that work with the\nImmutable.js collections or use a library like mudash, which provides a port of\nLodash to Immutable.js.\n NOTE You can access the mudash library at https://github.com/brianneisler/mudash.\nTheo What would you advise?\nJoe A cup of coffee, then I’ll show you how to port functions from Lodash to\nImmutable.js and how to adapt the code from your Library Management System.\nYou can decide on whichever approach works best for your current project.\n9.4 Persistent data structures in action\nJoe Let’s start with our search query. Can you look at the current code and tell me\nthe Lodash functions that we used to implement the search query?\nTheo Including the code for the unit tests?\nJoe Of course!\n NOTE See chapter 6 for the unit test of the search query.\n9.4.1 Writing queries with persistent data structures\nTheo The Lodash functions we used were get, map, filter, and isEqual.\nJoe Here’s the port of those four functions from Lodash to Immutable.js.\nListing9.12 Porting some functions from Lodash to Immutable.js\nImmutable.map = function(coll, f) {\nreturn coll.map(f);\n};\nImmutable.filter = function(coll, f) {\nif(Immutable.isMap(coll)) {\nreturn coll.valueSeq().filter(f);\n}\nreturn coll.filter(f);\n};\nImmutable.isEqual = Immutable.is;\nTheo The code seems quite simple. But can you explain it to me, function by function?\nJoe Sure. Let’s start with get. For accessing a field in a map, Immutable.js provides\ntwo functions: get for direct fields and getIn for nested fields. It’s different\nfrom Lodash, where _.get works both on direct and nested fields.\n--- Page 217 ---\n9.4 Persistent data structures in action 189\nTheo What about map?\nJoe Immutable.js provides its own map function. The only difference is that it is a\nmethod of the collection, but it is something that we can easily adapt.\nTheo What about filter? How would you make it work both for arrays and maps\nlike Lodash’s filter?\nJoe Immutable.js provides a valueSeq method that returns the values of a map.\nTheo Cool. And what about isEqual to compare two collections?\nJoe That’s easy. Immutable.js provides a function named is that works exactly as\nisEqual.\nTheo So far, so good. What do I need to do now to make the code of the search\nquery work with Immutable.js?\nJoe You simply replace each occurrence of an _ with Immutable; _.map becomes\nImmutable.map, _.filter becomes Immutable.filter, and _.isEqual\nbecomes Immutable.isEqual.\nTheo I can’t believe it’s so easy!\nJoe Try it yourself; you’ll see. Sometimes, it’s a bit more cumbersome because\nyou need to convert the JavaScript objects to Immutable.js objects using\nImmutable.fromJS.\nTheo copies and pastes the snippets for the code and the unit tests of the search query.\nThen, he uses his IDE to replace the _ with Immutable. When Theo executes the tests and\nthey pass, he is surprised but satisfied. Joe smiles.\nListing9.13 Implementing book search with persistent data structures\nclass Catalog {\nstatic authorNames(catalogData, authorIds) {\nreturn Immutable.map(authorIds, function(authorId) {\nreturn Immutable.getIn(\ncatalogData,\n[\"authorsById\", authorId, \"name\"]);\n});\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = Immutable.Map({\n\"title\": Immutable.get(book, \"title\"),\n\"isbn\": Immutable.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(\ncatalogData,\nImmutable.get(book, \"authorIds\"))\n});\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = Immutable.get(catalogData, \"booksByIsbn\");\nvar queryLowerCased = query.toLowerCase();\nvar matchingBooks = Immutable.filter(allBooks, function(book) {\n--- Page 218 ---\n190 CHAPTER 9 Persistent data structures\nreturn Immutable.get(book, \"title\").\ntoLowerCase().\nincludes(queryLowerCased);\n});\nvar bookInfos = Immutable.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\nListing9.14 Testing book search with persistent data structures\nvar catalogData = Immutable.fromJS({\n\"booksByIsbn\": {\n\"978-1779501127\": {\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"publicationYear\": 1987,\n\"authorIds\": [\"alan-moore\",\n\"dave-gibbons\"]\n}\n},\n\"authorsById\": {\n\"alan-moore\": {\n\"name\": \"Alan Moore\",\n\"bookIsbns\": [\"978-1779501127\"]\n},\n\"dave-gibbons\": {\n\"name\": \"Dave Gibbons\",\n\"bookIsbns\": [\"978-1779501127\"]\n}\n}\n});\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Watchmen\"),\nImmutable.fromJS([bookInfo]));\n// → true\nImmutable.isEqual(\nCatalog.searchBooksByTitle(catalogData, \"Batman\"),\nImmutable.fromJS([]));\n// → true\n--- Page 219 ---\n9.4 Persistent data structures in action 191\n9.4.2 Writing mutations with persistent data structures\nTheo Shall we move forward and port the add member mutation?\nJoe Sure. Porting the add member mutation from Lodash to Immutable.js only\nrequires you to again replace the underscore (_) with Immutable. Let’s look at\nsome code.\nListing9.15 Implementing member addition with persistent data structures\nUserManagement.addMember = function(userManagement, member) {\nvar email = Immutable.get(member, \"email\");\nvar infoPath = [\"membersByEmail\", email];\nif(Immutable.hasIn(userManagement, infoPath)) {\nthrow \"Member already exists.\";\n}\nvar nextUserManagement = Immutable.setIn(userManagement,\ninfoPath,\nmember);\nreturn nextUserManagement;\n};\nTheo So, for the tests, I’d convert the JavaScript objects to Immutable.js objects with\nImmutable.fromJS(). How does this look?\nListing9.16 Testing member addition with persistent data structures\nvar jessie = Immutable.fromJS({\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n});\nvar franck = Immutable.fromJS({\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n});\nvar userManagementStateBefore = Immutable.fromJS({\n\"membersByEmail\": {\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n}\n}\n});\nvar expectedUserManagementStateAfter = Immutable.fromJS({\n\"membersByEmail\": {\n\"jessie@gmail.com\": {\n\"email\": \"jessie@gmail.com\",\n\"password\": \"my-secret\"\n},\n\"franck@gmail.com\": {\n\"email\": \"franck@gmail.com\",\n\"password\": \"my-top-secret\"\n--- Page 220 ---\n192 CHAPTER 9 Persistent data structures\n}\n}\n});\nvar result = UserManagement.addMember(userManagementStateBefore, jessie);\nImmutable.isEqual(result, expectedUserManagementStateAfter);\n// → true\nJoe Great!\n9.4.3 Serialization and deserialization\nTheo Does Immutable.js also support JSON serialization and deserialization?\nJoe It supports serialization out of the box. As for deserialization, we need to write\nour own function.\nTheo Does Immutable.js provide an Immutable.stringify() function?\nJoe That’s not necessary because the native JSON.stringify() function works\nwith Immutable.js objects. Here’s another example.\nListing9.17 JSON serialization of an Immutable.js collection\nvar bookInfo = Immutable.fromJS({\n\"isbn\": \"978-1779501127\",\n\"title\": \"Watchmen\",\n\"authorNames\": [\"Alan Moore\",\n\"Dave Gibbons\"]\n});\nJSON.stringify(bookInfo);\n// → {\\\"isbn\\\":\\\"978-1779501127\\\",\\\"title\\\":\\\"Watchmen\\\",\n// → \\\"authorNames\\\":[\\\"Alan Moore\\\",\\\"Dave Gibbons\\\"]}\nTheo How does JSON.stringify() know how to handle an Immutable.js collection?\nJoe As an OOP developer, you shouldn’t be surprised by that.\nTheo Hmm...let me think a minute. OK, here’s my guess. Is that because JSON\n.stringify() calls some method on its argument?\nJoe Exactly! If the object passed to JSON.stringify() has a .toJSON() method,\nit’s called by JSON.stringify().\nTheo Nice. What about JSON deserialization?\nJoe That needs to be done in two steps. You first convert the JSON string to a Java-\nScript object and then to an immutable collection.\nTheo Something like this piece of code?\nListing9.18 Converting a JSON string into an immutable collection\nImmutable.parseJSON = function(jsonString) {\nreturn Immutable.fromJS(JSON.parse(jsonString));\n};\nJoe Exactly.\n--- Page 221 ---\n9.4 Persistent data structures in action 193\n9.4.4 Structural diff\nTheo So far, we have ported pieces of code that dealt with simple data manipula-\ntions. I’m curious to see how it goes with complex data manipulations such as\nthe code that computes the structural diff between two maps.\n NOTE Chapter 5 introduces structural diff.\nJoe That also works smoothly, but we need to port another eight functions.\nListing9.19 Porting Lodash functions involved in structural diff computation\nImmutable.reduce = function(coll, reducer, initialReduction) {\nreturn coll.reduce(reducer, initialReduction);\n};\nImmutable.isEmpty = function(coll) {\nreturn coll.isEmpty();\n};\nImmutable.keys = function(coll) {\nreturn coll.keySeq();\n};\nImmutable.isObject = function(coll) {\nreturn Immutable.Map.isMap(coll);\n};\nImmutable.isArray = Immutable.isIndexed;\nImmutable.union = function() {\nreturn Immutable.Set.union(arguments);\n};\nTheo Everything looks trivial with one exception: the use of arguments in Immutable\n.union.\nJoe In JavaScript, arguments is an implicit array-like object that contains the values\nof the function arguments.\nTheo I see. It’s one of those pieces of JavaScript magic!\nJoe Yep. We need to use arguments because Lodash and Immutable.js differ slightly\nin the signature of the union function. Immutable.Set.union receives an array\nof lists, whereas a Lodash _.union receives several arrays.\nTheo Makes sense. Let me give it a try.\nBlowing on his fingers like a seasoned safecracker, first one hand and then the next, Theo\nbegins typing. Once again, Theo is surprised to discover that after replacing the _ with\nImmutable in listing 9.20, the tests pass with the code in listing 9.21.\nListing9.20 Implementing structural diff with persistent data structures\nfunction diffObjects(data1, data2) {\nvar emptyObject = Immutable.isArray(data1) ?\nImmutable.fromJS([]) :\n--- Page 222 ---\n194 CHAPTER 9 Persistent data structures\nImmutable.fromJS({});\nif(data1 == data2) {\nreturn emptyObject;\n}\nvar keys = Immutable.union(Immutable.keys(data1), Immutable.keys(data2));\nreturn Immutable.reduce(keys,\nfunction (acc, k) {\nvar res = diff(Immutable.get(data1, k),\nImmutable.get(data2, k));\nif((Immutable.isObject(res) && Immutable.isEmpty(res)) ||\n(res == \"data-diff:no-diff\")) {\nreturn acc;\n}\nreturn Immutable.set(acc, k, res);\n},\nemptyObject);\n}\nfunction diff(data1, data2) {\nif(Immutable.isObject(data1) && Immutable.isObject(data2)) {\nreturn diffObjects(data1, data2);\n}\nif(data1 !== data2) {\nreturn data2;\n}\nreturn \"data-diff:no-diff\";\n}\nListing9.21 Testing structural diff with persistent data structures\nvar data1 = Immutable.fromJS({\ng: {\nc: 3\n},\nx: 2,\ny: {\nz: 1\n},\nw: [5]\n});\nvar data2 = Immutable.fromJS({\ng: {\nc:3\n},\nx: 2,\ny: {\nz: 2\n},\nw: [4]\n});\nImmutable.isEqual(diff(data1, data2),\nImmutable.fromJS({\n--- Page 223 ---\nSummary 195\n\"w\": [\n4\n],\n\"y\": {\n\"z\": 2\n}\n}));\nJoe What do you think of all this, my friend?\nTheo I think that using persistent data collections with a library like Immutable.js is\nmuch easier than understanding the internals of persistent data structures. But\nI’m also glad that I know how it works under the hood.\nAfter accompanying Joe to the office door, Theo meets Dave. Dave had been peering\nthrough the window in Theo’s office, looking at the whiteboard, anxious to catch a glimpse\nof today’s topic on DOP.\nDave What did Joe teach you today?\nTheo He took me to the university and taught me the foundations of persistent data\nstructures for dealing with immutability at scale.\nDave What’s wrong with the structural sharing that I implemented a couple of\nmonths ago?\nTheo When the number of elements in the collection is big enough, naive structural\nsharing has performance issues.\nDave I see. Could you tell me more about that?\nTheo I’d love to, but my brain isn’t functioning properly after this interesting but\nexhausting day. We’ll do it soon, promise.\nDave No worries. Have a nice evening, Theo.\nTheo You too, Dave.\nSummary\n It’s possible to manually ensure that our data isn’t mutated, but it’s cumbersome.\n At scale, naive structural sharing causes a performance hit, both in terms of\nmemory and computation.\n Naive structural sharing doesn’t prevent data structures from being accidentally\nmutated.\n Immutable collections are not the same as persistent data structures.\n Immutable collections don’t provide an efficient way to create new versions of\nthe collections.\n Persistent data structures protect data from mutation.\n Persistent data structures provide an efficient way to create new versions of the\ncollections.\n Persistent data structures always preserve the previous version of themselves when\nthey are modified.\n--- Page 224 ---\n196 CHAPTER 9 Persistent data structures\n Persistent data structures represent data internally in such a way that structural\nsharing scales well, both in terms of memory and computation.\n When data is immutable, it is safe to share it.\n Internally, persistence uses a branching factor of 32.\n In practice, manipulation of persistent data structures is efficient even for col-\nlections with 10 billion entries!\n Due to modern architecture considerations, the performance of updating a\npersistent list is dominated much more by the depth of the tree than by the\nnumber of nodes at each level of the tree.\n Persistent lists can be manipulated in near constant time.\n In most languages, third-party libraries provide an implementation of persistent\ndata structures.\n Paguro collections implement the read-only parts of Java collection interfaces.\n Paguro collections can be passed to any methods that expect to receive a Java\ncollection without mutating them.\n--- Page 225 ---\nDatabase operations\nA cloud is a cloud\nThis chapter covers\n Fetching data from the database\n Storing data in the database\n Manipulating data fetched from the database\nTraditionally in OOP, we use design patterns and complex layers of objects to struc-\nture access to the database. In DOP, we prefer to represent data fetched from the\ndatabase with generic data collections, namely, lists of maps, where fields in the\nmaps correspond to database column values. As we’ll see throughout the chapter,\nthe fact that fields inside a map are accessible dynamically via their names allows us\nto use the same generic code for different data entities.\nTIP The best way to manipulate data is to represent data as data.\nIn this chapter, we’ll illustrate the application of data-oriented principles when\naccessing data from a relational database. Basic knowledge of relational database\nand SQL query syntax (like SELECT, AS, WHERE, and INNER JOIN) is assumed. This\napproach can be easily adapted to NoSQL databases.\n197\n--- Page 226 ---\n198 CHAPTER 10 Database operations\nApplications that run on the server usually store data in a database. In DOP, we\nrepresent data retrieved from the database the same way we represent any other data\nin our application—with generic data collections. This leads to\n Reduced system complexity.\n Increased genericity.\n10.1 Fetching data from the database\nTheo and Joe go for a walk in a park near the office. They sit on a bench close to a beau-\ntiful lake and gaze at the clouds in the sky. After a couple of minutes of meditative\nsilence, Joe asks Theo, “What do you see?” Theo tells him that this cloud looks to him\nlike a horse, and that one looks like a car. On their way back to the office, Theo asks Joe\nfor an explanation about the clouds. Joe answers with a mysterious smile on his lips, “A\ncloud is a cloud.”\nTheo So far you’ve shown me how DOP represents data that lives in the memory of\nthe application. What about data that comes from the outside?\nJoe What do you mean by outside?\nTheo Data that comes from the database.\nJoe I’ll return the question to you. How do you think that we should represent data\nthat comes from the database in DOP?\nTheo As generic data collections, I guess.\nJoe Exactly! In DOP, we always represent data with generic data collections.\nTheo Does that mean that we can manipulate data from the database with the same\nflexibility as we manipulate in-memory data?\nJoe Definitely.\nTIP In DOP, we represent data from the database with generic data collections, and\nwe manipulate it with generic functions.\nTheo Would you show me how to retrieve book search results when the catalog data\nis stored in an SQL database?\nJoe I’ll show you in a moment. First, tell me how you would design the tables that\nstore catalog data.\nTheo Do you mean the exact table schemas with the information about primary keys\nand nullability of each and every column?\nJoe No, I only need a rough overview of the tables, their columns, and the relation-\nships between the tables.\nTheo goes to the whiteboard. Figure 10.1 shows the diagram he draws as he explains his\nthinking to Joe.\n--- Page 227 ---\n10.1 Fetching data from the database 199\nT books\nT authors\nisbn VARCHAR[32]\nid VARCHAR[64]\ntitle VARCHAR[64]\nname VARCHAR[64]\npublication_year INTEGER\n1\nA book 1 An author\nmay have may author\nmany authors. many books.\n* *\nbook_authors\nT (relationships of books and authors)\nbook_isbn VARCHAR[32] Figure 10.1 The database model\nauthor_id VARCHAR[64]\nfor books and authors\nTheo I have a books table with three columns: title, isbn, and publication_\nyear. I also have an authors table with two columns: for id and name. Here,\nlet me draw these tables on the whiteboard to give you a visual (see tables 10.1\nand 10.2).\nTable 10.1 The books table filled with two books\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nTable 10.2 The authors table filled with three authors\nid name\nsean-covey Sean Covey\nstephen-covey Stephen Covey\ncharles-duhigg Charles Duhigg\nJoe What about the connection between books and authors?\nTheo Let’s see, a book could be written by multiple authors, and an author could write\nmultiple books. Therefore, I need a many-to-many book_authors table that con-\nnects authors and books with two columns, book_isbn and author_id.\nTheo once again turns to the whiteboard. He pens the book_authors table 10.3 to show Joe.\nTable 10.3 The book_authors table with rows connecting books with their authors\nbook_isbn author_id\n978-1982137274 sean-covey\n978-1982137274 stephen-covey\n978-0812981605 charles-duhigg\n--- Page 228 ---\n200 CHAPTER 10 Database operations\nJoe Great! Let’s start with the simplest case. We’re going to write code that searches\nfor books matching a title and that returns basic information about the books.\nBy basic information, I mean title, ISBN, and publication year.\nTheo What about the book authors?\nJoe We’ll deal with that later, as it’s a bit more complicated. Can you write an SQL\nquery for retrieving books that contain he word habit in their title?\nTheo Sure.\nThis assignment is quite easy for Theo. First, he jots down the SQL query, then he displays\nthe results in table 10.4.\nListing10.1 SQL query to retrieve books whose title contains habit\nSELECT\ntitle,\nisbn,\npublication_year\nFROM\nbooks\nWHERE title LIKE '%habit%';\nTable 10.4 Results of the SQL query for books whose title contains the word habit\ntitle isbn publication_year\nThe Power of Habit 978-0812981605 2012\n7 Habits of Highly Effective People 978-1982137274 1989\nJoe How would you describe these results as a data collection?\nTheo I would say it’s a list of maps.\nTIP In DOP, accessing data from a NoSQL database is similar to the way we access\ndata from a relational database.\nJoe Right! Now, can you write the search results as a list of maps?\nTheo It doesn’t sound too complicated. How about this?\nListing10.2 Search results as a list of maps\n[\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"publication_year\": 1989\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"publication_year\": 2012\n}\n]\n--- Page 229 ---\n10.1 Fetching data from the database 201\nJoe What about the JSON schema for the search results?\nTheo It shouldn’t be too difficult if you allow me to take a look at the JSON schema\ncheat sheet you kindly offered me the other day.\nJoe Of course. The purpose of a gift is to be used by the one who receives it.\nTheo takes a look at the JSON Schema cheat sheet to refresh his memory about the JSON\nSchema syntax. After a few minutes, Theo comes up with a schema for the search results.\nHe certainly is putting Joe’s gift to good use.\nListing10.3 JSON schema cheat sheet\n{\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"myNumber\": {\"type\": \"number\"},\n\"myString\": {\"type\": \"string\"},\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]},\n\"myBool\": {\"type\": \"boolean\"}\n},\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\n}\n}\nListing10.4 The JSON schema for search results from the database\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"publication_year\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"publication_year\": {\"type\": \"integer\"}\n}\n}\n};\nJoe Excellent. Now I’m going to show you how to implement searchBooks in a\nway that fetches data from the database and returns a JSON string with the\nresults. The cool thing is that we’re only going to use generic data collections\nfrom the database layer down to the JSON serialization.\nTheo Will it be similar to the implementation of searchBooks that we wrote when\nyou taught me the basis of DOP?\nJoe Absolutely. The only difference is that then the state of the system was stored\nlocally, and we queried it with a function like _.filter. Now, we use SQL\n--- Page 230 ---\n202 CHAPTER 10 Database operations\nqueries to fetch the state from the database. In terms of data representation\nand manipulation, it’s exactly the same.\nJoe goes to the whiteboard and sketches out the data flow in figure 10.2. Theo studies the\ndiagram.\nDatabase\nDatabase driver\nData (list of maps)\nData manipulation\nData Figure 10.2 Data flow for serving\na request that fetches data from\nJSON serialize\nthe database\nJoe The data manipulation step in the diagram is implemented via generic func-\ntions that manipulate data collections. As our examples get more elaborate, I\nthink you’ll see the benefits of being able to manipulate data collections with\ngeneric functions.\nTheo Sounds intriguing...\nJoe For the communication with the database, we use a driver that returns a list of\nmaps. In JavaScript, you could use an SQL driver like node-postgres.\n NOTE See https://node-postgres.com for more information about this collection of\nnode.js modules for interfacing with PostgreSQL databases.\nTheo And in Java?\nJoe In Java, you could use JDBC (Java database connectivity) in addition to a small\nutility function that converts a JDBC result set into a list of maps. If I can use\nyour laptop, I’ll show you what I mean.\nJoe pulls a piece of code from one of his personal GitHub repositories. He then shows the\ncode for the JDBC conversion to Theo, who seems a bit surprised.\nListing10.5 Converting a JDBC result set into a list of hash maps\nList<Map<String, Object>> convertJDBCResultSetToListOfMaps(ResultSet rs) {\nList<Map<String, Object>> listOfMaps =\nnew ArrayList<Map<String, Object>>();\nResultSetMetaData meta = rs.getMetaData();\nwhile (rs.next()) {\nMap map = new HashMap();\nfor (int i = 1; i <= meta.getColumnCount(); i++) {\nString key = meta.getColumnLabel(i);\nObject value = rs.getObject(i);\n--- Page 231 ---\n10.1 Fetching data from the database 203\nmap.put(key, value);\n}\nlistOfMaps.add(map);\n}\nreturn listOfMaps;\n}\nTIP Converting a JDBC result set into a list of hash maps is quite straightforward.\nTheo I expected it to be much more complicated to convert a JDBC result set into a\nlist of hash maps.\nJoe It’s straightforward because, in a sense, JDBC is data-oriented.\nTheo What about the field types?\nJoe When we convert a JDBC result set into a list of maps, each value is considered\nan Object.\nTheo That’s annoying because it means that in order to access the value, we need to\ncast it to its type.\nJoe Yes and no. Look at our book search use case. We pass all the values along with-\nout really looking at their type. The concrete value type only matters when we\nserialize the result into JSON and that’s handled by the JSON serialization\nlibrary. It’s called late binding.\n NOTE With late binding, we defer dealing with data types as long as possible.\nTheo Does that mean in my application that I’m allowed to manipulate data without\ndealing with concrete types?\nTIP In DOP, flexibility is increased as many parts of the system are free to manipulate\ndata without dealing with concrete types.\nJoe Exactly. You’ll see late binding in action in a moment. That’s one of the great-\nest benefits of DOP.\nTheo Interesting, I can’t wait to see that!\nJoe One last thing before I show you the code for retrieving search results from the\ndatabase. In order to make it easier to read, I’m going to write JavaScript code\nas if JavaScript were dealing with I/O is a synchronous way.\nTheo What do you mean?\nJoe In JavaScript, an I/O operation like sending a query to the database is done\nasynchronously. In real life, it means using either callback functions or using\nasync and await keywords.\nTheo Oh yeah, that’s because JavaScript is single-threaded.\n NOTE For sake of simplicity, the JavaScript snippets in this chapter are written as if\nJavaScript were dealing with I/O in a synchronous way. In real-life JavaScript, we need\nto use async and await around I/O calls.\nJoe Indeed, so I’ll be writing the code that communicates with the database as\nthough JavaScript were dealing with I/O synchronously. Here’s an example.\n--- Page 232 ---\n204 CHAPTER 10 Database operations\nListing10.6 Searching books in the database, returning the results in JSON\ndbClient holds the Initializes Ajv (a JSON schema validation\nvar dbClient; DB connection. library) with allErrors: true to catch all\nthe data validation errors\nvar ajv = new Ajv({allErrors: true});\nvar title = \"habit\";\nvar matchingBooksQuery = `SELECT title, isbn Uses a parameterized\nSQL query as a security\nFROM books\nbest practice\nWHERE title LIKE '%$1%'`;\nvar books = dbClient.query(matchingBooksQuery,\nPasses the parameters to the SQL\n[title]);\nquery as a list of values (in our\nif(!ajv.validate(dbSearchResultSchema, books)) {\ncase, a list with a single value)\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" + errors;\n}\nJSON.stringify(books);\nTheo In a dynamically-typed language like JavaScript, I understand that the types of\nthe values in the list of maps returned by dbClient.query are determined at\nrun time. How does it work in a statically-typed language like Java, and what are\nthe types of the data fields in books?\nJoe The function convertJDBCResultSetToListOfMaps we created earlier (see\nlisting 10.5) returns a list of Map<String, Object>. But JSON serialization\nlibraries like Gson know how to detect at run time the concrete type of the val-\nues in a map and serialize the values according to their type.\n NOTE See https://github.com/google/gson for information about Gson’s Java\nserialization/deserialization library.\nTheo What do you mean by serializing a value according to its type?\nJoe For instance, the value of the field publication_year is a number; therefore,\nit is not wrapped with quotes. However, the value of the field title is a string;\ntherefore, it is wrapped with quotes.\nTheo Nice! Now, I understand what you mean by late binding.\nJoe Cool! Now, let me show you how we store data in the database.\n10.2 Storing data in the database\nIn the previous section, we saw how to retrieve data from the database as a list of maps.\nNext, we’ll see how to store data in the database when data is represented with a map.\nTheo I guess that storing data in the database is quite similar to fetching data from\nthe database.\nJoe It’s similar in the sense that we deal only with generic data collections. Can you\nwrite a parameterized SQL query that inserts a row with user info using only\nemail and encrypted_password, please?\nTheo OK.",
        "sections_found": []
      },
      "accurate_page_range": "202-232"
    },
    {
      "text": "- 9.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 70
    },
    {
      "text": "- 9.1 The need for persistent data structures",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.1 The need for persistent data structures (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 71
    },
    {
      "text": "- 9.2 The efficiency of persistent data structures",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.2 The efficiency of persistent data structures (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 72
    },
    {
      "text": "- 9.3.0 Introduction (사용자 추가)",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.3.0 Introduction (사용자 추가) (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 73
    },
    {
      "text": "- 9.3.1 Persistent data structures in Java",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.3.1 Persistent data structures in Java (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 74
    },
    {
      "text": "- 9.3.2 Persistent data structures in JavaScript",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.3.2 Persistent data structures in JavaScript (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 75
    },
    {
      "text": "- 9.4.0 Introduction (사용자 추가)",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.4.0 Introduction (사용자 추가) (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 76
    },
    {
      "text": "- 9.4.1 Writing queries with persistent data structures",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.4.1 Writing queries with persistent data structures (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 77
    },
    {
      "text": "- 9.4.2 Writing mutations with persistent data structures",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.4.2 Writing mutations with persistent data structures (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 78
    },
    {
      "text": "- 9.4.3 Serialization and deserialization",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.4.3 Serialization and deserialization (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 79
    },
    {
      "text": "- 9.4.4 Structural diff",
      "node_level": 4,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- 9.4.4 Structural diff (node4) **[LEAF]**",
      "is_part_intro": false,
      "id": 80
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "9 Persistent data structures",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 81
    },
    {
      "text": "- 10.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 82,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.1 Fetching data from the database",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.1 Fetching data from the database (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 83,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.2 Storing data in the database",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.2 Storing data in the database (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 84,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.3 Simple data manipulation",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.3 Simple data manipulation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 85,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 10.4 Advanced data manipulation",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- 10.4 Advanced data manipulation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 86,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "10 Database operations",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 87,
      "chapter_info": {
        "page": 262,
        "title": "Database operations",
        "pattern_matched": "Chapter 10",
        "text_preview": "234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physic"
      },
      "chapter_sections": {
        "start_page": 262,
        "end_page": 292,
        "content": "\n--- Page 262 ---\n234 CHAPTER 11 Web services\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nTheo Yes! I think we now have all the pieces to enrich our search results.\n11.6 Search result enrichment in action\nJoe Can you write the steps of the enrichment data flow?\nTheo Sure.\nTheo goes to the whiteboard. He takes a moment to gather his thoughts, and then erases\nenough space so there’s room to list the steps.\nThe steps for the search result enrichment data flow\n1 Receive a request from a client.\n2 Extract from the client’s request the query and the fields to fetch from Open\nLibrary.\n3 Retrieve from the database the books that match the query.\n4 Fetch information from Open Library for each ISBN that match the query.\n5 Extract from Open Library responses for the required fields.\n6 Combine book information from the database with information from Open\nLibrary.\n7 Send the response to the client.\nJoe Perfect! Would you like to try to implement it?\nTheo I think I’ll start with the implementation of the book retrieval from the data-\nbase. It’s quite similar to what we did last month.\n NOTE See chapter 10 for last month’s lesson.\nJoe Actually, it’s even simpler because you don’t need to join tables.\nTheo That’s right, I need values only for the isbn and available columns.\nTheo works for a bit in his IDE. He begins with the book retrieval from the database.\nListing11.14 Retrieving books whose title matches a query\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n--- Page 263 ---\n11.6 Search result enrichment in action 235\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \" +\nerrors;\n}\nreturn books;\n}\n}\nJoe So far, so good...\nTheo Next, I’ll go with the implementation of the retrieval of book information from\nOpen Library for several books. Unfortunately, the Open Library Books API\ndoesn’t support querying several books at once. I’ll need to send one request\nper book.\nJoe That’s a bit annoying. Let’s make our life easier and pretend that _.map works\nwith asynchronous functions. In real life, you’d need something like Promise\n.all in order to send the requests in parallel and combine the responses.\nTheo OK, then it’s quite straightforward. I’ll take the book retrieval code and add a\nmultipleBookInfo function that maps over bookInfo.\nTheo looks over the book retrieval code in listing 11.9 and then concentrates as he types\ninto his IDE. When he’s done, he shows the result in listing 11.15 to Joe.\nListing11.15 Retrieving book information from Open Library for several books\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 264 ---\n236 CHAPTER 11 Web services\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(dbSearchResultSchema, bookInfoSchema)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo =\n_.pick(_.pick(rawInfo, relevantFields), requestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nJoe Nice! Now comes the fun part: combining information from several data sources.\nTheo Yeah. I have two arrays in my hands: one with book information from the data-\nbase and one with book information from Open Library. I somehow need to\njoin the arrays, but I’m not sure I can assume that the positions of the book\ninformation are the same in both arrays.\nJoe What would you like to have in your hands?\nTheo I wish I had two hash maps.\nJoe And what would the keys in the hash maps be?\nTheo Book ISBNs.\nJoe Well, I have good news for you: your wish is granted!\nTheo How?\nJoe Lodash provides a function named _.keyBy that transforms an array into a map.\nTheo I can’t believe it. Can you show me an example?\nJoe Sure. Let’s call _.keyBy on an array with two books.\nListing11.16 Transforming an array into a map with _.keyBy\nvar books = [\n{\n\"title\": \"7 Habits of Highly Effective People\",\n\"isbn\": \"978-1982137274\",\n\"available\": true\n},\n{\n\"title\": \"The Power of Habit\",\n\"isbn\": \"978-0812981605\",\n\"available\": false\n}\n];\n_.keyBy(books, \"isbn\");\n--- Page 265 ---\n11.6 Search result enrichment in action 237\nJoe And here’s the result.\nListing11.17 The result of keyBy\n{\n\"978-0812981605\": {\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\"\n},\n\"978-1982137274\": {\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\"\n}\n}\nTheo keyBy is awesome!\nJoe Don’t exaggerate, my friend; _.keyBy is quite similar to _.groupBy. The\nonly difference is that _.keyBy assumes that there’s only one element in\neach group.\nTheo I think that, with _.keyBy, I’ll be able to write a generic joinArrays function.\nJoe I’m glad to see you thinking in terms of implementing business logic through\ngeneric data manipulation functions.\nTIP Many parts of the business logic can be implemented through generic data\nmanipulation functions.\nTheo The joinArrays function needs to receive the arrays and the field name for\nwhich we decide the two elements that need to be combined, for instance,\nisbn.\nJoe Remember, in general, it’s not necessarily the same field name for both arrays.\nTheo Right, so joinArrays needs to receive four arguments: two arrays and two\nfield names.\nJoe Go for it! And, please, write a unit test for joinArrays.\nTheo Of course...\nTheo works for a while and produces the code in listing 11.18. He then types the unit test\nin listing 11.19.\nListing11.18 A generic function for joining arrays\nfunction joinArrays(a, b, keyA, keyB) {\nvar mapA = _.keyBy(a, keyA);\nvar mapB = _.keyBy(b, keyB);\nvar mapsMerged = _.merge(mapA, mapB);\nreturn _.values(mapsMerged);\n}\n--- Page 266 ---\n238 CHAPTER 11 Web services\nListing11.19 A unit test for joinArrays\nvar dbBookInfos = [\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"available\": true\n},\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"The Power of Habit\",\n\"available\": false\n}\n];\nvar openLibBookInfos = [\n{\n\"isbn\": \"978-0812981605\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"number_of_pages\": 432,\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"The Power of Habit\",\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\"\n],\n}\n];\nvar joinedArrays = [\n{\n\"available\": true,\n\"isbn\": \"978-1982137274\",\n\"subjects\": [\n\"Social aspects\",\n\"Habit\",\n\"Change (Psychology)\",\n],\n\"subtitle\": \"Why We Do What We Do in Life and Business\",\n\"title\": \"The Power of Habit\",\n},\n{\n\"available\": false,\n\"isbn\": \"978-0812981605\",\n\"number_of_pages\": 432,\n\"subtitle\": \"Powerful Lessons in Personal Change\",\n\"title\": \"7 Habits of Highly Effective People\",\n},\n]\n--- Page 267 ---\n11.6 Search result enrichment in action 239\n_.isEqual(joinedArrays,\njoinArrays(dbBookInfos, openLibBookInfos, \"isbn\", \"isbn\"));\nJoe Excellent! Now, you are ready to adjust the last piece of the extended search\nresult endpoint.\nTheo That’s quite easy. We fetch data from the database and from Open Library and\njoin them.\nTheo works quite rapidly. He then shows Joe the code.\nListing11.20 Search books and enriched book information\nclass Catalog {\nstatic enrichedSearchBooksByTitle(searchPayload) {\nif(!ajv.validate(searchBooksRequestSchema, searchPayload)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(searchPayload, \"title\");\nvar fields = _.get(searchPayload, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar res = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn res;\n}\n}\nNow comes the tricky part. Theo takes a few moments to meditate about the simplicity of\nthe code that implements the extended search endpoint. He thinks about how classes are\nmuch less complex when we use them only to aggregate stateless functions that operate on\nsimilar domain entities and then goes to work plotting the code.\nListing11.21 Schema for the extended search endpoint (Open Books API part)\nvar basicBookInfoSchema = {\n\"type\": \"object\",\n\"required\": [\"title\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n--- Page 268 ---\n240 CHAPTER 11 Web services\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_13\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn_10\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nvar mandatoryIsbn13 = {\n\"type\": \"object\",\n\"required\": [\"isbn_13\"]\n};\nvar mandatoryIsbn10 = {\n\"type\": \"object\",\n\"required\": [\"isbn_10\"]\n};\nvar bookInfoSchema = {\n\"allOf\": [\nbasicBookInfoSchema,\n{\n\"anyOf\": [mandatoryIsbn13, mandatoryIsbn10]\n}\n]\n};\nListing11.22 Extended search endpoint (Open Books API part)\nvar ajv = new Ajv({allErrors: true});\nclass OpenLibraryDataSource {\nstatic rawBookInfo(isbn) {\nvar url = `https:/ /openlibrary.org/isbn/${isbn}.json`;\nvar jsonString = fetchResponseBody(url);\nreturn JSON.parse(jsonString);\n}\nstatic bookInfo(isbn, requestedFields) {\nvar relevantFields = [\"title\", \"full_title\",\n\"subtitle\", \"publisher\",\n\"publish_date\", \"weight\",\n--- Page 269 ---\n11.6 Search result enrichment in action 241\n\"physical_dimensions\", \"genre\",\n\"subjects\", \"number_of_pages\"];\nvar rawInfo = rawBookInfo(isbn);\nif(!ajv.validate(bookInfoSchema, rawInfo)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from Open Books API: \" +\nerrors;\n}\nvar relevantInfo = _.pick(\n_.pick(rawInfo, relevantFields),\nrequestedFields);\nreturn _.set(relevantInfo, \"isbn\", isbn);\n}\nstatic multipleBookInfo(isbns, fields) {\nreturn _.map(function(isbn) {\nreturn bookInfo(isbn, fields);\n}, isbns);\n}\n}\nListing11.23 Extended search endpoint (database part)\nvar dbClient;\nvar dbSearchResultSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"isbn\", \"available\"],\n\"properties\": {\n\"isbn\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"}\n}\n}\n};\nclass CatalogDB {\nstatic matchingBooks(title) {\nvar matchingBooksQuery = `\nSELECT isbn, available\nFROM books\nWHERE title = like '%$1%';\n`;\nvar books = dbClient.query(catalogDB, matchingBooksQuery, [title]);\nif(!ajv.validate(dbSearchResultSchema, books)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Internal error: Unexpected result from the database: \"\n+ errors;\n}\nreturn books;\n}\n}\n--- Page 270 ---\n242 CHAPTER 11 Web services\nListing11.24 Schema for the implementation of the extended search endpoint\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": [\n\"title\",\n\"full_title\",\n\"subtitle\",\n\"publisher\",\n\"publish_date\",\n\"weight\",\n\"physical_dimensions\",\n\"number_of_pages\",\n\"subjects\",\n\"publishers\",\n\"genre\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nvar searchBooksResponseSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"available\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"available\": {\"type\": \"boolean\"},\n\"publishers\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"number_of_pages\": {\"type\": \"integer\"},\n\"weight\": {\"type\": \"string\"},\n\"physical_format\": {\"type\": \"string\"},\n\"subjects\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"isbn\": {\"type\": \"string\"},\n\"publish_date\": {\"type\": \"string\"},\n\"physical_dimensions\": {\"type\": \"string\"}\n}\n};\nListing11.25 Schema for the extended search endpoint (combines the pieces)\nclass Catalog {\nstatic enrichedSearchBooksByTitle(request) {\n--- Page 271 ---\n11.6 Search result enrichment in action 243\nif(!ajv.validate(searchBooksRequestSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid request:\" + errors;\n}\nvar title = _.get(request, \"title\");\nvar fields = _.get(request, \"fields\");\nvar dbBookInfos = CatalogDataSource.matchingBooks(title);\nvar isbns = _.map(dbBookInfos, \"isbn\");\nvar openLibBookInfos =\nOpenLibraryDataSource.multipleBookInfo(isbns, fields);\nvar response = joinArrays(dbBookInfos, openLibBookInfos);\nif(!ajv.validate(searchBooksResponseSchema, request)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow \"Invalid response:\" + errors;\n}\nreturn response;\n}\n}\nclass Library {\nstatic searchBooksByTitle(payloadBody) {\nvar payloadData = JSON.parse(payloadBody);\nvar results = Catalog.searchBooksByTitle(payloadData);\nreturn JSON.stringify(results);\n}\n}\nTIP Classes are much less complex when we use them as a means to aggregate state-\nless functions that operate on similar domain entities.\nJoe interrupts Theo’s meditation moment. After looking over the code in the previous list-\nings, he congratulates Theo.\nJoe Excellent job, my friend! By the way, after reading The Power of Habit, I quit\nchewing my nails.\nTheo Wow! That’s terrific! Maybe I should read that book to overcome my habit of\ndrinking too much coffee.\nJoe Thanks, and good luck with the coffee habit.\nTheo I was supposed to call Nancy later today with an ETA for the Open Library\nBook milestone. I wonder what her reaction will be when I tell her the feature\nis ready.\nJoe Maybe you should tell her it’ll be ready in a week, which would give you time to\nbegin work on the next milestone.\n--- Page 272 ---\n244 CHAPTER 11 Web services\nDelivering on time\nJoe was right! Theo recalls Joe’s story about the young woodcutter and the old man. Theo\nwas able to learn DOP and deliver the project on time! He’s pleased that he took the time\n“to sharpen his saw and commit to a deeper level of practice.”\n NOTE If you are unable to recall the story or if you missed it, check out the opener\nto part 2.\nThe Klafim project is a success. Nancy is pleased. Theo’s boss is satisfied. Theo got pro-\nmoted. What more can a person ask for?\nTheo remembers his deal with Joe. As he strolls through the stores of the Westfield San\nFrancisco Center to look for a gift for each of Joe’s children, Neriah and Aurelia, he is\nfilled with a sense of purpose and great pleasure. He buys a DJI Mavic Air 2 drone for Ner-\niah, and the latest Apple Airpod Pros for Aurelia. He also takes this opportunity to buy a\nnecklace and a pair of earrings for his wife, Jane. It’s a way for him to thank her for having\nendured his long days at work since the beginning of the Klafim project.\n NOTE The story continues in the opener of part 3.\nSummary\n We build the insides of our systems like we build the outsides.\n Components inside a program communicate via data that is represented as\nimmutable data collections in the same way as components communicate via\ndata over the wire.\n In DOP, the inner components of a program are loosely coupled.\n Many parts of business logic can be implemented through generic data manipu-\nlation functions. We use generic functions to\n– Implement each step of the data flow inside a web service.\n– Parse a request from a client.\n– Apply business logic to the request.\n– Fetch data from external sources (e.g., database and other web services).\n– Apply business logic to the responses from external sources.\n– Serialize response to the client.\n Classes are much less complex when we use them as a means to aggregate\ntogether stateless functions that operate on similar domain entities.\nLodash functions introduced in this chapter\nFunction Description\nkeyBy(coll, f) Creates a map composed of keys generated from the results of running each ele-\nment of coll through f; the corresponding value for each key is the last element\nresponsible for generating the key.\n--- Page 273 ---\nPart 3\nMaintainability\nA\nfter a month, the Klafim project enters what Alabatross calls the mainte-\nnance phase. Small new features need to be added on a weekly basis. Bugs need to be\nfixed; nothing dramatic....\nMonica, Theo’s boss, decides to allocate Dave to the maintenance of the Klafim\nproject. It makes sense. Over the last few months, Dave has demonstrated a great atti-\ntude of curiosity and interest, and he has solid programming skills. Theo sets up a\nmeeting with Joe and Dave, hoping that Joe will be willing to teach DOP to Dave so\nthat he can continue to advance the good work he’s already done on Klafim. Theo\nand Dave place a conference call to Joe.\nTheo Hi, Joe. Will you have time over the next few weeks to teach Dave the\nprinciples of DOP?\nJoe Yes, but I prefer not to.\nDave Why? Is it because I don’t have enough experience in software develop-\nment? I can guarantee you that I’m a fast learner.\nJoe It has nothing to do with your experience, Dave.\nTheo Why not then?\nJoe Theo, I think that you could be a great mentor for Dave.\nTheo But, I don’t even know all the parts of DOP!\nDave Come on! No false modesty between us, my friend.\nJoe Knowledge is never complete. As the great Socrates used to say, “The more\nI know, the more I realize I know nothing.” I’m confident you will be able\nto learn the missing parts by yourself and maybe even invent some.\nTheo How will I be able to invent missing parts?\n--- Page 274 ---\n246 PART 3 Maintainability\nJoe You see, DOP is such a simple paradigm that it’s fertile material for innovation.\nPart of the material I taught you I learned from others, and part of it was an\ninvention of mine. If you keep practicing DOP, I’m quite sure you, too, will\ncome up with some inventions of your own.\nTheo What do you say Dave? Are you willing to learn DOP from me?\nDave Definitely!\nTheo Joe, will you be continue to be available if we need your help from time to time?\nJoe Of course!\n--- Page 275 ---\nAdvanced data\nvalidation\nA self-made gift\nThis chapter covers\n Validating function arguments\n Validating function return values\n Data validation beyond static types\n Automatic generation of data model diagrams\n Automatic generation of schema-based unit tests\nAs the size of a code base grows in a project that follows DOP principles, it becomes\nharder to manipulate functions that receive and return only generic data. It is hard\nto figure out the expected shape of the function arguments, and when we pass\ninvalid data, we don’t get meaningful errors.\nUntil now, we have illustrated how to validate data at system boundaries. In this\nchapter, we will illustrate how to validate data when it flows inside the system by\ndefining data schemas for function arguments and their return values. This allows\nus to make explicit the expected shape of function arguments, and it eases develop-\nment. We gain some additional benefits from this endeavor, such as automatic gen-\neration of data model diagrams and schema-based unit tests.\n247\n--- Page 276 ---\n248 CHAPTER 12 Advanced data validation\n12.1 Function arguments validation\nDave’s first task is to implement a couple of new HTTP endpoints to download the catalog\nas a CSV file, search books by author, and rate the books. Once he is done with the tasks,\nDave calls Theo for a code review.\n NOTE The involvement of Dave in the Klafim project is explained in the opener for\npart 3. Please take a moment to read the opener if you missed it.\nTheo Was it difficult to get your head around the DOP code?\nDave Not so much. I read your notes of the meetings with Joe, and I must admit, the\ncode is quite simple to grasp.\nTheo Cool!\nDave But there is something that I can’t get used to.\nTheo What’s that?\nDave I’m struggling with the fact that all the functions receive and return generic\ndata. In OOP, I know the expected shape of the arguments for each and every\nfunction.\nTheo Did you validate data at system boundaries, like I have done?\nDave Absolutely. I defined a data schema for every additional user request, database\nquery, and external service response.\nTheo Nice!\nDave Indeed, when the system runs in production, it works well. When data is valid,\nthe data flows through the system, and when data is invalid, we are able to dis-\nplay a meaningful error message to the user.\nTheo What’s the problem then?\nDave The problem is that during development, it’s hard to figure out the expected\nshape of the function arguments. And when I pass invalid data by mistake, I\ndon’t get clear error messages.\nTheo I see. I remember that when Joe showed me how to validate data at system\nboundaries, I raised this concern about the development phase. Joe told me\nthen that we validate data as it flows inside the system exactly like we validate data\nat system boundaries: we separate between data schema and data representation.\nDave Are we going to use JSON Schema also?\nTheo Yes.\nDave Cool.... I like JSON Schema.\nTheo The main purpose of data validation at system boundaries is to prevent invalid\ndata from getting into the system, whereas the main purpose of data validation\ninside the system is to make it easier to develop the system. Here, let me draw a\ntable on the whiteboard for you to visualize this (table 12.1).\nTable 12.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\n--- Page 277 ---\n12.1 Function arguments validation 249\nDave By making it easier to develop the system, do you mean to help the developers\nunderstand the expected shape of function arguments as in OOP?\nTheo Exactly.\nDave But I’m impatient.... Will you help me figure out how to validate the argu-\nments of the function that implements a book search?\nTheo Let me see the code of the implementation, and I’ll do my best.\nDave We have two implementations of a book search: one where library data lives\nin memory from the prototype phase and one where library data lives in the\ndatabase.\nTheo I think that the schema for library data in memory is going to be more interest-\ning than the schema for library data in the database, as the book search func-\ntion receives catalog data in addition to the query.\nDave When you say more interesting data schema, you mean more difficult to write?\nTheo More difficult to write, but it’s also more insightful.\nDave Then let’s go with library data in memory. The code for Catalog.search-\nBooksByTitle from the prototype phase would look like this.\nDave pulls up some code on his laptop. He shows it to Theo.\nListing12.1 The implementation of search without data validation\nclass Catalog {\nstatic authorNames(catalogData, book) {\nvar authorIds = _.get(book, \"authorIds\");\nvar names = _.map(authorIds, function(authorId) {\nreturn _.get(catalogData, [\"authorsById\", authorId, \"name\"]);\n});\nreturn names;\n}\nstatic bookInfo(catalogData, book) {\nvar bookInfo = {\n\"title\": _.get(book, \"title\"),\n\"isbn\": _.get(book, \"isbn\"),\n\"authorNames\": Catalog.authorNames(catalogData, book)\n};\nreturn bookInfo;\n}\nstatic searchBooksByTitle(catalogData, query) {\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n}\n}\n--- Page 278 ---\n250 CHAPTER 12 Advanced data validation\nTheo Dave, please remind me of the expected shapes for catalogData and query.\nDave Sure. query should be a string, and catalogData should be a map that con-\nforms to the catalog data model.\nTheo What is the catalog data model?\nDave Let me see. I have seen a diagram of it somewhere.\nDave rummages around a bit in his folder for Klafim’s Library Management System. Find-\ning what he’s looking for, he draws the diagram in figure 12.1 on the whiteboard.\nC Catalog\nbooksByIsbn: {Book}\nauthorsById: {Author}\nC Book\nC Author\ntitle : String\npublicationYear: Number id: String\nisbn: String name: String\nauthorlds: [String] booklsbns: [String]\nbookltems: [Bookltem]\nC Bookltem\nid: String\nlibld: String\npurchaseDate: String\nisLent: Boolean\nFigure 12.1 The catalog data model\n NOTE The schemas for this book use JSON Schema version 2020-12.\nTheo Can you write a JSON Schema for the catalog data model?\nDave Am I allowed to use internal variables for book and author schemas, or do I\nhave to nest all the schemas inside the catalog schema?\nTheo JSON Schema is part of the code. If you feel that using internal variables would\nmake the code more readable, go for it.\nDave OK. Now I need the JSON Schema gift that Joe gave you.\nTheo picks up a well-worn piece of paper that is a bit torn and quite wrinkled. He gives\nDave the JSON Schema cheat sheet.\nListing12.2 JSON Schema cheat sheet\nAt the root level,\n{\ndata is an array.\n\"type\": \"array\",\n\"items\": { Each element of the array is a map.\n\"type\": \"object\",\nThe properties of each field in the map\n\"properties\": {\n--- Page 279 ---\n12.1 Function arguments validation 251\n\"myNumber\": {\"type\": \"number\"},\nmyNumber\n\"myString\": {\"type\": \"string\"}, myEnum is an enumeration\nis a number.\n\"myEnum\": {\"enum\": [\"myVal\", \"yourVal\"]}, value with two possibilities,\nmyString is \"myBool\": {\"type\": \"boolean\"} \"myVal\" and \"yourVal\".\na string. },\n\"required\": [\"myNumber\", \"myString\"], myBool is a boolean.\n\"additionalProperties\": false\n} The mandatory fields in the map\n} We don’t allow fields that are not are myNumber and myString.\nexplicitly mentioned in the schema. Other fields are optional.\nDave I think I’ll start with the author schema. It seems simpler than the book schema.\nQuickly composing the code, Dave shows Theo the author schema. Dave, still new to DOP,\nlooks for Theo’s reaction.\nListing12.3 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nTheo Well done! Let’s move on to the book schema now.\nDave I think I am going to store the book item schema in a variable.\nListing12.4 The book item schema\nvar bookItemSchema = {\n\"type\": \"object\",\n\"properties\":{\n\"id\": {\"type\": \"string\"},\n\"libId\": {\"type\": \"string\"},\n\"purchaseDate\": {\"type\": \"string\"},\n\"isLent\": {\"type\": \"boolean\"}\n},\n\"required\": [\"id\", \"libId\", \"purchaseDate\", \"isLent\"]\n};\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": {\"type\": \"integer\"},\n--- Page 280 ---\n252 CHAPTER 12 Advanced data validation\n\"isbn\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n},\n\"bookItems\": {\n\"type\": \"array\",\n\"items\": bookItemSchema\n}\n}\n};\nTIP When you define a complex data schema, it is advisable to store nested schemas\nin variables to make the schemas easier to read.\nTheo Why didn’t you include publicationYear in the list of required fields in the\nbook schema?\nDave Because, for some books, the publication year is missing. Unlike in OOP, it will\nthen be easy to deal with nullable fields.\nTheo Excellent! And now, please tackle the final piece, the catalog schema.\nDave Here I have a problem. The catalog should be a map with two fields, books-\nByIsbn and authorsById. Both values should be indexes, represented in the\nmodel diagram with curly braces. I have no idea how to define the schema for\nan index.\nTheo Do you remember how we represent indexes in DOP?\nDave Yes, indexes are represented as maps.\nTheo Right, and what’s the difference between those maps and the maps that we use\nfor records?\nDave For records, we use maps where the names of the fields are known and the val-\nues can have different shapes. For indexes, we use maps where the names of\nthe fields are unknown and the values have a common shape.\nTheo Right. We call the maps for records heterogeneous maps and the maps for\nindexes homogeneous maps.\nTIP In DOP, records are represented as heterogeneous maps, whereas indexes are repre-\nsented as homogeneous maps.\nDave Then how do we define the schema of an homogeneous map in JSON Schema?\nTheo I don’t know. Let’s check the JSON Schema online documentation.\n NOTE See https://json-schema.org/ to access the online documentation for JSON\nSchema version 2020-12.\nAfter a couple of minutes of digging into the JSON Schema online documentation, Theo\nfinds a piece about additionalProperties. He studies the information for a while before\nmaking up his mind.\n--- Page 281 ---\n12.1 Function arguments validation 253\nTheo I think we could use additionalProperties. Here’s the JSON Schema for an\nhomogeneous map where the values are numbers.\nListing12.5 The JSON Schema for an homogeneous map with values as numbers\n{\n\"type\": \"object\",\n\"additionalProperties\": {\"type\": \"number\"}\n}\nDave I thought that additionalProperties was supposed to be a boolean and that\nit was used to allow or forbid properties not mentioned in the schema.\nTheo That’s correct. Usually additionalProperties is a boolean, but the documen-\ntation says it could also be a map that defines a schema. In that case, it means\nproperties not mentioned in the schema should have the value of the schema\nassociated with additionalProperties.\nDave I see. But what does that have to do with homogeneous maps?\nTheo Well, a homogeneous map could be seen as a map with no predefined proper-\nties, where all the additional properties are of an expected type.\nDave Tricky!\nTIP In JSON Schema, homogeneous string maps have type: object with no\nproperties and additionalProperties associated to a schema.\nTheo Indeed. Now, let me show you what the catalog schema looks like.\nTheo types briefly on his laptop. He shows Dave the catalog schema.\nListing12.6 The schema for catalog data\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\nDave Are we ready to plug the catalog and the query schema into the Catalog\n.searchBooksByTitle implementation?\nTheo We could, but I think we can do better by defining a single schema that com-\nbines both the catalog and query schemas.\nDave How would we combine two schemas into a single schema?\n--- Page 282 ---\n254 CHAPTER 12 Advanced data validation\nTheo Do you know what a tuple is?\nDave I think I know, but I can’t define it formally.\nTheo A tuple is an array where the size is fixed, and the elements can be of different\nshapes.\nDave OK. So, how do we define tuples in JSON Schema?\nOnce again, Theo explores the JSON Schema online documentation. Fortunately, he has\nbookmarked the page, and in no time at all, finds the information he needs.\nTheo I found it! We use prefixItems in the definition of a tuple made of a string\nand a number, for instance.\nTheo types more code on his laptop. When he finishes, he shows Dave the schema for a\ntuple.\nListing12.7 The schema for a tuple made of a string and a number\n{\n\"type\": \"array\",\n\"prefixItems\": [\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n}\nDave I see. And how would you define the schema for the arguments of Catalog\n.searchBooksByTitle?\nTheo Well, it’s a tuple of size 2, where the first element is a catalog and the second\nelement is a string.\nDave Something like this schema?\nListing12.8 The schema for the arguments of Catalog.searchBooksByTitle\nvar searchBooksArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\ncatalogSchema,\n{ \"type\": \"string\" },\n]\n};\nTheo Exactly!\nDave Now that we have the schema for the arguments, how do we plug it into the\nimplementation of search books?\nTheo That’s similar to the way we validate data at system boundaries. The main dif-\nference is that the data validation for data that flows inside the system should\nrun only at development time, and it should be disabled when the code runs in\nproduction.\nDave Why?\n--- Page 283 ---\n12.2 Return value validation 255\nTheo Because that data has been already validated up front at a system boundary.\nValidating it again on a function call is superfluous, and it would impact\nperformance.\nDave When you say development time, does that include testing and staging\nenvironments?\nTheo Yes, all the environments besides production.\nDave I see. It’s like assertions in Java. They are disabled in production code.\nTIP Data validation inside the system should be disabled in production.\nTheo Exactly. For now, I am going to assume that we have a dev function that returns\ntrue when the code runs in the development environment and false when it\nruns in production. Having said that, take a look at this code.\nListing12.9 Implementation of search with validation of function arguments\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nvar args = [catalogData, query];\nif(!ajv.validate(searchBooksArgsSchema, args)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\nThe implementation of dev() depends on the run-time\n}\nenvironment: it returns true when the code runs in dev\n}\nenvironments and false when it runs in production.\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nreturn bookInfos;\n};\nDave Do you think we should validate the arguments of all the functions?\nTheo No. I think we should treat data validation like we treat unit tests. We should\nvalidate function arguments only for functions for whom we would write unit\ntests.\nTIP Treat data validation like unit tests.\n12.2 Return value validation\nDave Do you think it would make sense to also validate the return value of functions?\nTheo Absolutely.\nDave Cool. Let me try to write the JSON Schema for the return value of Catalog\n.searchBooksByTitle.\n--- Page 284 ---\n256 CHAPTER 12 Advanced data validation\nAfter a few minutes, Dave comes up with the schema. Taking a deep breath, then releasing\nit, he shows the code to Theo.\nListing12.10 The schema for the return value of Catalog.searchBooksByTitle\nvar searchBooksResponseSchema = {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorNames\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"isbn\": {\"type\": \"string\"},\n\"authorNames\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n};\nTheo Well done! Now, would you like to try adding return value validation to the\ncode of Catalog.searchBooksByTitle?\nDave Sure.\nDave works for a bit in his IDE. A bit more confident this time, he shows the result to Theo.\nListing12.11 Search with data validation for both input and output\nCatalog.searchBooksByTitle = function(catalogData, query) {\nif(dev()) {\nif(!ajv.validate(searchBooksArgsSchema, [catalogData, query])) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle called with invalid arguments: \" +\nerrors);\n}\n}\nvar allBooks = _.get(catalogData, \"booksByIsbn\");\nvar matchingBooks = _.filter(allBooks, function(book) {\nreturn _.get(book, \"title\").includes(query);\n});\nvar bookInfos = _.map(matchingBooks, function(book) {\nreturn Catalog.bookInfo(catalogData, book);\n});\nif(dev()) {\nif(!ajv.validate(searchBooksResponseSchema, bookInfos)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"searchBooksByTitle returned an invalid value: \" +\nerrors);\n}\n}\n--- Page 285 ---\n12.3 Advanced data validation 257\nreturn bookInfos;\n};\nTheo Excellent! Now we need to figure out how to deal with advanced data validation.\n12.3 Advanced data validation\nDave What do you mean by advanced data validation?\nTheo I mean going beyond static types.\nDave Could you give me an example?\nTheo Sure. Take, for instance, the publication year of a book. It’s an integer, but\nwhat else could you say about this number?\nDave It has to be positive. It would say it’s a positive integer.\nTheo Come on, Dave! Be courageous, go beyond types.\nDave I don’t know. I would say it’s a number that should be higher than 1900. I\ndon’t think it makes sense to have a book that is published before 1900.\nTheo Exactly. And what about the higher limit?\nDave I’d say that the publication year should be less than the current year.\nTheo Very good! I see that JSON Schema supports number ranges. Here is how we\ncan write the schema for an integer that represents a year and should be\nbetween 1900 and 2021.\nListing12.12 The schema for an integer between 1900 and 2021\nvar publicationYearSchema = {\n\"type\": \"integer\",\n\"minimum\": 1900,\n\"maximum\": 2021\n};\nDave Why isn’t this kind of data validation possible in OOP?\nTheo I’ll let you think about that for a moment.\nDave I think have it! In DOP, data validation is executed at run time, while static\ntype validation in OOP is executed at compile time. At compile time, we only\nhave information about static types; at run time, we have the data itself. That’s\nwhy in DOP data validation, it’s possible to go beyond types.\n NOTE Of course, it’s also possible in traditional OOP to write custom run-time data\nvalidation. Here, though, we are comparing data schema with static types.\nTheo You got it! Now, let me show you how to write the schema for a string that\nshould match a regular expression.\n NOTE See http://mng.bz/OGNP for the JavaScript Guide to regular expressions.\nTheo Let’s take for example the book ID. I am assuming it must be a UUID.\nDave Right.\nTheo Can you write the regular expression for a valid UUID?\n--- Page 286 ---\n258 CHAPTER 12 Advanced data validation\nDave googles “UUID regex” and finds something he thinks just might work. He shows the\nregular expression to Theo.\nListing12.13 The regular expression for a valid UUID\n[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\nDave Now, how do we plug a regular expression into a JSON Schema?\nTheo While you were looking for the UUID regular expression, I read about the\npattern field. Here’s how we can plug the UUID regular expression into a\nJSON Schema.\nListing12.14 The schema for a UUID\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nDave Nice! Let me improve the catalog schema and refine the schema for purchase-\nDate, isbn, libId, and authorId with regular expressions.\nTheo Before you do that, though, let me tell you something I read about regular\nexpressions: some of them are predefined. For example, there is a predefined\nregular expression for dates.\nDave How does it work?\nTheo With the help of the format field.\n NOTE According to JSON Schema specification, format is just for annotation and\ndoesn’t affect validation. But in practice, JSON Schema validation libraries use format\nalso for validation.\nTheo moves to his laptop. He inputs the schema for a date and shows it to Dave.\nListing12.15 The schema for a date\n{\n\"type\": \"string\",\n\"format\": \"date\"\n}\nTIP In DOP, data validation goes beyond static types (e.g., number ranges, regular\nexpressions, and so on).\nDave Very cool! Do I have all the information I need in order to refine the catalog\nschema?\nTheo Yes, go for it!\nIt takes Dave a bit of time to write the regular expressions for isbn, authorId, and libId.\nBut with the help of Google (again) and a bit of simplification, Dave comes up with the\nschema in listings 12.16 and 12.17.\n--- Page 287 ---\n12.3 Advanced data validation 259\nListing12.16 The refined schema of the catalog data (Part 1)\nvar isbnSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[0-9-]{10,20}$\"\n};\nvar libIdSchema = {\n\"type\": \"string\",\n\"pattern\": \"^[a-z0-9-]{3,20}$\"\n};\nvar authorIdSchema ={\n\"type\": \"string\",\n\"pattern\": \"[a-z-]{2,50}\"\n};\nvar bookItemSchema = {\n\"type\": \"object\",\n\"additionalProperties\": {\n\"id\": uuidSchema,\n\"libId\": libIdSchema,\n\"purchaseDate\": {\n\"type\": \"string\",\n\"format\": \"date\"\n},\n\"isLent\": {\"type\": \"boolean\"}\n}\n};\nListing12.17 The refined schema of the catalog data (Part 2)\nvar bookSchema = {\n\"type\": \"object\",\n\"required\": [\"title\", \"isbn\", \"authorIds\", \"bookItems\"],\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"publicationYear\": publicationYearSchema,\n\"isbn\": isbnSchema,\n\"publisher\": {\"type\": \"string\"},\n\"authorIds\": {\n\"type\": \"array\",\n\"items\": authorIdSchema\n},\n\"bookItems\": bookItemSchema\n}\n};\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"id\", \"name\", \"bookIsbns\"],\n\"properties\": {\n\"id\": {\"type\": \"string\"},\n\"name\": {\"type\": \"string\"},\n--- Page 288 ---\n260 CHAPTER 12 Advanced data validation\n\"bookIsbns\": {\n\"items\": isbnSchema\n}\n}\n};\nvar catalogSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"booksByIsbn\": {\n\"type\": \"object\",\n\"additionalProperties\": bookSchema\n},\n\"authorsById\": {\n\"type\": \"object\",\n\"additionalProperties\": authorSchema\n}\n},\n\"required\": [\"booksByIsbn\", \"authorsById\"]\n};\n12.4 Automatic generation of data model diagrams\nBefore going home, Theo phones Joe to tell him about how he and Dave used data valida-\ntion inside the system. Joe tells Theo that that’s exactly how he recommends doing it and\nsuggests he come and visit Theo and Dave at the office tomorrow. He wants to show them\nsome cool advanced stuff related to data validation. The next day, with coffee in hand, Joe\nstarts the discussion.\nJoe Are you guys starting to feel the power of data validation à la DOP?\nDave Yes, it’s a bit less convenient to validate a JSON Schema than it is to write the\nclass of function arguments, but this drawback is compensated by the fact that\nJSON Schema supports conditions that go beyond static types.\nTheo We also realized that we don’t have to validate data for each and every function.\nJoe Correct. Now, let me show you another cool thing that we can do with JSON\nSchema.\nDave What’s that?\nJoe Generate a data model diagram.\nDave Wow! How does that work?\nJoe There are tools that receive a JSON Schema as input and produce a diagram in\na data model format.\nDave What is a data model format?\nJoe It’s a format that allows you to define a data model in plain text. After that, you\ncan generate an image from the text. My favorite data format is PlantUML.\n NOTE For more on PlantUML, see https://plantuml.com/.\nDave Do you know of other tools that generate data model diagrams?\nJoe I have used JSON Schema Viewer and Malli.\n--- Page 289 ---\n12.4 Automatic generation of data model diagrams 261\n NOTE You can find information on the JSON Schema Viewer at https://navneethg\n.github.io/jsonschemaviewer/ and on Malli at https://github.com/metosin/malli.\nJoe shows Dave and Theo the PlantUML diagram that Malli generated (listing 12.18) from\nthe catalog schema in listings 12.16 and 12.17.\nListing12.18 A PlantUML diagram generated from the catalog data schema\n@startuml\nEntity1 *-- Entity2\nEntity1 *-- Entity4\nEntity2 *-- Entity3\nclass Entity1 {\n+ booksByIsbn: {Entity2}\n+ authorsById: {Entity4}\n}\nclass Entity2 {\n+ title : String\n+ publicationYear: Number\n+ isbn: String\n+ authorIds: [String]\n+ bookItems: [Entity3]\n}\nclass Entity3 {\n+ id: String\n+ libId: String\n+ purchaseDate: String\n+ isLent: Boolean\n}\nclass Entity4 {\n+ id: String\n+ name: String\n+ bookIsbns: [String]\n}\n@enduml\nDave Is it possible to visualize this diagram?\nJoe Absolutely. Let me copy and paste the diagram text into the PlantText online\ntool.\n NOTE See https://www.planttext.com/ for more on the PlantText online tool.\nDave opens his web browser and types the URL for PlantText. After copying and pasting\nthe text, he steps aside so that Theo and Dave can view the diagram that looks like the\nimage in figure 12.2.\n--- Page 290 ---\n262 CHAPTER 12 Advanced data validation\nC Entity1\nbooksByIsbn: {Entity2}\nauthorsById: {Entity3}\nC Entity2 C Entity4\ntitle : String id: String\npublicationYear: Number name: String\nisbn: String booklsbns: [String]\nauthorlds: [String]\nbookltems: [Entity3]\nC Entity3\nid: String\nlibld: String\nFigure 12.2 A visualization of\npurchaseDate: String\nthe PlantUML diagram generated\nisLent: Boolean\nfrom the catalog data schema\nDave That’s cool! But why are the diagram entities named Entity1, Entity2, and\nso on?\nJoe Because in JSON Schema, there’s no way to give a name to a schema. Malli has\nto autogenerate random names for you.\nTheo Also, I see that the extra information we have in the schema, like the number\nrange for publicationYear and string regular expression for isbn, is missing\nfrom the diagram.\nJoe Right, that extra information is not part of the data model. That’s why it’s not\nincluded in the generated data model diagram.\nDave Anyway, it’s very cool!\nJoe If you guys like the data model generation feature, I’m sure you’re going to\nlike the next feature.\nDave What’s it about?\nJoe Automatic generation of unit tests.\nTheo Wow, sounds exciting!\n12.5 Automatic generation of schema-based unit tests\nJoe Once you’ve defined a data schema for function arguments and for its return\nvalue, it’s quite simple to generate a unit test for this function.\nDave How?\nJoe Well, think about it. What’s the essence of a unit test for a function?\nDave A unit test calls a function with some arguments and checks whether the func-\ntion returns the expected value.\nJoe Exactly! Now, let’s adapt it to the context of data schema and DOP. Let’s say you\nhave a function with a schema for their arguments and for their return value.\n--- Page 291 ---\n12.5 Automatic generation of schema-based unit tests 263\nDave OK.\nJoe Here’s the flow of a schema-based unit test. We call the function with random\narguments that conform to the schema of the function arguments. Then, we\ncheck whether the function returns a value that conforms to the schema of the\nreturn value. Here, let me diagram it.\nJoe goes to the whiteboard. He draws the diagram in figure 12.3.\nGeneraterandom datathat conforms toinput schema\nExecute the function The input\nis random.\nYes No\nOutput conforms to output schema\nTest passes Test fails\nFigure 12.3 The flow of\na schema-based unit test\nDave How do you generate random data that conforms to a schema?\nJoe Using a tool like JSON Schema Faker. For example, let’s start with a simple\nschema: the schema for a UUID. Let me show you how to generate random\ndata that conforms to the schema.\n NOTE You’ll find more information about JSON Schema Faker at https://github\n.com/json-schema-faker/json-schema-faker.\nJoe types on the keyboard for a bit. He then shows the code to generate random data to\nDave and Theo.\nListing12.19 Generating random data that conforms to a UUID schema\nvar uuidSchema = {\n\"type\": \"string\",\n\"pattern\": \"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}\" +\n\"-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}\"\n};\nJSONSchemaFaker.generate(uuidSchema);\n// → \"7aA8CdF3-14DF-9EF5-1A19-47dacdB16Fa9\"\nDave executes the code snippet a couple of times, and indeed, on each evaluation, it returns\na different UUID.\nDave Very cool! Let me see how it works with more complex schemas like the cata-\nlog schema.\n--- Page 292 ---\n264 CHAPTER 12 Advanced data validation\nWhen Dave calls JSONSchemaFaker.generate with the catalog schema, he gets some\nquite long random data. He’s a bit surprised by the results.\nListing12.20 Generating random data that conforms to the catalog schema\n{\n\"booksByIsbn\": {\n\"Excepteur7\": {\n\"title\": \"elit veniam anim\",\n\"isbn\": \"5419903-3563-7\",\n\"authorIds\": [\n\"vfbzqahmuemgdegkzntfhzcjhjrbgfoljfzogfuqweggchum\",\n\"inxmqh-\",\n],\n\"bookItems\": {\n\"ullamco5\": {\n\"id\": \"f7dac8c3-E59D-bc2E-7B33-C27F3794E2d6\",\n\"libId\": \"4jtbj7q7nrylfu114m\",\n\"purchaseDate\": \"2001-08-01\",\n\"isLent\": false\n},\n\"culpa_3e\": {\n\"id\": \"423DCdDF-CDAe-2CAa-f956-C6cd9dA8054b\",\n\"libId\": \"6wcxbh\",\n\"purchaseDate\": \"1970-06-24\",\n\"isLent\": true\n}\n},\n\"publicationYear\": 1930,\n\"publisher\": \"sunt do nisi\"\n},\n\"aliquip_d7\": {\n\"title\": \"aute\",\n\"isbn\": \"348782167518177\",\n\"authorIds\": [\"owfgtdxjbiidsobfgvjpjlxuabqpjhdcqmmmrjb-ezrsz-u\"],\n\"bookItems\": {\n\"ipsum__0b\": {\n\"id\": \"6DfE93ca-DB23-5856-56Fd-82Ab8CffEFF5\",\n\"libId\": \"bvjh0p2p2666vs7dd\",\n\"purchaseDate\": \"2018-03-30\",\n\"isLent\": false\n}\n},\n\"publisher\": \"ea anim ut ex id\",\n\"publicationYear\": 1928\n}\n},\n\"authorsById\": {\n\"labore_b88\": {\n\"id\": \"adipisicing nulla proident\",\n\"name\": \"culpa in minim\",\n\"bookIsbns\": [\n\"6243029--7\",\n\"5557199424742986\"\n]",
        "sections_found": []
      },
      "accurate_page_range": "262-292"
    },
    {
      "text": "- 11.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- 11.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 88
    },
    {
      "text": "- 11.1 Another feature request",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- 11.1 Another feature request (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 89
    },
    {
      "text": "- 11.2 Building the insides like the outsides",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- 11.2 Building the insides like the outsides (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 90
    },
    {
      "text": "- 11.3 Representing a client request as a map",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- 11.3 Representing a client request as a map (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 91
    },
    {
      "text": "- 11.4 Representing a server response as a map",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- 11.4 Representing a server response as a map (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 92
    },
    {
      "text": "- 11.5 Passing information forward",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- 11.5 Passing information forward (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 93
    },
    {
      "text": "- 11.6 Search result enrichment in action",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- 11.6 Search result enrichment in action (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 94
    },
    {
      "text": "- Delivering on time",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- Delivering on time (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 95
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "11 Web services",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 96
    },
    {
      "text": "- Part3 Introduction content",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "Part3 Introduction (사용자 추가)",
      "raw_line": "- Part3 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 97,
      "accurate_page_range": "298-302",
      "extracted_content": "\n=== Page 298 ===\n270 CHAPTER 12 Advanced data validation\n\"myLetters\": {\nmyLetters is a string with\n\"type\": \"string\",\nletters only (lowercase or\n\"pattern\": \"[a-zA-Z]*\"\nuppercase).\n}\n\"myNumberMap\": {\nmyNumberMap is an homogeneous\n\"type\": \"object\",\nstring map where all the values are\n\"additionalProperties\": {\"type\": \"number\"}\nnumbers.\n},\n\"myTuple\": {\nmyTuple is a tuple where the first\n\"type\": \"array\",\nelement is a string and the second\n\"prefixItems\": [\nelement is a number.\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n} The mandatory fields in the map\nare myNumber and myString.\n},\nOther fields are optional.\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nListing12.31 An example of valid data\n[\n{\n\"myNumber\": 42,\n\"myString\": \"I-love-you\",\n\"myEnum\": \"myVal\",\n\"myBool\": true,\n\"myTuple\": [\"Hello\", 42]\n},\n{\n\"myNumber\": 54,\n\"myString\": \"Happy\",\n\"myAge\": 42,\n\"myBirthday\": \"1978-11-23\",\n\"myLetters\": \"Hello\",\n\"myNumberMap\": {\n\"banana\": 23,\n\"apple\": 34\n}\n}\n]\nSummary\n We define data schemas using a language like JSON Schema for function argu-\nments and return values.\n Function argument schemas allow developers to figure out the expected shape of\nthe function arguments they want to call.\n When invalid data is passed, data validation third-party libraries give meaning-\nful errors with detailed information about the data parts that are not valid.\n\n=== Page 299 ===\nSummary 271\n Unlike data validation at system boundaries, data validation inside the system is\nsupposed to run only at development time and should be disabled in production.\n We visualize a data schema by generating a data model diagram out of a JSON\nSchema.\n For functions that have data schemas for their arguments and return values, we\ncan automatically generate schema-based unit tests.\n Data validation is executed at run time.\n We can define advanced data validation conditions that go beyond static types,\nlike checking whether a number is within a range or if a string matches a regu-\nlar expression.\n Data validation inside the system should be disabled in production.\n Records are represented as heterogeneous maps, and indexes are represented as\nhomogeneous maps.\n When you define a complex data schema, it is advised to store nested schemas\nin variables to make the schemas easier to read.\n We treat data validation like unit tests.\n\n=== Page 300 ===\nPolymorphism\nPlaying with the animals\nin the countryside\nThis chapter covers\n Mimicking objects with multimethods (single\ndispatch)\n Implementing multimethod on several argument\ntypes (multiple dispatch)\n Implementing multimethods dynamically on\nseveral arguments (dynamic dispatch)\nOOP is well-known for allowing different classes to be called with the same inter-\nface via a mechanism called polymorphism. It may seem that the only way to have\npolymorphism in a program is with objects. In fact, in this chapter, we are going to\nsee that it is possible to have polymorphism without objects, thanks to multimeth-\nods. Moreover, multimethods provide a more advanced polymorphism than OOP\npolymorphism because they support cases where the chosen implementation\ndepends on several argument types (multiple dispatch) and even on the dynamic\nvalue of the arguments (dynamic dispatch).\n272\n\n=== Page 301 ===\n13.1 The essence of polymorphism 273\n13.1 The essence of polymorphism\nFor today’s session, Dave has invited Theo to come and visit him at his parents’ house in\nthe countryside. As Theo’s drive across the Golden Gate Bridge takes him from the freeway\nto increasingly rural country roads, he lets himself be carried away by the beauty of the\nlandscape, the smell of fresh earth, and the sounds of animals in nature. This “nature\nbath” puts him in an excellent mood. What a way to start the week!\nDave receives Theo in jeans and a T-shirt, a marked contrast with the elegant clothes he\nwears at the office. A straw hat completes his country look. Theo says hello to Dave’s par-\nents, now retired. Dave suggests that they go pick a few oranges in the field to squeeze for\njuice. After drinking a much more flavorful orange juice than they are used to in San Fran-\ncisco, Theo and Dave get to work.\nDave When I was waiting for you this morning, I thought of another thing I miss\nfrom OOP.\nTheo What’s that?\nDave Polymorphism.\nTheo What kind of polymorphism?\nDave You know, you define an interface, and different classes implement the same\ninterface in different ways.\nTheo I see. And why do you think polymorphism is valuable?\nDave Because it allows us to decouple an interface from its implementations.\nTheo Would you mind illustrating that with a concrete example?\nDave Sure. Because we’re in the country, I’ll use the classic OOP polymorphism\nexample with animals.\nTheo Good idea!\nDave Let’s say that each animal has its own greeting by making a sound and saying\nits name.\nTheo Oh cool, like in anthropomorphic comics books.\nDave Anthro what?\nTheo You know, comics books where animals can walk, speak, and so forth—like\nMickey Mouse.\nDave Of course, but I don’t know that term. Where does it come from?\nTheo Anthropomorphism comes from the Greek ánthro–pos, which means human, and\nmorphe–, which means form.\nDave I see. So an anthropomorphic book is a book where animals have human traits.\nThe word sounds related to polymorphism.\nTheo Absolutely. Polymorphism comes from the Greek polús, which means many, and\nmorphe–, which, again, means form.\nDave That makes sense. Polymorphism is the ability of different objects to imple-\nment the same method in different ways. That brings me back to my animal\nexample. In OOP, I’d define an IAnimal interface with a greet method, and\neach animal class would implement greet in its own way. Here, I happen to\nhave an example.\n\n=== Page 302 ===\n274 CHAPTER 13 Polymorphism\nListing13.1 OOP polymorphism illustrated with animals\ninterface IAnimal {\npublic void greet();\n}\nclass Dog implements IAnimal {\nprivate String name;\npublic void greet() {\nSystem.out.println(\"Woof woof! My name is \" + animal.name);\n}\n}\nclass Cat implements IAnimal {\nprivate String name;\npublic void greet() {\nSystem.out.println(\"Meow! I am \" + animal.name);\n}\n}\nclass Cow implements IAnimal {\nprivate String name;\npublic void greet() {\nSystem.out.println(\"Moo! Call me \" + animal.name);\n}\n}\nTheo Let me challenge you a bit. What is the fundamental difference between OOP\npolymorphism and a switch statement?\nDave What do you mean?\nTheo I could, for instance, represent an animal with a map having two fields, name\nand type, and call a different piece of code, depending on the value of type.\nTheo pulls his laptop from its bag and fires it up. While the laptop is booting up, he enjoys\nanother taste of that wonderful orange juice. When the laptop is ready, he quickly types in\nthe example switch case. Meanwhile, Dave has finished his glass of orange juice.\nListing13.2 A switch case where behavior depends on type\nfunction greet(animal) {\nswitch (animal.type) {\ncase \"dog\":\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}"
    },
    {
      "text": "- 12.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- 12.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 98,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- 12.1 Function arguments validation",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- 12.1 Function arguments validation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 99,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- 12.2 Return value validation",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- 12.2 Return value validation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 100,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- 12.3 Advanced data validation",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- 12.3 Advanced data validation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 101,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- 12.4 Automatic generation of data model diagrams",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- 12.4 Automatic generation of data model diagrams (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 102,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- 12.5 Automatic generation of schema-based unit tests",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- 12.5 Automatic generation of schema-based unit tests (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 103,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- 12.6 A new gift",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- 12.6 A new gift (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 104,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "12 Advanced data validation",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 105,
      "chapter_info": {
        "page": 303,
        "title": "Advanced data validation",
        "pattern_matched": "Chapter 12",
        "text_preview": "13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with "
      },
      "chapter_sections": {
        "start_page": 303,
        "end_page": 333,
        "content": "\n--- Page 303 ---\n13.1 The essence of polymorphism 275\nDave How would animal look, exactly?\nTheo Like I just said, a map with two fields: name and type. Let me input that for you.\nListing13.3 Representing animals with maps\nvar myDog = {\n\"type\": \"dog\",\n\"name\": \"Fido\"\n};\nvar myCat = {\n\"type\": \"cat\",\n\"name\": \"Milo\"\n};\nvar myCow = {\n\"type\": \"cow\",\n\"name\": \"Clarabelle\"\n};\nDave Could you have given another name to the field that holds the animal type?\nTheo Absolutely. It could be anything.\nDave I see. You’re asking me the fundamental difference between your code with a\nswitch statement and my code with an interface and three classes?\nTheo Exactly.\nDave First of all, if you pass an invalid map to your greet function, bad things will\nhappen.\nTheo You’re right. Let me fix that and validate input data.\nListing13.4 Data validation\nvar animalSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nSee chapter 12 about\ndata validation for\nfunction greet(animal) {\ndetails.\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\n--- Page 304 ---\n276 CHAPTER 13 Polymorphism\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}\n NOTE You should not use switch statements like this in your production code.\nWe use them here for didactic purposes only as a step towards distilling the essence of\npolymorphism.\nDave Another drawback of your approach is that when you want to modify the\nimplementation of greet for a specific animal, you have to change the code\nthat deals with all the animals, while in my approach, you would change only a\nspecific animal class.\nTheo I agree, and I could also fix that by having a separate function for each animal,\nsomething like this.\nListing13.5 Different implementations in different functions\nfunction greetDog(animal) {\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\n}\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am: \" + animal.name);\n}\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\nfunction greet(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nswitch (animal.type) {\ncase \"dog\":\ngreetDog(animal);\nbreak;\ncase \"cat\":\ngreetCat(animal);\nbreak;\ncase \"cow\":\ngreetCow(animal);\n--- Page 305 ---\n13.2 Multimethods with single dispatch 277\nbreak;\n};\n}\nDave But what if you want to extend the functionality of greet and add a new animal?\nTheo Now you got me. I admit that with a switch statement, I can’t add a new animal\nwithout modifying the original code, whereas in OOP, I can add a new class\nwithout having to modify the original code.\nDave Yeah, but you helped me to realize that the main benefit of polymorphism is\nthat it makes the code easily extensible.\nTIP The main benefit of polymorphism is extensibility.\nTheo I’m going to ask Joe if there’s a way to benefit from polymorphism without\nobjects.\nTheo sends a message to Joe and asks him about polymorphism in DOP. Joe answers that\nhe doesn’t have time to get into a deep response because he is in a tech conference where\nhe is about to give a talk about DOP. The only thing he has time to tell Theo is that he\nshould take a look at multimethods.\nTheo and Dave read some online material about multimethods. It doesn’t look too\ncomplicated. They decide that after lunch they will give multimethods a try.\n13.2 Multimethods with single dispatch\nDuring lunch, Theo asks Dave how it feels to have grown up in the country. Dave starts\nwith an enthusiastic description about being in direct contact with nature and living a sim-\npler life than in the city. He’s grateful for the experience, but he admits that country life\ncan sometimes be hard without the conveniences of the city. But who said simple was easy?\nAfter lunch, they decide to have coffee. Dave asks Theo if he’d like to grind the coffee\nbeans himself. Theo accepts with joy. Next, Dave explains how to use a French press coffee\nmaker to get the ideal tradeoff between bitterness and rich taste. While savoring their\nFrench press coffee in the garden, Theo and Dave continue their exploration of polymor-\nphism à la DOP.\nTheo From what I read before lunch, it seems that multimethods are a software con-\nstruct that provide polymorphism without the need for objects.\nDave I don’t get how that’s possible.\nTheo Multimethods have two parts: a dispatch function and a set of methods that\nprovide an implementation for each dispatched value.\nDave I’m not sure I’m clear on that. Is a dispatch function like an interface?\nTheo It’s like an interface in the sense that it defines the way the function needs to\nbe called, but it goes beyond that. It also dispatches a value that differentiates\nbetween the different implementations.\nDave That’s a bit abstract for me.\nTheo I think I understand how to implement the animal greeting capabilities. If we\nuse a multimethod called greet, we need a dispatch function and three\nmethods. Let’s call the dispatch function greetDispatch. It dispatches the\nanimal type, either \"dog\", \"cat\", or \"cow\". Then, each dispatch value is\n--- Page 306 ---\n278 CHAPTER 13 Polymorphism\nhandled by a specific method: \"dog\" by greetDog, \"cat\" by greetCat, and\n\"cow\" by greetCow.\nTheo takes out his notebook and opens it to a blank piece of paper. He draws a diagram\nlike the one in figure 13.1.\n\"dog\" greetDog\nGreet as a dog\ngreetDispatch \"cat\" greetCat\nEmit the animal type Greet as a cat\nanimal\ntype, name \"cow\" greetCow\nGreet as a cow\nFigure 13.1 The logic flow\nof the greet multimethod\nDave Why is there an arrow between animal and the methods, in addition to the\narrows between animal and the dispatch functions?\nTheo Because the arguments of a multimethod are passed to the dispatch function\nand to the methods.\nTIP The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\nDave Arguments plural?... I see only a single argument.\nTheo You’re right. Right now our multimethod only receives a single argument, but\nsoon it will receive several arguments.\nDave I see. Could you show me how to write the code for the greet multimethod?\nTheo For that, we need a library. For instance, in JavaScript, the arrows/multi-\nmethod library provides an implementation of multimethods. Basically, we call\nmulti to create a multimethod called method to add a method.\n NOTE See http://mng.bz/nY9v for examples and documentation about this library.\nDave Where should we start?\nTheo We’ll start with multimethod initialization by creating a dispatch function\ngreetDispatch that defines the signature of the multimethod, validates the\narguments, and emits the type of the animal. Then we’ll pass greetDispatch\nto multi in order to create the greet multimethod. Our dispatch function\nwould then look like this.\nListing13.6 The dispatch function for greet multimethod\nfunction greetDispatch(animal) {\nSignature definition\nif(dev()) {\n--- Page 307 ---\n13.2 Multimethods with single dispatch 279\nif(!ajv.validate(animalSchema, animal)) {\nArgument validation\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"greet called with invalid arguments: \" + errors);\n}\n}\nDispatch value\nreturn animal.type;\n}\nMultimethod\ninitialization\nvar greet = multi(greetDispatch);\nTIP A multimethod dispatch function is responsible for three things: it defines the sig-\nnature of the multimethod, it validates the arguments, and it emits a dispatch value.\nDave What’s next?\nTheo Now we need to implement a method for each dispatched value. Let’s start\nwith the method that deals with dogs. We create a greetDog function that\nreceives an animal and then add a dog method to the greet multimethod\nusing the method function from the arrows/multimethod library. The method\nfunction receives two arguments: the dispatched value and a function that cor-\nresponds to the dispatch value.\nListing13.7 Implementation of greet method for dogs\nfunction greetDog(animal) {\nMethod\nconsole.log(\"Woof woof! My name is \" + animal.name);\nimplementation\n}\ngreet = method(\"dog\", greetDog)(greet);\nMethod declaration\nDave Does the method implementation have to be in the same module as the multi-\nmethod initialization?\nTheo No, not at all! Method declarations are decoupled from multimethod initializa-\ntion exactly like class definitions are decoupled from the interface definition.\nThat’s what make multimethods extensible.\nTIP Multimethods provides extensibility by decoupling between multimethod initial-\nization and method implementations.\nDave What about cats and cows?\nTheo We add their method implementations like we did for dogs.\nTheo takes a moment to envision the implementation. Then he codes up two more greet\nmethods for cats and cows.\nListing13.8 Implementation of greet method for cats\nfunction greetCat(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ngreet = method(\"cat\", greetCat)(greet);\n--- Page 308 ---\n280 CHAPTER 13 Polymorphism\nListing13.9 Implementation of greet method for cows\nfunction greetCow(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ngreet = method(\"cow\", greetCow)(greet);\nTIP In the context of multimethods, a method is a function that provides an imple-\nmentation for a dispatch value.\nDave Are the names of dispatch functions and methods important?\nTheo According to what I read, not really, but I like to follow a simple naming con-\nvention: use the name of the multimethod (for example, greet) as a prefix for\nthe dispatch function (for example, greetDispatch) and the methods. Then\nI’d have the Dispatch suffix for the dispatch function and a specific suffix for\neach method (for example, greetDog, greetCat, and greetCow).\nDave How does the multimethod mechanism work under the hood?\nTheo Internally, a multimethod maintains a hash map where the keys are the dis-\npatched values, and the values are the methods. When we add a method, an\nentry is added to the hash map, and when we call the multimethod, we query the\nhash map to find the implementation that corresponds to the dispatched value.\nDave I don’t think you’ve told me yet how to call a multimethod.\nTheo We call it as a regular function. Give me a minute, and I’ll show you an exam-\nple that calls a multimethod.\nListing13.10 Calling a multimethod like a regular function\ngreet(myDog);\n// → \"Woof woof! My name is Fido\"\ngreet(myCat);\n// → \"Meow! I am Milo\"\ngreet(myCow);\n// → \"Moo! Call me Clarabelle\"\nTIP Multimethods are called like regular functions.\nDave You told me earlier that in the dispatch function, we should validate the argu-\nments. Is that mandatory or is it a best practice?\nTheo It’s a best practice.\nDave What happens if the dispatch function doesn’t validate the arguments, and we\npass an invalid argument?\nTheo Like when an animal has no corresponding method?\nDave Exactly!\nTheo In that case, you’ll get an error. For instance, the arrows/multimethods library\nthrows a NoMethodError exception.\nDave That’s annoying. Is there a way to provide a default implementation?\n--- Page 309 ---\n13.3 Multimethods with multiple dispatch 281\nTheo Absolutely! In order to define a default implementation, you pass to method—\nas a single argument—the function that provides the default implementation.\nTheo writes the code and shows it to Dave. Dave then tests Theo’s code and seems satisfied\nwith the result.\nListing13.11 Defining a default implementation\nfunction greetDefault(animal) {\nconsole.log(\"My name is \" + animal.name);\n}\ngreet = method(greetDefault)(greet);\nListing13.12 Calling a multimethod when no method fits the dispatch value\nvar myHorse = {\n\"type\": \"horse\",\n\"name\": \"Horace\"\n};\ngreet(myHorse);\n// → \"My name is Horace\"\nTIP Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\nDave Cool!\n13.3 Multimethods with multiple dispatch\nTheo So far, we’ve mimicked OOP by having the type of the multimethod argument\nas a dispatch value. But if you think again about the flow of a multimethod,\nyou’ll discover something interesting. Would you like to try and draw a dia-\ngram that describes the flow of a multimethod in general?\nDave Let me get a fresh napkin. The one under my glass is a bit wet.\nTheo Uh, Dave, you can use my notebook.\nIt takes Dave a few minutes to draw a diagram like the one in figure 13.2. He pushes the\nnotebook back to Theo.\nValue1 Method1\nHandle case 1\nDispatch function Value3 Method3\nEmit a dispatch value Handle case 3\nargs\nValue2 Method2\nHandle case 2\nFigure 13.2 The logic flow\nof multimethods\n--- Page 310 ---\n282 CHAPTER 13 Polymorphism\nTheo Excellent! I hope you see that the dispatch function can emit any value.\nDave Like what?\nTheo Like emitting the type of two arguments!\nDave What do you mean?\nTheo Imagine that our animals are polyglot.\nDave Poly what?\nTheo Polyglot comes from the Greek polús, meaning much, and from glôssa, meaning\nlanguage. A polyglot is a person who can speak many languages.\nDave What languages would our animals speak?\nTheo I don’t know. Let’s say English and French.\nDave OK, and how would we represent a language in our program?\nTheo With a map, of course!\nDave What fields would we have in a language map?\nTheo Let’s keep things simple and have two fields: type and name.\nDave Like an animal map?\nTheo Not exactly. In a language map, the type field must be either fr for French or en\nfor English, whereas in the animal map, the type field is either dog, cat, or cow.\nDave Let me try to write the language map schema and the two language maps.\nTheo gladly consents; his French press coffee is getting cold! Dave writes his implementa-\ntion of the code and shows Theo.\nListing13.13 The schema of a language map\nvar languageSchema = {\n\"type\": \"object\",\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"type\": \"string\"}\n},\n\"required\": [\"name\", \"type\"],\n};\nListing13.14 Two language maps\nvar french = {\n\"type\": \"fr\",\n\"name\": \"Français\"\n};\nvar english = {\n\"type\": \"en\",\n\"name\": \"English\"\n};\nTheo Excellent! Now, let’s write the code for the dispatch function and the methods\nfor our polyglot animals. Let’s call our multimethod, greetLang. We have one\ndispatch function and six methods.\n--- Page 311 ---\n13.3 Multimethods with multiple dispatch 283\nDave Right, three animals (dog, cat, and cow) times two languages (en and fr).\nBefore the implementation, I’d like to draw a flow diagram. It will help me to\nmake things crystal clear.\nTheo You need my notebook again?\nNot waiting for Dave to respond, Theo pushes his notebook across the table to Dave. Dave\ndraws a diagram like the one in figure 13.3 and slides the notebook back to Theo.\n[\"dog\", \"en\"] greetLangDogEn\nGreet as a dog in English\n[\"cat\", \"en\"] greetLangCatEn\nGreet as a cat in English\n[\"cow\", \"en\"] greetLangCowEn\nGreet as a cow in English\nargs greetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", \"fr\"] greetLangDogFr\nGreet as a dog in French\n[\"cat\", \"fr\"] greetLangCatFr\nGreet as a cat in French\n[\"cow\", \"fr\"] greetLangCowFr\nGreet as a cow in French\nFigure 13.3 The logic flow of the greetLang multimethod\nTheo Why did you omit the arrow between the arguments and the methods?\nDave In order to keep the diagram readable. Otherwise, there would be too many\narrows.\nTheo OK, I see. Are you ready for coding?\nDave Yes!\nTheo The dispatch function needs to validate its arguments and return an array with\ntwo elements: the type of animal and the type of language.\nDave types for a bit on his laptop. He initializes the multimethod with a dispatch function\nthat returns the type of its arguments and then shows the code to Theo.\nListing13.15 Initializing a multimethod with a dispatch function\nvar greetLangArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [animalSchema, languageSchema]\n};\nfunction greetLangDispatch(animal, language) {\nif(dev()) {\n--- Page 312 ---\n284 CHAPTER 13 Polymorphism\nif(!ajv.validate(greetLangArgsSchema, [animal, language])) {\nthrow (\"greetLang called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [animal.type, language.type];\n};\nvar greetLang = multi(greetLangDispatch);\nDave Does the order of the elements in the array matter?\nTheo It doesn’t matter, but it needs to be consistent with the wiring of the methods.\nThe implementation of greetLang would therefore look like this.\nListing13.16 The implementation of greetLang methods\nfunction greetLangDogEn(animal, language) {\nconsole.log(\"Woof woof! My name is \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"en\"], greetLangDogEn)(greetLang);\nfunction greetLangDogFr(animal, language) {\nconsole.log(\"Ouaf Ouaf! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"dog\", \"fr\"], greetLangDogFr)(greetLang);\nfunction greetLangCatEn(animal, language) {\nconsole.log(\"Meow! I am \" +\nanimal.name +\n\" and I speak \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"en\"], greetLangCatEn)(greetLang);\nfunction greetLangCatFr(animal, language) {\nconsole.log(\"Miaou! Je m'appelle \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cat\", \"fr\"], greetLangCatFr)(greetLang);\nfunction greetLangCowEn(animal, language) {\nconsole.log(\"Moo! Call me \" +\nanimal.name +\n\" and I speak \" +\n--- Page 313 ---\n13.3 Multimethods with multiple dispatch 285\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"en\"], greetLangCowEn)(greetLang);\nfunction greetLangCowFr(animal, language) {\nconsole.log(\"Meuh! Appelle moi \" +\nanimal.name +\n\" et je parle \" +\nlanguage.name);\n}\ngreetLang = method([\"cow\", \"fr\"], greetLangCowFr)(greetLang);\nDave looks at the code for the methods that deal with French. He is surprised to see Ouaf\nOuaf instead of Woof Woof for dogs, Miaou instead of Meow for cats, and Meuh instead of\nMoo for cows.\nDave I didn’t know that animal onomatopoeia were different in French than in\nEnglish!\nTheo Ono what?\nDave Onomatopoeia, from the Greek ónoma that means name and poiéo– that means to\nproduce. It is the property of words that sound like what they represent; for\ninstance, Woof, Meow, and Moo.\nTheo Yeah, for some reason in French, dogs Ouaf, cats Miaou, and cows Meuh.\nDave I see that in the array the animal type is always before the language type.\nTheo Right! As I told you before, in a multimethod that features multiple dispatch,\nthe order doesn’t really matter, but it has to be consistent.\nTIP Multiple dispatch is when a dispatch function emits a value that depends on more\nthan one argument. In a multimethod that features multiple dispatch, the order of\nthe elements in the array emitted by the dispatch function has to be consistent with\nthe order of the elements in the wiring of the methods.\nDave Now let me see if I can figure out how to use a multimethod that features mul-\ntiple dispatch.\nDave remembers that Theo told him earlier that multimethods are used like regular func-\ntions. With that in mind, he comes up with the code for a multimethod that features multi-\nple dispatch.\nListing13.17 Calling a multimethod that features multiple dispatch\ngreetLang(myDog, french);\n// → \"Ouaf Ouaf! Je m\\'appelle Fido et je parle Français\"\ngreetLang(myDog, english);\n// → \"Woof woof! My name is Fido and I speak English\"\ngreetLang(myCat, french);\n// → \"Miaou! Je m\\'appelle Milo et je parle Français\"\n--- Page 314 ---\n286 CHAPTER 13 Polymorphism\ngreetLang(myCat, english);\n// → \"Meow! I am Milo and I speak English\"\ngreetLang(myCow, french);\n// → \"Meuh! Appelle moi Clarabelle et je parle Français\"\ngreetLang(myCow, english);\n// → \"Moo! Call me Clarabelle and I speak English\"\nTheo Now do you agree that multimethods with multiple dispatch offer a more pow-\nerful polymorphism that OOP polymorphism?\nDave Indeed, I do.\nTheo Let me show you an even more powerful polymorphism called dynamic dis-\npatch. But first, let’s get some more of that wonderful French press coffee.\nDave Great idea! While we’re in the kitchen, I think my mom made an orange Bundt\ncake using the oranges from the grove.\n13.4 Multimethods with dynamic dispatch\nDave refills their coffee cups as Theo takes two slices from the cake and dishes them up.\nThey take their coffee and cake outside to enjoy more of the fresh country air before\nresuming their conversation.\nDave What is dynamic dispatch?\nTheo It’s when the dispatch function of a multimethod returns a value that goes\nbeyond the static type of its arguments.\nDave Like what, for example?\nTheo Like a number or a Boolean, for instance.\nDave Why would such a thing be useful?\nTheo Imagine that instead of being polyglot, our animals would suffer from\ndysmakrylexia.\nDave Suffering from what?\nTheo Dysmakrylexia. It comes from the Greek dus, expressing the idea of difficulty,\nmakrýs meaning long, and léxis meaning diction. Therefore, dysmakrylexia is dif-\nficulty pronouncing long words.\nDave I’ve never heard of that.\nTheo That’s because I just invented it.\nDave Funny. What’s considered a long word for our animals?\nTheo Let’s say that when their name has more than five letters, they’re not able to\nsay it.\nDave A bit weird, but OK.\nTheo Let’s call our multimethod dysGreet. Its dispatch function returns an array\nwith two elements: the animal type and a Boolean about whether the name is\nlong or not. Take a look at this multimethod initialization.\n--- Page 315 ---\n13.4 Multimethods with dynamic dispatch 287\nListing13.18 A multimethod using a dispatch function with dynamic dispatch\nfunction dysGreetDispatch(animal) {\nif(dev()) {\nif(!ajv.validate(animalSchema, animal)) {\nvar errors = ajv.errorsText(ajv.errors);\nthrow (\"dysGreet called with invalid arguments: \" + errors);\n}\n}\nvar hasLongName = animal.name.length > 5;\nreturn [animal.type, hasLongName];\n};\nvar dysGreet = multi(dysGreetDispatch);\nDave Writing the dysGreet methods doesn’t seem too complicated.\nAs Theo reaches over to pass Dave his notebook, he accidently hits his coffee cup. Now Theo’s\nnotebook is completely wet, and all the diagrams are soggy! Fortunately, Dave brought an\nextra napkin from the kitchen, and it’s still clean. He draws a flow diagram as in figure 13.4\nand then grabs his laptop and writes the implementation of the dysGreet methods.\n[\"dog\", true] dysGreetDogLong\nGreet as a dog mentioning name\n[\"cat\", true] dysGreetCatLong\nGreet as a cat mentioning name\n[\"cow\", true] dysGreetCowLong\nGreet as a cow mentioning name\nargs dysGreetLangDispatch\nanimal, language Emit the animal and the language types\n[\"dog\", false] dysGreetDogShort\nGreet as a dog omitting name\n[\"cat\", false] dysGreetCatShort\nGreet as a cat omitting name\n[\"cow\", false] dysGreetCowShort\nGreet as a cow omitting name\nFigure 13.4 The logic flow of the dysGreet multimethod\nListing13.19 The dysGreet methods\nfunction dysGreetDogLong(animal) {\nconsole.log(\"Woof woof! My name is \" + animal.name);\n}\ndysGreet = method([\"dog\", true], dysGreetDogLong)(dysGreet);\n--- Page 316 ---\n288 CHAPTER 13 Polymorphism\nfunction dysGreetDogShort(animal) {\nconsole.log(\"Woof woof!\");\n}\ndysGreet = method([\"dog\", false], dysGreetDogShort)(dysGreet);\nfunction dysGreetCatLong(animal) {\nconsole.log(\"Meow! I am \" + animal.name);\n}\ndysGreet = method([\"cat\", true], dysGreetCatLong)(dysGreet);\nfunction dysGreetCatShort(animal) {\nconsole.log(\"Meow!\");\n}\ndysGreet = method([\"cat\", false], dysGreetCatShort)(dysGreet);\nfunction dysGreetCowLong(animal) {\nconsole.log(\"Moo! Call me \" + animal.name);\n}\ndysGreet = method([\"cow\", true], dysGreetCowLong)(dysGreet);\nfunction dysGreetCowShort(animal) {\nconsole.log(\"Moo!\");\n}\ndysGreet = method([\"cow\", false], dysGreetCowShort)(dysGreet);\nTheo checks that the code works as expected. He compliments Dave, not only on the\nmethod implementation but also for having the foresight to grab an extra napkin.\nListing13.20 Testing dysGreet\ndysGreet(myDog);\ndysGreet(myCow);\ndysGreet(myCat);\n//\"Woof woof!\"\n//\"Moo! Call me Clarabelle\"\n//\"Meow!\"\nTheo Well done, my friend! Our exploration of multimethods has come to an end. I\nthink it’s time for me to drive back if I want to get home before dark and beat\nthe rush hour traffic.\nDave Before you leave, let’s check if multimethods are available in programming\nlanguages other than JavaScript.\nTheo That’s a question for Joe.\nDave Do you think it’s OK if I call him now?\nTheo I think it’s probably better if you send him an email. He’s in a tech conference,\nand I’m not sure if it’s all day. Thank you for this beautiful day in the country\nand the wonderful refreshments.\nDave I enjoyed it, also, especially our discussions about etymology. I think there are\nsome oranges for you to take home and enjoy later.\nTheo Great! I can’t wait until my wife tries one.\n--- Page 317 ---\n13.5 Integrating multimethods in a production system 289\nAfter Theo leaves, Dave sends Joe an email. A few minutes later, Dave receives an email\nfrom Joe with the subject, “Support for multimethods in different languages.”\nSupport for multimethods in different languages\nPython has a library called multimethods (https://github.com/weissjeffm/multimeth-\nods), and Ruby has one called Ruby multimethods (https://github.com/psantacl/\nruby-multimethods). Both seem to work quite like the JavaScript arrows/multi-\nmethod library.\nIn Java, there is the Java Multimethod Framework (http://igm.univ-mlv.fr/~forax/\nworks/jmmf/), and C# supports multimethods natively via the dynamic keyword.\nHowever, in both Java and C#, multimethods work only with static data types and not\nwith generic data structures.\nGeneric data structure\nLanguage URL\nsupport\nJavaScript https://github.com/caderek/arrows/tree/master/ Yes\npackages/multimethod\nJava http://igm.univ-mlv.fr/~forax/works/jmmf/ No\nC# Native support No\nPython https://github.com/weissjeffm/multimethods Yes\nRuby https://github.com/psantacl/ruby-multimethods Yes\n13.5 Integrating multimethods in a production system\nWhile Theo is driving back home, his thoughts take him back to the fresh air of the coun-\ntry. This pleasant moment is interrupted by a phone call from Nancy at Klafim.\nNancy How are you doing?\nTheo Fine. I’m driving back from the countryside.\nNancy Cool. Are you available to talk about work?\nTheo Sure.\nNancy I’d like to add a tiny feature to the catalog.\nIn the past, when Nancy qualified a feature as tiny, it scared Theo because tiny turned into\nhuge. What seemed easy to her always took him a surprising amount of time to develop.\nBut after refactoring the system according to DOP principles, now what seems tiny to\nNancy is usually quite easy to implement.\nTheo What feature?\nNancy I’d like to allow librarians to view the list of authors, ordered by last name, in\ntwo formats: HTML and Markdown.\n--- Page 318 ---\n290 CHAPTER 13 Polymorphism\nTheo It doesn’t sound too complicated.\nNancy Also, I need a bit of text formatting.\nTheo What kind of text formatting?\nNancy Depending on the number of books an author has written, their name should\nbe in bold and italic fonts.\nTheo Could you send me an email with all the details. I’ll take a look at it tomorrow\nmorning.\nNancy Perfect. Have a safe drive!\nBefore going to bed, Theo reflects about today’s etymology lessons. He realizes that he\nnever looked for the etymology of the word etymology itself! He searches for the term etymol-\nogy online and learns that the word etymology derives from the Greek étumon, meaning true\nsense, and the suffix logia, denoting the study of. During the night, Theo dreams of dogs,\ncats, and cows programming on their laptops in a field of grass.\nWhen Theo arrives at the office the next day, he opens Nancy’s email with the details\nabout the text formatting feature. The details are summarized in table 13.1.\nTable 13.1 Text formatting for author names according to the number of books\nthey have written\nNumber of books Italic Bold\n10 or fewer Yes No\nBetween 11 and 50 No Yes\n51 or more Yes Yes\nTheo forwards Nancy’s email to Dave and asks him to take care of this task. Delegating\nresponsibility, after all, is the trait of a great manager.\nDave thinks the most difficult part of the feature lies in implementing an Author\n.myName(author, format) function that receives two arguments: the author data and the\ntext format. He asks himself whether he can implement this function as a multimethod\nand use what he learned yesterday with Theo at his parents’ home in the country. It seems\nthat this feature is quite similar to the one that dealt with dysmakrylexia. Instead of check-\ning the length of a string, he needs to check the length of an array.\nFirst, Dave needs a data schema for the text format. He could represent a format as a\nmap with a type field like Theo did yesterday for languages, but at the moment, it seems\nsimpler to represent a format as a string that could be either markdown or html. He comes\nup with the text format schema in listing 13.21. He already wrote the author schema with\nTheo last week. It’s in listing 13.22.\nListing13.21 The text format schema\nvar textFormatSchema = {\n\"name\": {\"type\": \"string\"},\n\"type\": {\"enum\": [\"markdown\", \"html\"]}\n};\n--- Page 319 ---\n13.5 Integrating multimethods in a production system 291\nListing13.22 The author schema\nvar authorSchema = {\n\"type\": \"object\",\n\"required\": [\"name\", \"bookIsbns\"],\n\"properties\": {\n\"name\": {\"type\": \"string\"},\n\"bookIsbns\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n};\nNow, Dave needs to write a dispatch function and initialize the multimethod. Remember-\ning that Theo had no qualms about creating the word dysmakrylexia, he decides that he\nprefers his own neologism, prolificity, over the existing nominal form prolificness. He finds it\nuseful to have an Author.prolificityLevel helper function that returns the level of\nprolificity of the author: either low, medium, or high. Now he’s ready to code the author-\nNameDispatch function.\nListing13.23 Author.myName multimethod initialization\nAuthor.prolificityLevel = function(author) {\nvar books = _.size(_.get(author, \"bookIsbns\"));\nif (books <= 10) {\nreturn \"low\";\n};\nif (books >= 51) {\nreturn \"high\";\n}\nreturn \"medium\";\n};\nvar authorNameArgsSchema = {\n\"type\": \"array\",\n\"prefixItems\": [\nauthorSchema,\n{\"enum\": [\"markdown\", \"html\"]}\n]\n};\nfunction authorNameDispatch(author, format) {\nif(dev()) {\nif(!ajv.validate(authorNameArgsSchema, [author, format])) {\nthrow (\"Author.myName called with invalid arguments: \" +\najv.errorsText(ajv.errors));\n}\n}\nreturn [Author.prolificityLevel(author), format];\n};\nAuthor.myName = multi(authorNameDispatch);\n--- Page 320 ---\n292 CHAPTER 13 Polymorphism\nThen Dave works on the methods: first, the HTML format methods. In HTML, bold text is\nwrapped inside a <b> tag, and italic text is wrapped in a <i> tag. For instance, in HTML,\nthree authors with different levels of prolificity would be written like this.\nListing13.24 Examples of bold and italic in HTML\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n<i>Yehonathan Sharvit<i>\nBold and italic formatting\n<b>Stephen Covey</b>\nfor highly prolific authors\n<b><i>Isaac Asimov</i></b>\nWith this information in hand, Dave writes the three methods that deal with HTML for-\nmatting. Easy!\nListing13.25 The methods that deal with HTML formatting\nfunction authorNameLowHtml(author, format) {\nreturn \"<i>\" + _.get(author, \"name\") + \"</i>\";\n}\nAuthor.myName = method([\"low\", \"html\"], authorNameLowHtml)(Author.myName);\nfunction authorNameMediumHtml(author, format) {\nreturn \"<b>\" + _.get(author, \"name\") + \"</b>\";\n}\nAuthor.myName =\nmethod([\"medium\", \"html\"], authorNameMediumHtml)(Author.myName);\nfunction authorNameHighHtml(author, format) {\nreturn \"<b><i>\" + _.get(author, \"name\") + \"</i></b>\";\n}\nAuthor.myName =\nmethod([\"high\", \"html\"], authorNameHighHtml)(Author.myName);\nThen, Dave moves on to the three methods that deal with Markdown formatting. In\nMarkdown, bold text is wrapped in two asterisks, and italic text is wrapped in a single\nasterisk. For instance, in Markdown, three authors with different levels of prolificity\nwould be written like the code in listing 13.26. The code for the Markdown methods is in\nlisting 13.27.\nListing13.26 Examples of bold and italic in Markdown\nItalic formatting for Bold formatting for\nminimally prolific authors moderately prolific authors\n*Yehonathan Sharvit*\nBold and italic formatting\n**Stephen Covey**\nfor highly prolific authors\n***Isaac Asimov***\n--- Page 321 ---\n13.5 Integrating multimethods in a production system 293\nListing13.27 The methods that deal with Markdown formatting\nfunction authorNameLowMarkdown(author, format) {\nreturn \"*\" + _.get(author, \"name\") + \"*\";\n}\nAuthor.myName =\nmethod([\"low\", \"markdown\"], authorNameLowMarkdown)(Author.myName);\nfunction authorNameMediumMarkdown(author, format) {\nreturn \"**\" + _.get(author, \"name\") + \"**\";\n}\nAuthor.myName =\nmethod([\"medium\", \"markdown\"], authorNameMediumMarkdown)(Author.myName);\nfunction authorNameHighMarkdown(author, format) {\nreturn \"***\" + _.get(author, \"name\") + \"***\";\n}\nAuthor.myName =\nmethod([\"high\", \"markdown\"], authorNameHighMarkdown)(Author.myName);\nDave decides to test his code by involving a mysterious author. Listing 13.28 and listing 13.29\nshow the tests.\nListing13.28 Testing HTML formatting\nvar yehonathan = {\n\"name\": \"Yehonathan Sharvit\",\n\"bookIsbns\": [\"9781617298578\"]\n};\nAuthor.myName(yehonathan, \"html\");\n// → \"<i>Yehonathan Sharvit</i>\"\nListing13.29 Testing Markdown formatting\nAuthor.myName(yehonathan, \"markdown\");\n// → \"*Yehonathan Sharvit*\"\nTheo shows up at Dave’s desk and asks to review Dave’s implementation of the list of\nauthors feature. Curious, Theo asks Dave about the author that appears in the test of\nAuthor.myName.\nTheo Who is Yehonathan Sharvit?\nDave I don’t really know. The name appeared when I googled “data-oriented pro-\ngramming” yesterday. He wrote a book on the topic. I thought it would be cool\nto use its ISBN in my test.\n--- Page 322 ---\n294 CHAPTER 13 Polymorphism\nSummary\n The main benefit of polymorphism is extensibility.\n Multimethods make it possible to benefit from polymorphism when data is repre-\nsented with generic maps.\n A multimethod is made of a dispatch function and multiple methods.\n The dispatch function of a multimethod emits a dispatch value.\n Each of the methods used in a multimethod provides an implementation for a\nspecific dispatch value.\n Multimethods can mimic OOP class inheritance via single dispatch.\n In single dispatch, a multimethod receives a single map that contains a type field,\nand the dispatch function of the multimethod emits the value of the type field.\n In addition to single dispatch, multimethods provide two kinds of advanced\npolymorphisms: multiple dispatch and dynamic dispatch.\n Multiple dispatch is used when the behavior of the multimethod depends on\nmultiple arguments.\n Dynamic dispatch is used when the behavior of the multimethod depends on run-\ntime arguments.\n The arguments of a multimethod are passed to the dispatch function and to the\nmethods.\n A multimethod dispatch function is responsible for\n– Defining the signature.\n– Validating the arguments.\n– Emitting a dispatch value.\n Multimethods provides extensibility by decoupling between multimethod ini-\ntialization and method implementations.\n Multimethods are called like regular functions.\n Multimethods support default implementations that are called when no method\ncorresponds to the dispatch value.\n In a multimethod that features multiple dispatch, the order of the elements in\nthe array emitted by the dispatch function has to be consistent with the order of\nthe elements in the wiring of the methods.\nLodash functions introduced in this chapter\nFunction Description\nsize(coll) Gets the size of coll\n--- Page 323 ---\nAdvanced data\nmanipulation\nWhatever is well-conceived\nis clearly said\nThis chapter covers\n Manipulating nested data\n Writing clear and concise code for business\nlogic\n Separating business logic and generic data\nmanipulation\n Building custom data manipulation tools\n Using the best tool for the job\nWhen our business logic involves advanced data processing, the generic data manip-\nulation functions provided by the language run time and by third-party libraries\nmight not be sufficient. Instead of mixing the details of data manipulation with\nbusiness logic, we can write our own generic data manipulation functions and imple-\nment our custom business logic using them. Separating business logic from the inter-\nnal details of data manipulation makes the business logic code concise and easy to\nread for other developers.\n295\n--- Page 324 ---\n296 CHAPTER 14 Advanced data manipulation\n14.1 Updating a value in a map with eloquence\nDave is more and more autonomous on the Klafim project. He can implement most fea-\ntures on his own, typically turning to Theo only for code reviews. Dave’s code quality stan-\ndards are quite high. Even when his code is functionally solid, he tends to be unsatisfied\nwith its readability. Today, he asks for Theo’s help in improving the readability of the code\nthat fixes a bug Theo introduced a long time ago.\nDave I think I have a found a bug in the code that returns book information from\nthe Open Library API.\nTheo What bug?\nDave Sometimes, the API returns duplicate author names, and we pass the dupli-\ncates through to the client.\nTheo It doesn’t sound like a complicated bug to fix.\nDave Right, I fixed it, but I’m not satisfied with the readability of the code I wrote.\nTheo Being critical of our own code is an important quality for a developer to prog-\nress. What is it exactly that you don’t like?\nDave Take a look at this code.\nListing14.1 Removing duplicates in a straightforward but tedious way\nfunction removeAuthorDuplicates(book) {\nvar authors = _.get(book, \"authors\");\nvar uniqAuthors = _.uniq(authors);\nreturn _.set(book,\"authors\", uniqAuthors);\n}\nDave I’m using _.get to retrieve the array with the author names, then _.uniq to\ncreate a duplicate-free version of the array, and finally, _.set to create a new\nversion of the book with no duplicate author names.\nTheo The code is tedious because the next value of authorNames needs to be based\non its current value.\nDave But it’s a common use case! Isn’t there a simpler way to write this kind of code?\nTheo Your astonishment definitely honors you as a developer, Dave. I agree with you\nthat there must be a simpler way. Let me phone Joe and see if he’s available for\na conference call.\nJoe How’s it going, Theo?\nTheo Great! Are you back from your tech conference?\nJoe I just landed. I’m on my way home now in a taxi.\nTheo How was your talk about DOP?\nJoe Pretty good. At the beginning people were a bit suspicious, but when I told\nthem the story of Albatross and Klafim, it was quite convincing.\nTheo Yeah, adults are like children in that way; they love stories.\nJoe What about you? Did you manage to achieve polymorphism with multimethods?\nTheo Yes! Dave even managed to implement a feature in Klafim with multimethods.\nJoe Cool!\n--- Page 325 ---\n14.1 Updating a value in a map with eloquence 297\nTheo Do you have time to help Dave with a question about programming?\nJoe Sure.\nDave Hi Joe. How are you doing?\nJoe Hello Dave. Not bad. What kind of help do you need?\nDave I’m wondering if there’s a simpler way to remove duplicates inside an array\nvalue in a map. Using _.get, _.uniq, and _.set looks quite tedious.\nJoe You should build your own data manipulation tools.\nDave What do you mean?\nJoe You should write a generic update function that updates a value in a map,\napplying a calculation based on its current value.1\nDave What would the arguments of update be in your opinion?\nJoe Put the cart before the horse.\nDave What?!\nJoe Rewrite your business logic as if update were already implemented, and you’ll\ndiscover what the arguments of update should be.\nDave I see what you mean: the horse is the implementation of update, and the cart is\nthe usage of update.\nJoe Exactly. But remember, it’s better if you keep your update function generic.\nDave How?\nJoe By not limiting it to your specific use case.\nDave I see. The implementation of update should not deal with removing duplicate\nelements. Instead, it should receive the updating function—in my case,\n_.uniq—as an argument.\nJoe Exactly! Uh, sorry Dave, I gotta go, I just got home. Good luck!\nDave Take care, Joe, and thanks!\nDave ends the conference call. Looking at Theo, he reiterates the conversation with Joe.\nDave Joe advised me to write my own update function. For that purpose, he told me\nto start by rewriting removeAuthorDuplicates as if update were already\nimplemented. That will allow us to make sure we get the signature of update\nright.\nTheo Sounds like a plan.\nDave Joe called it “putting the cart before the horse.”\nTheo Joe and his funny analogies...\nTIP The best way to find the signature of a custom data manipulation function is to\nthink about the most convenient way to use it.\nDave Anyway, the way I’d like to use update inside removeAuthorDuplicates is\nlike this.\n1 Lodash provides an implementation of update, but for the sake of teaching, we are writing our own imple-\nmentation.\n--- Page 326 ---\n298 CHAPTER 14 Advanced data manipulation\nListing14.2 The code that removes duplicates in an elegant way\nfunction removeAuthorDuplicates(book) {\nreturn update(book, \"authors\", _.uniq);\n}\nTheo Looks good to me!\nDave Wow! Now the code with update is much more elegant than the code with\n_.get and _.set!\nTheo Before you implement update, I suggest that you write down in plain English\nexactly what the function does.\nDave It’s quite easy: update receives a map called map, a path called path, and a\nfunction called fun. It returns a new version of map, where path is associated\nwith fun(currentValue), and currentValue is the value associated with\npath in map.\nThinking out loud, Dave simultaneously draws a diagram like that in figure 14.1. Theo is\nbecoming more and more impressed with his young protegé as he studies the figure.\n{\n\"position\" : \"manager\", \"income\"\n\"income\" : 100000\n} map fun path\nupdate\n{\n\"position\" : \"manager\",\n\"income\" : fun(100000)\nres Figure 14.1 The\n}\nbehavior of update\nTIP Before implementing a custom data manipulation function, formulate in plain\nEnglish exactly what the function does.\nTheo With such a clear definition, it’s going to be a piece of cake to implement\nupdate!\nAfter a few minutes, Dave comes up with the code. It doesn’t take long because the plain-\nEnglish diagram helps him to organize the code.\nListing14.3 A generic update function\nfunction update(map, path, fun) {\nvar currentValue = _.get(map, path);\nvar nextValue = fun(currentValue);\nreturn _.set(map, path, nextValue);\n}\n--- Page 327 ---\n14.2 Manipulating nested data 299\nTheo Why don’t you see if it works with a simple case such as incrementing a number\nin a map?\nDave Good idea! I’ll try multiplying a value in a map by 2 with update. How’s this\nlook?\nListing14.4 Multiplying a value in a map by 2\nvar m = {\n\"position\": \"manager\",\n\"income\": 100000\n};\nupdate(m, \"income\", function(x) {\nreturn x * 2;\n});\n// → {\"position\": \"manager\", \"income\": 200000}\nTheo Great! It seems to work.\n14.2 Manipulating nested data\nThe next Monday, during Theo and Dave’s weekly sync meeting, they discuss the upcom-\ning features for Klafim. Theo fondly remembers another Monday where they met at Dave’s\nfamily home in the country. Coming back to the present moment, Theo begins.\nTheo Recently, Nancy has been asking for more and more administrative features.\nDave Like what?\nTheo I’ll give you a few examples.... Let me find the email I got from Nancy yesterday.\nDave OK.\nTheo Here it is. There are three feature requests for now: listing all the book author\nIDs, calculating the book lending ratio, and grouping books by a physical library.\nDave What feature should I tackle first?\nTheo It doesn’t matter, but you should deliver the three of these before the end of\nthe week. Good luck, and don’t hesitate to call me if you need help.\nOn Tuesday, Dave asks for Theo’s help. Dave is not pleased with how his code looks.\nDave I started to work on the three admin features, but I don’t like the code I wrote.\nLet me show you the code for retrieving the list of author IDs from the list of\nbooks returned from the database.\nTheo Can you remind me what an element in a book list returned from the database\nlooks like?\nDave Each book is a map with an authorIds array field.\nTheo OK, so it sounds like a map over the books should do it.\nDave This is what I did, but it doesn’t work as expected. Here’s my code for listing\nthe book author IDs.\n--- Page 328 ---\n300 CHAPTER 14 Advanced data manipulation\nListing14.5 Retrieving the author IDs in books as an array of arrays\nfunction authorIdsInBooks(books) {\nreturn _.map(books, \"authorIds\");\n}\nTheo What’s the problem?\nDave The problem is that it returns an array of arrays of author IDs instead of an\narray of author IDs. For instance, when I run authorIdsInBooks on a catalog\nwith two books, I get this result.\nListing14.6 The author IDs in an array of arrays\n[\n[\"sean-covey\", \"stephen-covey\"],\n[\"alan-moore\", \"dave-gibbons\"]\n]\nTheo That’s not a big problem. You can flatten an array of arrays with _.flatten,\nand you should get the result you expect.\nDave Nice! This is exactly what I need! Give me a moment to fix the code of\nauthorIdsInBooks. . . here you go.\nListing14.7 Retrieving the author IDs in books as an array of strings\nfunction authorIdsInBooks(books) {\nreturn _.flatten(_.map(books, \"authorIds\"));\n}\nTheo Don’t you think that mapping and then flattening deserves a function of its own?\nDave Maybe. It’s quite easy to implement a flatMap function.2 How about this?\nListing14.8 The implementation of flatMap\nfunction flatMap(coll, f) {\nreturn _.flatten(_.map(coll,f));\n}\nTheo Nice!\nDave I don’t know.... It’s kind of weird to have such a small function.\nTheo I don’t think that code size is what matters here.\nDave What do you mean?\nTheo See what happens when you rewrite authorIdsInBooks using flatMap.\nDave OK, here’s how I’d use flatMap to list the author IDs.\n2 Lodash provides an implementation of flatMap, but for the sake of teaching, we are writing our own\nimplementation.\n--- Page 329 ---\n14.3 Using the best tool for the job 301\nListing14.9 Retrieving the author IDs as an array of strings using flatMap\nfunction authorIdsInBooks(books) {\nreturn flatMap(books, \"authorIds\");\n}\nTheo What implementation do you prefer, the one with flatten and map (in listing\n14.7) or the one with flatMap (in listing 14.9)?\nDave I don’t know. To me, they look quite similar.\nTheo Right, but which implementation is more readable?\nDave Well, assuming I know what flatMap does, I would say the implementation\nwith flatMap. Because it’s more concise, it is a bit more readable.\nTheo Again, it’s not about the size of the code. It’s about the clarity of intent and the\npower of naming things.\nDave I don’t get that.\nTheo Let me give you an example from our day-to-day language.\nDave OK.\nTheo Could you pass me that thing on your desk that’s used for writing?\nIt takes Dave a few seconds to get that Theo has asked him to pass the pen on the desk.\nAfter he passes Theo the pen, he asks:\nDave Why didn’t you simply ask for the pen?\nTheo I wanted you to experience how it feels when we use descriptions instead of\nnames to convey our intent.\nDave Oh, I see. You mean that once we use a name for the operation that maps and\nflattens, the code becomes clearer.\nTheo Exactly.\nDave Let’s move on to the second admin feature: calculating the book lending ratio.\nTheo Before that, I think we deserve a short period for rest and refreshments, where\nwe drink a beverage made by percolation from roasted and ground seeds.\nDave A coffee break!\n14.3 Using the best tool for the job\nAfter the coffee break, Dave shows Theo his implementation of the book lending ratio cal-\nculation. This time, he seems to like the code he wrote.\nDave I’m quite proud of the code I wrote to calculate the book lending ratio.\nTheo Show me the money!\nDave My function receives a list of books from the database like this.\nListing14.10 A list of two books with bookItems\n[\n{\n\"isbn\": \"978-1779501127\",\n--- Page 330 ---\n302 CHAPTER 14 Advanced data manipulation\n\"title\": \"Watchmen\",\n\"bookItems\": [\n{\n\"id\": \"book-item-1\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": true\n}\n]\n},\n{\n\"isbn\": \"978-1982137274\",\n\"title\": \"7 Habits of Highly Effective People\",\n\"bookItems\": [\n{\n\"id\": \"book-item-123\",\n\"libId\": \"hudson-park-lib\",\n\"isLent\": true\n},\n{\n\"id\": \"book-item-17\",\n\"libId\": \"nyc-central-lib\",\n\"isLent\": false\n}\n]\n}\n]\nTheo Quite a nested piece of data!\nDave Yeah, but now that I’m using flatMap, calculating the lending ratio is quite\neasy. I’m going over all the book items with forEach and incrementing either\nthe lent or the notLent counter. At the end, I return the ratio between lent\nand (lent + notLent). Here’s how I do that.\nListing14.11 Calculating the book lending ratio using forEach\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar lent = 0;\nvar notLent = 0;\n_.forEach(bookItems, function(item) {\nif(_.get(item, \"isLent\")) {\nlent = lent + 1;\n} else {\nnotLent = notLent + 1;\n}\n});\nreturn lent/(lent + notLent);\n}\nTheo Would you allow me to tell you frankly what I think of your code?\nDave If you are asking this question, it means that you don’t like it. Right?\nTheo It’s nothing against you; I don’t like any piece of code with forEach.\n--- Page 331 ---\n14.3 Using the best tool for the job 303\nDave What’s wrong with forEach?\nTheo It’s too generic!\nDave I thought that genericity was a positive thing in programming.\nTheo It is when we build a utility function, but when we use a utility function, we\nshould use the least generic function that solves our problem.\nDave Why?\nTheo Because we ought to choose the right tool for the job, like in the real life.\nDave What do you mean?\nTheo Let me give you an example. Yesterday, I had to clean my drone from the\ninside. Do you think that I used a screwdriver or a Swiss army knife to unscrew\nthe drone cover?\nDave A screwdriver, of course! It’s much more convenient to manipulate.\nTheo Right. Also, imagine that someone looks at me using a screwdriver. It’s quite\nclear to them that I am turning a screw. It conveys my intent clearly.\nDave Are you saying that forEach is like the Swiss army knife of data manipulation?\nTheo That’s a good way to put it.\nTIP Pick the least generic utility function that solves your problem.\nDave What function should I use then, to iterate over the book item collection?\nTheo You could use _.reduce.\nDave I thought reduce was about returning data from a collection. Here, I don’t\nneed to return data; I need to update two variables, lent and notLent.\nTheo You could represent those two values in a map with two keys.\nDave Can you show me how to rewrite my lendingRatio function using reduce?\nTheo Sure. The initial value passed to reduce is the map, {\"lent\": 0, \"notLent\": 0},\nand inside each iteration, we update one of the two keys, like this.\nListing14.12 Calculating the book lending ratio using reduce\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = _.reduce(bookItems, function(res, item) {\nif(_.get(item, \"isLent\")) {\nres.lent = res.lent + 1;\n} else {\nres.notLent = res.notLent + 1;\n}\nreturn res;\n}, {notLent: 0, lent:0});\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nDave Instead of updating the variables lent and notLent, now we are updating lent\nand notLent map fields. What’s the difference?\n--- Page 332 ---\n304 CHAPTER 14 Advanced data manipulation\nTheo Dealing with map fields instead of variables allows us to get rid of reduce in\nour business logic code.\nDave How could you iterate over a collection without forEach and without reduce?\nTheo I can’t avoid the iteration over a collection, but I can hide reduce behind a\nutility function. Take a look at the way reduce is used inside the code of\nlendingRatio. What is the meaning of the reduce call?\nDave looks at the code in listing 14.12. He thinks for a long moment before he answers.\nDave I think it’s counting the number of times isLent is true and false.\nTheo Right. Now, let’s use Joe’s advice about building our own data manipulation\ntool.\nDave How exactly?\nTheo I suggest that you write a countByBoolField utility function that counts the\nnumber of times a field is true and false.\nDave OK, but before implementing this function, let me first rewrite the code of\nlendingRatio, assuming this function already exists.\nTheo You are definitely a fast learner, Dave!\nDave Thanks! I think that by using countByBoolField, the code for calculating the\nlending ratio using a custom utility function would be something like this.\nListing14.13 Calculating the book lending ratio\nfunction lendingRatio(books) {\nvar bookItems = flatMap(books, \"bookItems\");\nvar stats = countByBoolField(bookItems, \"isLent\", \"lent\", \"notLent\");\nreturn stats.lent/(stats.lent + stats.notLent);\n}\nTIP Don’t use _.reduce or any other low-level data manipulation function inside\ncode that deals with business logic. Instead, write a utility function—with a proper\nname—that hides _.reduce.\nTheo Perfect. Don’t you think that this code is clearer than the code using _.reduce?\nDave I do! The code is both more concise and the intent is clearer. Let me see if I\ncan implement countByBoolField now.\nTheo I suggest that you write a unit test first.\nDave Good idea.\nDave types for a bit. When he’s satisfied, he shows Theo the result.\nListing14.14 A unit test for countByBoolField\nvar input = [\n{\"a\": true},\n{\"a\": false},\n{\"a\": true},\n--- Page 333 ---\n14.4 Unwinding at ease 305\n{\"a\": true}\n];\nvar expectedRes = {\n\"aTrue\": 3,\n\"aFalse\": 1\n};\n_.isEqual(countByBoolField(input, \"a\", \"aTrue\", \"aFalse\"), expectedRes);\nTheo Looks good to me. Now, for the implementation of countByBoolField, I\nthink you are going to need our update function.\nDave I think you’re right. On each iteration, I need to increment the value of either\naTrue or aFalse using update and a function that increments a number by 1.\nAfter a few minutes of trial and error, Dave comes up with the piece of code that uses\nreduce, update, and inc. He shows Theo the code for countByBoolField.\nListing14.15 The implementation of countByBoolField\nfunction inc (n) {\nreturn n + 1;\n}\nfunction countByBoolField(coll, field, keyTrue, keyFalse) {\nreturn _.reduce(coll, function(res, item) {\nif (_.get(item, field)) {\nreturn update(res, keyTrue, inc);\n}\nreturn update(res, keyFalse, inc);\n}, {[keyTrue]: 0,\nCreates a map with\n[keyFalse]: 0});\nkeyTrue and keyFalse\n}\nassociated to 0\nTheo Well done! Shall we move on and review the third admin feature?\nDave The third feature is more complicated. I would like to use the teachings from\nthe first two features for the implementation of the third feature.\nTheo OK. Call me when you’re ready for the code review.\n14.4 Unwinding at ease\nDave really struggled with the implementation of the last admin feature, grouping books\nby a physical library. After a couple of hours of frustration, Dave calls Theo for a rescue.\nDave I really had a hard time implementing the grouping by library feature.\nTheo I only have a couple of minutes before my next meeting, but I can try to help\nyou. What’s the exact definition of grouping by library?\nDave Let me show you the unit test I wrote.",
        "sections_found": []
      },
      "accurate_page_range": "303-333"
    },
    {
      "text": "- 13.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "13 Polymorphism",
      "raw_line": "- 13.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 106
    },
    {
      "text": "- 13.1 The essence of polymorphism",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "13 Polymorphism",
      "raw_line": "- 13.1 The essence of polymorphism (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 107
    },
    {
      "text": "- 13.2 Multimethods with single dispatch",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "13 Polymorphism",
      "raw_line": "- 13.2 Multimethods with single dispatch (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 108
    },
    {
      "text": "- 13.3 Multimethods with multiple dispatch",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "13 Polymorphism",
      "raw_line": "- 13.3 Multimethods with multiple dispatch (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 109
    },
    {
      "text": "- 13.4 Multimethods with dynamic dispatch",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "13 Polymorphism",
      "raw_line": "- 13.4 Multimethods with dynamic dispatch (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 110
    },
    {
      "text": "- 13.5 Integrating multimethods in a production system",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "13 Polymorphism",
      "raw_line": "- 13.5 Integrating multimethods in a production system (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 111
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "13 Polymorphism",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 112
    },
    {
      "text": "- 14.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "14 Advanced data manipulation",
      "raw_line": "- 14.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 113
    },
    {
      "text": "- 14.1 Updating a value in a map with eloquence",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "14 Advanced data manipulation",
      "raw_line": "- 14.1 Updating a value in a map with eloquence (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 114
    },
    {
      "text": "- 14.2 Manipulating nested data",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "14 Advanced data manipulation",
      "raw_line": "- 14.2 Manipulating nested data (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 115
    },
    {
      "text": "- 14.3 Using the best tool for the job",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "14 Advanced data manipulation",
      "raw_line": "- 14.3 Using the best tool for the job (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 116
    },
    {
      "text": "- 14.4 Unwinding at ease",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "14 Advanced data manipulation",
      "raw_line": "- 14.4 Unwinding at ease (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 117
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "14 Advanced data manipulation",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 118
    },
    {
      "text": "- 15.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- 15.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 119
    },
    {
      "text": "- 15.1 Determinism in programming",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- 15.1 Determinism in programming (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 120
    },
    {
      "text": "- 15.2 Reproducibility with numbers and strings",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- 15.2 Reproducibility with numbers and strings (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 121
    },
    {
      "text": "- 15.3 Reproducibility with any data",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- 15.3 Reproducibility with any data (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 122
    },
    {
      "text": "- 15.4 Unit tests",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- 15.4 Unit tests (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 123
    },
    {
      "text": "- 15.5 Dealing with external data sources",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- 15.5 Dealing with external data sources (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 124
    },
    {
      "text": "- Farewell",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- Farewell (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 125
    },
    {
      "text": "- Summary",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- Summary (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 126
    },
    {
      "text": "- A.0 Introduction (사용자 추가)",
      "node_level": 2,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.0 Introduction (사용자 추가) (node2) **[LEAF]**",
      "is_part_intro": false,
      "id": 127
    },
    {
      "text": "- A.1.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.1.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 128
    },
    {
      "text": "- A.1.1 Illustration of Principle #1",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.1.1 Illustration of Principle #1 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 129
    },
    {
      "text": "- A.1.2 Benefits of Principle #1",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.1.2 Benefits of Principle #1 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 130
    },
    {
      "text": "- A.1.3 Cost for Principle #1",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.1.3 Cost for Principle #1 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 131
    },
    {
      "text": "- A.1.4 Summary of Principle #1",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.1.4 Summary of Principle #1 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 132
    },
    {
      "text": "- A.2.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.2.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 133
    },
    {
      "text": "- A.2.1 Illustration of Principle #2",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.2.1 Illustration of Principle #2 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 134
    },
    {
      "text": "- A.2.2 Benefits of Principle #2",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.2.2 Benefits of Principle #2 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 135
    },
    {
      "text": "- A.2.3 Cost for Principle #2",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.2.3 Cost for Principle #2 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 136
    },
    {
      "text": "- A.2.4 Summary of Principle #2",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.2.4 Summary of Principle #2 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 137
    },
    {
      "text": "- A.3.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.3.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 138
    },
    {
      "text": "- A.3.1 Illustration of Principle #3",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.3.1 Illustration of Principle #3 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 139
    },
    {
      "text": "- A.3.2 Benefits of Principle #3",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.3.2 Benefits of Principle #3 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 140
    },
    {
      "text": "- A.3.3 Cost for Principle #3",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.3.3 Cost for Principle #3 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 141
    },
    {
      "text": "- A.3.4 Summary of Principle #3",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.3.4 Summary of Principle #3 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 142
    },
    {
      "text": "- A.4.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.4.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 143
    },
    {
      "text": "- A.4.1 Illustration of Principle #4",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.4.1 Illustration of Principle #4 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 144
    },
    {
      "text": "- A.4.2 Benefits of Principle #4",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.4.2 Benefits of Principle #4 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 145
    },
    {
      "text": "- A.4.3 Cost for Principle #4",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.4.3 Cost for Principle #4 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 146
    },
    {
      "text": "- A.4.4 Summary of Principle #4",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- A.4.4 Summary of Principle #4 (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 147
    },
    {
      "text": "- Conclusion",
      "node_level": 2,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- Conclusion (node2) **[LEAF]**",
      "is_part_intro": false,
      "id": 148
    },
    {
      "text": "- B.0 Introduction (사용자 추가)",
      "node_level": 2,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.0 Introduction (사용자 추가) (node2) **[LEAF]**",
      "is_part_intro": false,
      "id": 149
    },
    {
      "text": "- B.1.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.1.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 150
    },
    {
      "text": "- B.1.1 Accessing non-nested map fields with dynamic getters",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.1.1 Accessing non-nested map fields with dynamic getters (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 151
    },
    {
      "text": "- B.1.2 Accessing nested map fields with dynamic getters",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.1.2 Accessing nested map fields with dynamic getters (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 152
    },
    {
      "text": "- B.2.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.2.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 153
    },
    {
      "text": "- B.2.1 Accessing non-nested map fields with value getters",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.2.1 Accessing non-nested map fields with value getters (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 154
    },
    {
      "text": "- B.2.2 Accessing nested map fields with value getters",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.2.2 Accessing nested map fields with value getters (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 155
    },
    {
      "text": "- B.3.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.3.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 156
    },
    {
      "text": "- B.3.1 Accessing non-nested map fields with typed getters",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.3.1 Accessing non-nested map fields with typed getters (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 157
    },
    {
      "text": "- B.3.2 Accessing nested map fields with typed getters",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.3.2 Accessing nested map fields with typed getters (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 158
    },
    {
      "text": "- B.4.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.4.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 159
    },
    {
      "text": "- B.4.1 Generic access to non-nested class members",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.4.1 Generic access to non-nested class members (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 160
    },
    {
      "text": "- B.4.2 Generic access to nested class members",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.4.2 Generic access to nested class members (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 161
    },
    {
      "text": "- B.4.3 Automatic JSON serialization of objects",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- B.4.3 Automatic JSON serialization of objects (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 162
    },
    {
      "text": "- Summary",
      "node_level": 2,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- Summary (node2) **[LEAF]**",
      "is_part_intro": false,
      "id": 163
    },
    {
      "text": "- C.0 Introduction (사용자 추가)",
      "node_level": 2,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.0 Introduction (사용자 추가) (node2) **[LEAF]**",
      "is_part_intro": false,
      "id": 164
    },
    {
      "text": "- C.1.1 1958: Lisp",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.1.1 1958: Lisp (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 165
    },
    {
      "text": "- C.1.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.1.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 166
    },
    {
      "text": "- C.1.2 1981: Values and objects",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.1.2 1981: Values and objects (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 167
    },
    {
      "text": "- C.1.3 2000: Ideal hash trees",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.1.3 2000: Ideal hash trees (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 168
    },
    {
      "text": "- C.1.4 2006: Out of the Tar Pit",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.1.4 2006: Out of the Tar Pit (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 169
    },
    {
      "text": "- C.1.5 2007: Clojure",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.1.5 2007: Clojure (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 170
    },
    {
      "text": "- C.1.6 2009: Immutability for all",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.1.6 2009: Immutability for all (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 171
    },
    {
      "text": "- C.2.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.2.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 172
    },
    {
      "text": "- C.2.1 Principle #1: Separate code from data",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.2.1 Principle #1: Separate code from data (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 173
    },
    {
      "text": "- C.2.2 Principle #2: Represent data with generic data structures",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.2.2 Principle #2: Represent data with generic data structures (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 174
    },
    {
      "text": "- C.2.3 Principle #3: Data is immutable",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.2.3 Principle #3: Data is immutable (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 175
    },
    {
      "text": "- C.2.4 Principle #4: Separate data schema from data representation",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.2.4 Principle #4: Separate data schema from data representation (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 176
    },
    {
      "text": "- C.3.0 Introduction (사용자 추가)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.3.0 Introduction (사용자 추가) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 177
    },
    {
      "text": "- C.3.1 Data-oriented design",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.3.1 Data-oriented design (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 178
    },
    {
      "text": "- C.3.2 Data-driven programming",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.3.2 Data-driven programming (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 179
    },
    {
      "text": "- C.3.3 Data-oriented programming (DOP)",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- C.3.3 Data-oriented programming (DOP) (node3) **[LEAF]**",
      "is_part_intro": false,
      "id": 180
    },
    {
      "text": "- Summary",
      "node_level": 2,
      "part": "Part3—Maintainability",
      "chapter": "15 Debugging",
      "raw_line": "- Summary (node2) **[LEAF]**",
      "is_part_intro": false,
      "id": 181
    }
  ],
  "part_intro_nodes": [
    {
      "text": "- Part1 Introduction content",
      "node_level": 3,
      "part": "Part1—Flexibility",
      "chapter": "Part1 Introduction (사용자 추가)",
      "raw_line": "- Part1 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 1,
      "accurate_page_range": "30-31",
      "extracted_content": "\n=== Page 30 ===\n2 PART 1 Flexibility\nThe requirements for the Klafim prototype\n Two kinds of library users are members and librarians.\n Users log in to the system via email and password.\n Members can borrow books.\n Members and librarians can search books by title or by author.\n Librarians can block and unblock members (e.g., when they are late in return-\ning a book).\n Librarians can list the books currently lent to a member.\n There could be several copies of a book.\n The book belongs to a physical library.\nTheo Well, that’s pretty clear.\nNancy How much time would it take for your company to deliver the prototype?\nTheo I think we should be able to deliver within a month. Let’s say Wednesday the\n30th.\nNancy That’s too long. We need it in two weeks!\nTheo That’s tough! Can you cut a feature or two?\nNancy Unfortunately, we cannot cut any feature, but if you like, you can make the\nsearch very basic.\n(Theo really doesn’t want to lose this contract, so he’s willing to work hard and sleep later.)\nTheo I think it should be doable by Wednesday the 16th.\nNancy Perfect!\n\n=== Page 31 ===\nComplexity of object-\noriented programming\nA capricious entrepreneur\nThis chapter covers\n The tendency of OOP to increase system\ncomplexity\n What makes OOP systems hard to understand\n The cost of mixing code and data together into\nobjects\nIn this chapter, we’ll explore why object-oriented programming (OOP) systems tend to\nbe complex. This complexity is not related to the syntax or the semantics of a specific\nOOP language. It is something that is inherent to OOP’s fundamental insight—\nprograms should be composed from objects, which consist of some state, together\nwith methods for accessing and manipulating that state.\nOver the years, OOP ecosystems have alleviated this complexity by adding new\nfeatures to the language (e.g., anonymous classes and anonymous functions) and\nby developing frameworks that hide some of this complexity, providing a simpler\ninterface for developers (e.g., Spring and Jackson in Java). Internally, the frame-\nworks rely on the advanced features of the language such as reflection and custom\nannotations.\n3"
    },
    {
      "text": "- Part2 Introduction content",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "6 Unit tests",
      "raw_line": "- Part2 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 55,
      "accurate_page_range": "171-175",
      "extracted_content": "\n=== Page 171 ===\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n\n=== Page 172 ===\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n\n=== Page 173 ===\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n\n=== Page 174 ===\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\n=== Page 175 ===\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer"
    },
    {
      "text": "- Part2 Introduction content",
      "node_level": 3,
      "part": "Part2—Scalability",
      "chapter": "Part2 Introduction (사용자 추가)",
      "raw_line": "- Part2 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 56,
      "accurate_page_range": "171-175",
      "extracted_content": "\n=== Page 171 ===\n7.2 JSON Schema in a nutshell 143\nJoe This architectural diagram defines what we call the boundaries of the system in\nterms of data exchange. Can you tell me what the three boundaries of the sys-\ntem are?\n NOTE The boundaries of a system are defined as the areas where the system exchanges\ndata.\nTheo Let me see. The first one is the client boundary, then we have the database\nboundary, and finally, the web service boundary.\nJoe Exactly! It’s important to identify the boundaries of a system because, in\nDOP, we differentiate between two kinds of data validation: validation that\noccurs at the boundaries of the system and validation that occurs inside the\nsystem. Today, we’re going to focus on validation that occurs at the boundar-\nies of the system.\nTheo Does that mean data validation at the boundaries of the system is more\nimportant?\nJoe Absolutely! Once you’ve ensured that data going into and out of the system is\nvalid, the odds for an unexpected piece of data inside the system are pretty low.\nTIP When data at system boundaries is validated, it’s not critical to validate data\nagain inside the system.\nTheo Why do we need data validation inside the system then?\nJoe It has to do with making it easier to code your system as your code base grows.\nTheo And, what’s the main purpose of data validation at the boundaries?\nJoe To prevent invalid data from going in and out of the system, and to display\ninformative errors when we encounter invalid data. Let me draw a table on the\nwhiteboard so you can see the distinction (table 7.1).\nTable 7.1 Two kinds of data validation\nKind of data validation Purpose Environment\nBoundaries Guardian Production\nInside Ease of development Dev\nTheo When will you teach me about data validation inside the system?\nJoe Later, when the code base is bigger.\n7.2 JSON Schema in a nutshell\nTheo For now, the Library Management System is an application that runs in mem-\nory, with no database and no HTTP clients connected to it. But Nancy will\nprobably want me to make the system into a real web server with clients, data-\nbase, and external services.\nJoe OK. Let’s imagine how a client request for searching books would look.\n\n=== Page 172 ===\n144 CHAPTER 7 Basic data validation\nTheo Basically, a search request is made of a string and the fields you’d like to\nretrieve for the books whose title contains the string. So the request has two\nfields: title, which is a string, and fields, which is an array of strings.\nTheo quickly writes on the whiteboard. When he finishes, he steps aside to let Joe view his\ncode for a search request.\nListing7.1 An example of a search request\n{\n\"title\": \"habit\",\n\"fields\": [\"title\", \"weight\", \"number_of_pages\"]\n}\nJoe I see. Let me show you how to express the schema of a search request sepa-\nrately from the representation of the search request data.\nTheo What do you mean exactly by “separately?”\nJoe Data representation stands on its own, and the data schema stands on its own.\nYou are free to validate that a piece of data conforms with a data schema as you\nwill and when you will.\nTIP In DOP, the data schema is separate from the data representation.\nTheo It’s a bit abstract for me.\nJoe I know. It will become much clearer in a moment. For now, I am going to show\nyou how to build the data schema for the search request in a schema language\ncalled JSON Schema.\nTheo I love JSON!\n NOTE Information on the JSON Schema language can be found at https://json\n-schema.org. The schemas in this book use JSON Schema version 2020-12.\nJoe First, we have to express the data type of the request. What’s the data type in\nthe case of a book search request?\nTheo It’s a map.\nJoe In JSON Schema, the data type for maps is called object. Look at this basic\nskeleton of a map. It’s a map with two fields: type and properties.\nJoe goes to the whiteboard. He quickly writes the code for the map with its two fields.\nListing7.2 Basic schema skeleton of a map\n{\n\"type\": \"object\",\n\"properties\": {...}\n}\n\n=== Page 173 ===\n7.2 JSON Schema in a nutshell 145\nJoe The value of type is \"object\", and the value of properties is a map with the\nschema for the map fields.\nTheo I assume that, inside properties, we are going to express the schema of the map\nfields as JSON Schema.\nJoe Correct.\nTheo I am starting to feel the dizziness of recursion.\nJoe In JSON Schema, a schema is usually a JSON object with a field called type,\nwhich specifies the data type. For example, the type for the title field is\nstring and...\nTheo ...the type for the fields field is array.\nJoe Yes!\nNow it’s Theo’s turn to go to the whiteboard. He fills the holes in the search request\nschema with the information about the fields.\nListing7.3 Schema skeleton for search request\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\"type\": \"array\"}\n}\n}\nOn Theo’s way back from the whiteboard to his desk, Joe makes a sign with his right hand\nthat says, “Stay near the whiteboard, please.” Theo turns and goes back to the whiteboard.\nJoe We can be a little more precise about the fields property by providing infor-\nmation about the type of the elements in the array. In JSON Schema, an array\nschema has a property called items, whose value is the schema for the array\nelements.\nWithout any hesitation, Theo adds this information on the whiteboard. Stepping aside, he\nshows Joe the result.\nListing7.4 Schema for search request with information about array elements\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\"type\": \"string\"}\n}\n}\n}\n\n=== Page 174 ===\n146 CHAPTER 7 Basic data validation\nBefore going back to his desk, Theo asks Joe:\nTheo Are we done now?\nJoe Not yet. We can be more precise about the fields field in the search request.\nI assume that the fields in the request should be part of a closed list of fields.\nTherefore, instead of allowing any string, we could have a list of allowed values.\nTheo Like an enumeration value?\nJoe Exactly! In fact, JSON Schema supports enumeration values with the enum key-\nword. Instead of {\"type\": \"string\"}, you need to have {\"enum\": […]} and\nreplace the dots with the supported fields.\nOnce again, Theo turns to the whiteboard. He replaces the dots with the information Joe\nrequests.\nListing7.5 Schema for the search request with enumeration values\n{\n\"type\": \"object\",\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n}\n}\nTheo Are we done, now?\nJoe Almost. We need to decide whether the fields of our search request are optional\nor required. In our case, both title and fields are required.\nTheo How do we express this information in JSON Schema?\nJoe There is a field called required whose value is an array made of the names of\nthe required fields in the map.\nAfter adding the required field, Theo looks at Joe. This time he makes a move with his\nright hand that says, “Now you can go back to your desk.”\nListing7.6 Schema of a search request\nvar searchBooksRequestSchema = {\n\"type\": \"object\",\n\n=== Page 175 ===\n7.2 JSON Schema in a nutshell 147\n\"properties\": {\n\"title\": {\"type\": \"string\"},\n\"fields\": {\n\"type\": \"array\",\n\"items\": {\n\"enum\": [\n\"publishers\",\n\"number_of_pages\",\n\"weight\",\n\"physical_format\",\n\"subjects\",\n\"publish_date\",\n\"physical_dimensions\"\n]\n}\n}\n},\n\"required\": [\"title\", \"fields\"]\n};\nJoe Now I’ll show you how to validate a piece of data according to a schema.\nTheo What do you mean, validate?\nJoe Validating data according to a schema means checking whether data conforms\nto the schema. In our case, it means checking whether a piece of data is a valid\nsearch books request.\nTIP Data validation in DOP means checking whether a piece of data conforms to a\nschema.\nTheo I see.\nJoe There are a couple of libraries that provide JSON Schema validation. They\nhave a validate function that receives a schema and a piece of data and\nreturns true when the data is valid and false when the data is not valid. I just\nhappen to have a file in my laptop that provides a table with a list of schema\nvalidation libraries (table 7.2). We can print it out if you like.\nTheo turns on the printer as Joe scans through his laptop for the table. When he has it up,\nhe checks with Theo and presses Print.\nTable 7.2 Libraries for JSON Schema validation\nLanguage Library URL\nJavaScript Ajv https://github.com/ajv-validator/ajv\nJava Snow https://github.com/ssilverman/snowy-json\nC# JSON.net Schema https://www.newtonsoft.com/jsonschema\nPython jschon https://github.com/marksparkza/jschon\nRuby JSONSchemer https://github.com/davishmcclurg/json_schemer"
    },
    {
      "text": "- Part3 Introduction content",
      "node_level": 3,
      "part": "Part3—Maintainability",
      "chapter": "Part3 Introduction (사용자 추가)",
      "raw_line": "- Part3 Introduction content (node3) **[LEAF]**",
      "is_part_intro": true,
      "id": 97,
      "accurate_page_range": "298-302",
      "extracted_content": "\n=== Page 298 ===\n270 CHAPTER 12 Advanced data validation\n\"myLetters\": {\nmyLetters is a string with\n\"type\": \"string\",\nletters only (lowercase or\n\"pattern\": \"[a-zA-Z]*\"\nuppercase).\n}\n\"myNumberMap\": {\nmyNumberMap is an homogeneous\n\"type\": \"object\",\nstring map where all the values are\n\"additionalProperties\": {\"type\": \"number\"}\nnumbers.\n},\n\"myTuple\": {\nmyTuple is a tuple where the first\n\"type\": \"array\",\nelement is a string and the second\n\"prefixItems\": [\nelement is a number.\n{ \"type\": \"string\" },\n{ \"type\": \"number\" }\n]\n} The mandatory fields in the map\nare myNumber and myString.\n},\nOther fields are optional.\n\"required\": [\"myNumber\", \"myString\"],\n\"additionalProperties\": false\nWe don’t allow fields that\n}\nare not explicitly mentioned\n}\nin the schema.\nListing12.31 An example of valid data\n[\n{\n\"myNumber\": 42,\n\"myString\": \"I-love-you\",\n\"myEnum\": \"myVal\",\n\"myBool\": true,\n\"myTuple\": [\"Hello\", 42]\n},\n{\n\"myNumber\": 54,\n\"myString\": \"Happy\",\n\"myAge\": 42,\n\"myBirthday\": \"1978-11-23\",\n\"myLetters\": \"Hello\",\n\"myNumberMap\": {\n\"banana\": 23,\n\"apple\": 34\n}\n}\n]\nSummary\n We define data schemas using a language like JSON Schema for function argu-\nments and return values.\n Function argument schemas allow developers to figure out the expected shape of\nthe function arguments they want to call.\n When invalid data is passed, data validation third-party libraries give meaning-\nful errors with detailed information about the data parts that are not valid.\n\n=== Page 299 ===\nSummary 271\n Unlike data validation at system boundaries, data validation inside the system is\nsupposed to run only at development time and should be disabled in production.\n We visualize a data schema by generating a data model diagram out of a JSON\nSchema.\n For functions that have data schemas for their arguments and return values, we\ncan automatically generate schema-based unit tests.\n Data validation is executed at run time.\n We can define advanced data validation conditions that go beyond static types,\nlike checking whether a number is within a range or if a string matches a regu-\nlar expression.\n Data validation inside the system should be disabled in production.\n Records are represented as heterogeneous maps, and indexes are represented as\nhomogeneous maps.\n When you define a complex data schema, it is advised to store nested schemas\nin variables to make the schemas easier to read.\n We treat data validation like unit tests.\n\n=== Page 300 ===\nPolymorphism\nPlaying with the animals\nin the countryside\nThis chapter covers\n Mimicking objects with multimethods (single\ndispatch)\n Implementing multimethod on several argument\ntypes (multiple dispatch)\n Implementing multimethods dynamically on\nseveral arguments (dynamic dispatch)\nOOP is well-known for allowing different classes to be called with the same inter-\nface via a mechanism called polymorphism. It may seem that the only way to have\npolymorphism in a program is with objects. In fact, in this chapter, we are going to\nsee that it is possible to have polymorphism without objects, thanks to multimeth-\nods. Moreover, multimethods provide a more advanced polymorphism than OOP\npolymorphism because they support cases where the chosen implementation\ndepends on several argument types (multiple dispatch) and even on the dynamic\nvalue of the arguments (dynamic dispatch).\n272\n\n=== Page 301 ===\n13.1 The essence of polymorphism 273\n13.1 The essence of polymorphism\nFor today’s session, Dave has invited Theo to come and visit him at his parents’ house in\nthe countryside. As Theo’s drive across the Golden Gate Bridge takes him from the freeway\nto increasingly rural country roads, he lets himself be carried away by the beauty of the\nlandscape, the smell of fresh earth, and the sounds of animals in nature. This “nature\nbath” puts him in an excellent mood. What a way to start the week!\nDave receives Theo in jeans and a T-shirt, a marked contrast with the elegant clothes he\nwears at the office. A straw hat completes his country look. Theo says hello to Dave’s par-\nents, now retired. Dave suggests that they go pick a few oranges in the field to squeeze for\njuice. After drinking a much more flavorful orange juice than they are used to in San Fran-\ncisco, Theo and Dave get to work.\nDave When I was waiting for you this morning, I thought of another thing I miss\nfrom OOP.\nTheo What’s that?\nDave Polymorphism.\nTheo What kind of polymorphism?\nDave You know, you define an interface, and different classes implement the same\ninterface in different ways.\nTheo I see. And why do you think polymorphism is valuable?\nDave Because it allows us to decouple an interface from its implementations.\nTheo Would you mind illustrating that with a concrete example?\nDave Sure. Because we’re in the country, I’ll use the classic OOP polymorphism\nexample with animals.\nTheo Good idea!\nDave Let’s say that each animal has its own greeting by making a sound and saying\nits name.\nTheo Oh cool, like in anthropomorphic comics books.\nDave Anthro what?\nTheo You know, comics books where animals can walk, speak, and so forth—like\nMickey Mouse.\nDave Of course, but I don’t know that term. Where does it come from?\nTheo Anthropomorphism comes from the Greek ánthro–pos, which means human, and\nmorphe–, which means form.\nDave I see. So an anthropomorphic book is a book where animals have human traits.\nThe word sounds related to polymorphism.\nTheo Absolutely. Polymorphism comes from the Greek polús, which means many, and\nmorphe–, which, again, means form.\nDave That makes sense. Polymorphism is the ability of different objects to imple-\nment the same method in different ways. That brings me back to my animal\nexample. In OOP, I’d define an IAnimal interface with a greet method, and\neach animal class would implement greet in its own way. Here, I happen to\nhave an example.\n\n=== Page 302 ===\n274 CHAPTER 13 Polymorphism\nListing13.1 OOP polymorphism illustrated with animals\ninterface IAnimal {\npublic void greet();\n}\nclass Dog implements IAnimal {\nprivate String name;\npublic void greet() {\nSystem.out.println(\"Woof woof! My name is \" + animal.name);\n}\n}\nclass Cat implements IAnimal {\nprivate String name;\npublic void greet() {\nSystem.out.println(\"Meow! I am \" + animal.name);\n}\n}\nclass Cow implements IAnimal {\nprivate String name;\npublic void greet() {\nSystem.out.println(\"Moo! Call me \" + animal.name);\n}\n}\nTheo Let me challenge you a bit. What is the fundamental difference between OOP\npolymorphism and a switch statement?\nDave What do you mean?\nTheo I could, for instance, represent an animal with a map having two fields, name\nand type, and call a different piece of code, depending on the value of type.\nTheo pulls his laptop from its bag and fires it up. While the laptop is booting up, he enjoys\nanother taste of that wonderful orange juice. When the laptop is ready, he quickly types in\nthe example switch case. Meanwhile, Dave has finished his glass of orange juice.\nListing13.2 A switch case where behavior depends on type\nfunction greet(animal) {\nswitch (animal.type) {\ncase \"dog\":\nconsole.log(\"Woof Woof! My name is: \" + animal.name);\nbreak;\ncase \"cat\":\nconsole.log(\"Meow! I am: \" + animal.name);\nbreak;\ncase \"cow\":\nconsole.log(\"Moo! Call me \" + animal.name);\nbreak;\n};\n}"
    }
  ]
}