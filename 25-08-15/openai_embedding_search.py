"""
ìƒì„± ì‹œê°„: 2025-08-15 17:15:00
í•µì‹¬ ë‚´ìš©: OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬¸ì„œ ì¬ì„ë² ë”© ë° ê²€ìƒ‰ ì‹œìŠ¤í…œ
ìƒì„¸ ë‚´ìš©:
    - OpenAIEmbeddingProcessor í´ë˜ìŠ¤(ë¼ì¸ 27-82): ë¬¸ì„œ ì„ë² ë”© ë° ê²€ìƒ‰ ì²˜ë¦¬
    - process_document_embeddings ë©”ì„œë“œ(ë¼ì¸ 34-55): ê¸°ì¡´ ë¬¸ì„œ OpenAIë¡œ ì¬ì„ë² ë”©
    - search_with_openai ë©”ì„œë“œ(ë¼ì¸ 57-82): OpenAI ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
    - main í•¨ìˆ˜(ë¼ì¸ 84-125): ë¬¸ì„œ ì¬ì„ë² ë”© í›„ ê²€ìƒ‰ ë° ê²°ê³¼ ì €ì¥
    - ì„ê³„ê°’: 0.7ë¡œ ì„¤ì •
    - ê²°ê³¼ ì €ì¥: openai_search_results.txt íŒŒì¼ì— ì €ì¥
ìƒíƒœ: 
ì£¼ì†Œ: openai_embedding_search
ì°¸ì¡°: vector_search_system, neon_db_v2
"""

import os
import sys
import json
from typing import List, Dict, Any
import logging
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
from neon_db_v2 import NeonVectorDBV2

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(dotenv_path='/home/nadle/projects/Concept_Sherpa_V2/.env')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAIEmbeddingProcessor:
    """
    OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬¸ì„œ ì²˜ë¦¬ ë° ê²€ìƒ‰ í´ë˜ìŠ¤
    """
    
    def __init__(self, similarity_threshold: float = 0.7):
        self.db = NeonVectorDBV2()
        self.similarity_threshold = similarity_threshold
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        if not os.getenv('OPENAI_API_KEY'):
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    def process_document_embeddings(self, doc_id: str):
        """
        ê¸°ì¡´ ë¬¸ì„œë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ì¬ì²˜ë¦¬
        
        Args:
            doc_id: ì¬ì²˜ë¦¬í•  ë¬¸ì„œ ID
        """
        logger.info(f"ë¬¸ì„œ {doc_id}ë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ì¬ì²˜ë¦¬ ì¤‘...")
        
        # ë¬¸ì„œ ì¡°íšŒ
        document = self.db.get_document_by_id(doc_id)
        if not document:
            logger.error(f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {doc_id}")
            return
        
        # ê° ì„¹ì…˜ë³„ë¡œ ì„ë² ë”© ìƒì„±
        sections = [
            ("core_content_embeddings", "core", document.get('extracted_info', '').split('## í•µì‹¬ ë‚´ìš©\n')[-1].split('## ìƒì„¸ í•µì‹¬ ë‚´ìš©')[0].strip()),
            ("detailed_core_embeddings", "detailed", document.get('extracted_info', '').split('## ìƒì„¸ í•µì‹¬ ë‚´ìš©\n')[-1].split('## ì£¼ìš” í™”ì œ')[0].strip()),
            ("main_topic_embeddings", "main", document.get('extracted_info', '').split('## ì£¼ìš” í™”ì œ\n')[-1].split('## ë¶€ì°¨ í™”ì œ')[0].strip()),
            ("sub_topic_embeddings", "sub", document.get('extracted_info', '').split('## ë¶€ì°¨ í™”ì œ\n')[-1].strip())
        ]
        
        for table_name, section_type, content in sections:
            if content.strip():
                # OpenAI ì„ë² ë”© ìƒì„±
                response = self.client.embeddings.create(
                    model="text-embedding-3-small",
                    input=content
                )
                embedding = response.data[0].embedding
                
                # ì„ë² ë”© ì €ì¥
                embedding_id = f"{doc_id}_{section_type}_openai_001"
                metadata = {
                    "section_type": section_type,
                    "embedding_model": "text-embedding-3-small",
                    "language": "mixed",
                    "file_name": document['title'],
                    "content_length": len(content)
                }
                
                self.db.insert_embedding(
                    table_name=table_name,
                    embedding_id=embedding_id,
                    embedding=embedding,
                    document_id=doc_id,
                    metadata=metadata
                )
                
                logger.info(f"OpenAI ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {table_name} - {embedding_id}")
    
    def search_with_openai(self, question: str, max_results: int = 3) -> List[Dict[str, Any]]:
        """
        OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•œ ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            max_results: ìµœëŒ€ ë°˜í™˜ ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"OpenAI ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ ì‹œì‘: {question}")
        
        # ì§ˆë¬¸ì„ OpenAI ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=question
        )
        question_embedding = response.data[0].embedding
        
        found_documents = []
        
        # ê³„ì¸µì  ê²€ìƒ‰ ìˆ˜í–‰
        # 1. í•µì‹¬ ë‚´ìš© ê²€ìƒ‰
        logger.info("í•µì‹¬ ë‚´ìš© í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ ì¤‘...")
        core_results = self.db.search_embeddings(
            'core_content_embeddings', 
            question_embedding, 
            max_results
        )
        
        if core_results and any(result['distance'] < self.similarity_threshold for result in core_results):
            logger.info(f"í•µì‹¬ ë‚´ìš©ì—ì„œ {len(core_results)}ê°œ ê²°ê³¼ ë°œê²¬ (ìœ ì‚¬ë„ >= {1-self.similarity_threshold:.1f})")
            found_documents.extend(core_results)
        else:
            logger.info("í•µì‹¬ ë‚´ìš©ì—ì„œ ìœ ì‚¬í•œ ê²°ê³¼ ì—†ìŒ, ìƒì„¸ í•µì‹¬ ë‚´ìš© ê²€ìƒ‰ ì¤‘...")
            detailed_results = self.db.search_embeddings(
                'detailed_core_embeddings', 
                question_embedding, 
                max_results
            )
            if detailed_results:
                logger.info(f"ìƒì„¸ í•µì‹¬ ë‚´ìš©ì—ì„œ {len(detailed_results)}ê°œ ê²°ê³¼ ë°œê²¬")
                found_documents.extend(detailed_results)
        
        # 2. í™”ì œ ê¸°ë°˜ ê²€ìƒ‰
        logger.info("ì£¼ìš” í™”ì œ í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ ì¤‘...")
        main_topic_results = self.db.search_embeddings(
            'main_topic_embeddings', 
            question_embedding, 
            max_results
        )
        
        if main_topic_results and any(result['distance'] < self.similarity_threshold for result in main_topic_results):
            logger.info(f"ì£¼ìš” í™”ì œì—ì„œ {len(main_topic_results)}ê°œ ê²°ê³¼ ë°œê²¬")
            found_documents.extend(main_topic_results)
        else:
            logger.info("ì£¼ìš” í™”ì œì—ì„œ ìœ ì‚¬í•œ ê²°ê³¼ ì—†ìŒ, ë¶€ì°¨ í™”ì œ ê²€ìƒ‰ ì¤‘...")
            sub_topic_results = self.db.search_embeddings(
                'sub_topic_embeddings', 
                question_embedding, 
                max_results
            )
            if sub_topic_results:
                logger.info(f"ë¶€ì°¨ í™”ì œì—ì„œ {len(sub_topic_results)}ê°œ ê²°ê³¼ ë°œê²¬")
                found_documents.extend(sub_topic_results)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_docs = {}
        for doc in found_documents:
            doc_id = doc['document_id']
            if doc_id not in unique_docs or doc['distance'] < unique_docs[doc_id]['distance']:
                unique_docs[doc_id] = doc
        
        final_results = sorted(unique_docs.values(), key=lambda x: x['distance'])[:max_results]
        logger.info(f"ìµœì¢… {len(final_results)}ê°œ ë¬¸ì„œ ë°˜í™˜")
        return final_results

def save_results_to_file(results: List[Dict[str, Any]], question: str, db: NeonVectorDBV2, filename: str = "openai_search_results.txt"):
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
    """
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write(f"OpenAI ì„ë² ë”© ê²€ìƒ‰ ê²°ê³¼\n")
            f.write(f"ê²€ìƒ‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì§ˆë¬¸: {question}\n")
            f.write(f"ì„ê³„ê°’: 0.7\n")
            f.write(f"ì„ë² ë”© ëª¨ë¸: text-embedding-3-small\n")
            f.write("=" * 80 + "\n\n")
            
            if not results:
                f.write("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
                return
            
            for i, result in enumerate(results, 1):
                f.write(f"### ê²°ê³¼ {i}\n")
                f.write(f"ë¬¸ì„œ ID: {result['document_id']}\n")
                f.write(f"ìœ ì‚¬ë„: {1 - result['distance']:.4f}\n")
                f.write(f"ê±°ë¦¬: {result['distance']:.4f}\n")
                f.write(f"ë©”íƒ€ë°ì´í„°: {result.get('metadata', {})}\n")
                f.write("-" * 50 + "\n")
                
                # ë¬¸ì„œ ìƒì„¸ ë‚´ìš©
                document = db.get_document_by_id(result['document_id'])
                if document:
                    f.write(f"ì œëª©: {document.get('title', 'N/A')}\n")
                    f.write(f"ì¶”ì¶œ ì •ë³´ (ì²˜ìŒ 500ì):\n{document.get('extracted_info', 'N/A')[:500]}...\n")
                    f.write(f"ë‚´ìš© (ì²˜ìŒ 300ì):\n{document.get('content', 'N/A')[:300]}...\n")
                
                f.write("\n" + "=" * 80 + "\n\n")
        
        logger.info(f"ê²€ìƒ‰ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    try:
        # OpenAI ì„ë² ë”© í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        processor = OpenAIEmbeddingProcessor(similarity_threshold=0.7)
        
        # ê¸°ì¡´ ë¬¸ì„œë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ì¬ì²˜ë¦¬
        doc_id = "00_lev0_gpt_5_agentic_coding_with_claude_code_info"
        logger.info(f"ë¬¸ì„œ ì¬ì„ë² ë”© ì‹œì‘: {doc_id}")
        processor.process_document_embeddings(doc_id)
        
        # ë™ì¼í•œ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
        question = "ì—ì´ì „íŠ¸ ì‘ì—…ì—ì„œ í•µì‹¬ì ìœ¼ë¡œ ì¤‘ìš”í•œ ê²ƒì´ ë­ì•¼?"
        logger.info(f"ê²€ìƒ‰ ì‹œì‘: {question}")
        results = processor.search_with_openai(question, max_results=3)
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
        filename = f"/home/nadle/projects/Concept_Sherpa_V2/25-08-15/openai_search_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        save_results_to_file(results, question, processor.db, filename)
        
        # ì½˜ì†”ì—ë„ ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ” OpenAI ì„ë² ë”© ê²€ìƒ‰ ì™„ë£Œ!")
        print(f"ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(results)}")
        print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {filename}")
        
        if results:
            print(f"\nğŸ“ˆ ìµœê³  ìœ ì‚¬ë„: {1 - results[0]['distance']:.4f}")
            print(f"ğŸ“‰ ìµœì € ìœ ì‚¬ë„: {1 - results[-1]['distance']:.4f}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
        processor.db.close()
        
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()