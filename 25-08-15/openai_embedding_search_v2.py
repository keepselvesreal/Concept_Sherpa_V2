"""
ìƒì„± ì‹œê°„: 2025-08-15 17:25:00
í•µì‹¬ ë‚´ìš©: OpenAI 1536ì°¨ì› ì„ë² ë”©ì„ ì‚¬ìš©í•œ ë¬¸ì„œ ì¬ì„ë² ë”© ë° ê²€ìƒ‰ ì‹œìŠ¤í…œ
ìƒì„¸ ë‚´ìš©:
    - OpenAIEmbeddingProcessor í´ë˜ìŠ¤(ë¼ì¸ 29-131): OpenAI ì„ë² ë”© ì²˜ë¦¬
    - process_document_embeddings ë©”ì„œë“œ(ë¼ì¸ 36-80): ë¬¸ì„œë¥¼ OpenAIë¡œ ì¬ì„ë² ë”©
    - search_with_openai ë©”ì„œë“œ(ë¼ì¸ 82-131): ê³„ì¸µì  ë²¡í„° ê²€ìƒ‰
    - save_results_to_file í•¨ìˆ˜(ë¼ì¸ 133-180): ê²°ê³¼ë¥¼ íŒŒì¼ì— ìƒì„¸ ì €ì¥
    - main í•¨ìˆ˜(ë¼ì¸ 182-220): ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    - ì„ê³„ê°’: 0.7 ì„¤ì •, 1536ì°¨ì› OpenAI ì„ë² ë”© ì‚¬ìš©
ìƒíƒœ: 
ì£¼ì†Œ: openai_embedding_search_v2
ì°¸ì¡°: openai_neon_db
"""

import os
import sys
import json
from typing import List, Dict, Any
import logging
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
from openai_neon_db import OpenAINeonVectorDB
from neon_db_v2 import NeonVectorDBV2, DocumentParser

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(dotenv_path='/home/nadle/projects/Concept_Sherpa_V2/.env')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAIEmbeddingProcessor:
    """
    OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¬¸ì„œ ì²˜ë¦¬ ë° ê²€ìƒ‰ í´ë˜ìŠ¤ (1536ì°¨ì›)
    """
    
    def __init__(self, similarity_threshold: float = 0.7):
        self.openai_db = OpenAINeonVectorDB()  # OpenAI ì „ìš© DB
        self.similarity_threshold = similarity_threshold
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        if not os.getenv('OPENAI_API_KEY'):
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    def process_document_embeddings(self, file_path: str, doc_id: str):
        """
        ë¬¸ì„œ íŒŒì¼ì„ íŒŒì‹±í•˜ê³  OpenAI ì„ë² ë”©ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            file_path: ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ
            doc_id: ë¬¸ì„œ ID
        """
        logger.info(f"ë¬¸ì„œ {doc_id}ë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ì²˜ë¦¬ ì¤‘...")
        
        # ë¬¸ì„œ íŒŒì‹±
        parsed_doc = DocumentParser.parse_document(file_path)
        
        # ì „ì²´ ì¶”ì¶œ ì„¹ì…˜ êµ¬ì„±
        extracted_sections = [
            f"## í•µì‹¬ ë‚´ìš©\n{parsed_doc['core_content']}",
            f"## ìƒì„¸ í•µì‹¬ ë‚´ìš©\n{parsed_doc['detailed_core']}",
            f"## ì£¼ìš” í™”ì œ\n{parsed_doc['main_topics']}",
            f"## ë¶€ì°¨ í™”ì œ\n{parsed_doc['sub_topics']}"
        ]
        extracted_info = "\n\n".join(extracted_sections)
        
        # documents í…Œì´ë¸”ì— ì‚½ì…
        self.openai_db.insert_document(
            doc_id=doc_id,
            title=parsed_doc['title'],
            extracted_info=extracted_info,
            content=parsed_doc['content'],
            child_doc_ids=parsed_doc['child_doc_ids']
        )
        
        # ê° ì„¹ì…˜ë³„ë¡œ OpenAI ì„ë² ë”© ìƒì„±
        sections = [
            ("openai_core_content_embeddings", "core", parsed_doc['core_content']),
            ("openai_detailed_core_embeddings", "detailed", parsed_doc['detailed_core']),
            ("openai_main_topic_embeddings", "main", parsed_doc['main_topics']),
            ("openai_sub_topic_embeddings", "sub", parsed_doc['sub_topics'])
        ]
        
        for table_name, section_type, content in sections:
            if content.strip():
                # OpenAI ì„ë² ë”© ìƒì„±
                response = self.client.embeddings.create(
                    model="text-embedding-3-small",
                    input=content
                )
                embedding = response.data[0].embedding
                
                # ì„ë² ë”© ì €ì¥
                embedding_id = f"{doc_id}_{section_type}_openai_001"
                metadata = {
                    "section_type": section_type,
                    "embedding_model": "text-embedding-3-small",
                    "dimensions": 1536,
                    "language": "mixed",
                    "file_name": parsed_doc['title'],
                    "content_length": len(content)
                }
                
                self.openai_db.insert_embedding(
                    table_name=table_name,
                    embedding_id=embedding_id,
                    embedding=embedding,
                    document_id=doc_id,
                    metadata=metadata
                )
                
                logger.info(f"OpenAI ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {table_name} - {embedding_id}")
    
    def search_with_openai(self, question: str, max_results: int = 3) -> List[Dict[str, Any]]:
        """
        OpenAI ì„ë² ë”©ì„ ì‚¬ìš©í•œ ê³„ì¸µì  ê²€ìƒ‰ ìˆ˜í–‰
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            max_results: ìµœëŒ€ ë°˜í™˜ ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"OpenAI ì„ë² ë”©ìœ¼ë¡œ ê²€ìƒ‰ ì‹œì‘: {question}")
        
        # ì§ˆë¬¸ì„ OpenAI ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
        response = self.client.embeddings.create(
            model="text-embedding-3-small",
            input=question
        )
        question_embedding = response.data[0].embedding
        
        found_documents = []
        search_log = []
        
        # 1. ë‚´ìš© ê¸°ë°˜ ê³„ì¸µì  ê²€ìƒ‰ (í•µì‹¬ â†’ ìƒì„¸)
        logger.info("í•µì‹¬ ë‚´ìš© í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ ì¤‘...")
        core_results = self.openai_db.search_embeddings(
            'openai_core_content_embeddings', 
            question_embedding, 
            max_results
        )
        
        if core_results and any(result['distance'] < self.similarity_threshold for result in core_results):
            logger.info(f"í•µì‹¬ ë‚´ìš©ì—ì„œ {len(core_results)}ê°œ ê²°ê³¼ ë°œê²¬ (ì„ê³„ê°’ {self.similarity_threshold} í†µê³¼)")
            found_documents.extend(core_results)
            search_log.append(f"âœ… í•µì‹¬ ë‚´ìš© í…Œì´ë¸”: {len(core_results)}ê°œ ê²°ê³¼ (ìµœê³  ìœ ì‚¬ë„: {1-min(r['distance'] for r in core_results):.4f})")
        else:
            logger.info("í•µì‹¬ ë‚´ìš©ì—ì„œ ìœ ì‚¬í•œ ê²°ê³¼ ì—†ìŒ, ìƒì„¸ í•µì‹¬ ë‚´ìš© ê²€ìƒ‰ ì¤‘...")
            search_log.append(f"âš ï¸ í•µì‹¬ ë‚´ìš© í…Œì´ë¸”: ì„ê³„ê°’ ë¯¸ë‹¬, ìƒì„¸ ê²€ìƒ‰ìœ¼ë¡œ ì´ë™")
            
            detailed_results = self.openai_db.search_embeddings(
                'openai_detailed_core_embeddings', 
                question_embedding, 
                max_results
            )
            if detailed_results:
                logger.info(f"ìƒì„¸ í•µì‹¬ ë‚´ìš©ì—ì„œ {len(detailed_results)}ê°œ ê²°ê³¼ ë°œê²¬")
                found_documents.extend(detailed_results)
                search_log.append(f"âœ… ìƒì„¸ í•µì‹¬ ë‚´ìš© í…Œì´ë¸”: {len(detailed_results)}ê°œ ê²°ê³¼ (ìµœê³  ìœ ì‚¬ë„: {1-min(r['distance'] for r in detailed_results):.4f})")
            else:
                search_log.append(f"âŒ ìƒì„¸ í•µì‹¬ ë‚´ìš© í…Œì´ë¸”: ê²°ê³¼ ì—†ìŒ")
        
        # 2. í™”ì œ ê¸°ë°˜ ê³„ì¸µì  ê²€ìƒ‰ (ì£¼ìš” â†’ ë¶€ì°¨) - ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰
        logger.info("ì£¼ìš” í™”ì œ í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ ì¤‘...")
        main_topic_results = self.openai_db.search_embeddings(
            'openai_main_topic_embeddings', 
            question_embedding, 
            max_results
        )
        
        if main_topic_results and any(result['distance'] < self.similarity_threshold for result in main_topic_results):
            logger.info(f"ì£¼ìš” í™”ì œì—ì„œ {len(main_topic_results)}ê°œ ê²°ê³¼ ë°œê²¬")
            found_documents.extend(main_topic_results)
            search_log.append(f"âœ… ì£¼ìš” í™”ì œ í…Œì´ë¸”: {len(main_topic_results)}ê°œ ê²°ê³¼ (ìµœê³  ìœ ì‚¬ë„: {1-min(r['distance'] for r in main_topic_results):.4f})")
        else:
            logger.info("ì£¼ìš” í™”ì œì—ì„œ ìœ ì‚¬í•œ ê²°ê³¼ ì—†ìŒ, ë¶€ì°¨ í™”ì œ ê²€ìƒ‰ ì¤‘...")
            search_log.append(f"âš ï¸ ì£¼ìš” í™”ì œ í…Œì´ë¸”: ì„ê³„ê°’ ë¯¸ë‹¬, ë¶€ì°¨ ê²€ìƒ‰ìœ¼ë¡œ ì´ë™")
            
            sub_topic_results = self.openai_db.search_embeddings(
                'openai_sub_topic_embeddings', 
                question_embedding, 
                max_results
            )
            if sub_topic_results:
                logger.info(f"ë¶€ì°¨ í™”ì œì—ì„œ {len(sub_topic_results)}ê°œ ê²°ê³¼ ë°œê²¬")
                found_documents.extend(sub_topic_results)
                search_log.append(f"âœ… ë¶€ì°¨ í™”ì œ í…Œì´ë¸”: {len(sub_topic_results)}ê°œ ê²°ê³¼ (ìµœê³  ìœ ì‚¬ë„: {1-min(r['distance'] for r in sub_topic_results):.4f})")
            else:
                search_log.append(f"âŒ ë¶€ì°¨ í™”ì œ í…Œì´ë¸”: ê²°ê³¼ ì—†ìŒ")
        
        # 3. ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_docs = {}
        for doc in found_documents:
            doc_id = doc['document_id']
            if doc_id not in unique_docs or doc['distance'] < unique_docs[doc_id]['distance']:
                unique_docs[doc_id] = doc
        
        final_results = sorted(unique_docs.values(), key=lambda x: x['distance'])[:max_results]
        logger.info(f"ìµœì¢… {len(final_results)}ê°œ ë¬¸ì„œ ë°˜í™˜")
        
        # ê²€ìƒ‰ ë¡œê·¸ë„ ê²°ê³¼ì— í¬í•¨
        for result in final_results:
            result['search_log'] = search_log
        
        return final_results

def save_results_to_file(results: List[Dict[str, Any]], question: str, db: OpenAINeonVectorDB, filename: str):
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì¼ì— ìƒì„¸ ì €ì¥
    """
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("=" * 100 + "\n")
            f.write("OpenAI ì„ë² ë”© ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë³´ê³ ì„œ\n")
            f.write("=" * 100 + "\n")
            f.write(f"ê²€ìƒ‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì§ˆë¬¸: {question}\n")
            f.write(f"ì„ê³„ê°’: 0.7\n")
            f.write(f"ì„ë² ë”© ëª¨ë¸: text-embedding-3-small (1536ì°¨ì›)\n")
            f.write(f"ì´ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ\n")
            f.write("=" * 100 + "\n\n")
            
            # ê²€ìƒ‰ ë¡œê·¸ ì¶œë ¥
            if results and 'search_log' in results[0]:
                f.write("ğŸ” ê²€ìƒ‰ ê³¼ì • ë¡œê·¸:\n")
                for log_entry in results[0]['search_log']:
                    f.write(f"  {log_entry}\n")
                f.write("\n" + "-" * 80 + "\n\n")
            
            if not results:
                f.write("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
                return
            
            for i, result in enumerate(results, 1):
                f.write(f"ğŸ“„ ê²€ìƒ‰ ê²°ê³¼ {i}/{len(results)}\n")
                f.write("-" * 50 + "\n")
                f.write(f"ë¬¸ì„œ ID: {result['document_id']}\n")
                f.write(f"ì„ë² ë”© ID: {result['id']}\n")
                f.write(f"ìœ ì‚¬ë„: {1 - result['distance']:.6f}\n")
                f.write(f"ì½”ì‚¬ì¸ ê±°ë¦¬: {result['distance']:.6f}\n")
                f.write(f"ë©”íƒ€ë°ì´í„°: {json.dumps(result.get('metadata', {}), ensure_ascii=False, indent=2)}\n")
                f.write("\n")
                
                # ë¬¸ì„œ ìƒì„¸ ë‚´ìš©
                document = db.get_document_by_id(result['document_id'])
                if document:
                    f.write(f"ğŸ“‹ ë¬¸ì„œ ìƒì„¸ ì •ë³´:\n")
                    f.write(f"  ì œëª©: {document.get('title', 'N/A')}\n")
                    f.write(f"  ì¶”ì¶œ ì •ë³´ ê¸¸ì´: {len(document.get('extracted_info', ''))}\n")
                    f.write(f"  ë‚´ìš© ê¸¸ì´: {len(document.get('content', ''))}\n")
                    f.write("\n")
                    f.write("ğŸ“ ì¶”ì¶œ ì •ë³´ (ì²˜ìŒ 1000ì):\n")
                    f.write(f"{document.get('extracted_info', 'N/A')[:1000]}...\n\n")
                
                f.write("=" * 100 + "\n\n")
        
        logger.info(f"ê²€ìƒ‰ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    try:
        # OpenAI ì„ë² ë”© í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        processor = OpenAIEmbeddingProcessor(similarity_threshold=0.7)
        
        # ë¬¸ì„œ íŒŒì¼ ê²½ë¡œì™€ ID
        file_path = "/home/nadle/projects/Concept_Sherpa_V2/25-08-15/00_lev0_gpt_5_agentic_coding_with_claude_code_info.md"
        doc_id = "00_lev0_gpt_5_agentic_coding_with_claude_code_info"
        
        # ë¬¸ì„œë¥¼ OpenAI ì„ë² ë”©ìœ¼ë¡œ ì²˜ë¦¬
        logger.info(f"ë¬¸ì„œ OpenAI ì„ë² ë”© ì²˜ë¦¬ ì‹œì‘: {doc_id}")
        processor.process_document_embeddings(file_path, doc_id)
        
        # ë™ì¼í•œ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
        question = "ì—ì´ì „íŠ¸ ì‘ì—…ì—ì„œ í•µì‹¬ì ìœ¼ë¡œ ì¤‘ìš”í•œ ê²ƒì´ ë­ì•¼?"
        logger.info(f"OpenAI ì„ë² ë”© ê²€ìƒ‰ ì‹œì‘: {question}")
        results = processor.search_with_openai(question, max_results=3)
        
        # ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"/home/nadle/projects/Concept_Sherpa_V2/25-08-15/openai_search_results_{timestamp}.txt"
        save_results_to_file(results, question, processor.openai_db, filename)
        
        # ì½˜ì†” ì¶œë ¥
        print(f"\nğŸ‰ OpenAI ì„ë² ë”© ê²€ìƒ‰ ì™„ë£Œ!")
        print(f"ğŸ”§ ì„ë² ë”© ëª¨ë¸: text-embedding-3-small (1536ì°¨ì›)")
        print(f"âš¡ ì„ê³„ê°’: 0.7")
        print(f"ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(results)}")
        print(f"ğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {filename}")
        
        if results:
            print(f"\nğŸ“ˆ ìµœê³  ìœ ì‚¬ë„: {1 - results[0]['distance']:.6f}")
            print(f"ğŸ“‰ ìµœì € ìœ ì‚¬ë„: {1 - results[-1]['distance']:.6f}")
            print(f"ğŸ¯ ì‚¬ìš©ëœ ë²¡í„° í…Œì´ë¸”: {results[0]['search_log']}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
        processor.openai_db.close()
        
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()