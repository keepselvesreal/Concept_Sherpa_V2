#!/usr/bin/env python3
"""
ìƒì„± ì‹œê°„: 2025-08-13 20:24:04 KST
í•µì‹¬ ë‚´ìš©: Medium í¬ìŠ¤íŒ…ì˜ ëª¨ë“  êµ¬ì¡°ì™€ ë‚´ìš©ì„ ì™„ì „íˆ ë³´ì¡´í•˜ì—¬ ì¶”ì¶œí•˜ëŠ” ìµœì¢… ë„êµ¬
ìƒì„¸ ë‚´ìš©:
    - extract_complete_medium_post(): ì™„ì „í•œ í¬ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
    - preserve_text_structure(): í…ìŠ¤íŠ¸ êµ¬ì¡° ë³´ì¡´ í•¨ìˆ˜
    - extract_clean_paragraphs(): ê¹”ë”í•œ ë¬¸ë‹¨ ì¶”ì¶œ í•¨ìˆ˜
    - main(): ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
ìƒíƒœ: í™œì„±
ì£¼ì†Œ: medium_post_extractor_final
ì°¸ì¡°: medium_post_extractor_v3
"""

import re
from bs4 import BeautifulSoup
import sys
import os

def extract_clean_paragraphs(soup):
    """ê¹”ë”í•˜ê²Œ ë¬¸ë‹¨ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    # Mediumì˜ ì£¼ìš” ì½˜í…ì¸  ì˜ì—­ ì°¾ê¸°
    content_selectors = [
        'article',
        '[data-testid="storyContent"]', 
        'section[data-field="body"]',
        '.postArticle-content',
        'main'
    ]
    
    main_content = None
    for selector in content_selectors:
        elements = soup.select(selector)
        if elements:
            main_content = elements[0]
            break
    
    if not main_content:
        main_content = soup.find('body') or soup
    
    # ëª¨ë“  í…ìŠ¤íŠ¸ ìš”ì†Œë¥¼ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ
    all_elements = main_content.find_all([
        'h1', 'h2', 'h3', 'h4', 'h5', 'h6',  # ì œëª©ë“¤
        'p',                                   # ë¬¸ë‹¨
        'blockquote',                         # ì¸ìš©
        'ul', 'ol', 'li',                     # ë¦¬ìŠ¤íŠ¸
        'div'                                 # ì¼ë¶€ div
    ])
    
    structured_content = []
    current_section = None
    
    for elem in all_elements:
        if not elem:
            continue
            
        # ë¶€ëª¨ ìš”ì†Œê°€ ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì†Œì¸ì§€ í™•ì¸
        if any(parent in [e.get('processed_elem') for e in structured_content if isinstance(e, dict)] for parent in elem.parents):
            continue
            
        text = elem.get_text().strip()
        
        # ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ í•„í„°ë§
        if len(text) < 5:
            continue
            
        # Medium íŠ¹ìœ ì˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        if any(phrase in text.lower() for phrase in [
            'medium member', 'keep reading for free', 'sign in', 'follow',
            'subscribe', 'clap for this story', 'written by', 'read more',
            'view original', 'see all from'
        ]):
            continue
            
        # ìˆ«ìë‚˜ ë‚ ì§œë§Œ ìˆëŠ” í…ìŠ¤íŠ¸ ì œê±°
        if re.match(r'^[\d\s\-.:,]+$', text):
            continue
            
        tag_name = elem.name.lower()
        
        # ì œëª© ì²˜ë¦¬
        if tag_name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            level = int(tag_name[1])
            structured_content.append({
                'type': 'heading',
                'level': level,
                'text': text,
                'formatted': '#' * level + ' ' + text,
                'processed_elem': elem
            })
            current_section = text
            
        # ë¬¸ë‹¨ ì²˜ë¦¬
        elif tag_name == 'p':
            # ì¸ë¼ì¸ í¬ë§·íŒ… ë³´ì¡´
            formatted_text = preserve_inline_formatting(elem)
            if len(formatted_text) > 10:
                structured_content.append({
                    'type': 'paragraph',
                    'text': text,
                    'formatted': formatted_text,
                    'section': current_section,
                    'processed_elem': elem
                })
                
        # ì¸ìš©ë¬¸ ì²˜ë¦¬
        elif tag_name == 'blockquote':
            structured_content.append({
                'type': 'quote',
                'text': text,
                'formatted': '> ' + text,
                'section': current_section,
                'processed_elem': elem
            })
            
        # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        elif tag_name in ['ul', 'ol']:
            list_items = elem.find_all('li', recursive=False)
            if list_items:
                list_content = []
                for i, li in enumerate(list_items):
                    li_text = li.get_text().strip()
                    if li_text:
                        if tag_name == 'ul':
                            list_content.append(f"â€¢ {li_text}")
                        else:
                            list_content.append(f"{i+1}. {li_text}")
                
                if list_content:
                    structured_content.append({
                        'type': 'list',
                        'list_type': tag_name,
                        'text': text,
                        'formatted': '\n'.join(list_content),
                        'section': current_section,
                        'processed_elem': elem
                    })
                    
        # íŠ¹ë³„í•œ div (highlight, callout ë“±)
        elif tag_name == 'div':
            div_class = ' '.join(elem.get('class', [])).lower()
            if any(cls in div_class for cls in ['highlight', 'pullquote', 'callout', 'graf']):
                if len(text) > 15:
                    structured_content.append({
                        'type': 'special',
                        'text': text,
                        'formatted': f"ğŸ“Œ {text}",
                        'section': current_section,
                        'class': div_class,
                        'processed_elem': elem
                    })
    
    return structured_content

def preserve_inline_formatting(element):
    """ì¸ë¼ì¸ í¬ë§·íŒ…ì„ ë³´ì¡´í•©ë‹ˆë‹¤."""
    result = []
    
    for item in element.children:
        if hasattr(item, 'name') and item.name:
            tag_name = item.name.lower()
            text_content = item.get_text().strip()
            
            if tag_name in ['strong', 'b']:
                result.append(f"**{text_content}**")
            elif tag_name in ['em', 'i']:
                result.append(f"*{text_content}*")
            elif tag_name == 'code':
                result.append(f"`{text_content}`")
            elif tag_name == 'a':
                href = item.get('href', '')
                if href and not href.startswith('#'):
                    result.append(f"[{text_content}]({href})")
                else:
                    result.append(text_content)
            else:
                result.append(text_content)
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸
            text = str(item).strip()
            if text:
                result.append(text)
    
    return ' '.join(result)

def extract_complete_medium_post(html_file_path):
    """ì™„ì „í•œ Medium í¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        with open(html_file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        title_tag = soup.find('title')
        title = title_tag.get_text() if title_tag else "ì œëª© ì—†ìŒ"
        
        # ì‘ì„±ì ì¶”ì¶œ (ì—¬ëŸ¬ ë°©ë²•)
        author = "ì‘ì„±ì ì •ë³´ ì—†ìŒ"
        
        # titleì—ì„œ ë¨¼ì € ì¶”ì¶œ
        if "by " in title:
            author_match = re.search(r'by\s+([^|]+)', title)
            if author_match:
                author = author_match.group(1).strip()
        
        # HTMLì—ì„œ ì‘ì„±ì ì •ë³´ ì°¾ê¸°
        author_selectors = [
            'span[data-testid="authorName"]',
            'a[rel="author"]', 
            '.author-name',
            '[data-testid="storyAuthorName"]',
            'a[href*="/@"]'
        ]
        
        for selector in author_selectors:
            author_elem = soup.select_one(selector)
            if author_elem and author == "ì‘ì„±ì ì •ë³´ ì—†ìŒ":
                potential_author = author_elem.get_text().strip()
                if potential_author and len(potential_author) < 50:
                    author = potential_author
                    break
        
        # ë°œí–‰ ë‚ ì§œ ì¶”ì¶œ
        date = "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
        date_selectors = [
            'time',
            '[data-testid="storyPublishDate"]',
            '.published-date'
        ]
        
        for selector in date_selectors:
            date_elem = soup.select_one(selector)
            if date_elem:
                date_text = date_elem.get_text().strip()
                datetime_attr = date_elem.get('datetime', '')
                date = date_text or datetime_attr
                if date != "ë‚ ì§œ ì •ë³´ ì—†ìŒ":
                    break
        
        # ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•˜ê²Œ)
        images = []
        img_tags = soup.find_all('img')
        for i, img in enumerate(img_tags):
            src = img.get('src', '')
            alt = img.get('alt', '')
            if src and not src.startswith('data:image/svg'):
                images.append({
                    'index': i + 1,
                    'src': src,
                    'alt': alt,
                    'is_embedded': src.startswith('data:image')
                })
        
        # êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ì¶”ì¶œ
        structured_content = extract_clean_paragraphs(soup)
        
        return {
            'title': title,
            'author': author,
            'date': date,
            'images': images,
            'content': structured_content,
            'total_elements': len(structured_content),
            'image_count': len(images)
        }
        
    except Exception as e:
        return {'error': f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

def main():
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python medium_post_extractor_final.py <html_file_path>")
        sys.exit(1)
    
    html_file = sys.argv[1]
    
    if not os.path.exists(html_file):
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {html_file}")
        sys.exit(1)
    
    print("Medium í¬ìŠ¤íŠ¸ ì™„ì „ ì¶”ì¶œ ì¤‘...")
    result = extract_complete_medium_post(html_file)
    
    if 'error' in result:
        print(f"ì˜¤ë¥˜: {result['error']}")
        sys.exit(1)
    
    print("=" * 100)
    print(f"ì œëª©: {result['title']}")
    print(f"ì‘ì„±ì: {result['author']}")
    print(f"ë‚ ì§œ: {result['date']}")
    print(f"ì¶”ì¶œëœ ìš”ì†Œ ìˆ˜: {result['total_elements']}")
    print(f"ì´ë¯¸ì§€ ìˆ˜: {result['image_count']}")
    print("=" * 100)
    print()
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
    base_name = os.path.basename(html_file)
    output_file = base_name.replace('.html', '_complete_final.md')
    output_path = os.path.join(os.path.dirname(html_file), output_file)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        # í—¤ë” ì •ë³´
        f.write(f"# {result['title']}\n\n")
        f.write(f"**ì‘ì„±ì:** {result['author']}  \n")
        f.write(f"**ë‚ ì§œ:** {result['date']}  \n")
        f.write(f"**ì´ë¯¸ì§€ ìˆ˜:** {result['image_count']}  \n\n")
        f.write("---\n\n")
        
        # êµ¬ì¡°í™”ëœ ì½˜í…ì¸ 
        for item in result['content']:
            f.write(item['formatted'] + "\n\n")
        
        # ì´ë¯¸ì§€ ì •ë³´
        if result['images']:
            f.write("---\n\n## ì´ë¯¸ì§€ ëª©ë¡\n\n")
            for img in result['images']:
                f.write(f"**ì´ë¯¸ì§€ {img['index']}:**  \n")
                f.write(f"- URL: {img['src']}  \n")
                if img['alt']:
                    f.write(f"- ì„¤ëª…: {img['alt']}  \n")
                f.write(f"- íƒ€ì…: {'ì„ë² ë””ë“œ' if img['is_embedded'] else 'ì™¸ë¶€'}\n\n")
    
    print(f"ì™„ì „í•œ í¬ìŠ¤íŠ¸ê°€ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
    
    # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë²„ì „ë„ ì €ì¥
    txt_output_path = output_path.replace('.md', '.txt')
    with open(txt_output_path, 'w', encoding='utf-8') as f:
        f.write(f"{result['title']}\n")
        f.write(f"ì‘ì„±ì: {result['author']}\n")
        f.write(f"ë‚ ì§œ: {result['date']}\n")
        f.write("=" * 80 + "\n\n")
        
        for item in result['content']:
            if item['type'] == 'heading':
                f.write(f"\n{item['text']}\n")
                f.write("-" * len(item['text']) + "\n\n")
            else:
                f.write(f"{item['text']}\n\n")
    
    print(f"í…ìŠ¤íŠ¸ ë²„ì „ë„ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {txt_output_path}")

if __name__ == "__main__":
    main()