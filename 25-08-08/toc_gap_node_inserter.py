#!/usr/bin/env python3
"""
ìƒì„± ì‹œê°„: 2025-08-08 09:15 KST
í•µì‹¬ ë‚´ìš©: TOC êµ¬ì¡°ì— Introduction ê°­ ë…¸ë“œë¥¼ ì‚½ì…í•˜ì—¬ ìƒˆë¡œìš´ êµ¬ì¡°í™”ëœ JSON ìƒì„±
ìƒì„¸ ë‚´ìš©:
    - TocGapNodeInserter í´ë˜ìŠ¤ (1-200í–‰): TOC ë…¸ë“œ ë¶„ì„ ë° ê°­ ë…¸ë“œ ì‚½ì… ê¸°ëŠ¥
    - extract_numbering() (30-50í–‰): íƒ€ì´í‹€ì—ì„œ ë„˜ë²„ë§ ì²´ê³„ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜
    - create_introduction_node() (60-80í–‰): Introduction ë…¸ë“œ ìƒì„± ë¡œì§
    - detect_and_insert_gaps() (100-150í–‰): ê°­ íƒì§€ ë° ë…¸ë“œ ì‚½ì… ë©”ì¸ ë¡œì§
    - main() (180-200í–‰): ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
ìƒíƒœ: 
ì£¼ì†Œ: toc_gap_node_inserter
ì°¸ì¡°: gap_section_extractor.py
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass

@dataclass
class TocNode:
    """TOC ë…¸ë“œ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„°í´ë˜ìŠ¤"""
    title: str
    level: int
    start_page: int
    end_page: int
    page_count: int
    is_added_node: bool = False

class TocGapNodeInserter:
    """TOC êµ¬ì¡°ì—ì„œ ë ˆë²¨ ê°­ì„ íƒì§€í•˜ê³  Introduction ë…¸ë“œë¥¼ ì‚½ì…í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, json_path: str, output_path: str):
        self.json_path = Path(json_path)
        self.output_path = Path(output_path)
        self.original_nodes = []
        self.enhanced_nodes = []
        
        # ì›ë³¸ JSON ë°ì´í„° ë¡œë“œ
        self._load_original_data()
    
    def _load_original_data(self) -> None:
        """ì›ë³¸ JSON íŒŒì¼ì—ì„œ TOC ë…¸ë“œ ë°ì´í„°ë¥¼ ë¡œë“œ"""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                nodes_data = json.load(f)
            
            for node_data in nodes_data:
                node = TocNode(
                    title=node_data.get('title', ''),
                    level=node_data.get('level', 0),
                    start_page=node_data.get('start_page', 0),
                    end_page=node_data.get('end_page', 0),
                    page_count=node_data.get('page_count', 0),
                    is_added_node=False  # ì›ë³¸ ë…¸ë“œëŠ” ëª¨ë‘ False
                )
                self.original_nodes.append(node)
            
            print(f"âœ… ì›ë³¸ TOC ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.original_nodes)}ê°œ ë…¸ë“œ")
            
        except Exception as e:
            raise Exception(f"ì›ë³¸ JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def extract_numbering(self, title: str) -> Optional[str]:
        """íƒ€ì´í‹€ì—ì„œ ë„˜ë²„ë§ ì²´ê³„ë¥¼ ì¶”ì¶œ (ì¼ë°˜ì ì¸ ìˆ«ì/ë¬¸ì ë„˜ë²„ë§ë§Œ)"""
        # íŒ¨í„´: ìˆ«ìë¡œ ì‹œì‘í•˜ê±°ë‚˜ ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë„˜ë²„ë§
        patterns = [
            r'^(\d+(?:\.\d+)*)',          # 1, 1.1, 1.1.1 í˜•íƒœ
            r'^([A-Z](?:\.\d+)*)',        # A, A.1, A.1.1 í˜•íƒœ
        ]
        
        for pattern in patterns:
            match = re.match(pattern, title.strip())
            if match:
                return match.group(1)
        
        return None
    
    def create_introduction_node(self, current_node: TocNode, next_node: TocNode) -> Optional[TocNode]:
        """í˜„ì¬ ë…¸ë“œì˜ ì¡°ì§í™” ì²´ê³„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Introduction ë…¸ë“œ ìƒì„±"""
        current_title = current_node.title
        
        # í˜„ì¬ ë…¸ë“œì˜ ì¡°ì§í™” ì²´ê³„ë¥¼ ì¶”ì¶œ
        if current_title.startswith("Part"):
            # "Part 1â€”Flexibility" â†’ "Part 1 Introduction"
            part_match = re.match(r'^(Part\s+\d+)', current_title)
            if part_match:
                intro_title = f"{part_match.group(1)} Introduction"
            else:
                return None
        elif current_title.startswith("Appendix"):
            # "Appendix Aâ€”Principles..." â†’ "Appendix A Introduction"
            appendix_match = re.match(r'^(Appendix\s+[A-Z])', current_title)
            if appendix_match:
                intro_title = f"{appendix_match.group(1)} Introduction"
            else:
                return None
        else:
            # ì¼ë°˜ì ì¸ ë„˜ë²„ë§ ì²´ê³„ ì¶”ì¶œ
            current_numbering = self.extract_numbering(current_title)
            if not current_numbering:
                return None
            intro_title = f"{current_numbering} Introduction"
        
        # í˜ì´ì§€ ë²”ìœ„ ê³„ì‚°
        if current_node.end_page > next_node.start_page:
            # ìƒìœ„ ë²”ì£¼ ì¼€ì´ìŠ¤ (Part â†’ Chapter)
            gap_start = current_node.start_page
            gap_end = next_node.start_page
        else:
            # ì¼ë°˜ ì¼€ì´ìŠ¤ (Chapter â†’ Section)
            gap_start = current_node.end_page
            gap_end = next_node.start_page
        
        # í˜ì´ì§€ ë²”ìœ„ëŠ” ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬ (íƒ€ì´í‹€ ê¸°ë°˜ í•„í„°ë§ì— ì˜ì¡´)
        # ë ˆë²¨ ì°¨ì´ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ Introduction ë…¸ë“œ ìƒì„±
        if gap_start <= 0:
            gap_start = 1  # ìµœì†Œ 1í˜ì´ì§€ë¡œ ì„¤ì •
        
        if gap_end <= gap_start:
            gap_end = gap_start + 1  # ìµœì†Œ 1í˜ì´ì§€ ë²”ìœ„ ë³´ì¥
        
        gap_page_count = gap_end - gap_start + 1
        
        intro_node = TocNode(
            title=intro_title,
            level=next_node.level,  # ë‹¤ìŒ ë…¸ë“œì™€ ê°™ì€ ë ˆë²¨
            start_page=gap_start,
            end_page=gap_end,
            page_count=gap_page_count,
            is_added_node=True
        )
        
        return intro_node
    
    def detect_and_insert_gaps(self) -> List[TocNode]:
        """ë ˆë²¨ ê°­ì„ íƒì§€í•˜ê³  Introduction ë…¸ë“œë¥¼ ì‚½ì…í•˜ì—¬ ìƒˆë¡œìš´ TOC êµ¬ì¡° ìƒì„±"""
        print("ğŸ” ë ˆë²¨ ê°­ íƒì§€ ë° Introduction ë…¸ë“œ ì‚½ì… ì¤‘...")
        
        enhanced_nodes = []
        inserted_count = 0
        
        for i in range(len(self.original_nodes)):
            current_node = self.original_nodes[i]
            
            # í˜„ì¬ ë…¸ë“œë¥¼ ê²°ê³¼ì— ì¶”ê°€
            enhanced_nodes.append(current_node)
            
            # ë‹¤ìŒ ë…¸ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            if i + 1 < len(self.original_nodes):
                next_node = self.original_nodes[i + 1]
                
                # ë ˆë²¨ ê°­ì´ ìˆëŠ”ì§€ í™•ì¸ (current_level < next_level)
                if current_node.level < next_node.level:
                    # Introduction ë…¸ë“œ ìƒì„±
                    intro_node = self.create_introduction_node(current_node, next_node)
                    
                    if intro_node:
                        enhanced_nodes.append(intro_node)
                        inserted_count += 1
                        
                        print(f"  ğŸ“„ Introduction ë…¸ë“œ ì‚½ì…:")
                        print(f"     ì´ì „: {current_node.title} (Level {current_node.level})")
                        print(f"     ì‚½ì…: {intro_node.title} (Level {intro_node.level})")
                        print(f"     ë‹¤ìŒ: {next_node.title} (Level {next_node.level})")
                        print(f"     í˜ì´ì§€: {intro_node.start_page}-{intro_node.end_page}")
        
        self.enhanced_nodes = enhanced_nodes
        print(f"âœ… ì´ {inserted_count}ê°œ Introduction ë…¸ë“œ ì‚½ì… ì™„ë£Œ")
        print(f"ğŸ“Š ì „ì²´ ë…¸ë“œ ìˆ˜: {len(self.original_nodes)} â†’ {len(self.enhanced_nodes)}")
        
        return enhanced_nodes
    
    def save_enhanced_toc(self) -> None:
        """í–¥ìƒëœ TOC êµ¬ì¡°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not self.enhanced_nodes:
            print("âš ï¸ ì €ì¥í•  í–¥ìƒëœ TOC ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            # JSON í˜•íƒœë¡œ ë³€í™˜
            json_data = []
            for node in self.enhanced_nodes:
                node_dict = {
                    "title": node.title,
                    "level": node.level,
                    "start_page": node.start_page,
                    "end_page": node.end_page,
                    "page_count": node.page_count,
                    "is_added_node": node.is_added_node
                }
                
                json_data.append(node_dict)
            
            # íŒŒì¼ ì €ì¥
            with open(self.output_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ í–¥ìƒëœ TOC íŒŒì¼ ì €ì¥ ì™„ë£Œ: {self.output_path}")
            
            # í†µê³„ ì •ë³´ ì¶œë ¥
            self._print_statistics()
            
            # ì¶”ê°€ëœ ë…¸ë“œë§Œ ë”°ë¡œ ì €ì¥
            self._save_added_nodes_only()
            
        except Exception as e:
            print(f"âŒ TOC íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_added_nodes_only(self) -> None:
        """ì¶”ê°€ëœ ë…¸ë“œë§Œ ë”°ë¡œ JSON íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # ì¶”ê°€ëœ ë…¸ë“œë§Œ í•„í„°ë§
            added_nodes = [node for node in self.enhanced_nodes if node.is_added_node]
            
            if not added_nodes:
                print("âš ï¸ ì¶”ê°€ëœ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # JSON í˜•íƒœë¡œ ë³€í™˜
            json_data = []
            for node in added_nodes:
                node_dict = {
                    "title": node.title,
                    "level": node.level,
                    "start_page": node.start_page,
                    "end_page": node.end_page,
                    "page_count": node.page_count,
                    "is_added_node": node.is_added_node
                }
                json_data.append(node_dict)
            
            # ì¶”ê°€ëœ ë…¸ë“œë§Œ ì €ì¥í•˜ëŠ” íŒŒì¼ ê²½ë¡œ
            added_nodes_path = self.output_path.parent / f"{self.output_path.stem}_added_nodes_only.json"
            
            # íŒŒì¼ ì €ì¥
            with open(added_nodes_path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“‹ ì¶”ê°€ëœ ë…¸ë“œë§Œ ì €ì¥: {added_nodes_path} ({len(added_nodes)}ê°œ)")
            
        except Exception as e:
            print(f"âŒ ì¶”ê°€ëœ ë…¸ë“œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _print_statistics(self) -> None:
        """ì‚½ì… ê²°ê³¼ í†µê³„ ì¶œë ¥"""
        original_count = len(self.original_nodes)
        enhanced_count = len(self.enhanced_nodes)
        introduction_count = enhanced_count - original_count
        
        print(f"\nğŸ“Š TOC êµ¬ì¡° í–¥ìƒ í†µê³„:")
        print(f"   ì›ë³¸ ë…¸ë“œ ìˆ˜: {original_count}")
        print(f"   í–¥ìƒëœ ë…¸ë“œ ìˆ˜: {enhanced_count}")
        print(f"   ì‚½ì…ëœ Introduction ë…¸ë“œ: {introduction_count}")
        
        # ë ˆë²¨ë³„ í†µê³„
        level_stats = {}
        intro_level_stats = {}
        
        for node in self.enhanced_nodes:
            level_key = f"Level {node.level}"
            level_stats[level_key] = level_stats.get(level_key, 0) + 1
            
            if node.is_added_node:
                intro_level_stats[level_key] = intro_level_stats.get(level_key, 0) + 1
        
        print(f"\nğŸ“ˆ ë ˆë²¨ë³„ ë…¸ë“œ ë¶„í¬:")
        for level, count in sorted(level_stats.items()):
            intro_count = intro_level_stats.get(level, 0)
            print(f"   {level}: {count}ê°œ (Introduction: {intro_count}ê°œ)")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    input_json = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-07/core_toc_with_page_ranges.json"
    output_json = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-08/core_toc_with_page_ranges_v2.json"
    
    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(input_json).exists():
        print(f"âŒ ì…ë ¥ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_json}")
        return
    
    print("ğŸš€ TOC êµ¬ì¡° í–¥ìƒ ì‘ì—… ì‹œì‘")
    print(f"ğŸ“Š ì…ë ¥ íŒŒì¼: {input_json}")
    print(f"ğŸ’¾ ì¶œë ¥ íŒŒì¼: {output_json}")
    
    try:
        # TOC ê°­ ë…¸ë“œ ì‚½ì…ê¸° ìƒì„±
        inserter = TocGapNodeInserter(input_json, output_json)
        
        # ê°­ íƒì§€ ë° Introduction ë…¸ë“œ ì‚½ì…
        enhanced_nodes = inserter.detect_and_insert_gaps()
        
        if enhanced_nodes:
            # í–¥ìƒëœ TOC êµ¬ì¡° ì €ì¥
            inserter.save_enhanced_toc()
            print("\nâœ… TOC êµ¬ì¡° í–¥ìƒ ì‘ì—… ì™„ë£Œ!")
        else:
            print("âš ï¸ ì‚½ì…í•  Introduction ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nâŒ TOC êµ¬ì¡° í–¥ìƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()