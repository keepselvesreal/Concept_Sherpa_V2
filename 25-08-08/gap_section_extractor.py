#!/usr/bin/env python3
"""
ìƒì„± ì‹œê°„: 2025-08-08 08:29 KST
í•µì‹¬ ë‚´ìš©: ë…¸ë“œ ë ˆë²¨ ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ PDFì—ì„œ ì„¹ì…˜ ê°„ gap ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ìƒì„¸ ë‚´ìš©:
    - GapSectionExtractor í´ë˜ìŠ¤ (1-250í–‰): ë©”ì¸ ì¶”ì¶œ í´ë˜ìŠ¤, JSON ë¶„ì„ ë° PDF ì²˜ë¦¬ ê¸°ëŠ¥
    - detect_level_gaps() (60-90í–‰): ë…¸ë“œ ê°„ ë ˆë²¨ ì°¨ì´ íƒì§€ ì•Œê³ ë¦¬ì¦˜
    - extract_gap_content() (120-150í–‰): PDFì—ì„œ íŠ¹ì • í˜ì´ì§€ ë²”ìœ„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    - save_gap_section() (180-200í–‰): ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥
    - main() (220-250í–‰): ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜, CLI ì¸í„°í˜ì´ìŠ¤ ì œê³µ
ìƒíƒœ: 
ì£¼ì†Œ: gap_section_extractor
ì°¸ì¡°: 
"""

import json
import pdfplumber
import re
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

@dataclass
class NodeGap:
    """ë…¸ë“œ ê°„ gap ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„°í´ë˜ìŠ¤"""
    current_node: Dict
    next_node: Dict
    gap_start_page: int
    gap_end_page: int
    gap_description: str

class GapSectionExtractor:
    """ë…¸ë“œ ë ˆë²¨ ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ PDFì—ì„œ gap ì„¹ì…˜ì„ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, json_path: str, pdf_path: str, output_dir: str):
        self.json_path = Path(json_path)
        self.pdf_path = Path(pdf_path)
        self.output_dir = Path(output_dir)
        self.nodes = []
        self.gaps = []
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(exist_ok=True)
        
        # JSON ë°ì´í„° ë¡œë“œ
        self._load_json_data()
    
    def _load_json_data(self) -> None:
        """JSON íŒŒì¼ì—ì„œ ë…¸ë“œ ë°ì´í„°ë¥¼ ë¡œë“œ"""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                self.nodes = json.load(f)
            print(f"âœ… JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.nodes)}ê°œ ë…¸ë“œ")
        except Exception as e:
            raise Exception(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def detect_level_gaps(self) -> List[NodeGap]:
        """ë…¸ë“œ ê°„ ë ˆë²¨ ì°¨ì´ê°€ ìˆëŠ” gapì„ íƒì§€"""
        print("ğŸ” ë…¸ë“œ ë ˆë²¨ gap íƒì§€ ì¤‘...")
        gaps = []
        
        for i in range(len(self.nodes) - 1):
            current_node = self.nodes[i]
            next_node = self.nodes[i + 1]
            
            current_level = current_node.get('level', 0)
            next_level = next_node.get('level', 0)
            
            # í˜„ì¬ ë…¸ë“œì˜ ë ˆë²¨ì´ ë‹¤ìŒ ë…¸ë“œë³´ë‹¤ ì‘ì€ ê²½ìš° (ê³ ì°¨ì› â†’ ì €ì°¨ì›ìœ¼ë¡œ ë³€í™”)
            if current_level < next_level:
                # gap í˜ì´ì§€ ë²”ìœ„ ê³„ì‚°
                current_end_page = current_node.get('end_page', 0)
                next_start_page = next_node.get('start_page', 0)
                
                # í˜ì´ì§€ ë²”ìœ„ ê³„ì‚° - ëª¨ë“  ë ˆë²¨ ë³€í™” í—ˆìš©
                gap_start = current_end_page
                gap_end = next_start_page
                
                # í˜ì´ì§€ ë²”ìœ„ê°€ ìœ íš¨í•œì§€ í™•ì¸
                if gap_start > 0:
                    gap_description = f"Level {current_level} â†’ Level {next_level}"
                    
                    gap = NodeGap(
                        current_node=current_node,
                        next_node=next_node,
                        gap_start_page=gap_start,
                        gap_end_page=gap_end,
                        gap_description=gap_description
                    )
                    gaps.append(gap)
                    
                    print(f"  ğŸ“„ Gap ë°œê²¬: {current_node['title']} â†’ {next_node['title']}")
                    print(f"     ë ˆë²¨: {current_level} â†’ {next_level}, í˜ì´ì§€: {gap_start}-{gap_end}")
        
        self.gaps = gaps
        print(f"âœ… ì´ {len(gaps)}ê°œ gap ë°œê²¬")
        return gaps
    
    def _normalize_title_for_search(self, title: str) -> str:
        """íƒ€ì´í‹€ì„ ê²€ìƒ‰ìš©ìœ¼ë¡œ ì •ê·œí™”"""
        # íŠ¹ìˆ˜ë¬¸ì, ìˆ«ì, ê³µë°± ë“±ì„ ì œê±°í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
        normalized = re.sub(r'[^\w\s]', ' ', title)  # íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ
        normalized = re.sub(r'\s+', ' ', normalized).strip()  # ë‹¤ì¤‘ ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
        return normalized.lower()
    
    def _extract_content_between_titles(self, page_text: str, current_title: str, next_title: str) -> str:
        """í˜ì´ì§€ì—ì„œ ë‘ íƒ€ì´í‹€ ì‚¬ì´ì˜ ì½˜í…ì¸ ë§Œ ì¶”ì¶œ"""
        lines = page_text.split('\n')
        
        # íƒ€ì´í‹€ ì •ê·œí™”
        current_normalized = self._normalize_title_for_search(current_title)
        next_normalized = self._normalize_title_for_search(next_title)
        
        start_idx = -1
        end_idx = len(lines)
        
        # í˜„ì¬ íƒ€ì´í‹€ ì´í›„ ì‹œì‘ì  ì°¾ê¸°
        for i, line in enumerate(lines):
            line_normalized = self._normalize_title_for_search(line)
            if current_normalized in line_normalized or line_normalized in current_normalized:
                start_idx = i + 1  # íƒ€ì´í‹€ ë‹¤ìŒ ì¤„ë¶€í„°
                break
        
        # ë‹¤ìŒ íƒ€ì´í‹€ ì´ì „ ëì  ì°¾ê¸°
        for i, line in enumerate(lines[start_idx:], start_idx):
            line_normalized = self._normalize_title_for_search(line)
            if next_normalized in line_normalized or line_normalized in next_normalized:
                end_idx = i
                break
        
        # ì¶”ì¶œëœ ì½˜í…ì¸  ë°˜í™˜
        if start_idx >= 0 and start_idx < end_idx:
            extracted_lines = lines[start_idx:end_idx]
            return '\n'.join(extracted_lines).strip()
        
        return ""
    
    def extract_gap_content(self, gap: NodeGap) -> str:
        """íŠ¹ì • gapì˜ í˜ì´ì§€ ë²”ìœ„ì—ì„œ ë‘ íƒ€ì´í‹€ ì‚¬ì´ì˜ PDF ì½˜í…ì¸ ë§Œ ì¶”ì¶œ"""
        try:
            with pdfplumber.open(self.pdf_path) as pdf:
                total_pages = len(pdf.pages)
                
                # í˜ì´ì§€ ë²”ìœ„ ìœ íš¨ì„± ê²€ì‚¬
                start_page = max(1, gap.gap_start_page) - 1  # 0-based ì¸ë±ìŠ¤ë¡œ ë³€í™˜
                end_page = min(total_pages, gap.gap_end_page) - 1
                
                current_title = gap.current_node.get('title', '')
                next_title = gap.next_node.get('title', '')
                
                content = ""
                for page_num in range(start_page, end_page + 1):
                    if page_num >= total_pages:
                        break
                    
                    page = pdf.pages[page_num]
                    page_text = page.extract_text() or ""
                    
                    if page_text.strip():
                        # íƒ€ì´í‹€ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë‚´ìš©ë§Œ ì¶”ì¶œ
                        extracted_text = self._extract_content_between_titles(
                            page_text, current_title, next_title
                        )
                        
                        if extracted_text:
                            content += f"=== PAGE {page_num + 1} ===\n{extracted_text}\n\n"
                        else:
                            # íƒ€ì´í‹€ ë§¤ì¹­ì´ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ í˜ì´ì§€ í¬í•¨ (fallback)
                            content += f"=== PAGE {page_num + 1} ===\n{page_text}\n\n"
                
                return content.strip()
                
        except Exception as e:
            print(f"âŒ ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def save_gap_section(self, gap: NodeGap, content: str) -> None:
        """ì¶”ì¶œëœ gap ì½˜í…ì¸ ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not content.strip():
            print(f"âš ï¸ ë¹ˆ ì½˜í…ì¸ , ì €ì¥ ê±´ë„ˆë›°ê¸°: {gap.gap_description}")
            return
        
        # íŒŒì¼ëª… ìƒì„±
        current_level = gap.current_node.get('level', 0)
        next_level = gap.next_node.get('level', 0)
        filename = f"gap_{current_level}_to_{next_level}_p{gap.gap_start_page}-{gap.gap_end_page}.md"
        
        # íŒŒì¼ ì €ì¥
        filepath = self.output_dir / filename
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {filename} ({len(content)} ë¬¸ì)")
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ {filename}: {e}")
    
    def extract_all_gaps(self) -> None:
        """ëª¨ë“  gapì˜ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•˜ê³  ì €ì¥"""
        if not self.gaps:
            print("âš ï¸ íƒì§€ëœ gapì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸš€ {len(self.gaps)}ê°œ gap ì½˜í…ì¸  ì¶”ì¶œ ì‹œì‘...")
        
        extracted_count = 0
        failed_count = 0
        
        for i, gap in enumerate(self.gaps, 1):
            print(f"\n[{i}/{len(self.gaps)}] {gap.gap_description}")
            print(f"  í˜ì´ì§€ {gap.gap_start_page}-{gap.gap_end_page} ì¶”ì¶œ ì¤‘...")
            
            content = self.extract_gap_content(gap)
            
            if content.strip():
                self.save_gap_section(gap, content)
                extracted_count += 1
            else:
                print(f"âŒ ë¹ˆ ì½˜í…ì¸ ")
                failed_count += 1
        
        print(f"\nğŸ“Š ì¶”ì¶œ ì™„ë£Œ: âœ… {extracted_count}ê°œ ì„±ê³µ, âŒ {failed_count}ê°œ ì‹¤íŒ¨")
        self._create_summary_report(extracted_count, failed_count)
    
    def create_gap_list_only(self) -> None:
        """Gap ëª©ë¡ë§Œ ìƒì„±í•˜ì—¬ ê²€ì¦ìš© íŒŒì¼ë¡œ ì €ì¥ (PDF ì¶”ì¶œ ì—†ìŒ)"""
        if not self.gaps:
            print("âš ï¸ íƒì§€ëœ gapì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“‹ {len(self.gaps)}ê°œ gap ëª©ë¡ ìƒì„± ì¤‘...")
        
        # ê²€ì¦ìš© gap ëª©ë¡ íŒŒì¼ ìƒì„±
        gap_list_file = self.output_dir / "gap_list_only.md"
        
        try:
            with open(gap_list_file, 'w', encoding='utf-8') as f:
                f.write("# Gap Detection List\n\n")
                f.write(f"**ì´ íƒì§€ëœ Gap ìˆ˜:** {len(self.gaps)}\n\n")
                f.write("## íƒì§€ëœ Gap ëª©ë¡\n\n")
                
                for i, gap in enumerate(self.gaps, 1):
                    f.write(f"### {i}. **Level {gap.current_node.get('level', 0)} â†’ Level {gap.next_node.get('level', 0)}**\n")
                    f.write(f"- **ì´ì „ ë…¸ë“œ**: {gap.current_node.get('title', '')}\n")
                    f.write(f"  - í˜ì´ì§€ ë²”ìœ„: {gap.current_node.get('start_page', 0)}-{gap.current_node.get('end_page', 0)}\n")
                    f.write(f"- **ë‹¤ìŒ ë…¸ë“œ**: {gap.next_node.get('title', '')}\n")
                    f.write(f"  - í˜ì´ì§€ ë²”ìœ„: {gap.next_node.get('start_page', 0)}-{gap.next_node.get('end_page', 0)}\n")
                    f.write(f"- **Gap í˜ì´ì§€**: {gap.gap_start_page}-{gap.gap_end_page}\n")
                    f.write(f"- **Gap ì„¤ëª…**: {gap.gap_description}\n\n")
                
                # ë ˆë²¨ë³„ í†µê³„
                f.write("## ë ˆë²¨ë³„ Gap í†µê³„\n\n")
                level_stats = {}
                for gap in self.gaps:
                    level_key = f"Level {gap.current_node.get('level', 0)} â†’ Level {gap.next_node.get('level', 0)}"
                    level_stats[level_key] = level_stats.get(level_key, 0) + 1
                
                for level_transition, count in sorted(level_stats.items()):
                    f.write(f"- **{level_transition}**: {count}ê°œ\n")
            
            print(f"ğŸ“„ Gap ëª©ë¡ íŒŒì¼ ìƒì„±: {gap_list_file}")
            
        except Exception as e:
            print(f"âŒ Gap ëª©ë¡ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_summary_report(self, extracted: int, failed: int) -> None:
        """ì¶”ì¶œ ê²°ê³¼ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        report_file = self.output_dir / "gap_extraction_report.md"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("# Gap Section Extraction Report\n\n")
                f.write(f"**ì´ Gap ìˆ˜:** {len(self.gaps)}\n")
                f.write(f"**ì¶”ì¶œ ì„±ê³µ:** {extracted}\n")
                f.write(f"**ì¶”ì¶œ ì‹¤íŒ¨:** {failed}\n\n")
                
                f.write("## Gap ìƒì„¸ ì •ë³´\n\n")
                for gap in self.gaps:
                    f.write(f"- **{gap.gap_description}**\n")
                    f.write(f"  - ì´ì „: {gap.current_node['title']}\n")
                    f.write(f"  - ë‹¤ìŒ: {gap.next_node['title']}\n")
                    f.write(f"  - í˜ì´ì§€: {gap.gap_start_page}-{gap.gap_end_page}\n\n")
            
            print(f"ğŸ“„ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±: {report_file}")
            
        except Exception as e:
            print(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    json_path = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-07/core_toc_with_page_ranges.json"
    pdf_path = "/home/nadle/projects/Knowledge_Sherpa/v2/2022_Data-Oriented Programming_Manning.pdf"
    output_dir = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-08/extracted_gaps"
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(json_path).exists():
        print(f"âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path}")
        return
    
    if not Path(pdf_path).exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return
    
    print("ğŸš€ ë…¸ë“œ ë ˆë²¨ gap ì„¹ì…˜ ì¶”ì¶œ ì‹œì‘")
    print(f"ğŸ“Š JSON: {json_path}")
    print(f"ğŸ“– PDF: {pdf_path}")
    print(f"ğŸ“ ì¶œë ¥: {output_dir}")
    
    try:
        # Gap ì¶”ì¶œê¸° ìƒì„±
        extractor = GapSectionExtractor(json_path, pdf_path, output_dir)
        
        # Gap íƒì§€
        gaps = extractor.detect_level_gaps()
        
        if gaps:
            # Gap ëª©ë¡ë§Œ ìƒì„± (ê²€ì¦ìš©)
            extractor.create_gap_list_only()
            print("\nâœ… Gap ëª©ë¡ ìƒì„± ì™„ë£Œ!")
        else:
            print("âš ï¸ íƒì§€í•  gapì´ ì—†ìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nâŒ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()