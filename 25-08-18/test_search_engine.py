"""
ìƒì„± ì‹œê°„: 2025-08-18 12:22:54
í•µì‹¬ ë‚´ìš©: DocumentSearchEngine í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ìƒì„¸ ë‚´ìš©:
    - test_search_engine í•¨ìˆ˜ (ë¼ì¸ 25-70): ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
    - setup_environment í•¨ìˆ˜ (ë¼ì¸ 72-90): í™˜ê²½ ì„¤ì • ë° ë¡œê¹… ì´ˆê¸°í™”
    - print_search_results í•¨ìˆ˜ (ë¼ì¸ 92-120): ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
    - í…ŒìŠ¤íŠ¸ ì§ˆì˜: "ai ì½”ë”©ì˜ ë¬¸ì œì  í•´ê²° ë„êµ¬ë“¤ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´"
ìƒíƒœ: 
ì£¼ì†Œ: test_search_engine
ì°¸ì¡°: document_search_engine
"""

import asyncio
import logging
import os
import sys
from typing import List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv('/home/nadle/projects/Knowledge_Sherpa/v2/.env')

from document_search_engine import DocumentSearchEngine, ReconstructedDocument

def setup_environment():
    """í™˜ê²½ ì„¤ì • ë° ë¡œê¹… ì´ˆê¸°í™”"""
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('search_engine_test.log')
        ]
    )
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_env_vars = ['OPENAI_API_KEY', 'ANTHROPIC_API_KEY', 'NEON_DATABASE_URL']
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"âš ï¸ ëˆ„ë½ëœ í™˜ê²½ ë³€ìˆ˜: {', '.join(missing_vars)}")
        print("í…ŒìŠ¤íŠ¸ë¥¼ ê³„ì† ì§„í–‰í•˜ì§€ë§Œ ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("âœ… ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ")

async def test_search_engine():
    """
    DocumentSearchEngine í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    ì§ˆì˜: "ai ì½”ë”©ì˜ ë¬¸ì œì  í•´ê²° ë„êµ¬ë“¤ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´"
    """
    logger = logging.getLogger(__name__)
    
    print("ğŸš€ DocumentSearchEngine í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
    search_engine = DocumentSearchEngine()
    
    try:
        print("ğŸ“¡ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        await search_engine.initialize(project_name="knowledge_sherpa")
        print("âœ… ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        print("\nğŸ” ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘...")
        status = await search_engine.get_system_status()
        print(f"  - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {'âœ…' if status.get('database_connected') else 'âŒ'}")
        print(f"  - ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”: {'âœ…' if status.get('components_initialized') else 'âŒ'}")
        print(f"  - ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ: {status.get('database_status', 'unknown')}")
        
        # í…ŒìŠ¤íŠ¸ ì§ˆì˜ ì‹¤í–‰
        test_query = "ai ì½”ë”©ì˜ ë¬¸ì œì  í•´ê²° ë„êµ¬ë“¤ì— ëŒ€í•´ ì•Œê³  ì‹¶ì–´"
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì§ˆì˜ ì‹¤í–‰: '{test_query}'")
        print("-" * 60)
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = await search_engine.search(
            query=test_query,
            project_name="knowledge_sherpa",
            max_results=3
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
        print("=" * 60)
        
        if results:
            print_search_results(results)
        else:
            print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("\nğŸ” ì›ì¸ ë¶„ì„:")
            print("  1. ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ë‚´ìš©ì˜ ë¬¸ì„œê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            print("  2. ì„ê³„ê°’(similarity_threshold)ì´ ë„ˆë¬´ ë†’ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            print("  3. ì„ë² ë”© í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        # ìµœì¢… í†µê³„
        final_stats = search_engine.search_stats
        print(f"\nğŸ“ˆ ê²€ìƒ‰ í†µê³„:")
        print(f"  - ì´ ê²€ìƒ‰ íšŸìˆ˜: {final_stats['total_searches']}")
        print(f"  - í‰ê·  ê²€ìƒ‰ ì‹œê°„: {final_stats['avg_search_time']:.2f}ì´ˆ")
        print(f"  - ì„±ê³µë¥ : {final_stats['success_rate']:.1f}%")
        
    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    finally:
        print("\nğŸ”„ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        try:
            await search_engine.close()
            print("âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print("\nğŸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

def print_search_results(results: List[ReconstructedDocument]):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    for i, doc in enumerate(results, 1):
        print(f"\nğŸ“„ ë¬¸ì„œ {i}: {doc.title}")
        print(f"   ğŸ¯ ìœ ì‚¬ë„: {doc.similarity_score:.4f}")
        print(f"   ğŸ” ê²€ìƒ‰ ì°¨ì›: {doc.search_dimension}")
        print(f"   ğŸ“ ë¬¸ì„œ ID: {doc.document_id}")
        
        # ë©”íƒ€ë°ì´í„° ì¶œë ¥
        metadata = doc.metadata
        print(f"   ğŸ“‚ ì†ŒìŠ¤ íƒ€ì…: {metadata.get('source_type', 'unknown')}")
        print(f"   ğŸŒ ì–¸ì–´: {metadata.get('document_language', 'unknown')}")
        print(f"   ğŸ—ï¸ êµ¬ì¡° íƒ€ì…: {metadata.get('structure_type', 'unknown')}")
        
        # ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì)
        content_preview = doc.formatted_content.replace('\n', ' ')[:200]
        print(f"   ğŸ“– ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content_preview}...")
        
        print("-" * 40)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    setup_environment()
    await test_search_engine()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)