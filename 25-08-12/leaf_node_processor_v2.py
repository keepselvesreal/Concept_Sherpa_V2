"""
ìƒì„± ì‹œê°„: 2025-08-12 15:07:00 KST
í•µì‹¬ ë‚´ìš©: ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ ì‹œìŠ¤í…œ V2 - ê³µí†µ ëª¨ë“ˆê³¼ ìƒˆë¡œìš´ ë¡œê¹… ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ëŠ” ê°œì„ ëœ ë²„ì „
ìƒì„¸ ë‚´ìš©:
    - LeafNodeProcessor í´ëž˜ìŠ¤ (ë¼ì¸ 30-): ê³µí†µ ëª¨ë“ˆ ê¸°ë°˜ ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ í´ëž˜ìŠ¤
    - ContentAnalyzer í†µí•© (ë¼ì¸ 35): 4ê°€ì§€ ì •ë³´ ì¶”ì¶œ ê³µí†µ ëª¨ë“ˆ í™œìš©
    - ProcessLogger í†µí•© (ë¼ì¸ 38): êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ í™œìš©
    - process_single_leaf_node() (ë¼ì¸ 70-): ë‹¨ì¼ ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ (ê°œì„ ë¨)
    - load_leaf_content() (ë¼ì¸ 135-): ë¦¬í”„ íŒŒì¼ì—ì„œ ë‚´ìš© ë¡œë“œ
    - update_section() (ë¼ì¸ 155-): íŒŒì¼ ì„¹ì…˜ ì—…ë°ì´íŠ¸
    - process_all_leaf_nodes_parallel() (ë¼ì¸ 175-): ë³‘ë ¬ ì²˜ë¦¬ ê´€ë¦¬ìž
ìƒíƒœ: í™œì„±  
ì£¼ì†Œ: leaf_node_processor_v2
ì°¸ì¡°: leaf_node_processor.py (ê¸°ì¡´ ë²„ì „), content_analysis_module.py, logging_system.py
"""

import asyncio
import time
from pathlib import Path
from typing import List, Dict, Optional, Any
from node_structure_analyzer import Node
from content_analysis_module import ContentAnalyzer
from logging_system import ProcessLogger, ReportGenerator


class LeafNodeProcessor:
    """ê³µí†µ ëª¨ë“ˆì„ ì‚¬ìš©í•˜ëŠ” ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ í´ëž˜ìŠ¤ V2"""
    
    def __init__(self, output_dir: str, max_concurrent_tasks: int = 2):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.max_concurrent_tasks = max_concurrent_tasks
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        
        # ê³µí†µ ëª¨ë“ˆ ì´ˆê¸°í™”
        self.logger = ProcessLogger("leaf_node_processor", self.output_dir)
        self.content_analyzer = ContentAnalyzer(self.logger.logger)
        self.report_generator = ReportGenerator(self.output_dir)
        
        # ì²˜ë¦¬ í†µê³„
        self.processing_stats = {
            "total_nodes": 0,
            "successful_nodes": 0,
            "failed_nodes": 0,
            "node_results": {}
        }
    
    def create_leaf_info_file(self, node: Node) -> Path:
        """ë¦¬í”„ ë…¸ë“œ ì •ë³´ íŒŒì¼ ê¸°ë³¸ êµ¬ì¡° ìƒì„±"""
        safe_title = node.title.replace(" ", "_").replace("/", "_").replace("\\", "_")
        info_file_path = self.output_dir / f"leaf_{safe_title}_info.md"
        
        template = """# ì¶”ê°€ ì •ë³´

## í•µì‹¬ ë‚´ìš©

## ìƒì„¸ í•µì‹¬ ë‚´ìš©

## ì£¼ìš” í™”ì œ

## ë¶€ì°¨ í™”ì œ
"""
        
        with open(info_file_path, 'w', encoding='utf-8') as f:
            f.write(template)
        
        self.logger.log_operation(f"ì •ë³´íŒŒì¼ìƒì„±_{node.title}", "ì„±ê³µ", {"íŒŒì¼ê²½ë¡œ": str(info_file_path)})
        return info_file_path

    async def process_single_leaf_node(self, node: Node, leaf_content_dir: Path) -> tuple:
        """ë‹¨ì¼ ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ (ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©)"""
        async with self.semaphore:
            operation_start_time = time.time()
            node_name = node.title
            
            try:
                self.logger.log_operation(f"ë…¸ë“œì²˜ë¦¬ì‹œìž‘_{node_name}", "ì‹œìž‘")
                
                # 1. ë¦¬í”„ ë…¸ë“œ ë‚´ìš© ë¡œë“œ
                leaf_content = self.load_leaf_content(node, leaf_content_dir)
                
                if not leaf_content:
                    self.logger.log_operation(f"ë…¸ë“œì²˜ë¦¬_{node_name}", "ì‹¤íŒ¨", {"ì´ìœ ": "ë¦¬í”„ ë‚´ìš© ë¡œë“œ ì‹¤íŒ¨"})
                    return (node, False)
                
                self.logger.log_operation(f"ë‚´ìš©ë¡œë“œ_{node_name}", "ì„±ê³µ", 
                                        {"ë‚´ìš©ê¸¸ì´": len(leaf_content), "ë¬¸ìžìˆ˜": len(leaf_content)})
                
                # 2. ì •ë³´ íŒŒì¼ ìƒì„±
                info_file_path = self.create_leaf_info_file(node)
                
                # 3. 4ê°€ì§€ ì •ë³´ ì¶”ì¶œ (ê³µí†µ ëª¨ë“ˆ ì‚¬ìš©)
                analysis_start_time = time.time()
                self.logger.log_operation(f"4ê°€ì§€ë¶„ì„ì‹œìž‘_{node_name}", "ì‹œìž‘")
                
                analysis_result = await self.content_analyzer.analyze_content(
                    content=leaf_content,
                    title=node_name,
                    context_type="section"
                )
                
                analysis_duration = time.time() - analysis_start_time
                self.logger.log_operation(f"4ê°€ì§€ë¶„ì„ì™„ë£Œ_{node_name}", "ì„±ê³µ", 
                                        {"ì†Œìš”ì‹œê°„": f"{analysis_duration:.2f}ì´ˆ"}, analysis_duration)
                
                # 4. ê²°ê³¼ë¥¼ íŒŒì¼ì— ì—…ë°ì´íŠ¸
                update_start_time = time.time()
                success_count = 0
                
                for section_name, content in analysis_result.items():
                    if content and not content.startswith("ë¶„ì„ ì‹¤íŒ¨") and len(content.strip()) > 0:
                        if self.update_section(info_file_path, section_name, content):
                            success_count += 1
                            self.logger.log_operation(f"ì„¹ì…˜ì—…ë°ì´íŠ¸_{node_name}_{section_name}", "ì„±ê³µ",
                                                    {"ë‚´ìš©ê¸¸ì´": len(content)})
                        else:
                            self.logger.log_operation(f"ì„¹ì…˜ì—…ë°ì´íŠ¸_{node_name}_{section_name}", "ì‹¤íŒ¨")
                    else:
                        self.logger.log_operation(f"ì„¹ì…˜ì—…ë°ì´íŠ¸_{node_name}_{section_name}", "ì‹¤íŒ¨",
                                                {"ì´ìœ ": "ë¶„ì„ ê²°ê³¼ ì—†ìŒ ë˜ëŠ” ì˜¤ë¥˜"})
                
                update_duration = time.time() - update_start_time
                
                # 5. ìž‘ì—… ì™„ë£Œ í›„ íŒŒì¼ëª… ë³€ê²½
                total_duration = time.time() - operation_start_time
                
                if success_count == 4:
                    filled_path = self.rename_to_filled(info_file_path)
                    self.logger.log_operation(f"ë…¸ë“œì²˜ë¦¬ì™„ë£Œ_{node_name}", "ì„±ê³µ", 
                                            {"ì„±ê³µì„¹ì…˜": f"{success_count}/4", 
                                             "ìµœì¢…íŒŒì¼": filled_path.name,
                                             "ì´ì†Œìš”ì‹œê°„": f"{total_duration:.2f}ì´ˆ"}, total_duration)
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self.processing_stats["successful_nodes"] += 1
                    self.processing_stats["node_results"][node_name] = {
                        "status": "ì„±ê³µ",
                        "success": True,
                        "updated_sections": list(analysis_result.keys()),
                        "duration": total_duration
                    }
                    
                    return (node, True)
                else:
                    self.logger.log_operation(f"ë…¸ë“œì²˜ë¦¬ë¶€ë¶„ì‹¤íŒ¨_{node_name}", "ê²½ê³ ", 
                                            {"ì„±ê³µì„¹ì…˜": f"{success_count}/4",
                                             "ì´ì†Œìš”ì‹œê°„": f"{total_duration:.2f}ì´ˆ"}, total_duration)
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self.processing_stats["failed_nodes"] += 1
                    self.processing_stats["node_results"][node_name] = {
                        "status": f"ë¶€ë¶„ì‹¤íŒ¨ ({success_count}/4 ì„¹ì…˜ ì„±ê³µ)",
                        "success": False,
                        "updated_sections": [k for k, v in analysis_result.items() if v and len(v.strip()) > 0],
                        "duration": total_duration
                    }
                    
                    return (node, False)
                
            except Exception as e:
                total_duration = time.time() - operation_start_time
                self.logger.log_error(f"ë…¸ë“œì²˜ë¦¬_{node_name}", e, {"ì†Œìš”ì‹œê°„": f"{total_duration:.2f}ì´ˆ"})
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                self.processing_stats["failed_nodes"] += 1
                self.processing_stats["node_results"][node_name] = {
                    "status": "ì˜¤ë¥˜ ë°œìƒ",
                    "success": False,
                    "error": str(e),
                    "duration": total_duration
                }
                
                return (node, False)

    def load_leaf_content(self, node: Node, content_dir: Path) -> Optional[str]:
        """ë¦¬í”„ ë…¸ë“œì˜ ë‚´ìš©ì„ ë¡œë“œ (leaf_ë¡œ ì‹œìž‘í•˜ëŠ” íŒŒì¼ì—ì„œ)"""
        safe_title = node.title.replace(" ", "_").replace("/", "_").replace("\\", "_")
        
        # leaf_ë¡œ ì‹œìž‘í•˜ëŠ” íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ë‚´ìš© ë¡œë“œ
        possible_files = [
            content_dir / f"leaf_{safe_title}.md",
            content_dir / f"leaf_{safe_title}_info_filled.md"
        ]
        
        for file_path in possible_files:
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    self.logger.log_operation(f"íŒŒì¼ë¡œë“œ_{node.title}", "ì„±ê³µ", 
                                            {"íŒŒì¼ê²½ë¡œ": str(file_path), "ë‚´ìš©ê¸¸ì´": len(content)})
                    return content
                except Exception as e:
                    self.logger.log_error(f"íŒŒì¼ì½ê¸°_{node.title}", e, {"íŒŒì¼ê²½ë¡œ": str(file_path)})
        
        self.logger.log_operation(f"íŒŒì¼ë¡œë“œ_{node.title}", "ì‹¤íŒ¨", 
                                {"ì‹œë„í•œíŒŒì¼ë“¤": [str(f) for f in possible_files]})
        return None

    def update_section(self, file_path: Path, header: str, content: str) -> bool:
        """íŒŒì¼ì˜ íŠ¹ì • í—¤ë” ì„¹ì…˜ì— ë‚´ìš© ì—…ë°ì´íŠ¸"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            header_pattern = f"## {header}"
            header_start = text.find(header_pattern)
            
            if header_start == -1:
                self.logger.log_validation(f"í—¤ë”ì°¾ê¸°_{header}", False, f"í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {header}")
                return False
            
            content_start = header_start + len(header_pattern)
            next_header_start = text.find("\n## ", content_start)
            
            if next_header_start == -1:
                new_text = text[:content_start] + f"\n{content}\n"
            else:
                new_text = text[:content_start] + f"\n{content}\n" + text[next_header_start:]
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_text)
            
            return True
            
        except Exception as e:
            self.logger.log_error(f"ì„¹ì…˜ì—…ë°ì´íŠ¸_{header}", e)
            return False

    async def process_all_leaf_nodes_parallel(self, leaf_nodes: List[Node], leaf_content_dir: Path) -> int:
        """ëª¨ë“  ë¦¬í”„ ë…¸ë“œë¥¼ ë³‘ë ¬ ì²˜ë¦¬ (ê³µí†µ ëª¨ë“ˆ ë° ë¡œê¹… ì‚¬ìš©)"""
        process_info = {
            "ì´ë…¸ë“œìˆ˜": len(leaf_nodes),
            "ìµœëŒ€ë™ì‹œìž‘ì—…": self.max_concurrent_tasks,
            "ë¦¬í”„ë‚´ìš©ë””ë ‰í† ë¦¬": str(leaf_content_dir),
            "ì¶œë ¥ë””ë ‰í† ë¦¬": str(self.output_dir)
        }
        
        self.logger.log_process_start(process_info)
        self.processing_stats["total_nodes"] = len(leaf_nodes)
        
        start_time = time.time()
        
        # ëª¨ë“  ìž‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•  íƒœìŠ¤í¬ ìƒì„±
        tasks = []
        for node in leaf_nodes:
            task = self.process_single_leaf_node(node, leaf_content_dir)
            tasks.append(task)
        
        try:
            self.logger.log_operation("ë³‘ë ¬ì²˜ë¦¬ì‹œìž‘", "ì‹œìž‘", {"ìž‘ì—…ìˆ˜": len(tasks)})
            
            # ëª¨ë“  íƒœìŠ¤í¬ ë³‘ë ¬ ì‹¤í–‰
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ë¶„ì„
            success_count = 0
            error_count = 0
            
            for result in results:
                if isinstance(result, Exception):
                    error_count += 1
                    self.logger.log_error("ë³‘ë ¬ìž‘ì—…", result)
                else:
                    node, success = result
                    if success:
                        success_count += 1
            
            elapsed_time = time.time() - start_time
            
            # ì²˜ë¦¬ ì™„ë£Œ ë¡œê¹…
            summary = {
                "ì„±ê³µë…¸ë“œ": f"{success_count}/{len(leaf_nodes)}",
                "ì‹¤íŒ¨ë…¸ë“œ": f"{len(leaf_nodes) - success_count}/{len(leaf_nodes)}",
                "ì„±ê³µë¥ ": f"{(success_count/len(leaf_nodes)*100):.1f}%",
                "ì´ì²˜ë¦¬ì‹œê°„": f"{elapsed_time:.2f}ì´ˆ",
                "í‰ê· ì²˜ë¦¬ì†ë„": f"{len(leaf_nodes)/elapsed_time:.2f} ë…¸ë“œ/ì´ˆ"
            }
            
            self.logger.log_process_end(success_count > len(leaf_nodes) // 2, summary)
            
            # ë³´ê³ ì„œ ìƒì„±
            process_report = self.logger.create_process_report()
            update_report = self.report_generator.generate_update_report(
                "leaf_node_processor", self.processing_stats["node_results"]
            )
            
            self.logger.log_operation("ë³´ê³ ì„œìƒì„±", "ì„±ê³µ", 
                                    {"í”„ë¡œì„¸ìŠ¤ë³´ê³ ì„œ": process_report.name,
                                     "ì—…ë°ì´íŠ¸ë³´ê³ ì„œ": update_report.name})
            
            return success_count
            
        except Exception as e:
            self.logger.log_error("ë³‘ë ¬ì²˜ë¦¬", e)
            self.logger.log_process_end(False, {"ì˜¤ë¥˜": str(e)})
            return 0

    def rename_to_filled(self, info_file_path: Path) -> Path:
        """ì •ë³´ íŒŒì¼ëª…ì„ _filled ì ‘ë¯¸ì‚¬ë¡œ ë³€ê²½"""
        filled_path = info_file_path.parent / f"{info_file_path.stem}_filled.md"
        info_file_path.rename(filled_path)
        return filled_path


async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    from node_structure_analyzer import NodeStructureAnalyzer
    
    json_path = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-12/chapter7_clean.json"
    leaf_content_dir = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-12"  # leaf_ íŒŒì¼ë“¤ì´ ìžˆëŠ” ë””ë ‰í† ë¦¬
    output_dir = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-12"
    
    print("=" * 60)
    print("ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ ì‹œìŠ¤í…œ V2 - ê³µí†µ ëª¨ë“ˆ ë²„ì „")
    print("=" * 60)
    
    # ë…¸ë“œ êµ¬ì¡° ë¶„ì„
    analyzer = NodeStructureAnalyzer(json_path, "")
    if not analyzer.load_json_structure():
        return
    
    # ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ (ë³‘ë ¬, MAX_CONCURRENT_TASKS=2)
    processor = LeafNodeProcessor(output_dir, max_concurrent_tasks=2)
    leaf_nodes = analyzer.get_leaf_nodes()
    
    print(f"ðŸŽ¯ ì²˜ë¦¬ ëŒ€ìƒ: {len(leaf_nodes)}ê°œ ë¦¬í”„ ë…¸ë“œ")
    print(f"ðŸ“‚ ë¦¬í”„ ë‚´ìš© ë””ë ‰í† ë¦¬: {leaf_content_dir}")
    
    # ë¹„ë™ê¸° ë³‘ë ¬ ì‹¤í–‰
    success_count = await processor.process_all_leaf_nodes_parallel(leaf_nodes, Path(leaf_content_dir))
    
    print(f"\nðŸŽ¯ ìµœì¢… ê²°ê³¼: {success_count}/{len(leaf_nodes)} ë¦¬í”„ ë…¸ë“œ ì²˜ë¦¬ ì„±ê³µ")
    
    # ìƒì„±ëœ íŒŒì¼ í™•ì¸
    print(f"\nðŸ“ ìƒì„±ëœ íŒŒì¼ í™•ì¸:")
    output_path = Path(output_dir)
    filled_files = list(output_path.glob("leaf_*_info_filled.md"))
    
    print(f"  - leaf_*_info_filled.md: {len(filled_files)}ê°œ")
    for file in filled_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
        print(f"    - {file.name}")
    if len(filled_files) > 5:
        print(f"    - ... ì™¸ {len(filled_files)-5}ê°œ")


if __name__ == "__main__":
    asyncio.run(main())