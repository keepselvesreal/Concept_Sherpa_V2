"""
ìƒì„± ì‹œê°„: 2025-08-21 16:35:15 KST
í•µì‹¬ ë‚´ìš©: ì‹¤ì œ IDE ë¼ì¸ ë²ˆí˜¸ì™€ ë‚´ìš© ëˆ„ë½ ê°ì§€ fallbackì„ í¬í•¨í•œ ëŒ€ë³¸ êµ¬ì¡°í™” ìŠ¤í¬ë¦½íŠ¸
ìƒì„¸ ë‚´ìš©:
    - extract_transcript_content(file_path): ë©”íƒ€ë°ì´í„°ì™€ ëŒ€ë³¸ ë‚´ìš© ë¶„ë¦¬
    - extract_first_last_sentences(transcript_content): ì²«/ë§ˆì§€ë§‰ ë¬¸ì¥ ì¶”ì¶œ ë° í•„ëŸ¬ ì›Œë“œ ì œê±°
    - check_content_coverage(original_sentences, improved_content): ë‚´ìš© ëˆ„ë½ ê²€ì‚¬
    - improve_transcript_with_claude(transcript_content, retry_count): Claude SDK í˜¸ì¶œ (fallback í¬í•¨)
    - update_actual_line_numbers(file_path): ì‹¤ì œ IDE ë¼ì¸ ë²ˆí˜¸ë¡œ ì—…ë°ì´íŠ¸
    - main(): ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
ìƒíƒœ: í™œì„±
ì£¼ì†Œ: transcript_improver_v4
ì°¸ì¡°: transcript_improver_v3
"""

import os
import re
import sys
import asyncio
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple, Set

from claude_code_sdk import query, ClaudeCodeOptions, AssistantMessage, TextBlock
from claude_code_sdk import CLINotFoundError, ProcessError, CLIJSONDecodeError


def extract_transcript_content(file_path: str) -> Tuple[Dict, str, List[str], int]:
    """
    ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„°ì™€ ëŒ€ë³¸ ë‚´ìš©ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        file_path (str): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        tuple: (metadata, transcript_content, original_lines, transcript_start_line)
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.strip().split('\n')
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì²´í¬ë°•ìŠ¤ í˜•íƒœ ì§€ì›)
        metadata = {}
        title = ""
        in_metadata = False
        transcript_start_idx = 0
        current_field = None
        
        for i, line in enumerate(lines):
            if line.startswith('# '):
                title = line[2:].strip()
                metadata['title'] = title
            elif line.startswith('**Source Type:**'):
                current_field = 'source_type'
                in_metadata = True
            elif line.startswith('**Source:**'):
                metadata['source'] = line.split(':', 1)[1].strip()
                current_field = None
            elif line.startswith('**Source Language:**'):
                current_field = 'source_language'
            elif line.startswith('**Structure Type:**'):
                current_field = 'structure_type'
            elif line.startswith('**Content Processing:**'):
                current_field = 'content_processing'
            elif line.startswith('**Extracted Time:**'):
                metadata['extracted_time'] = line.split(':', 1)[1].strip()
                current_field = None
            elif current_field and line.strip().startswith('- [x]'):
                # ì²´í¬ëœ í•­ëª© ì¶”ì¶œ
                checked_value = line.strip().replace('- [x] ', '')
                metadata[current_field] = checked_value
            elif line.strip() == '---' and in_metadata:
                transcript_start_idx = i + 1
                break
        
        # ëŒ€ë³¸ ë‚´ìš©ë§Œ ì¶”ì¶œ (ë¼ì¸ ë²ˆí˜¸ ì •ë³´ ì—†ì´)
        transcript_lines = lines[transcript_start_idx:]
        transcript_content = ""
        
        for line in transcript_lines:
            line = line.strip()
            if line and line.startswith('['):
                # [MM:SS] í˜•ì‹ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                match = re.match(r'\[(\d{2}):(\d{2})\] (.+)', line)
                if match:
                    transcript_content += f"{line}\n"
        
        return metadata, transcript_content.strip(), lines, transcript_start_idx + 1
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {}, "", [], 0


def extract_first_last_sentences(transcript_content: str) -> Tuple[Set[str], Set[str]]:
    """
    ëŒ€ë³¸ì—ì„œ ì²« ë¬¸ì¥ê³¼ ë§ˆì§€ë§‰ ë¬¸ì¥ì„ ì¶”ì¶œí•˜ê³  í•„ëŸ¬ ì›Œë“œë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    
    Args:
        transcript_content (str): ëŒ€ë³¸ ë‚´ìš©
        
    Returns:
        tuple: (first_sentence_words, last_sentence_words) - í•„ëŸ¬ ì›Œë“œ ì œê±°ëœ ë‹¨ì–´ ì§‘í•©
    """
    try:
        lines = [line.strip() for line in transcript_content.strip().split('\n') if line.strip()]
        
        if not lines:
            return set(), set()
        
        # ì²« ë¬¸ì¥ê³¼ ë§ˆì§€ë§‰ ë¬¸ì¥ ì¶”ì¶œ
        first_line = lines[0]
        last_line = lines[-1]
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        first_text = re.sub(r'\[\d{2}:\d{2}\]\s*', '', first_line)
        last_text = re.sub(r'\[\d{2}:\d{2}\]\s*', '', last_line)
        
        # í•„ëŸ¬ ì›Œë“œ ëª©ë¡
        filler_words = {
            'um', 'uh', 'ah', 'you', 'know', 'like', 'so', 'well', 'okay', 'right',
            'actually', 'basically', 'literally', 'really', 'just', 'kind', 'of', 'sort'
        }
        
        # ë‹¨ì–´ ì¶”ì¶œ ë° í•„ëŸ¬ ì›Œë“œ ì œê±°
        def extract_clean_words(text: str) -> Set[str]:
            words = re.findall(r'\b\w+\b', text.lower())
            return {word for word in words if word not in filler_words and len(word) > 2}
        
        first_words = extract_clean_words(first_text)
        last_words = extract_clean_words(last_text)
        
        return first_words, last_words
        
    except Exception as e:
        print(f"âŒ ì²«/ë§ˆì§€ë§‰ ë¬¸ì¥ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return set(), set()


def check_content_coverage(original_first_words: Set[str], original_last_words: Set[str], 
                          improved_content: str) -> bool:
    """
    êµ¬ì¡°í™”ëœ ë‚´ìš©ì— ì›ë³¸ì˜ ì²«/ë§ˆì§€ë§‰ ë¬¸ì¥ ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        original_first_words (Set[str]): ì›ë³¸ ì²« ë¬¸ì¥ì˜ ë‹¨ì–´ë“¤
        original_last_words (Set[str]): ì›ë³¸ ë§ˆì§€ë§‰ ë¬¸ì¥ì˜ ë‹¨ì–´ë“¤
        improved_content (str): êµ¬ì¡°í™”ëœ ë‚´ìš©
        
    Returns:
        bool: ì¶©ë¶„í•œ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ True
    """
    try:
        improved_text = improved_content.lower()
        
        # ì²« ë¬¸ì¥ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        first_found = any(word in improved_text for word in original_first_words)
        
        # ë§ˆì§€ë§‰ ë¬¸ì¥ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸  
        last_found = any(word in improved_text for word in original_last_words)
        
        return first_found and last_found
        
    except Exception as e:
        print(f"âŒ ë‚´ìš© í¬í•¨ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return True  # ì˜¤ë¥˜ ì‹œ í†µê³¼


async def improve_transcript_with_claude(transcript_content: str, original_first_words: Set[str], 
                                       original_last_words: Set[str], max_retries: int = 2) -> str:
    """
    Claude Code SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ë³¸ì„ êµ¬ì¡°í™”í•©ë‹ˆë‹¤ (fallback í¬í•¨).
    
    Args:
        transcript_content (str): ìˆœìˆ˜ ëŒ€ë³¸ ë‚´ìš©
        original_first_words (Set[str]): ì›ë³¸ ì²« ë¬¸ì¥ ë‹¨ì–´ë“¤
        original_last_words (Set[str]): ì›ë³¸ ë§ˆì§€ë§‰ ë¬¸ì¥ ë‹¨ì–´ë“¤
        max_retries (int): ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
    Returns:
        str: êµ¬ì¡°í™”ëœ ëŒ€ë³¸ ë‚´ìš©
    """
    for attempt in range(max_retries + 1):
        try:
            # Claude Code SDK ì˜µì…˜ ì„¤ì •
            options = ClaudeCodeOptions(
                system_prompt="ë‹¹ì‹ ì€ YouTube ëŒ€ë³¸ì„ êµ¬ì¡°í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
                max_turns=1
            )
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = f"""Please structure this YouTube transcript:

{transcript_content}

**ALLOWED OPERATIONS:**
1. Combine semantically related sentences into appropriate units
2. Remove filler words (um, uh, ah, you know, like, etc.)
3. Divide content into 5-7 sections with ## English section titles
4. Keep the start time in [MM:SS] format for each combined sentence
5. IMPORTANT: Include ALL content from beginning to end

**FORBIDDEN OPERATIONS:**
- Fix grammatical errors
- Improve incomplete sentences  
- Remove repetitive content
- Change or paraphrase original content
- Replace words or expressions
- Skip any part of the transcript

OUTPUT FORMAT:
## English Section Title

[time] Original content (with filler words removed and semantically combined)

Please follow these guidelines to only remove filler words, combine sentences by semantic units, and divide into 5-7 sections with ENGLISH section titles. NEVER skip any content - include everything from start to finish."""

            # Claude Code SDK í˜¸ì¶œ
            response_content = ""
            async for message in query(prompt=user_prompt, options=options):
                if isinstance(message, AssistantMessage):
                    for block in message.content:
                        if isinstance(block, TextBlock):
                            response_content += block.text
            
            if response_content:
                # ë‚´ìš© í¬í•¨ í™•ì¸
                if check_content_coverage(original_first_words, original_last_words, response_content):
                    print(f"âœ… ë‚´ìš© í¬í•¨ ê²€ì¦ í†µê³¼ (ì‹œë„ {attempt + 1}/{max_retries + 1})")
                    return response_content.strip()
                else:
                    if attempt < max_retries:
                        print(f"âš ï¸ ë‚´ìš© ëˆ„ë½ ê°ì§€ - ì¬ì‹œë„ {attempt + 1}/{max_retries}")
                        continue
                    else:
                        print(f"âš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬ - ë¶€ë¶„ ê²°ê³¼ ì‚¬ìš©")
                        return response_content.strip()
            else:
                print(f"âŒ ë¹ˆ ì‘ë‹µ ìˆ˜ì‹  (ì‹œë„ {attempt + 1}/{max_retries + 1})")
                
        except (CLINotFoundError, ProcessError, CLIJSONDecodeError) as e:
            print(f"âŒ Claude Code SDK ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {str(e)}")
        except Exception as e:
            print(f"âŒ Claude SDK í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {str(e)}")
    
    return ""


def update_actual_line_numbers(file_path: str) -> None:
    """
    êµ¬ì¡°í™”ëœ íŒŒì¼ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ë¼ì¸ ì•ì— "Line X:" ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        file_path (str): êµ¬ì¡°í™”ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        updated_lines = []
        for line_num, line in enumerate(lines, start=1):
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì‹œì‘í•˜ëŠ” ë¼ì¸ ([MM:SS])ì„ ì°¾ì•„ì„œ Line ì •ë³´ ì¶”ê°€
            if re.search(r'^\[\d{2}:\d{2}\]', line.strip()):
                updated_line = f"Line {line_num}: {line}"
                updated_lines.append(updated_line)
                print(f"ì—…ë°ì´íŠ¸: Line {line_num} - {line.strip()[:50]}...")
            else:
                updated_lines.append(line)
        
        # íŒŒì¼ì— ë‹¤ì‹œ ì €ì¥
        with open(file_path, 'w', encoding='utf-8') as f:
            f.writelines(updated_lines)
            
        print("âœ… ì‹¤ì œ IDE ë¼ì¸ ë²ˆí˜¸ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ë¼ì¸ ë²ˆí˜¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")


def combine_with_metadata(metadata: Dict, improved_content: str) -> str:
    """
    ë©”íƒ€ë°ì´í„°ì™€ êµ¬ì¡°í™”ëœ ëŒ€ë³¸ì„ ê²°í•©í•©ë‹ˆë‹¤ (ì²´í¬ë°•ìŠ¤ í˜•íƒœ).
    
    Args:
        metadata (Dict): ì›ë³¸ ë©”íƒ€ë°ì´í„°
        improved_content (str): êµ¬ì¡°í™”ëœ ëŒ€ë³¸
        
    Returns:
        str: ìµœì¢… ë§ˆí¬ë‹¤ìš´ ë‚´ìš©
    """
    title = metadata.get('title', 'YouTube Transcript')
    source_type = metadata.get('source_type', 'youtube')
    source = metadata.get('source', '')
    source_language = metadata.get('source_language', 'en')
    structure_type = metadata.get('structure_type', 'standalone')
    content_processing = metadata.get('content_processing', 'unified')
    extracted_time = metadata.get('extracted_time', '')
    
    # Source Type ì²´í¬ë°•ìŠ¤
    source_type_checkboxes = f"""- {"[x]" if source_type == "book" else "[ ]"} book
- {"[x]" if source_type == "post" else "[ ]"} post
- {"[x]" if source_type == "youtube" else "[ ]"} youtube"""
    
    # Source Language ì²´í¬ë°•ìŠ¤
    language_checkboxes = f"""- {"[x]" if source_language in ["ko", "korean"] else "[ ]"} korean
- {"[x]" if source_language in ["en", "english"] else "[ ]"} english
- {"[x]" if source_language not in ["ko", "korean", "en", "english"] else "[ ]"} other"""
    
    # Structure Type ì²´í¬ë°•ìŠ¤
    structure_type_checkboxes = f"""- {"[x]" if structure_type == "standalone" else "[ ]"} standalone
- {"[x]" if structure_type == "component" else "[ ]"} component"""
    
    # Content Processing ì²´í¬ë°•ìŠ¤
    content_processing_checkboxes = f"""- {"[x]" if content_processing == "unified" else "[ ]"} unified
- {"[x]" if content_processing == "segmented" else "[ ]"} segmented"""
    
    # ì²´í¬ë°•ìŠ¤ í˜•íƒœ í—¤ë” ìƒì„±
    header = f"""# {title}

**Source Type:**
{source_type_checkboxes}

**Source:** {source}

**Source Language:**
{language_checkboxes}

**Structure Type:**
{structure_type_checkboxes}

**Content Processing:**
{content_processing_checkboxes}

**Extracted Time:** {extracted_time}

---

"""
    
    return header + improved_content


def save_improved_transcript(content: str, output_file: str) -> bool:
    """
    ê°œì„ ëœ ëŒ€ë³¸ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        content (str): ì €ì¥í•  ë‚´ìš©
        output_file (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        return True
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


async def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("ğŸ¤– Claude Code SDK ëŒ€ë³¸ êµ¬ì¡°í™”ê¸° v4")
    print("=" * 50)
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        input_file = input("êµ¬ì¡°í™”í•  ëŒ€ë³¸ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    
    if not input_file or not os.path.exists(input_file):
        print("âŒ ìœ íš¨í•œ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_file}")
    print("ğŸ”‘ Claude Code SDK í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘...")
    
    # ë©”íƒ€ë°ì´í„°ì™€ ëŒ€ë³¸ ë‚´ìš© ë¶„ë¦¬
    print("ğŸ“– ë©”íƒ€ë°ì´í„°ì™€ ëŒ€ë³¸ ë‚´ìš© ë¶„ë¦¬ ì¤‘...")
    metadata, transcript_content, original_lines, transcript_start_line = extract_transcript_content(input_file)
    
    if not transcript_content:
        print("âŒ ëŒ€ë³¸ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    transcript_line_count = len([line for line in transcript_content.split('\n') if line.strip()])
    print(f"âœ… ë©”íƒ€ë°ì´í„° ë¶„ë¦¬ ì™„ë£Œ")
    print(f"âœ… {transcript_line_count}ê°œì˜ ëŒ€ë³¸ í•­ëª© ì¶”ì¶œ")
    
    # ì²«/ë§ˆì§€ë§‰ ë¬¸ì¥ ì¶”ì¶œ ë° í•„ëŸ¬ ì›Œë“œ ì œê±°
    print("ğŸ” ë‚´ìš© ëˆ„ë½ ê°ì§€ë¥¼ ìœ„í•œ ê¸°ì¤€ ë¬¸ì¥ ì¶”ì¶œ ì¤‘...")
    first_words, last_words = extract_first_last_sentences(transcript_content)
    print(f"âœ… ê¸°ì¤€ ë‹¨ì–´ ì¶”ì¶œ ì™„ë£Œ (ì²« ë¬¸ì¥: {len(first_words)}ê°œ, ë§ˆì§€ë§‰ ë¬¸ì¥: {len(last_words)}ê°œ)")
    
    # Claude Code SDKë¡œ ëŒ€ë³¸ êµ¬ì¡°í™” (fallback í¬í•¨)
    print("ğŸ¤– Claude Code SDKë¡œ ì „ì²´ ëŒ€ë³¸ êµ¬ì¡°í™” ì¤‘...")
    print("   - í•„ëŸ¬ ì›Œë“œ ì œê±°")
    print("   - ì˜ë¯¸ ë‹¨ìœ„ ë¬¸ì¥ í•©ì¹˜ê¸°")  
    print("   - 5-7ê°œ ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„")
    print("   - ì „ì²´ ëŒ€ë³¸ ì²˜ë¦¬")
    print("   - ë‚´ìš© ëˆ„ë½ ê°ì§€ ë° fallback")
    
    improved_content = await improve_transcript_with_claude(transcript_content, first_words, last_words)
    
    if not improved_content:
        print("âŒ ëŒ€ë³¸ êµ¬ì¡°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    print("âœ… ëŒ€ë³¸ êµ¬ì¡°í™” ì™„ë£Œ")
    
    # ë©”íƒ€ë°ì´í„°ì™€ ê²°í•©
    print("ğŸ”— ë©”íƒ€ë°ì´í„°ì™€ êµ¬ì¡°í™”ëœ ëŒ€ë³¸ ê²°í•© ì¤‘...")
    final_content = combine_with_metadata(metadata, improved_content)
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    output_file = f"{base_name}_structured.md"
    
    # íŒŒì¼ ì €ì¥
    print(f"ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘: {output_file}")
    if save_improved_transcript(final_content, output_file):
        print(f"âœ… ì„ì‹œ ì €ì¥ ì™„ë£Œ: {output_file}")
        
        # ì‹¤ì œ IDE ë¼ì¸ ë²ˆí˜¸ë¡œ ì—…ë°ì´íŠ¸
        print("ğŸ“ ì‹¤ì œ IDE ë¼ì¸ ë²ˆí˜¸ë¡œ ì—…ë°ì´íŠ¸ ì¤‘...")
        update_actual_line_numbers(output_file)
        
        # êµ¬ì¡°í™” ìš”ì•½ ì¶œë ¥
        sections = len([line for line in improved_content.split('\n') if line.strip().startswith('##')])
        print(f"ğŸ“Š êµ¬ì¡°í™” ìš”ì•½: {sections}ê°œ ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„")
        print(f"ğŸ“ ë¼ì¸ ë²ˆí˜¸: ì‹¤ì œ IDE ë¼ì¸ê³¼ ì¼ì¹˜")
        print(f"ğŸ›¡ï¸ ë‚´ìš© ëˆ„ë½ ê°ì§€: í™œì„±í™”ë¨")
    else:
        print("âŒ íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())