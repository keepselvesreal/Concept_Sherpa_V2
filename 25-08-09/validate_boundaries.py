#!/usr/bin/env python3
"""
ì¶”ì¶œëœ ê²½ê³„ ë§ˆì»¤ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ìƒì„±ëœ JSON íŒŒì¼ì˜ ê²½ê³„ ë§ˆì»¤ë“¤ì´ ì‹¤ì œë¡œ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ 
ì •í™•íˆ ì„¹ì…˜ì„ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import json
import re
from typing import Dict, List, Tuple


def normalize_for_comparison(text: str) -> str:
    """ë¹„êµë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def fuzzy_find(haystack: str, needle: str, threshold: float = 0.8) -> int:
    """ìœ ì‚¬ë„ ê¸°ë°˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰"""
    needle_norm = normalize_for_comparison(needle)
    
    # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
    pos = haystack.find(needle_norm)
    if pos >= 0:
        return pos
    
    # ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ì²˜ìŒ 50ìë§Œ)
    needle_short = needle_norm[:50]
    pos = haystack.find(needle_short)
    if pos >= 0:
        return pos
    
    return -1


def extract_section_by_boundaries(chapter_text: str, start_marker: str, end_marker: str) -> Tuple[str, int, int]:
    """ê²½ê³„ ë§ˆì»¤ë¥¼ ì‚¬ìš©í•´ì„œ ì„¹ì…˜ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    chapter_norm = normalize_for_comparison(chapter_text)
    
    # ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
    start_pos = fuzzy_find(chapter_norm, start_marker)
    if start_pos == -1:
        return "", -1, -1
    
    # ì¢…ë£Œ ìœ„ì¹˜ ì°¾ê¸° (ì‹œì‘ ìœ„ì¹˜ ì´í›„ë¶€í„°)
    end_pos = fuzzy_find(chapter_norm[start_pos:], end_marker)
    if end_pos == -1:
        return "", start_pos, -1
    
    end_pos = start_pos + end_pos + len(normalize_for_comparison(end_marker))
    
    # ì¶”ì¶œ
    extracted = chapter_norm[start_pos:end_pos]
    
    return extracted, start_pos, end_pos


def validate_extraction(chapter_text: str, nodes: List[Dict]) -> Dict:
    """ê²½ê³„ ë§ˆì»¤ë¥¼ ì‚¬ìš©í•œ ì„¹ì…˜ ì¶”ì¶œì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    
    results = {
        'total_nodes': len(nodes),
        'successful_extractions': 0,
        'failed_extractions': 0,
        'details': []
    }
    
    print("ğŸ” ê²½ê³„ ë§ˆì»¤ ê¸°ë°˜ ì„¹ì…˜ ì¶”ì¶œ ê²€ì¦ ì¤‘...")
    print("=" * 60)
    
    for node in nodes:
        title = node.get('title', '')
        start_marker = node.get('start_text', '')
        end_marker = node.get('end_text', '')
        expected_length = node.get('section_length', 0)
        
        if not start_marker or not end_marker:
            print(f"âŒ {title}: ë§ˆì»¤ ì—†ìŒ")
            results['failed_extractions'] += 1
            continue
        
        # ì„¹ì…˜ ì¶”ì¶œ ì‹œë„
        extracted_section, start_pos, end_pos = extract_section_by_boundaries(
            chapter_text, start_marker, end_marker
        )
        
        if extracted_section:
            extracted_length = len(extracted_section)
            success = True
            results['successful_extractions'] += 1
            
            print(f"âœ… {title}")
            print(f"   ì˜ˆìƒ ê¸¸ì´: {expected_length:,}ì")
            print(f"   ì¶”ì¶œ ê¸¸ì´: {extracted_length:,}ì")
            print(f"   ìœ„ì¹˜: {start_pos:,} - {end_pos:,}")
            
            # ê¸¸ì´ ì°¨ì´ê°€ í¬ë©´ ê²½ê³ 
            if abs(extracted_length - expected_length) > expected_length * 0.1:
                print(f"   âš ï¸  ê¸¸ì´ ì°¨ì´ê°€ í½ë‹ˆë‹¤ ({abs(extracted_length - expected_length):,}ì)")
                
        else:
            success = False
            results['failed_extractions'] += 1
            print(f"âŒ {title}: ì¶”ì¶œ ì‹¤íŒ¨")
            print(f"   ì‹œì‘ ë§ˆì»¤ ì°¾ê¸°: {'ì„±ê³µ' if start_pos >= 0 else 'ì‹¤íŒ¨'}")
            print(f"   ì¢…ë£Œ ë§ˆì»¤ ì°¾ê¸°: {'ì„±ê³µ' if end_pos >= 0 else 'ì‹¤íŒ¨'}")
        
        results['details'].append({
            'title': title,
            'success': success,
            'extracted_length': len(extracted_section) if extracted_section else 0,
            'expected_length': expected_length,
            'start_pos': start_pos,
            'end_pos': end_pos
        })
        
        print()
    
    return results


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê²½ê³„ ë§ˆì»¤ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    print("=" * 40)
    
    # íŒŒì¼ ê²½ë¡œ
    boundaries_json_path = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-09/chapter7_leaf_nodes_with_boundaries.json"
    chapter_text_path = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-09/extracted_texts/Level01_7 Basic data validation.md"
    
    # íŒŒì¼ ë¡œë“œ
    print("ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘...")
    with open(boundaries_json_path, 'r', encoding='utf-8') as f:
        nodes = json.load(f)
    
    with open(chapter_text_path, 'r', encoding='utf-8') as f:
        chapter_text = f.read()
    
    print(f"âœ… ë…¸ë“œ ìˆ˜: {len(nodes)}")
    print(f"âœ… ì›ë³¸ í…ìŠ¤íŠ¸: {len(chapter_text):,}ì")
    print()
    
    # ê²€ì¦ ì‹¤í–‰
    results = validate_extraction(chapter_text, nodes)
    
    # ê²°ê³¼ ìš”ì•½
    print("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
    print("=" * 40)
    print(f"ì „ì²´ ë…¸ë“œ: {results['total_nodes']}")
    print(f"ì¶”ì¶œ ì„±ê³µ: {results['successful_extractions']}")
    print(f"ì¶”ì¶œ ì‹¤íŒ¨: {results['failed_extractions']}")
    print(f"ì„±ê³µë¥ : {results['successful_extractions']/results['total_nodes']*100:.1f}%")
    
    # ì‹¤íŒ¨í•œ ë…¸ë“œë“¤ ìƒì„¸ ì •ë³´
    failed_nodes = [d for d in results['details'] if not d['success']]
    if failed_nodes:
        print(f"\nâŒ ì¶”ì¶œ ì‹¤íŒ¨ ë…¸ë“œë“¤:")
        for node in failed_nodes:
            print(f"  - {node['title']}")
    
    if results['successful_extractions'] == results['total_nodes']:
        print("\nğŸ‰ ëª¨ë“  ë…¸ë“œì—ì„œ ì„¹ì…˜ ì¶”ì¶œì´ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
        return 0
    else:
        print(f"\nâš ï¸  {results['failed_extractions']}ê°œ ë…¸ë“œì—ì„œ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return 1


if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)