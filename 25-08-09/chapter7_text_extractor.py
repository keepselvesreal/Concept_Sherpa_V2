#!/usr/bin/env python3
"""
ìƒì„± ì‹œê°„: 2025ë…„ 8ì›” 9ì¼ 12:46 KST
í•µì‹¬ ë‚´ìš©: Chapter 7 Basic Data Validation ë¦¬í”„ ë…¸ë“œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
ìƒì„¸ ë‚´ìš©:
    - extract_chapter7_text(): PDFì—ì„œ 7ì¥ í…ìŠ¤íŠ¸ ì¶”ì¶œí•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    - find_text_between(): ì‹œì‘/ì¢…ë£Œ ë¬¸ìì—´ ì‚¬ì´ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜  
    - clean_extracted_text(): ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ì •ê·œí™” í•¨ìˆ˜
    - save_extracted_texts(): ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë“¤ì„ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    - main(): ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜
ìƒíƒœ: ì‘ì„± ì™„ë£Œ
ì£¼ì†Œ: chapter7_text_extractor
ì°¸ì¡°: chapter7_leaf_nodes_with_boundaries.json ì‚¬ìš©
"""

import json
import re
import os
import sys
from pathlib import Path

# PyPDF2 import
try:
    import PyPDF2
except ImportError:
    print("PyPDF2ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install PyPDF2")
    sys.exit(1)

def load_leaf_nodes(json_path):
    """ê²½ê³„ ë¬¸ìì—´ì´ í¬í•¨ëœ ë¦¬í”„ ë…¸ë“œ ë°ì´í„° ë¡œë“œ"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # ì£¼ì„ ì œê±° (/* ... */ í˜•íƒœ)
            content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
            return json.loads(content)
    except Exception as e:
        print(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {json_path}: {e}")
        return []

def extract_pdf_text(pdf_path):
    """PDF ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            full_text = ""
            
            # í˜ì´ì§€ 169-190 (7ì¥ ë²”ìœ„)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì¶”ì¶œ
            start_page = 168  # 0-based index
            end_page = 195    # ì—¬ìœ ë¶„ í¬í•¨
            
            for page_num in range(start_page, min(end_page, len(pdf_reader.pages))):
                page = pdf_reader.pages[page_num]
                text = page.extract_text()
                full_text += text + "\n"
                
            return full_text
            
    except Exception as e:
        print(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ {pdf_path}: {e}")
        return ""

def find_text_between(full_text, start_text, end_text, node_title=""):
    """ì‹œì‘ ë¬¸ìì—´ê³¼ ì¢…ë£Œ ë¬¸ìì—´ ì‚¬ì´ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        full_text = re.sub(r'\s+', ' ', full_text)
        start_text = re.sub(r'\s+', ' ', start_text.strip())
        end_text = re.sub(r'\s+', ' ', end_text.strip())
        
        # ì‹œì‘ ë¬¸ìì—´ ì°¾ê¸°
        start_pattern = re.escape(start_text).replace(r'\ ', r'\s+')
        start_match = re.search(start_pattern, full_text, re.IGNORECASE)
        
        if not start_match:
            print(f"âš ï¸  '{node_title}' ì‹œì‘ ë¬¸ìì—´ ì°¾ì„ ìˆ˜ ì—†ìŒ: '{start_text}'")
            return ""
            
        start_pos = start_match.start()
        
        # ì¢…ë£Œ ë¬¸ìì—´ ì°¾ê¸° (ì‹œì‘ ìœ„ì¹˜ ì´í›„ì—ì„œ)
        end_pattern = re.escape(end_text).replace(r'\ ', r'\s+')
        end_match = re.search(end_pattern, full_text[start_pos:], re.IGNORECASE)
        
        if not end_match:
            print(f"âš ï¸  '{node_title}' ì¢…ë£Œ ë¬¸ìì—´ ì°¾ì„ ìˆ˜ ì—†ìŒ: '{end_text}'")
            # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ê¹Œì§€ ì¶”ì¶œ ì‹œë„
            next_section_patterns = [
                r'\d+\.\d+\s+[A-Z]',  # 7.1, 7.2 ë“±
                r'Summary\s*\n',
                r'Chapter\s+\d+'
            ]
            
            for pattern in next_section_patterns:
                next_match = re.search(pattern, full_text[start_pos + 100:], re.IGNORECASE)
                if next_match:
                    end_pos = start_pos + 100 + next_match.start()
                    extracted_text = full_text[start_pos:end_pos]
                    return clean_extracted_text(extracted_text)
            
            # ìµœëŒ€ 5000ìê¹Œì§€ë§Œ ì¶”ì¶œ
            extracted_text = full_text[start_pos:start_pos + 5000]
            return clean_extracted_text(extracted_text)
        
        end_pos = start_pos + end_match.end()
        extracted_text = full_text[start_pos:end_pos]
        
        return clean_extracted_text(extracted_text)
        
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜ '{node_title}': {e}")
        return ""

def clean_extracted_text(text):
    """ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ì •ê·œí™”"""
    if not text:
        return ""
    
    # ê¸°ë³¸ ì •ë¦¬
    text = text.strip()
    
    # í˜ì´ì§€ ë²ˆí˜¸ ì œê±°
    text = re.sub(r'=== í˜ì´ì§€ \d+ ===', '', text)
    text = re.sub(r'\n\d+\s+(CHAPTER|Summary)', r'\n\1', text)
    
    # ì—°ì†ëœ ê³µë°± ì •ë¦¬
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    text = re.sub(r' {2,}', ' ', text)
    
    # ì¤„ë°”ê¿ˆ ì •ë¦¬
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        line = line.strip()
        if line:
            cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)

def save_extracted_texts(extracted_data, output_dir):
    """ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë“¤ì„ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)
    
    for item in extracted_data:
        if item.get('extracted_text'):
            # íŒŒì¼ëª… ìƒì„±
            safe_title = re.sub(r'[^\w\s-]', '', item['title'])
            safe_title = re.sub(r'[-\s]+', '_', safe_title)
            filename = f"{item['id']:03d}_{safe_title}.md"
            filepath = os.path.join(output_dir, filename)
            
            # íŒŒì¼ ë‚´ìš© êµ¬ì„±
            content = f"# {item['title']}\n\n"
            content += f"**ID:** {item['id']}\n"
            content += f"**Level:** {item['level']}\n\n"
            content += "---\n\n"
            content += item['extracted_text']
            
            # íŒŒì¼ ì €ì¥
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            print(f"âœ… ì €ì¥: {filename} ({len(item['extracted_text'])} chars)")

def extract_chapter7_text():
    """Chapter 7 ë¦¬í”„ ë…¸ë“œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë©”ì¸ í•¨ìˆ˜"""
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = Path(__file__).parent
    json_path = current_dir / "chapter7_leaf_nodes_with_boundaries.json"
    pdf_path = current_dir / ".." / "2022_Data-Oriented Programming_Manning.pdf"
    output_dir = current_dir / "chapter7_extracted_texts"
    
    print("ğŸ“š Chapter 7 í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘...")
    
    # 1. ë¦¬í”„ ë…¸ë“œ ë°ì´í„° ë¡œë“œ
    leaf_nodes = load_leaf_nodes(json_path)
    if not leaf_nodes:
        print("âŒ ë¦¬í”„ ë…¸ë“œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
        
    print(f"ğŸ“‹ {len(leaf_nodes)}ê°œ ë¦¬í”„ ë…¸ë“œ ë¡œë“œ ì™„ë£Œ")
    
    # 2. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print("ğŸ“– PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘...")
    full_text = extract_pdf_text(pdf_path)
    if not full_text:
        print("âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
        return
        
    print(f"âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(full_text)} chars)")
    
    # 3. ê° ë¦¬í”„ ë…¸ë“œë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    extracted_data = []
    
    for node in leaf_nodes:
        print(f"\nğŸ” ì²˜ë¦¬ ì¤‘: {node['title']}")
        
        extracted_text = find_text_between(
            full_text, 
            node['start_text'], 
            node['end_text'],
            node['title']
        )
        
        if extracted_text:
            word_count = len(extracted_text.split())
            char_count = len(extracted_text)
            print(f"âœ… ì¶”ì¶œ ì„±ê³µ: {word_count} words, {char_count} chars")
            status = "success"
        else:
            word_count = 0
            char_count = 0
            print(f"âŒ ì¶”ì¶œ ì‹¤íŒ¨")
            status = "failed"
        
        extracted_data.append({
            'id': node['id'],
            'title': node['title'],
            'level': node['level'],
            'start_text': node['start_text'],
            'end_text': node['end_text'],
            'extracted_text': extracted_text,
            'word_count': word_count,
            'char_count': char_count,
            'extraction_status': status
        })
    
    # 4. ê²°ê³¼ ì €ì¥
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # JSON ê²°ê³¼ ì €ì¥
    result_file = current_dir / "chapter7_extracted_results.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(extracted_data, f, ensure_ascii=False, indent=2)
    
    # ê°œë³„ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
    save_extracted_texts(extracted_data, output_dir)
    
    # 5. ê²°ê³¼ ìš”ì•½
    successful = sum(1 for item in extracted_data if item['extraction_status'] == 'success')
    total_words = sum(item['word_count'] for item in extracted_data)
    total_chars = sum(item['char_count'] for item in extracted_data)
    
    print(f"\nğŸ“Š ì¶”ì¶œ ì™„ë£Œ ìš”ì•½:")
    print(f"   ì„±ê³µ: {successful}/{len(extracted_data)} ë…¸ë“œ")
    print(f"   ì´ ë‹¨ì–´ìˆ˜: {total_words:,}")
    print(f"   ì´ ë¬¸ììˆ˜: {total_chars:,}")
    print(f"   ê²°ê³¼ íŒŒì¼: {result_file}")
    print(f"   í…ìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: {output_dir}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        extract_chapter7_text()
    except KeyboardInterrupt:
        print("\nâŒ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()