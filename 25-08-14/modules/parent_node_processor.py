"""
ìƒì„± ì‹œê°„: 2025-08-14 20:11:03 KST
í•µì‹¬ ë‚´ìš©: ë¶€ëª¨ ë…¸ë“œ ì „ìš© ì²˜ë¦¬ ëª¨ë“ˆ - ìì‹ ë…¸ë“œ ìš°ì„  ì²˜ë¦¬ ë° ê°œì„ ëœ ì—…ë°ì´íŠ¸ ë¡œì§
ìƒì„¸ ë‚´ìš©:
    - ParentNodeProcessor í´ë˜ìŠ¤ (ë¼ì¸ 30-): ë¶€ëª¨ ë…¸ë“œ ì „ìš© ì²˜ë¦¬ ë¡œì§
    - DataLoader í´ë˜ìŠ¤ (ë¼ì¸ 280-): ë¶€ëª¨ ë…¸ë“œìš© ë°ì´í„° ë¡œë”© ì „ìš©
    - process_parent_node() (ë¼ì¸ 50-): 5ë‹¨ê³„ ë¶€ëª¨ ë…¸ë“œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    - process_children_first() (ë¼ì¸ 95-): process_status=falseì¸ ìì‹ ë…¸ë“œ ìš°ì„  ì²˜ë¦¬
    - update_child_extraction_sections() (ë¼ì¸ 135-): í•µì‹¬/ìƒì„¸í•µì‹¬ë§Œ ì—…ë°ì´íŠ¸
    - process_parent_extraction() (ë¼ì¸ 175-): ë¶€ëª¨ ë…¸ë“œ ì¶”ì¶œ ì‘ì—…
    - finalize_parent_extraction() (ë¼ì¸ 220-): ë¶€ëª¨ ë…¸ë“œ ìµœì¢… ì—…ë°ì´íŠ¸
ìƒíƒœ: í™œì„±
ì£¼ì†Œ: parent_node_processor/v3_integrated
ì°¸ì¡°: content_analysis_module_v3.py
"""

import asyncio
import time
from pathlib import Path
from typing import List, Dict, Any, Optional

from content_analysis_module_v3 import ContentAnalyzer
from logging_system_v2 import ProcessLogger


class ParentNodeProcessor:
    """ë¶€ëª¨ ë…¸ë“œ ì „ìš© ì²˜ë¦¬ í´ë˜ìŠ¤ - ìì‹ ë…¸ë“œ ìš°ì„  ì²˜ë¦¬ ë° ê°œì„ ëœ ì—…ë°ì´íŠ¸ ë¡œì§"""
    
    def __init__(self, node_docs_dir: str, logger: Optional[ProcessLogger] = None):
        self.node_docs_dir = Path(node_docs_dir)
        self.node_docs_dir.mkdir(exist_ok=True)
        
        # ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if logger is None:
            self.output_dir = self.node_docs_dir.parent
            self.logger = ProcessLogger("parent_node_processor", self.output_dir)
        else:
            self.logger = logger
            
        # ë¶„ì„ ëª¨ë“ˆ ì´ˆê¸°í™” (V3 ì‚¬ìš©)
        self.content_analyzer = ContentAnalyzer(self.logger.logger)
        self.data_loader = DataLoader(self.node_docs_dir, self.logger)
        
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì²˜ë¦¬ ì œí•œ
        self.semaphore = asyncio.Semaphore(2)
    
    async def process_parent_node(self, node_data: Dict[str, Any]) -> bool:
        """ë¶€ëª¨ ë…¸ë“œ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ - 5ë‹¨ê³„"""
        node_start = time.time()
        node_title = node_data.get("title", "")
        
        self.logger.log_operation(f"ë¶€ëª¨ë…¸ë“œì²˜ë¦¬ì‹œì‘_{node_title}", "ì‹œì‘")
        
        try:
            # 1ë‹¨ê³„: ìì‹ ë…¸ë“œë“¤ ìš°ì„  ì²˜ë¦¬ (process_status=falseì¸ ê²ƒë§Œ)
            children_success = await self.process_children_first(node_data)
            if not children_success:
                self.logger.log_error(f"ìì‹ë…¸ë“œì²˜ë¦¬_{node_title}", "ìì‹ ë…¸ë“œ ì²˜ë¦¬ ì‹¤íŒ¨")
                return False
            
            # 2ë‹¨ê³„: ë¶€ëª¨ ë…¸ë“œ ì¶”ì¶œ ì‘ì—…
            parent_extraction_success = await self.process_parent_extraction(node_data)
            if not parent_extraction_success:
                self.logger.log_error(f"ë¶€ëª¨ì¶”ì¶œ_{node_title}", "ë¶€ëª¨ ë…¸ë“œ ì¶”ì¶œ ì‹¤íŒ¨")
                return False
            
            # 3ë‹¨ê³„: ìì‹ ë…¸ë“œ ì¶”ì¶œ ì„¹ì…˜ ì—…ë°ì´íŠ¸
            update_success = await self.update_child_extraction_sections(node_data)
            if not update_success:
                self.logger.log_error(f"ìì‹ì—…ë°ì´íŠ¸_{node_title}", "ìì‹ ë…¸ë“œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                return False
            
            # 4ë‹¨ê³„: ë¶€ëª¨ ë…¸ë“œ ìµœì¢… ì—…ë°ì´íŠ¸ (ì—…ë°ì´íŠ¸ëœ ìì‹ ì •ë³´ ë°˜ì˜)
            final_success = await self.finalize_parent_extraction(node_data)
            if not final_success:
                self.logger.log_error(f"ë¶€ëª¨ìµœì¢…_{node_title}", "ë¶€ëª¨ ë…¸ë“œ ìµœì¢… ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                return False
            
            # 5ë‹¨ê³„: process_status ì—…ë°ì´íŠ¸
            status_success = self.update_node_status(node_data, True)
            
            node_time = time.time() - node_start
            self.logger.log_operation(f"ë¶€ëª¨ë…¸ë“œì²˜ë¦¬ì™„ë£Œ_{node_title}", 
                                    "ì„±ê³µ" if status_success else "ì²˜ë¦¬ì„±ê³µ_ìƒíƒœì‹¤íŒ¨", 
                                    {"ì²˜ë¦¬ì‹œê°„": f"{node_time:.2f}ì´ˆ"})
            
            return status_success
            
        except Exception as e:
            self.logger.log_error(f"ë¶€ëª¨ë…¸ë“œì²˜ë¦¬ì˜¤ë¥˜_{node_title}", e)
            return False
    
    async def process_children_first(self, node_data: Dict[str, Any]) -> bool:
        """ìì‹ ë…¸ë“œë“¤ ìš°ì„  ì²˜ë¦¬ - process_status=falseì¸ ê²ƒë§Œ"""
        node_title = node_data.get("title", "")
        composition_files = self.data_loader.get_composition_files(node_data)
        
        if not composition_files:
            self.logger.log_operation(f"ìì‹ë…¸ë“œì—†ìŒ_{node_title}", "í™•ì¸", {"êµ¬ì„±íŒŒì¼ìˆ˜": 0})
            return True
        
        # process_statusê°€ falseì¸ ìì‹ ë…¸ë“œë“¤ í•„í„°ë§
        unprocessed_children = []
        for file_name in composition_files:
            file_path = self.node_docs_dir / file_name
            if file_path.exists() and not self.check_node_status(file_path):
                unprocessed_children.append(file_name)
        
        if not unprocessed_children:
            self.logger.log_operation(f"ìì‹ë…¸ë“œì™„ë£Œë¨_{node_title}", "í™•ì¸", 
                                    {"ì´ìì‹ìˆ˜": len(composition_files), "ë¯¸ì²˜ë¦¬": 0})
            return True
        
        self.logger.log_operation(f"ìì‹ë…¸ë“œì²˜ë¦¬ì‹œì‘_{node_title}", "ì‹œì‘", 
                                {"ì´ìì‹ìˆ˜": len(composition_files), "ë¯¸ì²˜ë¦¬": len(unprocessed_children)})
        
        # ë¯¸ì²˜ë¦¬ ìì‹ ë…¸ë“œë“¤ ì²˜ë¦¬
        success_count = 0
        for file_name in unprocessed_children:
            file_path = self.node_docs_dir / file_name
            success = await self.process_single_child_node(file_path)
            if success:
                success_count += 1
        
        all_success = success_count == len(unprocessed_children)
        self.logger.log_operation(f"ìì‹ë…¸ë“œì²˜ë¦¬ì™„ë£Œ_{node_title}", 
                                "ì„±ê³µ" if all_success else "ë¶€ë¶„ì„±ê³µ", 
                                {"ì„±ê³µ": f"{success_count}/{len(unprocessed_children)}"})
        
        return all_success
    
    async def update_child_extraction_sections(self, node_data: Dict[str, Any]) -> bool:
        """ìì‹ ë…¸ë“œ ì¶”ì¶œ ì„¹ì…˜ ì—…ë°ì´íŠ¸ - í•µì‹¬ ë‚´ìš©, ìƒì„¸ í•µì‹¬ ë‚´ìš©ë§Œ"""
        node_title = node_data.get("title", "")
        composition_files = self.data_loader.get_composition_files(node_data)
        
        if not composition_files:
            return True
        
        # ë¶€ëª¨ ë…¸ë“œì˜ ì¶”ì¶œ ì •ë³´ ë¡œë“œ (ì°¸ê³  ì •ë³´)
        parent_file_path = self.data_loader._get_node_file_path(node_data)
        parent_extraction = self.data_loader._extract_section_from_file(parent_file_path, "ì¶”ì¶œ")
        
        if not parent_extraction:
            self.logger.log_error(f"ë¶€ëª¨ì¶”ì¶œì •ë³´ì—†ìŒ_{node_title}", "ë¶€ëª¨ ë…¸ë“œ ì¶”ì¶œ ì„¹ì…˜ì´ ì—†ìŒ")
            return False
        
        success_count = 0
        for file_name in composition_files:
            file_path = self.node_docs_dir / file_name
            if file_path.exists():
                success = await self.update_single_child_extraction(file_path, parent_extraction)
                if success:
                    success_count += 1
        
        all_success = success_count == len(composition_files)
        self.logger.log_operation(f"ìì‹ì—…ë°ì´íŠ¸ì™„ë£Œ_{node_title}", 
                                "ì„±ê³µ" if all_success else "ë¶€ë¶„ì„±ê³µ", 
                                {"ì„±ê³µ": f"{success_count}/{len(composition_files)}"})
        
        return all_success
    
    async def process_parent_extraction(self, node_data: Dict[str, Any]) -> bool:
        """ë¶€ëª¨ ë…¸ë“œ ì¶”ì¶œ ì‘ì—…"""
        node_title = node_data.get("title", "")
        
        # ì¶”ì¶œìš© ë°ì´í„° ë¡œë“œ
        extraction_data = self.data_loader.load_for_extraction(node_data)
        
        if not extraction_data.strip():
            # ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ìƒí™©
            self.logger.log_error(f"ë¶€ëª¨ë‚´ìš©ì—†ìŒ_{node_title}", "ë¶€ëª¨ ë…¸ë“œì— ë‚´ìš©ì´ ì—†ìŒ - ì •ìƒì ì´ì§€ ì•Šì€ ìƒí™©")
            return False
        
        # ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶”ì¶œ ìˆ˜í–‰ (ì •ìƒ ìƒí™©)
        extracted_info = await self.content_analyzer.extract_content(extraction_data, node_title)
        
        # ëª¨ë“  í•„ìˆ˜ ì„¹ì…˜ì´ ìˆëŠ”ì§€ ê²€ì¦
        missing_sections = self.validate_extraction_sections(extracted_info)
        
        if missing_sections:
            self.logger.log_operation(f"ëˆ„ë½ì„¹ì…˜ë°œê²¬_{node_title}", "ì¬ì¶”ì¶œ", 
                                    {"ëˆ„ë½ì„¹ì…˜": missing_sections})
            
            # ëˆ„ë½ëœ ì„¹ì…˜ë§Œ ì¬ì¶”ì¶œ
            retry_extracted = await self.retry_missing_sections(extraction_data, node_title, missing_sections)
            
            # ê¸°ì¡´ ê²°ê³¼ì™€ ì¬ì¶”ì¶œ ê²°ê³¼ ë³‘í•©
            extracted_info.update(retry_extracted)
        
        # ì¶”ì¶œ ì„¹ì…˜ì— ìƒˆë¡œìš´ í—¤ë” í˜•ì‹ìœ¼ë¡œ ì €ì¥
        node_file_path = self.data_loader._get_node_file_path(node_data)
        return self.save_extraction_with_new_header(node_file_path, extracted_info)
    
    async def finalize_parent_extraction(self, node_data: Dict[str, Any]) -> bool:
        """ë¶€ëª¨ ë…¸ë“œ ìµœì¢… ì—…ë°ì´íŠ¸ - ì—…ë°ì´íŠ¸ëœ ìì‹ ì •ë³´ ë°˜ì˜"""
        node_title = node_data.get("title", "")
        
        # ë¶€ëª¨ ë…¸ë“œì˜ í˜„ì¬ ì¶”ì¶œ ì„¹ì…˜
        parent_file_path = self.data_loader._get_node_file_path(node_data)
        base_extraction = self.data_loader._extract_section_from_file(parent_file_path, "ì¶”ì¶œ")
        
        # ìì‹ ë…¸ë“œë“¤ì˜ ì¶”ì¶œ ì„¹ì…˜ë“¤
        composition_files = self.data_loader.get_composition_files(node_data)
        children_extractions = []
        
        for file_name in composition_files:
            file_path = self.node_docs_dir / file_name
            if file_path.exists():
                child_extraction = self.data_loader._extract_section_from_file(file_path, "ì¶”ì¶œ")
                if child_extraction.strip():
                    children_extractions.append(child_extraction)
        
        if not children_extractions:
            self.logger.log_operation(f"ìµœì¢…ì—…ë°ì´íŠ¸ìŠ¤í‚µ_{node_title}", "ìŠ¤í‚µ", {"ì´ìœ ": "ìì‹ì¶”ì¶œì •ë³´ì—†ìŒ"})
            return True
        
        # ìµœì¢… í†µí•© ì—…ë°ì´íŠ¸
        final_extraction = await self.content_analyzer.update_parent_extraction(
            base_extraction, children_extractions, f"{node_title}_ìµœì¢…í†µí•©"
        )
        
        # ë¹ˆ ê²°ê³¼ ê²€ì¦ - ì—…ë°ì´íŠ¸ ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ì¡´ ë‚´ìš© ìœ ì§€
        if not final_extraction.strip():
            self.logger.log_operation(f"ìµœì¢…ì—…ë°ì´íŠ¸ê±´ë„ˆë›°ê¸°_{node_title}", "ê±´ë„ˆë›°ê¸°", {"ì´ìœ ": "ì—…ë°ì´íŠ¸ê²°ê³¼ë¹ˆë‚´ìš©", "ê¸°ì¡´ë‚´ìš©ìœ ì§€": True})
            return True
        
        # ì €ì¥
        return self.save_extraction_text(parent_file_path, final_extraction)
    
    async def process_single_child_node(self, file_path: Path) -> bool:
        """ë‹¨ì¼ ìì‹ ë…¸ë“œ ì²˜ë¦¬ - ì¶”ì¶œ ì‘ì—…"""
        file_name = file_path.name
        
        try:
            # ìì‹ ë…¸ë“œì˜ ë‚´ìš© ì„¹ì…˜ ë¡œë“œ
            content = self.data_loader._extract_section_from_file(file_path, "ë‚´ìš©")
            
            if not content.strip():
                self.logger.log_operation(f"ìì‹ë¹ˆë‚´ìš©_{file_name}", "ìŠ¤í‚µ", {"ì´ìœ ": "ë‚´ìš©ì—†ìŒ"})
                # ë¹ˆ ë‚´ìš©ì´ë¼ë„ process_statusëŠ” trueë¡œ ì„¤ì •
                return self.update_file_status(file_path, True)
            
            # ì¶”ì¶œ ì‘ì—…
            title = file_path.stem.replace("_info", "")
            extracted_info = await self.content_analyzer.extract_content(content, title)
            
            # ëª¨ë“  í•„ìˆ˜ ì„¹ì…˜ì´ ìˆëŠ”ì§€ ê²€ì¦
            missing_sections = self.validate_extraction_sections(extracted_info)
            
            if missing_sections:
                self.logger.log_operation(f"ìì‹ëˆ„ë½ì„¹ì…˜_{file_name}", "ì¬ì¶”ì¶œ", 
                                        {"ëˆ„ë½ì„¹ì…˜": missing_sections})
                
                # ëˆ„ë½ëœ ì„¹ì…˜ë§Œ ì¬ì¶”ì¶œ
                retry_extracted = await self.retry_missing_sections(content, title, missing_sections)
                
                # ê¸°ì¡´ ê²°ê³¼ì™€ ì¬ì¶”ì¶œ ê²°ê³¼ ë³‘í•©
                extracted_info.update(retry_extracted)
            
            # ì €ì¥
            save_success = self.save_extraction_with_new_header(file_path, extracted_info)
            
            if save_success:
                status_success = self.update_file_status(file_path, True)
                return status_success
            
            return False
            
        except Exception as e:
            self.logger.log_error(f"ìì‹ë…¸ë“œì²˜ë¦¬_{file_name}", e)
            return False
    
    async def update_single_child_extraction(self, file_path: Path, parent_extraction: str) -> bool:
        """ë‹¨ì¼ ìì‹ ë…¸ë“œ ì¶”ì¶œ ì„¹ì…˜ ì—…ë°ì´íŠ¸"""
        file_name = file_path.name
        
        try:
            # ìì‹ ë…¸ë“œì˜ í˜„ì¬ ì¶”ì¶œ ì„¹ì…˜
            base_extraction = self.data_loader._extract_section_from_file(file_path, "ì¶”ì¶œ")
            
            if not base_extraction.strip():
                self.logger.log_operation(f"ìì‹ì¶”ì¶œì—†ìŒ_{file_name}", "ìŠ¤í‚µ", {"ì´ìœ ": "ì¶”ì¶œì„¹ì…˜ì—†ìŒ"})
                return True
            
            # ì—…ë°ì´íŠ¸ ìˆ˜í–‰
            title = file_path.stem.replace("_info", "")
            updated_extraction = await self.content_analyzer.update_child_extraction(
                base_extraction, parent_extraction, title
            )
            
            # ì €ì¥
            return self.save_extraction_text(file_path, updated_extraction)
            
        except Exception as e:
            self.logger.log_error(f"ìì‹ì¶”ì¶œì—…ë°ì´íŠ¸_{file_name}", e)
            return False
    
    def save_extraction_with_new_header(self, file_path: Path, data: Dict[str, str]) -> bool:
        """ìƒˆë¡œìš´ í—¤ë” í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œ ì„¹ì…˜ì— ì €ì¥"""
        try:
            if not file_path.exists():
                self._create_basic_node_file(file_path)
            
            # ì¶”ì¶œ ì„¹ì…˜ ë‚´ìš© ìƒì„±
            extraction_content = self.content_analyzer.format_extraction_section(data)
            
            return self.save_extraction_text(file_path, extraction_content)
            
        except Exception as e:
            self.logger.log_error(f"ì¶”ì¶œì €ì¥_{file_path.name}", e)
            return False
    
    def save_extraction_text(self, file_path: Path, extraction_text: str) -> bool:
        """ì¶”ì¶œ ì„¹ì…˜ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ì— ì €ì¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            extraction_start = content.find("# ì¶”ì¶œ")
            if extraction_start == -1:
                content += "\n\n# ì¶”ì¶œ\n\n"
                extraction_start = content.find("# ì¶”ì¶œ")
            
            next_section_start = content.find("\n# ", extraction_start + 4)
            
            if next_section_start == -1:
                new_content = content[:extraction_start] + f"# ì¶”ì¶œ\n\n{extraction_text}\n"
            else:
                new_content = content[:extraction_start] + f"# ì¶”ì¶œ\n\n{extraction_text}\n" + content[next_section_start:]
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            self.logger.log_operation(f"ì¶”ì¶œì €ì¥ì™„ë£Œ_{file_path.name}", "ì„±ê³µ")
            return True
            
        except Exception as e:
            self.logger.log_error(f"ì¶”ì¶œì €ì¥ì‹¤íŒ¨_{file_path.name}", e)
            return False
    
    def update_node_status(self, node_data: Dict[str, Any], status: bool) -> bool:
        """ë…¸ë“œì˜ process_status ì—…ë°ì´íŠ¸"""
        node_file_path = self.data_loader._get_node_file_path(node_data)
        return self.update_file_status(node_file_path, status)
    
    def update_file_status(self, file_path: Path, status: bool) -> bool:
        """íŒŒì¼ì˜ process_status ì—…ë°ì´íŠ¸"""
        try:
            if not file_path.exists():
                return False
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            status_pattern = "process_status:"
            status_start = content.find(status_pattern)
            
            if status_start == -1:
                # process_statusê°€ ì—†ìœ¼ë©´ ì†ì„± ì„¹ì…˜ì— ì¶”ê°€
                attr_start = content.find("# ì†ì„±")
                if attr_start != -1:
                    attr_end = content.find("\n# ", attr_start + 4)
                    if attr_end == -1:
                        new_content = content + f"\nprocess_status: {str(status).lower()}\n"
                    else:
                        new_content = content[:attr_end] + f"\nprocess_status: {str(status).lower()}\n" + content[attr_end:]
                else:
                    new_content = f"# ì†ì„±\nprocess_status: {str(status).lower()}\n\n{content}"
            else:
                # ê¸°ì¡´ process_status ê°’ ì—…ë°ì´íŠ¸
                line_end = content.find('\n', status_start)
                if line_end == -1:
                    line_end = len(content)
                
                new_content = content[:status_start] + f"process_status: {str(status).lower()}" + content[line_end:]
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            self.logger.log_operation(f"ìƒíƒœì—…ë°ì´íŠ¸_{file_path.name}", "ì„±ê³µ", {"status": str(status).lower()})
            return True
            
        except Exception as e:
            self.logger.log_error(f"ìƒíƒœì—…ë°ì´íŠ¸_{file_path.name}", e)
            return False
    
    def check_node_status(self, file_path: Path) -> bool:
        """ë…¸ë“œì˜ process_status í™•ì¸"""
        try:
            if not file_path.exists():
                return False
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            status_pattern = "process_status:"
            status_start = content.find(status_pattern)
            
            if status_start == -1:
                return False
            
            line_end = content.find('\n', status_start)
            if line_end == -1:
                line_end = len(content)
            
            status_line = content[status_start:line_end]
            return "true" in status_line.lower()
            
        except Exception:
            return False
    
    def _create_basic_node_file(self, file_path: Path):
        """ê¸°ë³¸ ë…¸ë“œ ì •ë³´ íŒŒì¼ êµ¬ì¡° ìƒì„±"""
        template = """# ì†ì„±
process_status: false

# ì¶”ì¶œ

# ë‚´ìš©

# êµ¬ì„±
"""
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(template)
    
    def validate_extraction_sections(self, extracted_info: Dict[str, str]) -> List[str]:
        """ì¶”ì¶œëœ ì„¹ì…˜ë“¤ì´ ëª¨ë‘ ìˆëŠ”ì§€ ê²€ì¦í•˜ê³  ëˆ„ë½ëœ ì„¹ì…˜ ëª©ë¡ ë°˜í™˜"""
        required_sections = ["í•µì‹¬ ë‚´ìš©", "ìƒì„¸ í•µì‹¬ ë‚´ìš©", "ì£¼ìš” í™”ì œ", "ë¶€ì°¨ í™”ì œ"]
        missing_sections = []
        
        for section in required_sections:
            if section not in extracted_info or not extracted_info[section].strip():
                missing_sections.append(section)
        
        return missing_sections
    
    async def retry_missing_sections(self, extraction_data: str, title: str, missing_sections: List[str]) -> Dict[str, str]:
        """ëˆ„ë½ëœ ì„¹ì…˜ë“¤ë§Œ ì¬ì¶”ì¶œ"""
        retry_result = {}
        
        for section in missing_sections:
            try:
                if section == "í•µì‹¬ ë‚´ìš©":
                    section_name, content = await self.content_analyzer._extract_core_content(extraction_data, title)
                elif section == "ìƒì„¸ í•µì‹¬ ë‚´ìš©":
                    section_name, content = await self.content_analyzer._extract_detailed_content(extraction_data, title)
                elif section == "ì£¼ìš” í™”ì œ":
                    section_name, content = await self.content_analyzer._extract_main_topics(extraction_data, title)
                elif section == "ë¶€ì°¨ í™”ì œ":
                    section_name, content = await self.content_analyzer._extract_sub_topics(extraction_data, title)
                else:
                    continue
                
                if content and content.strip():
                    retry_result[section] = content.strip()
                    self.logger.log_operation(f"ì„¹ì…˜ì¬ì¶”ì¶œì„±ê³µ_{title}", section, {"ê¸¸ì´": f"{len(content)}ì"})
                else:
                    self.logger.log_operation(f"ì„¹ì…˜ì¬ì¶”ì¶œì‹¤íŒ¨_{title}", section, {"ê²°ê³¼": "ë¹ˆë‚´ìš©"})
                    
            except Exception as e:
                self.logger.log_error(f"ì„¹ì…˜ì¬ì¶”ì¶œì˜¤ë¥˜_{title}_{section}", e)
        
        return retry_result


class DataLoader:
    """ë¶€ëª¨ ë…¸ë“œ ì²˜ë¦¬ìš© ë°ì´í„° ë¡œë”© í´ë˜ìŠ¤"""
    
    def __init__(self, base_dir: Path, logger: ProcessLogger):
        self.base_dir = base_dir
        self.logger = logger
    
    def load_for_extraction(self, node_data: Dict[str, Any]) -> str:
        """ì¶”ì¶œ ì „ìš©: ë‚´ìš© ì„¹ì…˜ + êµ¬ì„± íŒŒì¼ë“¤ì˜ ë‚´ìš© ì„¹ì…˜ ê²°í•©"""
        try:
            node_title = node_data.get("title", "")
            
            # ë…¸ë“œ ì •ë³´ íŒŒì¼ ê²½ë¡œ
            node_file_path = self._get_node_file_path(node_data)
            if not node_file_path.exists():
                self.logger.log_error(f"ë…¸ë“œíŒŒì¼ì—†ìŒ_{node_title}", f"íŒŒì¼ ì—†ìŒ: {node_file_path}")
                return ""
            
            # 1. í˜„ì¬ ë…¸ë“œì˜ ë‚´ìš© ì„¹ì…˜ ì¶”ì¶œ
            current_content = self._extract_section_from_file(node_file_path, "ë‚´ìš©")
            
            # 2. êµ¬ì„± íŒŒì¼ë“¤ì˜ ë‚´ìš© ì„¹ì…˜ ìˆ˜ì§‘
            composition_files = self._get_composition_files(node_file_path)
            composition_contents = []
            
            for file_name in composition_files:
                comp_file_path = self.base_dir / file_name
                if comp_file_path.exists():
                    comp_content = self._extract_section_from_file(comp_file_path, "ë‚´ìš©")
                    if comp_content.strip():
                        composition_contents.append(f"=== {file_name} ë‚´ìš© ===\n{comp_content}")
            
            # 3. í†µí•© í…ìŠ¤íŠ¸ ìƒì„±
            combined_content = ""
            
            # í˜„ì¬ ë…¸ë“œ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if current_content.strip():
                combined_content += f"# {node_title} - í˜„ì¬ ë…¸ë“œ ë‚´ìš©\n{current_content}\n\n"
            
            # êµ¬ì„± íŒŒì¼ë“¤ ë‚´ìš© ì¶”ê°€
            if composition_contents:
                combined_content += f"# {node_title} - êµ¬ì„± ìš”ì†Œë“¤ ë‚´ìš©\n\n"
                combined_content += "\n\n".join(composition_contents)
            
            return combined_content
            
        except Exception as e:
            self.logger.log_error(f"ì¶”ì¶œë°ì´í„°ë¡œë”©_{node_data.get('title', '')}", e)
            return ""
    
    def get_composition_files(self, node_data: Dict[str, Any]) -> List[str]:
        """êµ¬ì„± ì„¹ì…˜ì—ì„œ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ"""
        try:
            node_file_path = self._get_node_file_path(node_data)
            return self._get_composition_files(node_file_path)
        except Exception:
            return []
    
    def _get_node_file_path(self, node_data: Dict[str, Any]) -> Path:
        """ë…¸ë“œ ì •ë³´ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        node_id = node_data.get("id", 0)
        level = node_data.get("level", 0)
        title = node_data.get("title", "")
        safe_title = title.lower().replace(" ", "_").replace("/", "_").replace("\\", "_")
        safe_title = safe_title.replace("-", "_")
        return self.base_dir / f"{node_id:02d}_lev{level}_{safe_title}_info.md"
    
    def _extract_section_from_file(self, file_path: Path, section_name: str) -> str:
        """íŒŒì¼ì—ì„œ íŠ¹ì • ì„¹ì…˜ ë‚´ìš© ì¶”ì¶œ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            header_pattern = f"# {section_name}"
            header_start = content.find(header_pattern)
            
            if header_start == -1:
                return ""
            
            content_start = header_start + len(header_pattern)
            
            lines = content[content_start:].split('\n')
            section_lines = []
            
            for line in lines:
                if line.strip().startswith('# ') and not line.strip().startswith('##'):
                    break
                section_lines.append(line)
            
            section_content = '\n'.join(section_lines).strip()
            return section_content
            
        except Exception as e:
            self.logger.log_error(f"ì„¹ì…˜ì¶”ì¶œ_{file_path.name}", e)
            return ""
    
    def _get_composition_files(self, node_file_path: Path) -> List[str]:
        """êµ¬ì„± ì„¹ì…˜ì—ì„œ íŒŒì¼ ëª©ë¡ ì¶”ì¶œ"""
        try:
            composition_content = self._extract_section_from_file(node_file_path, "êµ¬ì„±")
            if not composition_content:
                return []
            
            files = []
            for line in composition_content.split('\n'):
                line = line.strip()
                if line and not line.startswith('#') and line.endswith('.md'):
                    files.append(line)
            
            return files
            
        except Exception:
            return []


async def test_parent_node_processor():
    """ë¶€ëª¨ ë…¸ë“œ ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸"""
    import json
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    node_docs_dir = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-14/node_docs_v2"
    json_path = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-14/nodes.json"
    
    print("=" * 50)
    print("ë¶€ëª¨ ë…¸ë“œ ì²˜ë¦¬ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í”„ë¡œì„¸ì„œ ìƒì„±
    processor = ParentNodeProcessor(node_docs_dir)
    
    # í…ŒìŠ¤íŠ¸ìš© ë…¸ë“œ ë°ì´í„° ë¡œë“œ
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            nodes_data = json.load(f)
        
        # ë¶€ëª¨ ë…¸ë“œ ì°¾ê¸° (children_idsê°€ ìˆëŠ” ë…¸ë“œ)
        parent_nodes = [node for node in nodes_data if node.get("children_ids") and len(node.get("children_ids", [])) > 0]
        
        if not parent_nodes:
            print("âŒ í…ŒìŠ¤íŠ¸í•  ë¶€ëª¨ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì²« ë²ˆì§¸ ë¶€ëª¨ ë…¸ë“œë¡œ í…ŒìŠ¤íŠ¸
        test_node = parent_nodes[0]
        node_title = test_node.get("title", "")
        
        print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ë…¸ë“œ: {node_title}")
        print(f"   - ë ˆë²¨: {test_node.get('level', 0)}")
        print(f"   - ìì‹ ìˆ˜: {len(test_node.get('children_ids', []))}")
        
        # ì²˜ë¦¬ ì‹¤í–‰
        result = await processor.process_parent_node(test_node)
        
        print(f"\nğŸ“‹ ì²˜ë¦¬ ê²°ê³¼:")
        print(f"  {'âœ…' if result else 'âŒ'} {node_title}: {'ì„±ê³µ' if result else 'ì‹¤íŒ¨'}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    asyncio.run(test_parent_node_processor())