"""
ìƒì„± ì‹œê°„: 2025-08-14 14:55:00 KST
í•µì‹¬ ë‚´ìš©: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë°±ì—… ë° ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
ìƒì„¸ ë‚´ìš©:
    - backup_original_data() (ë¼ì¸ 25-): ì›ë³¸ node_docs í´ë” ë°±ì—…
    - reset_process_status() (ë¼ì¸ 45-): ëª¨ë“  ë…¸ë“œì˜ process_statusë¥¼ falseë¡œ ì´ˆê¸°í™”
    - restore_original_data() (ë¼ì¸ 70-): í…ŒìŠ¤íŠ¸ í›„ ì›ë³¸ ë°ì´í„° ë³µì›
    - create_test_nodes_subset() (ë¼ì¸ 90-): í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ë…¸ë“œ ì§‘í•© ìƒì„±
ìƒíƒœ: í™œì„±
ì£¼ì†Œ: test_data_backup
ì°¸ì¡°: -
"""

import json
import shutil
from pathlib import Path
from typing import Dict, List, Any


class TestDataManager:
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, base_dir: str = "/home/nadle/projects/Knowledge_Sherpa/v2/25-08-14"):
        self.base_dir = Path(base_dir)
        self.node_docs_dir = self.base_dir / "node_docs"
        self.backup_dir = self.base_dir / "test" / "backup"
        self.test_dir = self.base_dir / "test"
        
        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        self.backup_dir.mkdir(parents=True, exist_ok=True)
    
    def backup_original_data(self) -> bool:
        """ì›ë³¸ node_docs í´ë” ë°±ì—…"""
        try:
            backup_path = self.backup_dir / "node_docs_original"
            
            # ê¸°ì¡´ ë°±ì—… ì œê±°
            if backup_path.exists():
                shutil.rmtree(backup_path)
            
            # ì›ë³¸ ë°±ì—…
            shutil.copytree(self.node_docs_dir, backup_path)
            
            print(f"âœ… ì›ë³¸ ë°ì´í„° ë°±ì—… ì™„ë£Œ: {backup_path}")
            return True
            
        except Exception as e:
            print(f"âŒ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False
    
    def reset_process_status(self) -> Dict[str, bool]:
        """ëª¨ë“  ë…¸ë“œì˜ process_statusë¥¼ falseë¡œ ì´ˆê¸°í™”"""
        results = {}
        
        try:
            for file_path in self.node_docs_dir.glob("*_info.md"):
                # íŒŒì¼ ì½ê¸°
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # process_status ì°¾ê¸°/ì—…ë°ì´íŠ¸
                if "process_status:" in content:
                    # ê¸°ì¡´ ê°’ ì—…ë°ì´íŠ¸
                    updated_content = self._update_process_status(content, "false")
                else:
                    # process_status ì¶”ê°€
                    updated_content = self._add_process_status(content, "false")
                
                # íŒŒì¼ ì €ì¥
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(updated_content)
                
                results[file_path.name] = True
                print(f"ğŸ”„ {file_path.name}: process_status = false")
            
            print(f"âœ… ì´ {len(results)}ê°œ íŒŒì¼ì˜ process_status ì´ˆê¸°í™” ì™„ë£Œ")
            return results
            
        except Exception as e:
            print(f"âŒ process_status ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return {}
    
    def restore_original_data(self) -> bool:
        """í…ŒìŠ¤íŠ¸ í›„ ì›ë³¸ ë°ì´í„° ë³µì›"""
        try:
            backup_path = self.backup_dir / "node_docs_original"
            
            if not backup_path.exists():
                print("âŒ ë°±ì—… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # í˜„ì¬ ë°ì´í„° ì œê±°
            if self.node_docs_dir.exists():
                shutil.rmtree(self.node_docs_dir)
            
            # ë°±ì—…ì—ì„œ ë³µì›
            shutil.copytree(backup_path, self.node_docs_dir)
            
            print(f"âœ… ì›ë³¸ ë°ì´í„° ë³µì› ì™„ë£Œ: {self.node_docs_dir}")
            return True
            
        except Exception as e:
            print(f"âŒ ë³µì› ì‹¤íŒ¨: {e}")
            return False
    
    def create_test_nodes_subset(self, node_count: int = 3) -> str:
        """í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ë…¸ë“œ ì§‘í•© ìƒì„±"""
        try:
            # ì›ë³¸ nodes.json ì½ê¸°
            nodes_file = self.base_dir / "nodes.json"
            with open(nodes_file, 'r', encoding='utf-8') as f:
                all_nodes = json.load(f)
            
            # í…ŒìŠ¤íŠ¸ìš© ë¶€ë¶„ì§‘í•© ìƒì„± (ë ˆë²¨ 1 ë…¸ë“œë“¤ ì¤‘ ì¼ë¶€ë§Œ)
            test_nodes = []
            
            # ë£¨íŠ¸ ë…¸ë“œ (ë ˆë²¨ 0) ì¶”ê°€
            root_node = next(node for node in all_nodes if node["level"] == 0)
            
            # ë¦¬í”„ ë…¸ë“œë“¤ ì¤‘ ì²˜ìŒ ëª‡ ê°œë§Œ ì„ íƒ
            leaf_nodes = [node for node in all_nodes if node["level"] == 1][:node_count]
            
            # ë£¨íŠ¸ ë…¸ë“œì˜ children_ids ì—…ë°ì´íŠ¸
            root_node_copy = root_node.copy()
            root_node_copy["children_ids"] = [node["id"] for node in leaf_nodes]
            
            test_nodes.append(root_node_copy)
            test_nodes.extend(leaf_nodes)
            
            # í…ŒìŠ¤íŠ¸ìš© nodes.json ì €ì¥
            test_nodes_file = self.test_dir / "test_nodes.json"
            with open(test_nodes_file, 'w', encoding='utf-8') as f:
                json.dump(test_nodes, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… í…ŒìŠ¤íŠ¸ìš© ë…¸ë“œ ì§‘í•© ìƒì„± ì™„ë£Œ: {len(test_nodes)}ê°œ ë…¸ë“œ")
            print(f"   - ë£¨íŠ¸ ë…¸ë“œ: 1ê°œ (ë ˆë²¨ 0)")
            print(f"   - ë¦¬í”„ ë…¸ë“œ: {len(leaf_nodes)}ê°œ (ë ˆë²¨ 1)")
            print(f"   - íŒŒì¼: {test_nodes_file}")
            
            return str(test_nodes_file)
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ë…¸ë“œ ì§‘í•© ìƒì„± ì‹¤íŒ¨: {e}")
            return ""
    
    def _update_process_status(self, content: str, status: str) -> str:
        """ê¸°ì¡´ process_status ê°’ ì—…ë°ì´íŠ¸"""
        lines = content.split('\n')
        updated_lines = []
        
        for line in lines:
            if line.strip().startswith("process_status:"):
                updated_lines.append(f"process_status: {status}")
            else:
                updated_lines.append(line)
        
        return '\n'.join(updated_lines)
    
    def _add_process_status(self, content: str, status: str) -> str:
        """process_status í•„ë“œ ì¶”ê°€"""
        lines = content.split('\n')
        updated_lines = []
        
        attr_section_found = False
        attr_section_ended = False
        
        for line in lines:
            if line.strip() == "# ì†ì„±":
                attr_section_found = True
                updated_lines.append(line)
            elif attr_section_found and not attr_section_ended:
                if line.startswith("# ") and line.strip() != "# ì†ì„±":
                    # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘
                    updated_lines.append(f"process_status: {status}")
                    updated_lines.append("")
                    updated_lines.append(line)
                    attr_section_ended = True
                else:
                    updated_lines.append(line)
            else:
                updated_lines.append(line)
        
        # ì†ì„± ì„¹ì…˜ì´ ë§ˆì§€ë§‰ì´ë©´ ëì— ì¶”ê°€
        if attr_section_found and not attr_section_ended:
            updated_lines.append(f"process_status: {status}")
        
        return '\n'.join(updated_lines)
    
    def check_file_structure(self) -> Dict[str, Any]:
        """íŒŒì¼ êµ¬ì¡° ê²€ì‚¬"""
        results = {
            "total_files": 0,
            "valid_files": 0,
            "files_with_content": 0,
            "files_with_extraction": 0,
            "files_with_status": 0,
            "details": []
        }
        
        try:
            for file_path in self.node_docs_dir.glob("*_info.md"):
                results["total_files"] += 1
                
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                file_info = {
                    "name": file_path.name,
                    "has_attributes": "# ì†ì„±" in content,
                    "has_extraction": "# ì¶”ì¶œ" in content,
                    "has_content": "# ë‚´ìš©" in content,
                    "has_status": "process_status:" in content,
                    "content_length": 0,
                    "extraction_length": 0
                }
                
                # ë‚´ìš© ì„¹ì…˜ ê¸¸ì´ í™•ì¸
                if file_info["has_content"]:
                    content_start = content.find("# ë‚´ìš©")
                    if content_start != -1:
                        next_section = content.find("\n# ", content_start + 4)
                        if next_section == -1:
                            content_section = content[content_start:]
                        else:
                            content_section = content[content_start:next_section]
                        file_info["content_length"] = len(content_section.strip())
                        if file_info["content_length"] > 50:  # ìµœì†Œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°
                            results["files_with_content"] += 1
                
                # ì¶”ì¶œ ì„¹ì…˜ ê¸¸ì´ í™•ì¸
                if file_info["has_extraction"]:
                    extraction_start = content.find("# ì¶”ì¶œ")
                    if extraction_start != -1:
                        next_section = content.find("\n# ", extraction_start + 4)
                        if next_section == -1:
                            extraction_section = content[extraction_start:]
                        else:
                            extraction_section = content[extraction_start:next_section]
                        file_info["extraction_length"] = len(extraction_section.strip())
                        if file_info["extraction_length"] > 20:  # ìµœì†Œ ì¶”ì¶œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°
                            results["files_with_extraction"] += 1
                
                if file_info["has_attributes"] and file_info["has_extraction"] and file_info["has_content"]:
                    results["valid_files"] += 1
                
                if file_info["has_status"]:
                    results["files_with_status"] += 1
                
                results["details"].append(file_info)
            
            return results
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ êµ¬ì¡° ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            return results


def main():
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬ ì‹¤í–‰"""
    manager = TestDataManager()
    
    print("=" * 50)
    print("í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # 1. íŒŒì¼ êµ¬ì¡° ê²€ì‚¬
    print("\n1. íŒŒì¼ êµ¬ì¡° ê²€ì‚¬")
    structure_info = manager.check_file_structure()
    print(f"   ì´ íŒŒì¼: {structure_info['total_files']}ê°œ")
    print(f"   ìœ íš¨ íŒŒì¼: {structure_info['valid_files']}ê°œ")
    print(f"   ë‚´ìš© ìˆëŠ” íŒŒì¼: {structure_info['files_with_content']}ê°œ")
    print(f"   ì¶”ì¶œ ìˆëŠ” íŒŒì¼: {structure_info['files_with_extraction']}ê°œ")
    print(f"   ìƒíƒœ í•„ë“œ ìˆëŠ” íŒŒì¼: {structure_info['files_with_status']}ê°œ")
    
    # 2. ì›ë³¸ ë°ì´í„° ë°±ì—…
    print("\n2. ì›ë³¸ ë°ì´í„° ë°±ì—…")
    manager.backup_original_data()
    
    # 3. process_status ì´ˆê¸°í™”
    print("\n3. process_status ì´ˆê¸°í™”")
    manager.reset_process_status()
    
    # 4. í…ŒìŠ¤íŠ¸ìš© ë…¸ë“œ ì§‘í•© ìƒì„±
    print("\n4. í…ŒìŠ¤íŠ¸ìš© ë…¸ë“œ ì§‘í•© ìƒì„±")
    test_nodes_file = manager.create_test_nodes_subset(3)
    
    print("\nğŸ¯ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ!")
    print(f"   - ë°±ì—… ìœ„ì¹˜: {manager.backup_dir}")
    print(f"   - í…ŒìŠ¤íŠ¸ ë…¸ë“œ: {test_nodes_file}")


if __name__ == "__main__":
    main()