"""
í…ŒìŠ¤íŠ¸ 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© ë° ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
dialectical_synthesis_processor_v6.pyì˜ ë°ì´í„° ë¡œë”©ê³¼ ë…¸ë“œ ë¶„ë¥˜ ê¸°ëŠ¥ ê²€ì¦
"""

import sys
sys.path.append('/home/nadle/projects/Knowledge_Sherpa/v2/25-08-14/modules')

from pathlib import Path
from logging_system_v2 import TestLogger
from dialectical_synthesis_processor_v6 import DialecticalSynthesisProcessor
import json


def test_data_loading_and_classification():
    """1ë‹¨ê³„ í…ŒìŠ¤íŠ¸: ë°ì´í„° ë¡œë”© ë° ë¶„ë¥˜"""
    
    # í…ŒìŠ¤íŠ¸ ë¡œê±° ì´ˆê¸°í™”
    test_logger = TestLogger("stage_1_data_loading", Path("test/logs"))
    
    test_logger.log_process_start({
        "ë‹¨ê³„": "1ë‹¨ê³„",
        "ëª©ì ": "ë°ì´í„° ë¡œë”© ë° ë…¸ë“œ ë¶„ë¥˜ ê²€ì¦", 
        "í…ŒìŠ¤íŠ¸ ëŒ€ìƒ": "DialecticalSynthesisProcessor ì´ˆê¸°í™” ë° ë¶„ë¥˜"
    })
    
    try:
        # 1. í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
        test_logger.log_test_stage("í”„ë¡œì„¸ì„œ_ì´ˆê¸°í™”", "DialecticalSynthesisProcessor", "ì‹œì‘")
        
        processor = DialecticalSynthesisProcessor(
            output_dir="test/logs"
        )
        
        # í…ŒìŠ¤íŠ¸ìš© ë…¸ë“œ íŒŒì¼ ì„¤ì •
        base_dir = Path("/home/nadle/projects/Knowledge_Sherpa/v2/25-08-14")
        nodes_file = base_dir / "test/test_nodes.json"
        
        test_logger.log_test_stage("í”„ë¡œì„¸ì„œ_ì´ˆê¸°í™”", "DialecticalSynthesisProcessor", "ì„±ê³µ", {
            "output_dir": str(processor.output_dir),
            "nodes_file": str(nodes_file),
            "log_dir": str(processor.output_dir)
        })
        
        # 2. ë…¸ë“œ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
        test_logger.log_test_stage("ë…¸ë“œ_ë°ì´í„°_ë¡œë”©", "test_nodes.json", "ì‹œì‘")
        
        with open(nodes_file, 'r', encoding='utf-8') as f:
            loaded_nodes = json.load(f)
        
        test_logger.log_test_stage("ë…¸ë“œ_ë°ì´í„°_ë¡œë”©", "test_nodes.json", "ì„±ê³µ", {
            "ì´_ë…¸ë“œ_ìˆ˜": len(loaded_nodes),
            "ë£¨íŠ¸_ë…¸ë“œ": sum(1 for node in loaded_nodes if node["level"] == 0),
            "ë¦¬í”„_ë…¸ë“œ": sum(1 for node in loaded_nodes if node["level"] == 1)
        })
        
        # 3. ë…¸ë“œ ë¶„ë¥˜ ë° ê·¸ë£¹í™” í…ŒìŠ¤íŠ¸
        test_logger.log_test_stage("ë…¸ë“œ_ë¶„ë¥˜", "NodeGrouper", "ì‹œì‘")
        
        # ìˆ˜ë™ìœ¼ë¡œ ë¦¬í”„/ë¶€ëª¨ ë…¸ë“œ ë¶„ë¥˜
        leaf_nodes = [node for node in loaded_nodes if len(node.get("children_ids", [])) == 0]
        parent_nodes = [node for node in loaded_nodes if len(node.get("children_ids", [])) > 0]
        
        test_logger.log_test_stage("ë…¸ë“œ_ë¶„ë¥˜", "NodeGrouper", "ì„±ê³µ", {
            "ë¶„ë¥˜ëœ_ë¦¬í”„_ë…¸ë“œ": len(leaf_nodes),
            "ë¶„ë¥˜ëœ_ë¶€ëª¨_ë…¸ë“œ": len(parent_nodes),
            "ë¦¬í”„_ë…¸ë“œ_IDs": [node["id"] for node in leaf_nodes],
            "ë¶€ëª¨_ë…¸ë“œ_IDs": [node["id"] for node in parent_nodes]
        })
        
        # 4. ë ˆë²¨ë³„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
        test_logger.log_test_stage("ë ˆë²¨ë³„_ë¶„ë¥˜", "levels_groups", "ì‹œì‘")
        
        levels_groups = processor.node_grouper.group_and_sort_nodes(loaded_nodes)
        
        for level, nodes in levels_groups.items():
            test_logger.log_level_status(level, {
                "total": len(nodes),
                "completed": 0,
                "leaf_nodes": len([n for n in nodes if len(n.get("children_ids", [])) == 0]),
                "parent_nodes": len([n for n in nodes if len(n.get("children_ids", [])) > 0])
            })
        
        test_logger.log_test_stage("ë ˆë²¨ë³„_ë¶„ë¥˜", "levels_groups", "ì„±ê³µ", {
            "ì´_ë ˆë²¨_ìˆ˜": len(levels_groups),
            "ë ˆë²¨_ë¶„í¬": {f"ë ˆë²¨{k}": len(v) for k, v in levels_groups.items()}
        })
        
        # 5. ì˜ì¡´ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸
        test_logger.log_test_stage("ì˜ì¡´ì„±_êµ¬ì¡°_ê²€ì¦", "parent_children_mapping", "ì‹œì‘")
        
        # ë¶€ëª¨-ìì‹ ê´€ê³„ ê²€ì¦
        for parent_node in parent_nodes:
            children_ids = parent_node.get("children_ids", [])
            existing_children = [child["id"] for child in leaf_nodes if child["id"] in children_ids]
            
            test_logger.log_dependency_check(
                parent=f"ë…¸ë“œ{parent_node['id']}",
                children=[f"ë…¸ë“œ{cid}" for cid in children_ids],
                all_completed=len(existing_children) == len(children_ids),
                completed_children=[f"ë…¸ë“œ{cid}" for cid in existing_children]
            )
        
        test_logger.log_test_stage("ì˜ì¡´ì„±_êµ¬ì¡°_ê²€ì¦", "parent_children_mapping", "ì„±ê³µ")
        
        # 6. íŒŒì¼ ê²½ë¡œ ë§¤í•‘ í…ŒìŠ¤íŠ¸
        test_logger.log_test_stage("íŒŒì¼_ê²½ë¡œ_ë§¤í•‘", "node_file_paths", "ì‹œì‘")
        
        # ê°„ë‹¨í•œ íŒŒì¼ ê²½ë¡œ ìƒì„± í•¨ìˆ˜ (processor ë‚´ë¶€ ë©”ì„œë“œ ëŒ€ì‹ )
        def get_node_file_path(node_data):
            node_id = node_data["id"]
            level = node_data["level"]
            title = node_data["title"].lower().replace(" ", "_")
            filename = f"{node_id:02d}_lev{level}_{title}_info.md"
            return base_dir / "node_docs" / filename
        
        file_mapping_results = {}
        for node in loaded_nodes:
            expected_file = get_node_file_path(node)
            file_exists = expected_file.exists()
            
            file_mapping_results[f"ë…¸ë“œ{node['id']}"] = {
                "ì˜ˆìƒ_íŒŒì¼": expected_file.name,
                "íŒŒì¼_ì¡´ì¬": file_exists
            }
            
            if file_exists:
                # íŒŒì¼ ë‚´ìš© ê¸°ë³¸ ê²€ì¦
                with open(expected_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                test_logger.log_file_state(
                    file_path=expected_file,
                    section="ì „ì²´",
                    content_length=len(content),
                    status="ì¡´ì¬í•¨"
                )
        
        test_logger.log_test_stage("íŒŒì¼_ê²½ë¡œ_ë§¤í•‘", "node_file_paths", "ì„±ê³µ", {
            "ë§¤í•‘ëœ_íŒŒì¼_ìˆ˜": len(file_mapping_results),
            "ì¡´ì¬í•˜ëŠ”_íŒŒì¼": sum(1 for info in file_mapping_results.values() if info["íŒŒì¼_ì¡´ì¬"]),
            "ëˆ„ë½ëœ_íŒŒì¼": sum(1 for info in file_mapping_results.values() if not info["íŒŒì¼_ì¡´ì¬"])
        })
        
        # 7. ì „ì²´ 1ë‹¨ê³„ ê²°ê³¼ ê²€ì¦
        test_logger.log_assertion(
            test_name="ë¦¬í”„_ë…¸ë“œ_ìˆ˜_ê²€ì¦",
            expected=3,
            actual=len(leaf_nodes),
            passed=len(leaf_nodes) == 3,
            message="í…ŒìŠ¤íŠ¸ ë…¸ë“œ ì§‘í•©ì˜ ë¦¬í”„ ë…¸ë“œ ìˆ˜"
        )
        
        test_logger.log_assertion(
            test_name="ë¶€ëª¨_ë…¸ë“œ_ìˆ˜_ê²€ì¦", 
            expected=1,
            actual=len(parent_nodes),
            passed=len(parent_nodes) == 1,
            message="í…ŒìŠ¤íŠ¸ ë…¸ë“œ ì§‘í•©ì˜ ë¶€ëª¨ ë…¸ë“œ ìˆ˜"
        )
        
        test_logger.log_assertion(
            test_name="ì „ì²´_ë…¸ë“œ_ìˆ˜_ê²€ì¦",
            expected=4,
            actual=len(loaded_nodes),
            passed=len(loaded_nodes) == 4,
            message="í…ŒìŠ¤íŠ¸ ë…¸ë“œ ì§‘í•©ì˜ ì „ì²´ ë…¸ë“œ ìˆ˜"
        )
        
        success = True
        
    except Exception as e:
        test_logger.log_error("1ë‹¨ê³„_í…ŒìŠ¤íŠ¸_ì‹¤íŒ¨", e, {
            "ë‹¨ê³„": "ë°ì´í„° ë¡œë”© ë° ë¶„ë¥˜",
            "ì˜¤ë¥˜_ìœ„ì¹˜": "í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘"
        })
        success = False
    
    # í…ŒìŠ¤íŠ¸ ì™„ë£Œ
    test_logger.log_process_end(success, {
        "ì™„ë£Œëœ_í…ŒìŠ¤íŠ¸": "1ë‹¨ê³„ ë°ì´í„° ë¡œë”© ë° ë¶„ë¥˜",
        "ê²°ê³¼": "ì„±ê³µ" if success else "ì‹¤íŒ¨"
    })
    
    # í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±
    report_path = test_logger.create_test_report()
    print(f"\nğŸ“Š 1ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ: {report_path}")
    
    return success


if __name__ == "__main__":
    success = test_data_loading_and_classification()
    exit(0 if success else 1)