"""
í…ŒìŠ¤íŠ¸ 4ë‹¨ê³„: ë¶€ëª¨ ë…¸ë“œ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
dialectical_synthesis_processor_v6.pyì˜ ë¶€ëª¨ ë…¸ë“œ 3ë‹¨ê³„ ì²˜ë¦¬ ê³¼ì • ê²€ì¦
ë‹¨ê³„: ì¶”ì¶œ â†’ ìì‹ ë…¸ë“œ ì—…ë°ì´íŠ¸ â†’ ë¶€ëª¨ ë…¸ë“œ ìµœì¢… ì—…ë°ì´íŠ¸
"""

import sys
sys.path.append('/home/nadle/projects/Knowledge_Sherpa/v2/25-08-14/modules')

from pathlib import Path
from logging_system_v2 import TestLogger
from dialectical_synthesis_processor_v6 import DialecticalSynthesisProcessor
import json


def test_parent_node_pipeline():
    """4ë‹¨ê³„ í…ŒìŠ¤íŠ¸: ë¶€ëª¨ ë…¸ë“œ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸"""
    
    # í…ŒìŠ¤íŠ¸ ë¡œê±° ì´ˆê¸°í™”
    test_logger = TestLogger("stage_4_parent_pipeline", Path("test/logs"))
    
    test_logger.log_process_start({
        "ë‹¨ê³„": "4ë‹¨ê³„",
        "ëª©ì ": "ë¶€ëª¨ ë…¸ë“œ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ê²€ì¦",
        "í…ŒìŠ¤íŠ¸ ëŒ€ìƒ": "ì¶”ì¶œ â†’ ìì‹ì—…ë°ì´íŠ¸ â†’ ë¶€ëª¨ìµœì¢…ì—…ë°ì´íŠ¸"
    })
    
    try:
        # 1. í”„ë¡œì„¸ì„œ ë° ë°ì´í„° ì´ˆê¸°í™”
        test_logger.log_test_stage("ì´ˆê¸°í™”", "í”„ë¡œì„¸ì„œ_ë°_ë°ì´í„°", "ì‹œì‘")
        
        processor = DialecticalSynthesisProcessor(output_dir="test/logs")
        base_dir = Path("/home/nadle/projects/Knowledge_Sherpa/v2/25-08-14")
        nodes_file = base_dir / "test/test_nodes.json"
        
        with open(nodes_file, 'r', encoding='utf-8') as f:
            loaded_nodes = json.load(f)
        
        # ë…¸ë“œ ë¶„ë¥˜
        leaf_nodes = [node for node in loaded_nodes if len(node.get("children_ids", [])) == 0]
        parent_nodes = [node for node in loaded_nodes if len(node.get("children_ids", [])) > 0]
        
        test_logger.log_test_stage("ì´ˆê¸°í™”", "í”„ë¡œì„¸ì„œ_ë°_ë°ì´í„°", "ì„±ê³µ", {
            "ë¦¬í”„_ë…¸ë“œ_ìˆ˜": len(leaf_nodes),
            "ë¶€ëª¨_ë…¸ë“œ_ìˆ˜": len(parent_nodes)
        })
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„± í•¨ìˆ˜
        def get_node_file_path(node_data):
            node_id = node_data["id"]
            level = node_data["level"]
            title = node_data["title"].lower().replace(" ", "_").replace("-", "_")
            filename = f"{node_id:02d}_lev{level}_{title}_info.md"
            return base_dir / "node_docs" / filename
        
        # 2. ê° ë¶€ëª¨ ë…¸ë“œë³„ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        pipeline_results = {}
        
        for parent_node in parent_nodes:
            parent_id = parent_node["id"]
            parent_title = parent_node["title"]
            children_ids = parent_node.get("children_ids", [])
            
            test_logger.log_test_stage("ë¶€ëª¨ë…¸ë“œ_íŒŒì´í”„ë¼ì¸", f"ë…¸ë“œ{parent_id}_{parent_title}", "ì‹œì‘")
            
            pipeline_stages = {
                "stage_1_extraction": False,
                "stage_2_children_update": False,
                "stage_3_parent_final": False
            }
            
            try:
                # === 1ë‹¨ê³„: ì¶”ì¶œ (ë¶€ëª¨ ë…¸ë“œ ë‚´ìš© ì„¹ì…˜ë§Œ ë¡œë“œ) ===
                test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_1ë‹¨ê³„", f"ì¶”ì¶œ_{parent_id}", "ì‹œì‘")
                
                parent_file = get_node_file_path(parent_node)
                if not parent_file.exists():
                    test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_1ë‹¨ê³„", f"ì¶”ì¶œ_{parent_id}", "ì‹¤íŒ¨", 
                                             {"ì˜¤ë¥˜": "ë¶€ëª¨ë…¸ë“œ_íŒŒì¼_ì—†ìŒ"})
                    continue
                
                # DataLoaderë¥¼ ì‚¬ìš©í•œ ì¶”ì¶œ ì „ìš© ë¡œë”©
                extracted_content = processor.data_loader.load_for_extraction(parent_node)
                
                test_logger.log_file_state(
                    file_path=parent_file,
                    section="ì¶”ì¶œëœ_ë¶€ëª¨ë‚´ìš©",
                    content_length=len(extracted_content),
                    status="ì¶”ì¶œë¨" if extracted_content else "ë¹„ì–´ìˆìŒ"
                )
                
                if extracted_content:
                    pipeline_stages["stage_1_extraction"] = True
                    test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_1ë‹¨ê³„", f"ì¶”ì¶œ_{parent_id}", "ì„±ê³µ", {
                        "ì¶”ì¶œëœ_ë‚´ìš©_ê¸¸ì´": len(extracted_content)
                    })
                else:
                    test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_1ë‹¨ê³„", f"ì¶”ì¶œ_{parent_id}", "ì‹¤íŒ¨", 
                                             {"ì˜¤ë¥˜": "ì¶”ì¶œëœ_ë‚´ìš©_ì—†ìŒ"})
                    continue
                
                # === 2ë‹¨ê³„: ìì‹ ë…¸ë“œ ì—…ë°ì´íŠ¸ (ìì‹ë“¤ì˜ ì¶”ì¶œ ì„¹ì…˜ ê²°í•©) ===
                test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_2ë‹¨ê³„", f"ìì‹ì—…ë°ì´íŠ¸_{parent_id}", "ì‹œì‘")
                
                # ìì‹ ë…¸ë“œë“¤ì˜ ì¶”ì¶œëœ ë‚´ìš© ìˆ˜ì§‘
                children_extracted_content = []
                for child_id in children_ids:
                    child_node = next((node for node in loaded_nodes if node["id"] == child_id), None)
                    if child_node:
                        child_extracted = processor.data_loader.load_for_extraction(child_node)
                        if child_extracted:
                            children_extracted_content.append({
                                "child_id": child_id,
                                "content": child_extracted,
                                "length": len(child_extracted)
                            })
                
                # DataLoaderë¥¼ ì‚¬ìš©í•œ ì—…ë°ì´íŠ¸ ì „ìš© ë¡œë”© (ë¶€ëª¨ ë‚´ìš© + ìì‹ë“¤ ì¶”ì¶œ ê²°í•©)
                combined_content_for_update = processor.data_loader.load_for_update(parent_node)
                
                test_logger.log_file_state(
                    file_path=parent_file,
                    section="ê²°í•©ëœ_ì—…ë°ì´íŠ¸_ë‚´ìš©",
                    content_length=len(combined_content_for_update),
                    status="ê²°í•©ë¨" if combined_content_for_update else "ê²°í•©ì‹¤íŒ¨"
                )
                
                # ìì‹ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
                if len(children_extracted_content) == len(children_ids):
                    pipeline_stages["stage_2_children_update"] = True
                    test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_2ë‹¨ê³„", f"ìì‹ì—…ë°ì´íŠ¸_{parent_id}", "ì„±ê³µ", {
                        "ì²˜ë¦¬ëœ_ìì‹ìˆ˜": len(children_extracted_content),
                        "ê²°í•©ëœ_ë‚´ìš©_ê¸¸ì´": len(combined_content_for_update),
                        "ìì‹_ë‚´ìš©": [{"child_id": child["child_id"], "length": child["length"]} 
                                   for child in children_extracted_content]
                    })
                else:
                    test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_2ë‹¨ê³„", f"ìì‹ì—…ë°ì´íŠ¸_{parent_id}", "ì‹¤íŒ¨", {
                        "ê¸°ëŒ€_ìì‹ìˆ˜": len(children_ids),
                        "ì‹¤ì œ_ì²˜ë¦¬ëœ_ìì‹ìˆ˜": len(children_extracted_content)
                    })
                    continue
                
                # === 3ë‹¨ê³„: ë¶€ëª¨ ë…¸ë“œ ìµœì¢… ì—…ë°ì´íŠ¸ ===
                test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_3ë‹¨ê³„", f"ë¶€ëª¨ìµœì¢…ì—…ë°ì´íŠ¸_{parent_id}", "ì‹œì‘")
                
                # ëª¨ì˜ AI ì²˜ë¦¬ ê²°ê³¼ ìƒì„±
                mock_final_synthesis = f"""
# ì¢…í•© ë¶„ì„ ê²°ê³¼

## ê°œìš”
{parent_title}ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.

## ì£¼ìš” ë°œê²¬ì‚¬í•­
- ìì‹ ë…¸ë“œ {len(children_ids)}ê°œì˜ ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„
- ì´ {sum(child['length'] for child in children_extracted_content)}ìì˜ ë‚´ìš© ì²˜ë¦¬
- ì •ë°˜í•© ë°©ë²•ë¡ ì„ í†µí•œ í†µí•© ë¶„ì„ ì™„ë£Œ

## ê²°ë¡ 
{parent_title}ì˜ í•µì‹¬ ë‚´ìš©ì´ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œë˜ê³  ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
                """.strip()
                
                # DataSaverë¥¼ í†µí•œ ìµœì¢… ê²°ê³¼ ì €ì¥ ì‹œë®¬ë ˆì´ì…˜
                test_logger.log_file_state(
                    file_path=parent_file,
                    section="ìµœì¢…_ì¢…í•©_ê²°ê³¼",
                    content_length=len(mock_final_synthesis),
                    status="ìƒì„±ë¨"
                )
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
                test_logger.log_status_change(
                    node=f"ë…¸ë“œ{parent_id}",
                    before="false",
                    after="true(ì™„ë£Œ)",
                    file_path=parent_file.name
                )
                
                pipeline_stages["stage_3_parent_final"] = True
                test_logger.log_test_stage("íŒŒì´í”„ë¼ì¸_3ë‹¨ê³„", f"ë¶€ëª¨ìµœì¢…ì—…ë°ì´íŠ¸_{parent_id}", "ì„±ê³µ", {
                    "ìµœì¢…_ê²°ê³¼_ê¸¸ì´": len(mock_final_synthesis),
                    "ì²˜ë¦¬_ì™„ë£Œ": True
                })
                
                # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„±ê³µ
                all_stages_completed = all(pipeline_stages.values())
                
                test_logger.log_test_stage("ë¶€ëª¨ë…¸ë“œ_íŒŒì´í”„ë¼ì¸", f"ë…¸ë“œ{parent_id}_{parent_title}", 
                                         "ì„±ê³µ" if all_stages_completed else "ë¶€ë¶„ì™„ë£Œ", 
                                         pipeline_stages)
                
                pipeline_results[parent_id] = {
                    "parent_title": parent_title,
                    "stages": pipeline_stages,
                    "all_completed": all_stages_completed,
                    "children_processed": len(children_extracted_content),
                    "expected_children": len(children_ids)
                }
                
            except Exception as node_error:
                test_logger.log_error(f"ë¶€ëª¨ë…¸ë“œíŒŒì´í”„ë¼ì¸_{parent_id}", node_error, {
                    "ë¶€ëª¨_ë…¸ë“œ_ID": parent_id,
                    "ë¶€ëª¨_ë…¸ë“œ_ì œëª©": parent_title
                })
                pipeline_results[parent_id] = {
                    "parent_title": parent_title,
                    "stages": pipeline_stages,
                    "all_completed": False,
                    "error": str(node_error)
                }
        
        # 3. ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ìš”ì•½
        test_logger.log_test_stage("ì „ì²´_íŒŒì´í”„ë¼ì¸_ìš”ì•½", "ëª¨ë“ _ë¶€ëª¨ë…¸ë“œ", "ì‹œì‘")
        
        successful_pipelines = [
            result for result in pipeline_results.values() 
            if result["all_completed"]
        ]
        
        failed_pipelines = [
            result for result in pipeline_results.values() 
            if not result["all_completed"]
        ]
        
        # 4. ë ˆë²¨ ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        test_logger.log_level_status(
            level=0,
            stats={
                "total": len(parent_nodes),
                "completed": len(successful_pipelines),
                "failed": len(failed_pipelines),
                "leaf_nodes": 0,
                "parent_nodes": len(parent_nodes)
            },
            all_completed=len(successful_pipelines) == len(parent_nodes)
        )
        
        # 5. ë‹¨ì–¸ ê²€ì‚¬
        test_logger.log_assertion(
            test_name="ëª¨ë“ _ë¶€ëª¨ë…¸ë“œ_íŒŒì´í”„ë¼ì¸_ì™„ë£Œ",
            expected=len(parent_nodes),
            actual=len(successful_pipelines),
            passed=len(successful_pipelines) == len(parent_nodes),
            message="ëª¨ë“  ë¶€ëª¨ ë…¸ë“œì˜ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì´ ì™„ë£Œë˜ì–´ì•¼ í•¨"
        )
        
        test_logger.log_assertion(
            test_name="íŒŒì´í”„ë¼ì¸_ì‹¤íŒ¨_ì—†ìŒ",
            expected=0,
            actual=len(failed_pipelines),
            passed=len(failed_pipelines) == 0,
            message="íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹¤íŒ¨ê°€ ì—†ì–´ì•¼ í•¨"
        )
        
        # ê° ë‹¨ê³„ë³„ ì„±ê³µë¥  ê²€ì‚¬
        stage_success_rates = {
            "stage_1_extraction": 0,
            "stage_2_children_update": 0,
            "stage_3_parent_final": 0
        }
        
        for result in pipeline_results.values():
            for stage, success in result["stages"].items():
                if success:
                    stage_success_rates[stage] += 1
        
        for stage, success_count in stage_success_rates.items():
            test_logger.log_assertion(
                test_name=f"{stage}_ë‹¨ê³„_ì„±ê³µë¥ ",
                expected=len(parent_nodes),
                actual=success_count,
                passed=success_count == len(parent_nodes),
                message=f"{stage} ë‹¨ê³„ê°€ ëª¨ë“  ë¶€ëª¨ ë…¸ë“œì—ì„œ ì„±ê³µí•´ì•¼ í•¨"
            )
        
        overall_success = (
            len(successful_pipelines) == len(parent_nodes) and
            len(failed_pipelines) == 0 and
            all(count == len(parent_nodes) for count in stage_success_rates.values())
        )
        
        test_logger.log_test_stage("ì „ì²´_íŒŒì´í”„ë¼ì¸_ìš”ì•½", "ëª¨ë“ _ë¶€ëª¨ë…¸ë“œ", "ì„±ê³µ" if overall_success else "ë¶€ë¶„ì™„ë£Œ", {
            "ì„±ê³µí•œ_íŒŒì´í”„ë¼ì¸": len(successful_pipelines),
            "ì‹¤íŒ¨í•œ_íŒŒì´í”„ë¼ì¸": len(failed_pipelines),
            "ë‹¨ê³„ë³„_ì„±ê³µë¥ ": stage_success_rates,
            "ì „ì²´_ì„±ê³µ": overall_success
        })
        
    except Exception as e:
        test_logger.log_error("4ë‹¨ê³„_í…ŒìŠ¤íŠ¸_ì‹¤íŒ¨", e, {
            "ë‹¨ê³„": "ë¶€ëª¨ ë…¸ë“œ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸",
            "ì˜¤ë¥˜_ìœ„ì¹˜": "í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘"
        })
        overall_success = False
    
    # í…ŒìŠ¤íŠ¸ ì™„ë£Œ
    test_logger.log_process_end(overall_success, {
        "ì™„ë£Œëœ_í…ŒìŠ¤íŠ¸": "4ë‹¨ê³„ ë¶€ëª¨ ë…¸ë“œ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸",
        "ê²°ê³¼": "ì„±ê³µ" if overall_success else "ì‹¤íŒ¨",
        "ì„±ê³µí•œ_íŒŒì´í”„ë¼ì¸": len(successful_pipelines) if 'successful_pipelines' in locals() else 0,
        "ì „ì²´_ë¶€ëª¨ë…¸ë“œ": len(parent_nodes) if 'parent_nodes' in locals() else 0
    })
    
    # í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±
    report_path = test_logger.create_test_report()
    print(f"\nğŸ“Š 4ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ: {report_path}")
    
    return overall_success


if __name__ == "__main__":
    success = test_parent_node_pipeline()
    exit(0 if success else 1)