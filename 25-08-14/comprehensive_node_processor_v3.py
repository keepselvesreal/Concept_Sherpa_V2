# ìƒì„± ì‹œê°„: Fri Aug 16 17:40:12 KST 2025
# í•µì‹¬ ë‚´ìš©: ë…¸ë“œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥ìƒëœ ë…¸ë“œ ë¬¸ì„œ(node_docs_v3)ë¥¼ ìƒì„±í•˜ê³  í…ìŠ¤íŠ¸ ë¬¸ì„œì™€ í†µí•©í•˜ëŠ” ì¢…í•© ì²˜ë¦¬ê¸°
# ìƒì„¸ ë‚´ìš©:
#   - load_input_data() (line 30): JSON ë…¸ë“œ ì •ë³´ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì²˜ë¦¬
#   - extract_headers_from_md() (line 69): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ í—¤ë” êµ¬ì¡° ì¶”ì¶œ
#   - build_hierarchy() (line 102): ë ˆë²¨ ê¸°ë°˜ ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶•
#   - determine_has_content() (line 146): ìƒìœ„-í•˜ìœ„ ë…¸ë“œ ì‚¬ì´ ë‚´ìš© ì¡´ì¬ ì—¬ë¶€ íŒë‹¨
#   - save_nodes_json() (line 175): ì „ì²´ ë…¸ë“œ êµ¬ì¡°ë¥¼ nodes.jsonìœ¼ë¡œ ì €ì¥
#   - filter_and_save_content_nodes() (line 195): has_content=true ë˜ëŠ” ë¦¬í”„ ë…¸ë“œë¥¼ content_nodes.jsonìœ¼ë¡œ ì €ì¥
#   - create_node_documents_v3() (line 231): v3 ë…¸ë“œ ë¬¸ì„œ ìƒì„± (í–¥ìƒëœ ë©”íƒ€ë°ì´í„°ì™€ êµ¬ì¡°)
#   - integrate_with_text_documents() (line 328): ì¶”ì¶œëœ ì„¹ì…˜ íŒŒì¼ê³¼ í†µí•©
#   - process_nodes_comprehensive_v3() (line 380): ì „ì²´ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ í†µí•© ì‹¤í–‰
#   - main() (line 456): CLI ì¸í„°í˜ì´ìŠ¤ ë° ì‹¤í–‰ ë¡œì§
# ìƒíƒœ: í™œì„±
# ì£¼ì†Œ: comprehensive_node_processor_v3
# ì°¸ì¡°: comprehensive_node_processor_v2 (í–¥ìƒ ë²„ì „)

#!/usr/bin/env python3

import json
import os
import re
import sys
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

def load_input_data(input_path: str) -> Tuple[List[Dict[str, Any]], bool]:
    """
    ì…ë ¥ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤. JSON ë…¸ë“œ íŒŒì¼ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì§€ì›.
    
    Args:
        input_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        Tuple[ë…¸ë“œ ë¦¬ìŠ¤íŠ¸, ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì—¬ë¶€]
    """
    input_file = Path(input_path)
    
    if not input_file.exists():
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
    
    # íŒŒì¼ í™•ì¥ìë¡œ íƒ€ì… íŒë‹¨
    if input_file.suffix.lower() in ['.md', '.txt']:
        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()
        nodes = extract_headers_from_md(content)
        return nodes, True
        
    elif input_file.suffix.lower() == '.json':
        # JSON ë…¸ë“œ íŒŒì¼
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # headers í‚¤ê°€ ìˆëŠ” ê²½ìš° ì¶”ì¶œ
        if isinstance(data, dict) and 'headers' in data:
            nodes = data['headers']
        else:
            nodes = data
            
        return nodes, False
    
    else:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {input_file.suffix}")

def extract_headers_from_md(content: str) -> List[Dict[str, Any]]:
    """
    ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ì—ì„œ í—¤ë”ë¥¼ ì¶”ì¶œí•˜ì—¬ ë…¸ë“œ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        content: ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ 
        
    Returns:
        ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
    """
    headers = []
    pattern = r'^(#{1,6})\s+(.+)$'
    lines = content.split('\n')
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        match = re.match(pattern, line)
        
        if match:
            hash_marks = match.group(1)
            title = match.group(2).strip()
            level = len(hash_marks) - 1  # # = 0, ## = 1, ### = 2
            
            node = {
                "id": len(headers),
                "title": title,
                "level": level
            }
            headers.append(node)
    
    print(f"ğŸ“Š ë§ˆí¬ë‹¤ìš´ì—ì„œ {len(headers)}ê°œ í—¤ë” ì¶”ì¶œ ì™„ë£Œ")
    return headers

def build_hierarchy(nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ë ˆë²¨ ê¸°ë°˜ìœ¼ë¡œ ë¶€ëª¨-ìì‹ ê´€ê³„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ê³„ì¸µ ê´€ê³„ê°€ ì¶”ê°€ëœ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
    """
    print("ğŸ”— ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶• ì¤‘...")
    
    # ë…¸ë“œë¥¼ ì •ë ¬ (id ìˆœì„œëŒ€ë¡œ)
    nodes_sorted = sorted(nodes, key=lambda x: x.get('id', 0))
    
    # ê° ë…¸ë“œì— ê´€ê³„ í•„ë“œ ì´ˆê¸°í™”
    for node in nodes_sorted:
        node['parent_id'] = None
        node['children_ids'] = []
    
    # ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶•
    for i, current_node in enumerate(nodes_sorted):
        current_level = current_node.get('level', 0)
        
        # í˜„ì¬ ë…¸ë“œì˜ ë¶€ëª¨ ì°¾ê¸° (ë” ë‚®ì€ ë ˆë²¨ì˜ ê°€ì¥ ê°€ê¹Œìš´ ì´ì „ ë…¸ë“œ)
        for j in range(i-1, -1, -1):
            potential_parent = nodes_sorted[j]
            parent_level = potential_parent.get('level', 0)
            
            if parent_level < current_level:
                # ë¶€ëª¨ ë°œê²¬
                current_node['parent_id'] = potential_parent['id']
                potential_parent['children_ids'].append(current_node['id'])
                break
    
    # í†µê³„ ì¶œë ¥
    root_nodes = [n for n in nodes_sorted if n['parent_id'] is None]
    leaf_nodes = [n for n in nodes_sorted if len(n['children_ids']) == 0]
    
    print(f"   âœ… ë£¨íŠ¸ ë…¸ë“œ: {len(root_nodes)}ê°œ")
    print(f"   âœ… ë¦¬í”„ ë…¸ë“œ: {len(leaf_nodes)}ê°œ")
    
    return nodes_sorted

def determine_has_content(nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ìƒìœ„-í•˜ìœ„ ë…¸ë“œ ì‚¬ì´ì— ë‚´ìš©ì´ ì¡´ì¬í•˜ëŠ”ì§€ íŒë‹¨í•˜ì—¬ has_content í•„ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        has_content í•„ë“œê°€ ì¶”ê°€ëœ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
    """
    print("ğŸ“ has_content í•„ë“œ íŒë‹¨ ì¤‘...")
    
    # í˜„ì¬ëŠ” ë¦¬í”„ ë…¸ë“œì™€ ì²« ë²ˆì§¸ ë ˆë²¨ ë…¸ë“œì— ëŒ€í•´ has_content = Trueë¡œ ì„¤ì •
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”
    content_count = 0
    
    for node in nodes:
        # ë¦¬í”„ ë…¸ë“œëŠ” í•­ìƒ content ì¡´ì¬
        if len(node.get('children_ids', [])) == 0:
            node['has_content'] = True
            content_count += 1
        else:
            # ë¹„-ë¦¬í”„ ë…¸ë“œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ False, í–¥í›„ í™•ì¥ ê°€ëŠ¥
            node['has_content'] = False
    
    print(f"   âœ… has_content=True ë…¸ë“œ: {content_count}ê°œ")
    
    return nodes

def save_nodes_json(nodes: List[Dict[str, Any]], output_path: str = "nodes.json") -> bool:
    """
    ì „ì²´ ë…¸ë“œ êµ¬ì¡°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(nodes, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì „ì²´ ë…¸ë“œ êµ¬ì¡° ì €ì¥: {output_path} ({len(nodes)}ê°œ ë…¸ë“œ)")
        return True
    except Exception as e:
        print(f"âŒ nodes.json ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def filter_and_save_content_nodes(nodes: List[Dict[str, Any]], output_path: str = "content_nodes.json") -> bool:
    """
    has_content=True ë˜ëŠ” ë¦¬í”„ ë…¸ë“œë§Œ í•„í„°ë§í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸ” content ë…¸ë“œ í•„í„°ë§ ì¤‘...")
    
    filtered_nodes = []
    
    for node in nodes:
        has_content = node.get('has_content', False)
        is_leaf = len(node.get('children_ids', [])) == 0
        
        if has_content or is_leaf:
            filtered_node = {
                "id": node.get('id'),
                "level": node.get('level'),
                "title": node.get('title')
            }
            filtered_nodes.append(filtered_node)
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(filtered_nodes, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ content ë…¸ë“œ ì €ì¥: {output_path} ({len(filtered_nodes)}ê°œ ë…¸ë“œ)")
        return True
    except Exception as e:
        print(f"âŒ content_nodes.json ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def create_node_documents_v3(nodes: List[Dict[str, Any]], output_dir: str = "node_docs_v3") -> bool:
    """
    í–¥ìƒëœ ë©”íƒ€ë°ì´í„°ì™€ êµ¬ì¡°ë¥¼ ê°€ì§„ v3 ë…¸ë“œ ë¬¸ì„œ ìƒì„±
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ìƒì„± ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸ“„ ë…¸ë“œ ë¬¸ì„œ ìƒì„± ì¤‘ (v3 - í–¥ìƒëœ ë©”íƒ€ë°ì´í„°ì™€ êµ¬ì¡°)...")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    created_count = 0
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    for node in nodes:
        try:
            node_id = node.get('id', 0)
            level = node.get('level', 0)
            title = node.get('title', 'Untitled')
            parent_id = node.get('parent_id')
            children_ids = node.get('children_ids', [])
            has_content = node.get('has_content', False)
            
            # íŒŒì¼ëª… ìƒì„±: {id:02d}_lev{level}_{title}_info.md
            safe_title = re.sub(r'[^\w\s-]', '', title)
            safe_title = re.sub(r'[-\s]+', '_', safe_title)
            safe_title = safe_title.strip('_').lower()
            
            filename = f"{node_id:02d}_lev{level}_{safe_title}_info.md"
            
            # ë¶€ëª¨ ë…¸ë“œ ì •ë³´
            parent_info = ""
            if parent_id is not None:
                parent_node = next((n for n in nodes if n.get('id') == parent_id), None)
                if parent_node:
                    parent_title = parent_node.get('title', 'Untitled')
                    parent_safe_title = re.sub(r'[^\w\s-]', '', parent_title)
                    parent_safe_title = re.sub(r'[-\s]+', '_', parent_safe_title).strip('_').lower()
                    parent_filename = f"{parent_id:02d}_lev{parent_node.get('level', 0)}_{parent_safe_title}_info.md"
                    parent_info = f"parent: {parent_filename}"
            
            # ìì‹ ë…¸ë“œ íŒŒì¼ëª… ìƒì„±
            children_filenames = []
            if children_ids:
                for child_id in children_ids:
                    child_node = next((n for n in nodes if n.get('id') == child_id), None)
                    if child_node:
                        child_level = child_node.get('level', 0)
                        child_title = child_node.get('title', 'Untitled')
                        child_safe_title = re.sub(r'[^\w\s-]', '', child_title)
                        child_safe_title = re.sub(r'[-\s]+', '_', child_safe_title).strip('_').lower()
                        child_filename = f"{child_id:02d}_lev{child_level}_{child_safe_title}_info.md"
                        children_filenames.append(child_filename)
            
            # êµ¬ì„± ì„¹ì…˜ ë‚´ìš©
            composition_content = "\n".join(children_filenames) if children_filenames else ""
            
            # ë¬¸ì„œ ë‚´ìš© ìƒì„± (v2 í˜•ì‹ê³¼ ë™ì¼í•œ ê°„ë‹¨í•œ êµ¬ì¡°)
            content = f"""# ì†ì„±
process_status:

# ì¶”ì¶œ


# ë‚´ìš©


# êµ¬ì„±
{composition_content}"""
            
            # íŒŒì¼ ì €ì¥
            filepath = os.path.join(output_dir, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            created_count += 1
            print(f"   âœ… ìƒì„±: {filename}")
            
        except Exception as e:
            print(f"âŒ ë…¸ë“œ ID {node.get('id', 'N/A')} ë¬¸ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
    
    print(f"ğŸ“„ ë…¸ë“œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {output_dir}/ ({created_count}ê°œ íŒŒì¼)")
    return created_count > 0

def integrate_with_text_documents(nodes: List[Dict[str, Any]], sections_dir: str, output_dir: str = "node_docs_v3") -> bool:
    """
    ì¶”ì¶œëœ ì„¹ì…˜ íŒŒì¼ê³¼ ë…¸ë“œ ë¬¸ì„œë¥¼ í†µí•©í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        sections_dir: ì¶”ì¶œëœ ì„¹ì…˜ íŒŒì¼ ë””ë ‰í† ë¦¬
        output_dir: ë…¸ë“œ ë¬¸ì„œ ë””ë ‰í† ë¦¬
        
    Returns:
        í†µí•© ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸ”— í…ìŠ¤íŠ¸ ë¬¸ì„œì™€ í†µí•© ì¤‘...")
    
    if not os.path.exists(sections_dir):
        print(f"âš ï¸  ì„¹ì…˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sections_dir}")
        return False
    
    updated_count = 0
    
    for node in nodes:
        if not node.get('has_content', False):
            continue
            
        try:
            node_id = node.get('id', 0)
            level = node.get('level', 0)
            title = node.get('title', 'Untitled')
            
            # ë…¸ë“œ ë¬¸ì„œ íŒŒì¼ëª…
            safe_title = re.sub(r'[^\w\s-]', '', title)
            safe_title = re.sub(r'[-\s]+', '_', safe_title).strip('_').lower()
            node_filename = f"{node_id:02d}_lev{level}_{safe_title}_info.md"
            node_filepath = os.path.join(output_dir, node_filename)
            
            # ëŒ€ì‘í•˜ëŠ” ì„¹ì…˜ íŒŒì¼ ì°¾ê¸°
            section_filename = f"{node_id:02d}_lev{level}_{safe_title}.md"
            section_filepath = os.path.join(sections_dir, section_filename)
            
            if not os.path.exists(section_filepath):
                print(f"   âš ï¸  ì„¹ì…˜ íŒŒì¼ ì—†ìŒ: {section_filename}")
                continue
            
            if not os.path.exists(node_filepath):
                print(f"   âš ï¸  ë…¸ë“œ íŒŒì¼ ì—†ìŒ: {node_filename}")
                continue
            
            # ì„¹ì…˜ ë‚´ìš© ì½ê¸°
            with open(section_filepath, 'r', encoding='utf-8') as f:
                section_content = f.read().strip()
            
            # ë…¸ë“œ ë¬¸ì„œ ì½ê¸°
            with open(node_filepath, 'r', encoding='utf-8') as f:
                node_content = f.read()
            
            # ë‚´ìš© ì„¹ì…˜ì— ì‚½ì…
            lines = node_content.split('\n')
            content_section_start = -1
            
            for i, line in enumerate(lines):
                if line.strip() == '# ë‚´ìš©':
                    content_section_start = i
                    break
            
            if content_section_start == -1:
                print(f"   âš ï¸  '# ë‚´ìš©' ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {node_filename}")
                continue
            
            # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ì  ì°¾ê¸°
            next_section_start = len(lines)
            for i in range(content_section_start + 1, len(lines)):
                if lines[i].strip().startswith('# ') and lines[i].strip() != '# ë‚´ìš©':
                    next_section_start = i
                    break
            
            # ë‚´ìš© ì‚½ì…
            new_lines = (
                lines[:content_section_start + 1] +
                [''] +
                [section_content] +
                [''] +
                lines[next_section_start:]
            )
            
            # process_status ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰
            for i, line in enumerate(new_lines):
                if line.startswith('process_status:'):
                    new_lines[i] = "process_status: í†µí•©ì™„ë£Œ"
            
            # íŒŒì¼ ì €ì¥
            with open(node_filepath, 'w', encoding='utf-8') as f:
                f.write('\n'.join(new_lines))
            
            updated_count += 1
            print(f"   âœ… í†µí•©: {section_filename} â†’ {node_filename}")
            
        except Exception as e:
            print(f"âŒ ë…¸ë“œ ID {node.get('id', 'N/A')} í†µí•© ì˜¤ë¥˜: {e}")
    
    print(f"ğŸ”— í…ìŠ¤íŠ¸ ë¬¸ì„œ í†µí•© ì™„ë£Œ: {updated_count}ê°œ íŒŒì¼ ì—…ë°ì´íŠ¸")
    return updated_count > 0

def process_nodes_comprehensive_v3(input_path: str, sections_dir: Optional[str] = None, output_dir: str = ".") -> bool:
    """
    ì „ì²´ ë…¸ë“œ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ (v3 - í–¥ìƒëœ ë©”íƒ€ë°ì´í„°ì™€ í…ìŠ¤íŠ¸ í†µí•©).
    
    Args:
        input_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ (JSON ë…¸ë“œ íŒŒì¼ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼)
        sections_dir: ì¶”ì¶œëœ ì„¹ì…˜ íŒŒì¼ ë””ë ‰í† ë¦¬ (ì„ íƒì‚¬í•­)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸš€ ì¢…í•© ë…¸ë“œ ì²˜ë¦¬ ì‹œì‘ (v3 - í–¥ìƒëœ ë©”íƒ€ë°ì´í„°ì™€ í…ìŠ¤íŠ¸ í†µí•©)")
    print("=" * 80)
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_path}")
    print(f"ğŸ“ ì„¹ì…˜ ë””ë ‰í† ë¦¬: {sections_dir or 'ì§€ì •ë˜ì§€ ì•ŠìŒ'}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print()
    
    try:
        # 1. ì…ë ¥ ë°ì´í„° ë¡œë“œ
        print("1ï¸âƒ£ ì…ë ¥ ë°ì´í„° ë¡œë“œ")
        nodes, is_markdown = load_input_data(input_path)
        if is_markdown:
            print(f"   ğŸ“ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ {len(nodes)}ê°œ ë…¸ë“œ ì¶”ì¶œ")
        else:
            print(f"   ğŸ“„ JSON íŒŒì¼ì—ì„œ {len(nodes)}ê°œ ë…¸ë“œ ë¡œë“œ")
        
        if not nodes:
            print("âŒ ë…¸ë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # 2. ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶•
        print("\n2ï¸âƒ£ ê³„ì¸µ ê´€ê³„ êµ¬ì¶•")
        nodes = build_hierarchy(nodes)
        
        # 3. has_content í•„ë“œ íŒë‹¨
        print("\n3ï¸âƒ£ ë‚´ìš© ì¡´ì¬ ì—¬ë¶€ íŒë‹¨")
        nodes = determine_has_content(nodes)
        
        # 4. ì „ì²´ ë…¸ë“œ êµ¬ì¡° ì €ì¥ (nodes.json)
        print("\n4ï¸âƒ£ ì „ì²´ ë…¸ë“œ êµ¬ì¡° ì €ì¥")
        nodes_json_path = os.path.join(output_dir, "nodes.json")
        save_nodes_json(nodes, nodes_json_path)
        
        # 5. content ë…¸ë“œ í•„í„°ë§ ì €ì¥ (content_nodes.json)
        print("\n5ï¸âƒ£ ì½˜í…ì¸  ë…¸ë“œ í•„í„°ë§ ì €ì¥")
        content_nodes_path = os.path.join(output_dir, "content_nodes.json")
        filter_and_save_content_nodes(nodes, content_nodes_path)
        
        # 6. ë…¸ë“œ ë¬¸ì„œ ìƒì„± (v3 - í–¥ìƒëœ ë©”íƒ€ë°ì´í„°)
        print("\n6ï¸âƒ£ ë…¸ë“œ ë¬¸ì„œ ìƒì„± (v3)")
        docs_dir = os.path.join(output_dir, "node_docs_v3")
        create_node_documents_v3(nodes, docs_dir)
        
        # 7. í…ìŠ¤íŠ¸ ë¬¸ì„œì™€ í†µí•© (ì„¹ì…˜ ë””ë ‰í† ë¦¬ê°€ ì œê³µëœ ê²½ìš°)
        if sections_dir:
            print("\n7ï¸âƒ£ í…ìŠ¤íŠ¸ ë¬¸ì„œì™€ í†µí•©")
            integrate_with_text_documents(nodes, sections_dir, docs_dir)
        
        print("\nâœ¨ ì¢…í•© ë…¸ë“œ ì²˜ë¦¬ ì™„ë£Œ! (v3)")
        print("=" * 80)
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   - ì „ì²´ ë…¸ë“œ: {len(nodes)}ê°œ")
        print(f"   - ì½˜í…ì¸  ë…¸ë“œ: {len([n for n in nodes if n.get('has_content') or len(n.get('children_ids', [])) == 0])}ê°œ")
        print(f"   - ìƒì„±ëœ íŒŒì¼:")
        print(f"     â€¢ {nodes_json_path}")
        print(f"     â€¢ {content_nodes_path}")
        print(f"     â€¢ {docs_dir}/ (v3 íŒŒì¼ëª…: {'{id:02d}'}_lev{'{level}'}_{'{title}'}_info.md)")
        if sections_dir:
            print(f"     â€¢ í…ìŠ¤íŠ¸ ë¬¸ì„œ í†µí•© ì™„ë£Œ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='í–¥ìƒëœ ë©”íƒ€ë°ì´í„°ì™€ í…ìŠ¤íŠ¸ í†µí•©ì„ ì§€ì›í•˜ëŠ” ë…¸ë“œ ì •ë³´ ì¢…í•© ì²˜ë¦¬ê¸° (v3)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python comprehensive_node_processor_v3.py nodes.json
  python comprehensive_node_processor_v3.py nodes.json -s extracted_sections -o ./output
  python comprehensive_node_processor_v3.py document.md --sections-dir ./sections --output-dir ./processed

v3 ê°œì„ ì‚¬í•­:
  - í–¥ìƒëœ ë©”íƒ€ë°ì´í„° (ìƒì„±/ìˆ˜ì • ì‹œê°„, ìš°ì„ ìˆœìœ„, ì½˜í…ì¸  íƒ€ì… ë“±)
  - ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¬¸ì„œì™€ì˜ ìë™ í†µí•©
  - ë¶€ëª¨-ìì‹ ê´€ê³„ ì¶”ì 
  - ë” í’ë¶€í•œ ë¬¸ì„œ êµ¬ì¡°
        """
    )
    
    parser.add_argument('input_file', help='ì…ë ¥ íŒŒì¼ (JSON ë…¸ë“œ íŒŒì¼ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼)')
    parser.add_argument('-s', '--sections-dir', help='ì¶”ì¶œëœ ì„¹ì…˜ íŒŒì¼ ë””ë ‰í† ë¦¬ (í†µí•©ìš©)')
    parser.add_argument('-o', '--output-dir', default='.', help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬)')
    parser.add_argument('-v', '--verbose', action='store_true', help='ìƒì„¸ ì¶œë ¥')
    
    args = parser.parse_args()
    
    # ì²˜ë¦¬ ì‹¤í–‰
    success = process_nodes_comprehensive_v3(args.input_file, args.sections_dir, args.output_dir)
    
    if success:
        print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return 0
    else:
        print("\nğŸ’¥ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return 1

if __name__ == "__main__":
    exit(main())