#!/usr/bin/env python3

"""
ìƒì„± ì‹œê°„: 2025ë…„ 08ì›” 14ì¼ 10:13:28 KST
í•µì‹¬ ë‚´ìš©: ë…¸ë“œ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì™„ì „í•œ ë…¸ë“œ êµ¬ì¡° ë° ë¬¸ì„œë¥¼ ìƒì„±í•˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸
ìƒì„¸ ë‚´ìš©:
- load_input_data (ë¼ì¸ 45-80): JSON ë…¸ë“œ ì •ë³´ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì²˜ë¦¬
- extract_headers_from_md (ë¼ì¸ 85-120): ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ í—¤ë” êµ¬ì¡° ì¶”ì¶œ
- build_hierarchy (ë¼ì¸ 125-170): ë ˆë²¨ ê¸°ë°˜ ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶•
- determine_has_content (ë¼ì¸ 175-200): ìƒìœ„-í•˜ìœ„ ë…¸ë“œ ì‚¬ì´ ë‚´ìš© ì¡´ì¬ ì—¬ë¶€ íŒë‹¨
- save_nodes_json (ë¼ì¸ 205-225): ì „ì²´ ë…¸ë“œ êµ¬ì¡°ë¥¼ nodes.jsonìœ¼ë¡œ ì €ì¥
- filter_and_save_content_nodes (ë¼ì¸ 230-265): has_content=true ë˜ëŠ” ë¦¬í”„ ë…¸ë“œë¥¼ content_nodes.jsonìœ¼ë¡œ ì €ì¥
- create_node_documents (ë¼ì¸ 270-310): ëª¨ë“  ë…¸ë“œì— ëŒ€í•´ level_title_info.md íŒŒì¼ ìƒì„±
- process_nodes_comprehensive (ë¼ì¸ 315-380): ì „ì²´ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ í†µí•© ì‹¤í–‰
- main (ë¼ì¸ 385-420): ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ë° CLI ì¸í„°í˜ì´ìŠ¤
ìƒíƒœ: í™œì„±
ì£¼ì†Œ: comprehensive_node_processor
ì°¸ì¡°: header_to_json_converter.py, node_hierarchy_builder.py, content_node_filter_v2.py, node_document_generator.py ê¸°ëŠ¥ í†µí•©
"""

import json
import os
import re
import sys
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

def load_input_data(input_path: str) -> Tuple[List[Dict[str, Any]], bool]:
    """
    ì…ë ¥ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤. JSON ë…¸ë“œ íŒŒì¼ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì§€ì›.
    
    Args:
        input_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        Tuple[ë…¸ë“œ ë¦¬ìŠ¤íŠ¸, ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì—¬ë¶€]
    """
    input_file = Path(input_path)
    
    if not input_file.exists():
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")
    
    # íŒŒì¼ í™•ì¥ìë¡œ íƒ€ì… íŒë‹¨
    if input_file.suffix.lower() in ['.md', '.txt']:
        # ë§ˆí¬ë‹¤ìš´ íŒŒì¼
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()
        nodes = extract_headers_from_md(content)
        return nodes, True
        
    elif input_file.suffix.lower() == '.json':
        # JSON ë…¸ë“œ íŒŒì¼
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # headers í‚¤ê°€ ìˆëŠ” ê²½ìš° ì¶”ì¶œ
        if isinstance(data, dict) and 'headers' in data:
            nodes = data['headers']
        else:
            nodes = data
            
        return nodes, False
    
    else:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {input_file.suffix}")

def extract_headers_from_md(content: str) -> List[Dict[str, Any]]:
    """
    ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ ì—ì„œ í—¤ë”ë¥¼ ì¶”ì¶œí•˜ì—¬ ë…¸ë“œ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        content: ë§ˆí¬ë‹¤ìš´ ì½˜í…ì¸ 
        
    Returns:
        ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
    """
    headers = []
    pattern = r'^(#{1,6})\s+(.+)$'
    lines = content.split('\n')
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        match = re.match(pattern, line)
        
        if match:
            hash_marks = match.group(1)
            title = match.group(2).strip()
            level = len(hash_marks) - 1  # # = 0, ## = 1, ### = 2
            
            node = {
                "id": len(headers),
                "title": title,
                "level": level
            }
            headers.append(node)
    
    print(f"ğŸ“Š ë§ˆí¬ë‹¤ìš´ì—ì„œ {len(headers)}ê°œ í—¤ë” ì¶”ì¶œ ì™„ë£Œ")
    return headers

def build_hierarchy(nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ë ˆë²¨ ê¸°ë°˜ìœ¼ë¡œ ë¶€ëª¨-ìì‹ ê´€ê³„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ê³„ì¸µ ê´€ê³„ê°€ ì¶”ê°€ëœ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
    """
    print("ğŸ”— ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶• ì¤‘...")
    
    # ë…¸ë“œë¥¼ ì •ë ¬ (id ìˆœì„œëŒ€ë¡œ)
    nodes_sorted = sorted(nodes, key=lambda x: x.get('id', 0))
    
    # ê° ë…¸ë“œì— ê´€ê³„ í•„ë“œ ì´ˆê¸°í™”
    for node in nodes_sorted:
        node['parent_id'] = None
        node['children_ids'] = []
    
    # ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶•
    for i, current_node in enumerate(nodes_sorted):
        current_level = current_node.get('level', 0)
        
        # í˜„ì¬ ë…¸ë“œì˜ ë¶€ëª¨ ì°¾ê¸° (ë” ë‚®ì€ ë ˆë²¨ì˜ ê°€ì¥ ê°€ê¹Œìš´ ì´ì „ ë…¸ë“œ)
        for j in range(i-1, -1, -1):
            potential_parent = nodes_sorted[j]
            parent_level = potential_parent.get('level', 0)
            
            if parent_level < current_level:
                # ë¶€ëª¨ ë°œê²¬
                current_node['parent_id'] = potential_parent['id']
                potential_parent['children_ids'].append(current_node['id'])
                break
    
    # í†µê³„ ì¶œë ¥
    root_nodes = [n for n in nodes_sorted if n['parent_id'] is None]
    leaf_nodes = [n for n in nodes_sorted if len(n['children_ids']) == 0]
    
    print(f"   âœ… ë£¨íŠ¸ ë…¸ë“œ: {len(root_nodes)}ê°œ")
    print(f"   âœ… ë¦¬í”„ ë…¸ë“œ: {len(leaf_nodes)}ê°œ")
    
    return nodes_sorted

def determine_has_content(nodes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    ìƒìœ„-í•˜ìœ„ ë…¸ë“œ ì‚¬ì´ì— ë‚´ìš©ì´ ì¡´ì¬í•˜ëŠ”ì§€ íŒë‹¨í•˜ì—¬ has_content í•„ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        has_content í•„ë“œê°€ ì¶”ê°€ëœ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
    """
    print("ğŸ“ has_content í•„ë“œ íŒë‹¨ ì¤‘...")
    
    # í˜„ì¬ëŠ” ë¦¬í”„ ë…¸ë“œì™€ ì²« ë²ˆì§¸ ë ˆë²¨ ë…¸ë“œì— ëŒ€í•´ has_content = Trueë¡œ ì„¤ì •
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”
    content_count = 0
    
    for node in nodes:
        # ë¦¬í”„ ë…¸ë“œëŠ” í•­ìƒ content ì¡´ì¬
        if len(node.get('children_ids', [])) == 0:
            node['has_content'] = True
            content_count += 1
        else:
            # ë¹„-ë¦¬í”„ ë…¸ë“œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ False, í–¥í›„ í™•ì¥ ê°€ëŠ¥
            node['has_content'] = False
    
    print(f"   âœ… has_content=True ë…¸ë“œ: {content_count}ê°œ")
    
    return nodes

def save_nodes_json(nodes: List[Dict[str, Any]], output_path: str = "nodes.json") -> bool:
    """
    ì „ì²´ ë…¸ë“œ êµ¬ì¡°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(nodes, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ì „ì²´ ë…¸ë“œ êµ¬ì¡° ì €ì¥: {output_path} ({len(nodes)}ê°œ ë…¸ë“œ)")
        return True
    except Exception as e:
        print(f"âŒ nodes.json ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def filter_and_save_content_nodes(nodes: List[Dict[str, Any]], output_path: str = "content_nodes.json") -> bool:
    """
    has_content=True ë˜ëŠ” ë¦¬í”„ ë…¸ë“œë§Œ í•„í„°ë§í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸ” content ë…¸ë“œ í•„í„°ë§ ì¤‘...")
    
    filtered_nodes = []
    
    for node in nodes:
        has_content = node.get('has_content', False)
        is_leaf = len(node.get('children_ids', [])) == 0
        
        if has_content or is_leaf:
            filtered_node = {
                "id": node.get('id'),
                "level": node.get('level'),
                "title": node.get('title')
            }
            filtered_nodes.append(filtered_node)
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(filtered_nodes, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ content ë…¸ë“œ ì €ì¥: {output_path} ({len(filtered_nodes)}ê°œ ë…¸ë“œ)")
        return True
    except Exception as e:
        print(f"âŒ content_nodes.json ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def create_node_documents(nodes: List[Dict[str, Any]], output_dir: str = "node_docs") -> bool:
    """
    ëª¨ë“  ë…¸ë“œì— ëŒ€í•´ level_title_info.md íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        nodes: ë…¸ë“œ ë¦¬ìŠ¤íŠ¸
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ìƒì„± ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸ“„ ë…¸ë“œ ë¬¸ì„œ ìƒì„± ì¤‘...")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    created_count = 0
    
    for node in nodes:
        try:
            level = node.get('level', 0)
            title = node.get('title', 'Untitled')
            
            # íŒŒì¼ëª… ìƒì„±
            clean_title = re.sub(r'[^\w\s-]', '', title).strip()
            clean_title = re.sub(r'[-\s]+', '_', clean_title)
            filename = f"{level}_{clean_title}_info.md"
            
            # ìì‹ ë…¸ë“œ íŒŒì¼ëª… ìƒì„±
            children_filenames = ""
            if node.get('children_ids'):
                for child_id in node['children_ids']:
                    child_node = next((n for n in nodes if n.get('id') == child_id), None)
                    if child_node:
                        child_level = child_node.get('level', 0)
                        child_title = child_node.get('title', 'Untitled')
                        child_clean_title = re.sub(r'[^\w\s-]', '', child_title).strip()
                        child_clean_title = re.sub(r'[-\s]+', '_', child_clean_title)
                        child_filename = f"{child_level}_{child_clean_title}_info.md"
                        children_filenames += f"{child_filename}\n"
            
            # ë¬¸ì„œ ë‚´ìš© ìƒì„±
            content = f"""# ì†ì„±
process_status:

# ì¶”ì¶œ


# ë‚´ìš©


# êµ¬ì„±
{children_filenames}"""
            
            # íŒŒì¼ ì €ì¥
            filepath = os.path.join(output_dir, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            created_count += 1
            
        except Exception as e:
            print(f"âŒ ë…¸ë“œ ID {node.get('id', 'N/A')} ë¬¸ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
    
    print(f"ğŸ“„ ë…¸ë“œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {output_dir}/ ({created_count}ê°œ íŒŒì¼)")
    return created_count > 0

def process_nodes_comprehensive(input_path: str, output_dir: str = ".") -> bool:
    """
    ì „ì²´ ë…¸ë“œ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        input_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ (JSON ë…¸ë“œ íŒŒì¼ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
    """
    print("ğŸš€ ì¢…í•© ë…¸ë“œ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_path}")
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    print()
    
    try:
        # 1. ì…ë ¥ ë°ì´í„° ë¡œë“œ
        print("1ï¸âƒ£ ì…ë ¥ ë°ì´í„° ë¡œë“œ")
        nodes, is_markdown = load_input_data(input_path)
        if is_markdown:
            print(f"   ğŸ“ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ {len(nodes)}ê°œ ë…¸ë“œ ì¶”ì¶œ")
        else:
            print(f"   ğŸ“„ JSON íŒŒì¼ì—ì„œ {len(nodes)}ê°œ ë…¸ë“œ ë¡œë“œ")
        
        if not nodes:
            print("âŒ ë…¸ë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # 2. ë¶€ëª¨-ìì‹ ê´€ê³„ êµ¬ì¶•
        print("\n2ï¸âƒ£ ê³„ì¸µ ê´€ê³„ êµ¬ì¶•")
        nodes = build_hierarchy(nodes)
        
        # 3. has_content í•„ë“œ íŒë‹¨
        print("\n3ï¸âƒ£ ë‚´ìš© ì¡´ì¬ ì—¬ë¶€ íŒë‹¨")
        nodes = determine_has_content(nodes)
        
        # 4. ì „ì²´ ë…¸ë“œ êµ¬ì¡° ì €ì¥ (nodes.json)
        print("\n4ï¸âƒ£ ì „ì²´ ë…¸ë“œ êµ¬ì¡° ì €ì¥")
        nodes_json_path = os.path.join(output_dir, "nodes.json")
        save_nodes_json(nodes, nodes_json_path)
        
        # 5. content ë…¸ë“œ í•„í„°ë§ ì €ì¥ (content_nodes.json)
        print("\n5ï¸âƒ£ ì½˜í…ì¸  ë…¸ë“œ í•„í„°ë§ ì €ì¥")
        content_nodes_path = os.path.join(output_dir, "content_nodes.json")
        filter_and_save_content_nodes(nodes, content_nodes_path)
        
        # 6. ë…¸ë“œ ë¬¸ì„œ ìƒì„± (level_title_info.md)
        print("\n6ï¸âƒ£ ë…¸ë“œ ë¬¸ì„œ ìƒì„±")
        docs_dir = os.path.join(output_dir, "node_docs")
        create_node_documents(nodes, docs_dir)
        
        print("\nâœ¨ ì¢…í•© ë…¸ë“œ ì²˜ë¦¬ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   - ì „ì²´ ë…¸ë“œ: {len(nodes)}ê°œ")
        print(f"   - ì½˜í…ì¸  ë…¸ë“œ: {len([n for n in nodes if n.get('has_content') or len(n.get('children_ids', [])) == 0])}ê°œ")
        print(f"   - ìƒì„±ëœ íŒŒì¼:")
        print(f"     â€¢ {nodes_json_path}")
        print(f"     â€¢ {content_nodes_path}")
        print(f"     â€¢ {docs_dir}/ (ê° ë…¸ë“œë³„ info.md íŒŒì¼)")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='ë…¸ë“œ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì™„ì „í•œ ë…¸ë“œ êµ¬ì¡° ë° ë¬¸ì„œë¥¼ ìƒì„±',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python comprehensive_node_processor.py document.md
  python comprehensive_node_processor.py nodes.json -o ./output
  python comprehensive_node_processor.py script_structure.json --output-dir ./processed
        """
    )
    
    parser.add_argument('input_file', help='ì…ë ¥ íŒŒì¼ (JSON ë…¸ë“œ íŒŒì¼ ë˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼)')
    parser.add_argument('-o', '--output-dir', default='.', help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬)')
    parser.add_argument('-v', '--verbose', action='store_true', help='ìƒì„¸ ì¶œë ¥')
    
    args = parser.parse_args()
    
    # ì²˜ë¦¬ ì‹¤í–‰
    success = process_nodes_comprehensive(args.input_file, args.output_dir)
    
    if success:
        print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return 0
    else:
        print("\nğŸ’¥ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return 1

if __name__ == "__main__":
    exit(main())